\documentclass[a4paper]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\selectlanguage{italian}
\usepackage[table]{xcolor}
\usepackage{xcolor}
\usepackage{circuitikz}
\usetikzlibrary{positioning, circuits.logic.US}
\usetikzlibrary {shapes.gates.logic.US, shapes.gates.logic.IEC, calc}
\tikzset {branch/.style={fill, shape = circle, minimum size = 3pt, inner sep = 0pt}}
\usetikzlibrary{matrix,calc}
\usepackage{multirow}
\usepackage{float}
\usepackage{geometry}
\usepackage{tabularx}
\usepackage{pgf-pie}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color, soul}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{subfig}
\graphicspath{ {./img/} }
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corollario}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

% Specifiche
\geometry{
 a4paper,
 top=20mm,
 left=30mm,
 right=30mm,
 bottom=30mm
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LO]{\nouppercase{\leftmark}}
\fancyfoot[CE, CO]{\thepage}
\addtolength{\headheight}{1em}
\addtolength{\footskip}{-0.5em}

\newcommand{\quotes}[1]{``#1''}
\renewcommand\tabularxcolumn[1]{>{\vspace{\fill}}m{#1}<{\vspace{\fill}}}
\renewcommand\arraystretch{}
\newcolumntype{P}{>{\centering\arraybackslash}X}

\title{\textbf{Universit√† di Trieste\\ \vspace{1em}
Laurea in ingegneria elettronica e informatica}}
\author{Enrico Piccin - Corso di Fondamenti di informatica - Prof. Francesco Fabris}
\date{Anno Accademico 2021/2022 - 27 Settembre 2021}

%isolated term
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - node
%#3 - filling color
\newcommand{\implicantsol}[3][0]{
    \draw[rounded corners=3pt, fill=#3, opacity=0.3] ($(#2.north west)+(135:#1)$) rectangle ($(#2.south east)+(-45:#1)$);
    }


%internal group
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - top left node
%#3 - bottom right node
%#4 - filling color
\newcommand{\implicant}[4][0]{
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(#2.north west)+(135:#1)$) rectangle ($(#3.south east)+(-45:#1)$);
    }

%group lateral borders
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - top left node
%#3 - bottom right node
%#4 - filling color
\newcommand{\implicantcostats}[4][0]{
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(rf.east |- #2.north)+(90:#1)$)-| ($(#2.east)+(0:#1)$) |- ($(rf.east |- #3.south)+(-90:#1)$);
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(cf.west |- #2.north)+(90:#1)$) -| ($(#3.west)+(180:#1)$) |- ($(cf.west |- #3.south)+(-90:#1)$);
}

%group top-bottom borders
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - top left node
%#3 - bottom right node
%#4 - filling color
\newcommand{\implicantdaltbaix}[4][0]{
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(cf.south -| #2.west)+(180:#1)$) |- ($(#2.south)+(-90:#1)$) -| ($(cf.south -| #3.east)+(0:#1)$);
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(rf.north -| #2.west)+(180:#1)$) |- ($(#3.north)+(90:#1)$) -| ($(rf.north -| #3.east)+(0:#1)$);
}

%group corners
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - filling color
\newcommand{\implicantcantons}[2][0]{
    \draw[rounded corners=3pt, opacity=.3] ($(rf.east |- 0.south)+(-90:#1)$) -| ($(0.east |- cf.south)+(0:#1)$);
    \draw[rounded corners=3pt, opacity=.3] ($(rf.east |- 8.north)+(90:#1)$) -| ($(8.east |- rf.north)+(0:#1)$);
    \draw[rounded corners=3pt, opacity=.3] ($(cf.west |- 2.south)+(-90:#1)$) -| ($(2.west |- cf.south)+(180:#1)$);
    \draw[rounded corners=3pt, opacity=.3] ($(cf.west |- 10.north)+(90:#1)$) -| ($(10.west |- rf.north)+(180:#1)$);
    \fill[rounded corners=3pt, fill=#2, opacity=.3] ($(rf.east |- 0.south)+(-90:#1)$) -|  ($(0.east |- cf.south)+(0:#1)$) [sharp corners] ($(rf.east |- 0.south)+(-90:#1)$) |-  ($(0.east |- cf.south)+(0:#1)$) ;
    \fill[rounded corners=3pt, fill=#2, opacity=.3] ($(rf.east |- 8.north)+(90:#1)$) -| ($(8.east |- rf.north)+(0:#1)$) [sharp corners] ($(rf.east |- 8.north)+(90:#1)$) |- ($(8.east |- rf.north)+(0:#1)$) ;
    \fill[rounded corners=3pt, fill=#2, opacity=.3] ($(cf.west |- 2.south)+(-90:#1)$) -| ($(2.west |- cf.south)+(180:#1)$) [sharp corners]($(cf.west |- 2.south)+(-90:#1)$) |- ($(2.west |- cf.south)+(180:#1)$) ;
    \fill[rounded corners=3pt, fill=#2, opacity=.3] ($(cf.west |- 10.north)+(90:#1)$) -| ($(10.west |- rf.north)+(180:#1)$) [sharp corners] ($(cf.west |- 10.north)+(90:#1)$) |- ($(10.west |- rf.north)+(180:#1)$) ;
}

%Empty Karnaugh map 4x4
\newenvironment{Karnaugh}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (4,4);
\draw (0,4) -- node [pos=0.7,above right,anchor=south west] {$xy$} node [pos=0.7,below left,anchor=north east] {$zw$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=8.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                       \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $00$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $01$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(r11)| $11$             \& |(12)| \phantom{0} \& |(13)| \phantom{0} \& |(15)| \phantom{0} \& |(14)| \phantom{0} \&                     \\
|(r10)| $10$             \& |(8)|  \phantom{0} \& |(9)|  \phantom{0} \& |(11)| \phantom{0} \& |(10)| \phantom{0} \&                     \\
|(rf) | \phantom{00}   \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 4x4
\newenvironment{KarnaughExample}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
  \node[](start) at (2.55,-1.65){};
  \node[above=of start]() {
    \begin{tikzpicture}[scale=1.1, every node/.style={scale=1.1}]
      \draw (0,0) grid (4,4);
    \end{tikzpicture}
  };
\draw (-0.2,5.4) -- node [pos=0.7,above right,anchor=south west] {$xy$} node [pos=0.7,below left,anchor=north east] {$zw$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={1.1cm,between origins},
        row sep={1.1cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=8.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                       \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $00$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $01$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(r11)| $11$             \& |(12)| \phantom{0} \& |(13)| \phantom{0} \& |(15)| \phantom{0} \& |(14)| \phantom{0} \&                     \\
|(r10)| $10$             \& |(8)|  \phantom{0} \& |(9)|  \phantom{0} \& |(11)| \phantom{0} \& |(10)| \phantom{0} \&                     \\
|(rf) | \phantom{00}   \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 4x4
\newenvironment{KarnaughFunction}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (4,4);
\draw (0,4) -- node [pos=0.9,above right,anchor=south west] {$x_0x_1$} node [pos=0.7,below left,anchor=north east] {$x_2x_3$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=8.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                       \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $00$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $01$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(r11)| $11$             \& |(12)| \phantom{0} \& |(13)| \phantom{0} \& |(15)| \phantom{0} \& |(14)| \phantom{0} \&                     \\
|(r10)| $10$             \& |(8)|  \phantom{0} \& |(9)|  \phantom{0} \& |(11)| \phantom{0} \& |(10)| \phantom{0} \&                     \\
|(rf) | \phantom{00}   \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 4x4
\newenvironment{KarnaughSemplification}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
  \node[](start) at (2.55,-1.65){};
  \node[above=of start]() {
    \begin{tikzpicture}[scale=1.1, every node/.style={scale=1.1}]
      \draw (0,0) grid (4,4);
    \end{tikzpicture}
  };
\draw (-0.2,5.4) -- node [pos=0.9,above right,anchor=south west] {$x_1x_2$} node [pos=0.7,below left,anchor=north east] {$x_3x_4$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={1.1cm,between origins},
        row sep={1.1cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=8.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                       \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $00$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $01$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(r11)| $11$             \& |(12)| \phantom{0} \& |(13)| \phantom{0} \& |(15)| \phantom{0} \& |(14)| \phantom{0} \&                     \\
|(r10)| $10$             \& |(8)|  \phantom{0} \& |(9)|  \phantom{0} \& |(11)| \phantom{0} \& |(10)| \phantom{0} \&                     \\
|(rf) | \phantom{00}   \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 2x4
\newenvironment{Karnaughvuit}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (4,2);
\draw (0,2) -- node [pos=0.7,above right,anchor=south west] {$xy$} node [pos=0.7,below left,anchor=north east] {$z$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=4.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                      \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $0$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $1$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(rf) | \phantom{00}  \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 2x4
\newenvironment{KarnaughvuitPhi}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (4,2);
\draw (0,2) -- node [pos=0.9,above right,anchor=south west] {$\phi_1\phi_2$} node [pos=0.7,below left,anchor=north east] {$\phi_3$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=4.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                      \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $0$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $1$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(rf) | \phantom{00}  \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 2x4
\newenvironment{KarnaughvuitFunction}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (4,2);
\draw (0,2) -- node [pos=0.9,above right,anchor=south west] {$x_2 x_1$} node [pos=0.7,below left,anchor=north east] {$x_0$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=4.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                      \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $0$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $1$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(rf) | \phantom{00}  \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 2x2
\newenvironment{Karnaughquatre}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (2,2);
\draw (0,2) -- node [pos=0.7,above right,anchor=south west] {$x$} node [pos=0.7,below left,anchor=north east] {$y$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=2.center,
        ampersand replacement=\&] at (0.5,0.5)
{
          \& |(c00)| $0$          \& |(c01)| $1$  \\
|(r00)| $0$ \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \\
|(r01)| $1$ \& |(2)|  \phantom{0} \& |(3)|  \phantom{0} \\
};
}%
{
\end{tikzpicture}
}

%Defines 8 or 16 values (0,1,X)
\newcommand{\contingut}[1]{%
\foreach \x [count=\xi from 0]  in {#1}
     \path (\xi) node {$\x$};
}

%Places 1 in listed positions
\newcommand{\minterms}[1]{%
    \foreach \x in {#1}
        \path (\x) node {1};
}

%Places 0 in listed positions
\newcommand{\maxterms}[1]{%
    \foreach \x in {#1}
        \path (\x) node {0};
}

%Places X in listed positions
\newcommand{\indeterminats}[1]{%
    \foreach \x in {#1}
        \path (\x) node {X};
}

\begin{document}

\vspace{-10mm}
\maketitle

\tableofcontents
\newpage

\section{Analogico e digitale}

\subsection{Analogico}
Un \textbf{segnale analogico} √® un segnale (tipicamente di natura elettrica) che segue in modo analogo l'andamento di una grandezza di riferimento (una grandezza fisica).\\ Pertanto varia in modo continuo (con continuit√†) nel tempo (senza interrruzioni) e ha caratteristiche analoghe alla grandezza di riferimento.\\
Per trasformare un segnale analogico in uno digitale √® necessario impiegare un \textbf{trasduttore}, come per convertire un segnale di variazione (come la temperatura) in un segnale elettrico.

\subsection{Digitale}
Un \textbf{segnale digitale} (o \textbf{discreto}) viene espresso attraverso una sequenza di \textbf{simboli} di un \textbf{alfabeto finito}.\\
Un modo per rappresentare un segnale digitale composto da \(0\) e \(1\) √® quello di associare un valore di tensione al valore \(1\) e uno al valore \(0\), assicurandosi che siano ben distinti e identificabili.\\
L'\textbf{ordine di un alfabeto} costituisce il numero di simboli che si possono impiegare per rappresentare un segnale digitale.

\vspace{1em}
\noindent
\textbf{Osservazione}: Negli ultimi 30-40 anni si √® assistito a un passaggio
graduale dai sistemi analogici ai sistemi digitali. √à possibile, infatti, codificare un segnale analogico mediante un segnale digitale, attraverso la tecnica del campionamento.

\subsection{Teorema del campionamento}
Per trasformare un segnale analogico in uno digitale √® necessario campionare il segnale, ovvero rilevare il valore del segnale analogico ad intervalli di tempo regolari. La frequenza con cui avvengono i campionamenti prende il nome di \textbf{frequenza di campionamento}. Tanto pi√π alta sar√† la frequenza di campionamento tanto maggiore sar√† la precisione di rappresentazione digitale del segnale analogico corrispondente.\\
Dopo aver ottenuto la successione di valori di campionamento √® possibile ricostruire il segnale analogico per mezzo di quello digitale.\\
Se la \textbf{frequenza di campionamento} √® stata sufficientemente alta, ovvero
\[f_c > 2 \cdot B\]
\textbf{maggiore del doppio della larghezza di banda del segnale analogico originario}, allora √® possibile ricostruire il segnale senza ambiguit√†.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che la \textbf{larghezza di banda} di un segnale √® l'\textbf{insieme delle frequenze} di cui √® composto il segnale. Non solo, ma il segnale analogico che si otterr√† attraverso la trasformazione inversa (digitale - analogico), a seguito di un precedente campionamento, sar√† indistinguibile dal segnale analogico di partenza se la frequenza adottata corrisponde a quella di Nyquist.

\vspace{1em}
\noindent
\textbf{Osservazione}: Per la rappresentazione di un segnale \textbf{ad alta fedelt√†} √® necessario avere una larghezza di banda maggiore, dai \(20\)Hz ai \(22\)KHz. Mentre per una normale conversazione telefonica √® necessaria una larghezza di banda dai \(300\)Hz ai \(3400\)Hz.\\
L'elettronica che gestisce i segnali digitali √® molto pi√π conveniente rispetto a quella impiegata per gestire i segnali analogici.

\subsection{Rumore}
Nei sistemi reali, al segnale analogico si sovrappone sempre un segnale di \textbf{rumore} (ovvero tutto ci√≤ che \textbf{non √® segnale}). Nel caso dei circuiti elettronici chiusi, secondo la legge di \textbf{Lenz}, ogni variazione di campo elettromagnetico √® rumore per il segnale elettrico del circuito stesso.\\
Il pi√π comune dei rumori √® quello \textbf{termico}: l'agitazione delle particelle atomiche dovuta al calore induce del rumore.\\
I rumori elettromagnetici possono essere risolti ponendo il circuito interessato all'interno di uno schermo chiuso conduttore, ovvero la \textbf{gabbia di Faraday}: √® quello che accade negli ospedali all'interno delle stanze di misurazione molto precisa, come la T.A.C..\\
Il rumore termico, invece, √® molto difficile da arginare, in quanto non si ha sempre la disponibilit√† (fatta eccezione per casi particolari) di lavorare a \(-273,15 ^\circ\)C, ovvero in corrispondenza dello \textbf{\(0\) assoluto}.\\
Tuttavia, quando un segnale analogico viene \textbf{inquinato} dal rumore, √® impossibile eliminare a questo stadio tale inquinamento; infatti, l'inquinamento da rumore √® un fenomeno che presenta un carattere di \textbf{irreversibilit√†} nei segnali analogici.\\
L'unico modo per poter arginare il problema dell'inquinamento da rumore √® quello di aumentare il \textbf{rapporto segnale-disturbo}. Pertanto, si dovr√† lavorare con segnale pi√π consistenti, anche se questo determina sempre un aumento della complessit√† (e del costo) della circuiteria a disposizione.

\subsubsection{Rumore nei segnali digitali}
Se si usano i segnali digitali, il segnale pu√≤ essere ricostruito in modo perfetto, anche se √® stato inquinato dal rumore (a meno che il segnale di rumore non sia troppo forte).\\
Infatti, nel mondo digitale, l'inquinamento da rumore non √® irreversibile. Nel caso di una onda quadra inquinata da rumore, per esempio, calcolando la media delle variazioni del segnale determinate dal rumore, se essa √® superiore o inferiore ad un certo valore si pu√≤ discernere se codificare il segnale come \(0\), oppure \(1\).\\
La percezione del rumore, quindi, nei segnali digitali √® diversa rispetto a quella dei segnali analogici. Infatti, a differenza dei \textbf{segnali analogici}, in cui \textbf{il rumore si sovrapponeva costantemente a tutto il segnale}, alterandolo in maniera irreversibile, \textbf{nei sistemi digitali √® sempre possibile ricostruire il segnale originario}, con l'aggiunta di una probabilit√† pi√π o meno elevata di incorrere in un errore di codifica (risolvibile con algoritmi correttori): taluno costituisce un primo grande vantaggio dei sistemi digitali.

\subsection{L'importanza dell'alfabeto binario}
Tutti gli alfabeti con cui operano i sistemi digitali hanno \textbf{ordine 2}. Questo per due motivi:
\begin{enumerate}
    \item Da un punto di vista concettuale, esiste l'\textbf{algebra booleana} estremamente efficiente e performante.
    \item Da un punto di vista tecnico-pratico, se si dovesse operare con alfabeti con ordine maggiore di \(2\), aumenterebbe rovinosamente la \textbf{temperatura di esercizio} dei sistemi digitali. Infatti, nei circuiti elettronici sono presenti elementi attivi e passivi.\\
    Gli elementi passivi (che seguono le consuete regole dell'elettronica) sono
    \begin{itemize}
        \item \textbf{resistenze}
        \item \textbf{induttanze}
        \item \textbf{capacit√†}
    \end{itemize}
    Mentre gli elementi attivi sono i \textbf{transistors}, i quali vengono integrati in piccolissime piastrine di silicio. Le loro caratteristiche sono completamente diverse rispetto a quelle degli elementi passivi. La ragione dell'ordine binario degli alfabeti di codifica dei sistemi digitali √® da ricercarsi nel funzionamento del transistor.

    \def\CalcC#1{
    \coordinate (base) at (#1.B);
    \coordinate (collector) at (#1.C);
    \coordinate (emitter) at (#1.E);
    \draw (barycentric cs:base=0.32,collector=0.5,emitter=0.5) circle [radius=14pt];
    }

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
            \begin{circuitikz}
                \draw (0,0) node[npn] (name) {}
                (name.base) node[anchor=east] {B}
                (name.collector) node[anchor=south] {C}
                (name.emitter) node[anchor=north] {E};
                \CalcC{name}
            \end{circuitikz}
        \caption{Transistor}
        \label{fig:transistor}
    \end{figure}


    Questo componente elettronico attivo √® un dispositivo che comanda un flusso di corrente tra \textbf{collettore} ed \textbf{emettitore} attraverso un elettrodo che prende il nome di \textbf{base}. Se la corrente di base √® pressoch√© nulla, allora si ha una \textbf{interdizione} (non passa corrente), mentre se la corrente di base √® significativamente maggiore di \(0\), allora si ha \textbf{conduzione piena (o saturazione)}.\\
    Pertanto, un transistor, in un dato istante, si pu√≤ trovare solamente in uno di due stati:
    \begin{itemize}
        \item Se la corrente √® massima e la tensione √® nulla (\textbf{saturazione}) si ottiene il valore logico \(0\).

        % Contenitore per immagini
        \noindent
        \begin{figure}[H]
            \centering
                \begin{circuitikz}
                    \draw[line width=0.6pt,black,-stealth](-1.5,1.2)--(-1.5,-1.2) node[anchor=north west]{};
                    \filldraw[black] (-2.4,0.2) circle (0pt) node[anchor=north] {$I = max$};

                    \draw[line width=0.6pt,black,-stealth](1,-1.2)--(1,1.2) node[anchor=north west]{};
                    \filldraw[black] (1.8,0.2) circle (0pt) node[anchor=north] {$V = 0$};

                    \draw (0,0) node[npn] (name) {}
                    (name.base) node[anchor=east] {B}
                    (name.collector) node[anchor=south] {C}
                    (name.emitter) node[anchor=north] {E};
                    \CalcC{name}
                \end{circuitikz}
            \caption{Transistor in saturazione}
            \label{fig:transistor}
        \end{figure}

        \item Se la corrente √® nulla e la tensione √® massima (\textbf{interdizione})  si ottiene il valore logico \(1\).

        % Contenitore per immagini
        \noindent
        \begin{figure}[H]
            \centering
                \hspace{2.3em}
                \begin{circuitikz}
                    \draw[line width=0.6pt,black,-stealth](-1.5,1.2)--(-1.5,-1.2) node[anchor=north west]{};
                    \filldraw[black] (-2.2,0.2) circle (0pt) node[anchor=north] {$I = 0$};

                    \draw[line width=0.6pt,black,-stealth](1,-1.2)--(1,1.2) node[anchor=north west]{};
                    \filldraw[black] (2,0.2) circle (0pt) node[anchor=north] {$V = max$};

                    \draw (0,0) node[npn] (name) {}
                    (name.base) node[anchor=east] {B}
                    (name.collector) node[anchor=south] {C}
                    (name.emitter) node[anchor=north] {E};
                    \CalcC{name}
                \end{circuitikz}
            \caption{Transistor in saturazione}
            \label{fig:transistor}
        \end{figure}

    \end{itemize}
    La temperatura di esercizio viene determinata dalla seguente formula:
    \[P = V \cdot I\]
    per cui se il transistor √® in saturazione, la corrente √® massima e la tensione √® nulla, quindi la potenza √® nulla. Mentre se il transistor √® in interdizione, la corrente √® nulla e la tensione √® massima, quindi la potenza √® ancora una volta nulla.\\
    Per cui la potenza dissipata dai transistors √® sempre nulla in questi due stati, ma assume un valore non nullo nel passaggio dall'uno all'altro stato.\\
    A queste potenze deve aggiungersi anche la dissipazione di calore delle resistenze, che pu√≤ essere variabile.\\
    Se si aggiungesse un terzo stato logico, ad esso bisognerebbe attribuire un valore di tensione e uno di corrente, necessariamente diversi da \(0\), per cui anche la potenza dissipata sar√† diversa da \(0\) e questo aumenterebbe la temperatura di esercizio.\\
    Ci√≤ accadrebbe per ogni stato logico diverso dai due del sistema binario che si aggiungerebbe se si avesse un alfabeto di codifica di ordine \(> 2\). E la dissipazione, per quanto piccola, deve essere moltiplicata per il numero di transistors che si trovano in questo ipotetico stato che, in un moderno chip, sono \textbf{miliardi}: pertanto la dissipazione di calore non sarebbe trascurabile.
\end{enumerate}

\subsection{Vantaggi sistemi digitali}
Come si √® potuto appurare, vi sono molti vantaggi nell'adottare sistemi digitali in luogo di quelli analogici:
\begin{enumerate}
    \item Minor sollecitazione al rumore
    \item Maggior affidabilit√† (arginando la \textbf{deriva termica})
    \item Presenza dell'algebra booleana
    \item Minori dissipazioni di potenza
\end{enumerate}
I dispositivi analogici, invece, lavorano con la dissipazione di potenza, sempre ed in ogni stato; questo costituisce un problema, in quanto dissipazione di potenza significa scaldare per \textbf{effetto Joule}. Se la temperatura si innalza eccessivamente (\textbf{deriva termica}) il componente (transistor) si brucia.\\
Ci√≤ non accade (o accade molto raramente) nella circuiteria digitale, in quanto i dispositivi attivi dei circuiti non dissipano potenza a riposo.

\newpage
\begin{center}
    5 Ottobre 2021
\end{center}

\subsection{Riassunto}
Ci sono due diversi sistemi in utilizzo al giorno d'oggi, analogico e digitale, anche se negli ultimi \(40\) anni si √® progressivamente passati dai sistemi analogici a quelli digitali.\\
√à possibile passare da un segnale analogico ad uno digitale attraverso la tecnica del campionamento. Il teorema di campionamento afferma che se la frequenza di campionamento √® almeno doppia della larghezza di banda del segnale da campionare, allora il segnale digitale risultante sar√† indistinguibile da quello originario.\\
Il segnale di rumore, inoltre, √® sempre presente nei sistemi reali, e si sovrappone in maniera inevitabile al segnale di partenza, inquinandolo; per cercare di far fronte a tale problema bisogna aumentare il rapporto \textbf{segnale-rumore}.\\
Nei sistemi digitali, invece, il segnale di rumore non altera il valore del segnale di partenza, ma pu√≤ indurre a degli errori di ricostruzione (che possono essere risolti con dei sistemi di correzione degli errori).\\
I motivi per cui i sistemi digitali sono basati su una logica binaria sono svariati:
\begin{enumerate}
    \item La presenza e l'efficienza dell'algebra booleana;
    \item Migliore affidabilit√†, in quanto meno soggetti alla deriva termica, in quanto presentano una dissipazione nulla a riposo;
    \item Meno soggetti al segnale di rumore e maggiore facilit√† di ricostruzione del segnale;
    \item Nei sistemi elettronici sono presenti dispositivi passivi e attivi, ovvero i transistors, i quali non dissipano potenza a riposo, proprio perch√© a riposo si possono trovare in due soli stati, in cui la corrente √® massima e la tensione √® nulla, oppure la corrente √® nulla e la tensione √® massima.\\
    Se si avesse un terzo stato logico, infatti, il transistor che si trovasse su quello stato dissiperebbe potenza a riposo, per cui ammettendo che anche solo \(\frac{1}{3}\) dei transistor totali si trovi su questo stato, la dissipazione di calore sarebbe considerevole e non trascurabile: pertanto, si necessiterebbe di sistemi di raffreddamento molto costosi per un corretto funzionamento del sistema.\\
    Nei circuiti analogici (come gli amplificatori) i transistors devono essere polarizzati e quindi presentano una corrente di base tale da dissipare potenza anche a riposo e questo determina un aumento della temperatura di esercizio.\\
    Nei transistors, infatti, √® presente una corrente di base chiamata \textbf{corrente di deriva termica \(I_{C_{v_{0}}}\)} che tende ad aumentare esponenzialmente all'aumentare della temperatura di esercizio; aumentando la corrente, aumenta la dissapazione e ci√≤ alla \textbf{deriva termica}, e quindi alla rottura del transistors.
\end{enumerate}

\newpage
\section{Algebra booleana}
Tutta la tecnologia elettronica fa uso dell'algebra booleana che, grazie agli studi di Shannon, √® stato dimostrato essere fondamentale nella progettazione digitale.\\
L'ideazione dell'algebra booleana √® da attribuire a \textbf{George Boole}, ovvero un logico, mentre essa verr√† proficuamente impiegata, come anticipato, da \textbf{Claude Elwood Shannon} per la prima volta come strumento per la progettazione logica di circuiti composti da \textbf{rel√©}, ovvero un interruttore comandato da correnti.\\
Shannon, infatti, si accorse che l'algebra booleana poteva essere utilizzata per la gestione di una rete complessa di interrutori, tale da rendere tale operazione molto pi√π semplificata.

\subsection{Costanti booleane}
Le due costanti booleane sono \textbf{vero} e \textbf{falso}, corrispondenti ai due soli valori logici contemplati nei sistemi binari (\(0\), ovvero il valore basso di tensione, in generale) e (\(1\), ovvero il valore alto di tensione, in generale).

\subsection{Calcolo funzionale di verit√†}
Per la risoluzione di un problema logico √® necessario tenere conto di una serie di condizioni che devono essere verificate affinch√© possa essere prodotto un risultato logico (o pratico); in un problema concreto, si potrebbe pensare di disporre di una serie di sensori atti ciascuno a rilevare il valore logico di una certa proposizione.\\
L'algebra booleana viene usata, invece, per manipolare delle equazioni logiche composte da valori anch'essi di natura logica.\\
Il modo per rappresentare il valore logico di tali proposizioni √® costituito dalle \textbf{variabili binarie booleane}; il metodo che permette di manipolare tali variabili e di assegnare ad esse un valore di verit√† √® conosciuto come \textbf{calcolo funzionale di verit√†}.\\
Per ogni affermazione assertiva quale
\[\text{\quotes{La cintura di sicurezza √® allacciata}} \rightarrow B_{L}\]
si attribuisce il valore della proposizione ad una variabile booleana.\\
Per poter tenere conto della composizione di funzioni di verit√† si usano dei \textbf{connettivi logici}, come l'\textbf{and} (\(\cap\)) che produce un valore positivo se e solo se entrambe le proposizioni elementari sono vere:
\[A \cap B\]
Un altro connettivo logico √® l'\textbf{or} (\(\cup\)) che produce un valore positivo se almeno una delle due proposizioni elementari √® vera:
\[A \cup B\]
Il modo per ottenere il risultato logico di una funzione composta di verit√† √® rappresentato dalle tabelle di verit√†.

\subsection{Tavole di verit√†}
Di seguito la tavola di verit√† dei principali connettivi:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{>{\hsize=0.01\textwidth}PP|PPPPPP}
         $ $ & $ $ & $\text{AND}$ & $\text{OR}$ & $\text{XOR}$ & $\text{XNOR}$ & $\text{NOR}$ & $\text{NAND}$\\
         $A$ & $B$ & $A \cap B$ & $A \cup B$ & $A \oplus B$ & $A \equiv B$ & $A \downarrow B$ & $A \vert B$\\
         \hline
         $F$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$\\
         $F$ & $V$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$\\
         $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$\\
         $V$ & $V$ & $V$ & $V$ & $F$ & $V$ & $F$ & $F$\\
    \end{tabularx}
    \caption{Tavola di verit√† dei principali connettivi}
    \label{tab:tavola_verit√†_connettivi}
\end{table}

\vspace{1em}
\noindent
I primi quattro connettivi logici sono molto comuni, mentre gli ultimi due sono fondamentali, perch√© sono in grado di ricostruire ciascuna delle \(2^4 = 16\) possibili combinazioni di \(V\) e \(F\).\\
Si tenga presente che ciascun connettivo logico presenta un suo corrispettivo, chiamato \textbf{porta logica}. Pertanto, con le porte logiche \textbf{NOR} e \textbf{NAND} (le cui funzioni booleane associate sono le ultime due della Tabella \ref{tab:tavola_verit√†_connettivi}) √® possibile costruire qualunque funzione logica.\\
L'equazione logica si ottiene combinando fra di loro tutte le variabili logiche prese in considerazione attraverso i connettivi logici, pertanto:
\[C \equiv A \cap G \cap \left[\left(S_L \cap \overline{B_L}\right) \cup \left(S_R \cap \overline{B_R} \right) \right]\]
Per costruire tutte le possibili combinazioni di \(V\) e \(F\) su \(4\) posti basta eseguire un semplice calcolo
\[2^4 = 16\]
Infatti, in generale, se si dispone di \(n\) bit il numero delle possibili \(n\)-ple binarie √® pari a \[2^n\]

\subsection{Connettivi binari}
Nella Tabella \ref{tab:tavola_verit√†_connettivi} sono stati individuati sei connettivi logici, AND, OR, XOR e XNOR, NOR e NAND, che sono i pi√π interessanti. Poich√© per ciascuna coppia di valori delle variabili ci sono due possibilit√†, come si √® detto vi sono \(4\) righe, e quindi \(2^4 = 16\) connettivi logici, come illustrato di seguito:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{>{\hsize=0.01\textwidth}PP|PPPPPPPP>{\hsize=0.035\textwidth}PPPPPPPP}
         $ $ & $ $ & $0$ & $1$ & $2$ & $3$ & $4$ & $5$ & $6$ & $7$ & $8$ & $9$ & $10$ & $11$ & $12$ & $13$ & $14$ & $15$\\
         \hline
         $ $ & $ $ & $ $ & $\hspace{-0.7em} \text{AND}$ & $ $ & $ $ & $ $ & $ $ & $\hspace{-0.75em} \text{XOR}$ & $\hspace{-0.45em}  \text{OR}$ & $\hspace{-0.5em} \text{NOR}$ & $\hspace{-1em} \text{XNOR}$ & $ $ & $ $ & $ $ & $ $ & $\hspace{-0.75em} \text{NAND}$ & $ $\\
         $A$ & $B$ & $ $ & $\cap$ & $ $ & $ $ & $ $ & $ $ & $\oplus$ & $\cup$ & $\downarrow$ & $\equiv$ & $ $ & $\subset$ & $ $ & $\supset$ & $\hspace{0.4em} \vert$ & $ $\\
         \hline
         $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$\\
         $F$ & $V$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$\\
         $V$ & $F$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$\\
         $V$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$\\
    \end{tabularx}
    \caption{Tavola di verit√† dei $16$ connettivi binari}
    \label{tab:tavola_verit√†_connettivi_binari}
\end{table}

\noindent
Due ulteriori connettivi logici sono quelli di implicazione \(A \subset B\) e \(A \supset B\) (ovvero B implica A e A implica B).\\
Si noti che
\[A \equiv B \leftrightarrow A \supset B \text{ e } A \subset B\]
ovvero
\[(A \equiv B) \equiv (A \supset B) \cap (A \subset B)\]
e si pu√≤ verificare attraverso le tabelle di verit√†.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{2}
    \begin{tabularx}{\textwidth}{cc||P|P|P|c}
         $A$ & $B$ & $A \supset B$ & $A \subset B$ & $(A \supset B) \cap (A \subset B)$ & $A \equiv B $\\
         \hline
         $F$ & $F$ & $V$ & $V$ & $V$ & $V$\\
         $F$ & $V$ & $V$ & $F$ & $F$ & $F$\\
         $V$ & $F$ & $F$ & $V$ & $F$ & $F$\\
         $V$ & $V$ & $V$ & $V$ & $V$ & $V$\\
    \end{tabularx}
    \caption{Tabella di verit√† dell'implicazione}
    \label{tab:tabella_verit√†_implicazione}
\end{table}

\subsection{Insiemi minimi di connettivi}
Come si √® visto nella Tabella \ref{tab:tabella_verit√†_implicazione}, alcuni connettivi binari possono essere espressi sulla base di altri connettivi; in questo caso la XNOR viene espressa in funzione di \(\supset\), \(\subset\) e \(\cap\).\\
Si presenta quindi spontanea la domanda di quali siano i connettivi idonei a esprimere tutti gli altri, e quale sia l‚Äôinsieme minimo tra essi che permette di esprimere tutte le \(16\) combinazioni della Tabella \ref{tab:tavola_verit√†_connettivi_binari}.\\
Si consideri, ad esempio, l‚Äôinsieme dei connettivi che contiene solo \(\cup\) e \(\cap\), ovvero OR e AND. I casi in cui sia A che B sono falsi sono chiaramente situazioni critiche; infatti dalla Tabella \ref{tab:tavola_verit√†_connettivi} si osserva che sia \(A \cup B\) che \(A \cap B\) sono ambedue falsi; quindi, sulla base di questi due soli connettivi, non e possibile esprimere connettivi che assumono valore vero quando A e B sono falsi.\\
Per poter esprimere anche questi casi, e necessario arricchire l‚Äôinsieme introducendo anche il connettivo NOT. Ecco allora che l‚Äôinsieme dei connettivi AND, OR, NOT e un insieme sufficiente per ricostruire tutti gli altri connettivi, come si pu√≤ verificare dalla tavola di verit√† in Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT}.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{2}
    \begin{tabularx}{\textwidth}{|c|l|>{\hsize=0.066\textwidth}P||c|l|>{\hsize=0.066\textwidth}P|}
    \hline
         $FFVV$ & $A$ & $ $ & $FFVV$ & $A$ & $ $\\
         $FVFV$ & $B$ & $ $ & $FVFV$ & $B$ & $ $\\
         \hline
         \hline
         $FFFF$ & $f_{0} \equiv A \cap \overline{A}$ & $ $ & $VFFF$ & $f_{8} \equiv \overline{A \cup B}$ &\text{NOR}$ $\\
         $FFFV$ & $f_{1} \equiv A \cap B $ & $\text{AND}$ & $VFFV $ & $f_{9} \equiv (A \cup \overline{B}) \cap (\overline{A} \cup B)$ & $\text{XNOR}$\\
         $FFVF$ & $f_{2} \equiv A \cap \overline{B} $ & $ $ & $VFVF $ & $\hspace{1.2em} \equiv (\overline{A} \cap \overline{B}) \cup (A \cap B)$ & $ $\\
         $FFVV$ & $f_{3} \equiv A $ & $ $ & $VFVV$ & $ f_{10} \equiv \overline{B}$ & $ $\\
         $FVFF$ & $f_{4} \equiv \overline{A} \cap B $ & $ $ & $VVFF $ & $f_{11} \equiv A \cup \overline{B}$ & $\subset$\\
         $FVFV$ & $f_{5} \equiv B $ & $ $ & $VVFV$ & $f_{12} \equiv \overline{A}$ & $ $\\
         $FVVF$ & $f_{6} \equiv (A \cap \overline{B}) \cup (\overline{A} \cap B)$ & $\text{XOR}$ & $VVVF$ & $f_{13} \equiv \overline{A} \cup B$ & $\supset$\\
         $ $ & $\hspace{1.2em} \equiv (\overline{A} \cup \overline{B}) \cap (A \cup B) $ & $ $ & $VVVF$ & $f_{14} \equiv \overline{A \cap B} $ & $\text{NAND}$\\
         $FVVV$ & $f_{7} \equiv A \cup B $ & $\text{OR}$ & $VVVV$ & $f_{15} \equiv A \cup \overline{A} $ & $ $\\
         \hline
    \end{tabularx}
    \caption{I \(16\) connettivi binari espressi mediante AND, OR, NOT}
    \label{tab:connettivi_espressi_con_AND_OR_NOT}
\end{table}

\noindent
\textbf{Osservazione}: \textbf{Ogni connettivo binario} si pu√≤ esprimere, pertanto, tramite combinazione di altri connettivi binari.\\
Infatti, come si √® detto, i connettivi \textbf{NAND} e \textbf{NOR} sono \textbf{connettivi universali} e quindi sono in grado di rappresentare tutti gli altri connettivi binari.\\
Si noti, infatti, come utilizzando \textbf{AND}, \textbf{OR} e \textbf{NOT} si possono costruire tutte e \(16\) le possibili funzioni logiche.

\vspace{1em}
\noindent
Quasi tutti i connettivi da \(f_0, ..., f_{15}\) possono essere costruiti usando solo il connettivo \(\cup\) oppure solo il connettivo \(\cap\) (con l‚Äôeventuale negazione). L‚Äôunica eccezione √® costituita dai connettivi \(f_6\) ed \(f_9\), che necessitano l‚Äôimpiego contemporaneo di \(\cup\) e \(\cap\).\\
L‚Äôespressione risolutiva per la \(f_9\) si pu√≤ ricavare tenendo conto dell'equivalenza messa in evidenza nella Tabella \ref{tab:tabella_verit√†_implicazione} e del fatto che \(A \supset B \equiv \overline{A} \cup B\) e \(A \subset B \equiv A \cup \overline{B}\), e dunque la \(f_9 \equiv (A \cup \overline{B}) \cap (\overline{A} \cup B)\), mentre la \(f_6\) √® la sua negazione.\\
√à interessante notare, inoltre, che ci sono due modi per realizzare \(f_6\) e \(f_9\), combinando assieme \(\cup\) e \(\cap\), ma a ben guardare un po‚Äô tutti i connettivi possono essere espressi in modi alternativi: per esempio \(f_0 \equiv A \cap \overline{A}\) ma anche \(f_0 \equiv \overline{A \cup \overline{A}}\), e cos√¨ via.\\
Tutto ci√≤ deriva dalla circostanza che l‚Äôinsieme dei connettivi AND, OR, NOT non costituisce l'insieme minimo di connettivi atti ad ottenere tutti gli altri tramite combinazione dei propri elementi; il connettivo AND pu√≤, infatti, essere espresso in funzione del connettivo OR (e viceversa); a tal riguardo vale l‚Äôimportante \textbf{Teorema di De Morgan} (¬ß \ref{sec:teorema_de_morgan}).

\subsection{Teorema di De Morgan}
\label{sec:teorema_de_morgan}
Si espone di seguito il teorema di \textbf{De Morgan}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{TEOREMA DI DE MORGAN}}\\
    \parbox{\linewidth}{Si verifica che
    \[\overline{A \cup B} = \overline{A} \cap \overline{B}\]
    cos√¨ come
    \[\overline{A \cap B} = \overline{A} \cup \overline{B}\]
    \vspace{-3mm}}\\
    \hline
\end{tabularx}
\vspace{1em}

\noindent
Si pu√≤ dimostrare tale teorema attraverso il \textbf{metodo dell'induzione perfetta}, quindi compilando una tabella di verit√† per verificare l'effettiva veridicit√† dell'enunciato.

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{lr}
        {
            \noindent
            \hspace{-2.2em}
            \setlength{\tabcolsep}{6pt}
            \begin{tabularx}{0.48 \textwidth}{cc||c|c|c||P|P||}
                 $A$ & $B$ & $\overline{A}$ & $\overline{B}$ & $\overline{A} \cap \overline{B}$ & $A \cup B$ & $\overline{A \cup B}$\\
                 \hline
                 $F$ & $F$ & $V$ & $V$ & $V$ & $F$ & $V$\\
                 $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $F$\\
                 $V$ & $F$ & $F$ & $V$ & $F$ & $V$ & $F$\\
                 $V$ & $V$ & $F$ & $F$ & $F$ & $V$ & $F$\\
            \end{tabularx}
        }
        &
        {
            \noindent
            \hspace{-2.6em}
            \setlength{\tabcolsep}{6pt}
            \begin{tabularx}{0.48 \textwidth}{cc||c|c|c||P|P||}
                 $A$ & $B$ & $\overline{A}$ & $\overline{B}$ & $\overline{A} \cup \overline{B}$ & $A \cap B$ & $\overline{A \cap B}$\\
                 \hline
                 $F$ & $F$ & $V$ & $V$ & $V$ & $F$ & $V$\\
                 $F$ & $V$ & $V$ & $F$ & $V$ & $F$ & $V$\\
                 $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $V$\\
                 $V$ & $V$ & $F$ & $F$ & $F$ & $V$ & $F$\\
            \end{tabularx}
        }
    \end{tabularx}
    \caption{Dimostrazione del teorema di De Morgan con tabelle di verit√†}
    \label{tab:dimostrazione_teorema_de_morgan}
\end{table}

\vspace{1em}
\noindent
Il teorema di \textbf{De Morgan} si pu√≤ generalizzare al caso di pi√π di due variabili. Si verifica, infatti, che la negazione di un connettivo di pi√π variabili si ottiene negando ogni variabile e scambiando tra di loro i due operatori \(\cup\) e \(\cap\).\\
In termini formali si ha
\[\overline{F}(x_1, x_2, ..., x_n)[\cup, \cap]) = F(\overline{x_1}, \overline{x_2}, ..., \overline{x_n})[\cap, \cup]\]
I connettivi che legano le variabili non negate si esprimono allora come
\[A \cap B \equiv \overline{\overline{A} \cup \overline{B}} \hspace{0.5em} \text{ e } \hspace{0.5em} A \cup B \equiv \overline{\overline{A} \cap \overline{B}}\]
Poich√© l‚ÄôAND pu√≤ essere espresso in funzione di OR e NOT, quest‚Äôultimo insieme √® da solo sufficiente per coprire tutti i connettivi formulati in Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT} che sono riportati nella prima colonna della Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT_OR_NOT_AND_NOT}. Per farlo bisogna sostituire tutti i simboli \(\cap\) con l'espressione \(A \cap B \equiv \overline{\overline{A} \cup \overline{B}}\); cos√¨ facendo si ottiene la prima colonna della Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT_OR_NOT_AND_NOT}.\\
Lo stesso ragionamento pu√≤ essere fatto per l‚ÄôOR, che pu√≤ essere espresso in funzione di AND e NOT; per farlo bisogna sostituire tutti i simboli \(\cup\) con l'espressione \(A \cup B \equiv \overline{\overline{A} \cap \overline{B}}\); cos√¨ facendo si ottiene la seconda colonna della Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT_OR_NOT_AND_NOT}.

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{|P||l|l|l|}
         \hline
         $ $ & AND, OR, NOT & OR, NOT & AND, NOT\\
         \hline
         \hline
         $ $ & $f_0 \equiv A \cap \overline{A}$ & $\overline{\overline{A} \cup A}$ & $A \cap \overline{A}$\\
         AND & $f_1 \equiv A \cap B$ & $\overline{\overline{A} \cup \overline{B}}$ & $A \cap \overline{B}$\\
         $ $ & $f_2 \equiv A \cap \overline{B}$ & $\overline{\overline{A} \cup B}$ & $A \cap \overline{B}$\\
         $ $ & $f_3 \equiv A$ & $A$ & $A$\\
         $ $ & $f_4 \equiv \overline{A} \cap B$ & $\overline{A \cup \overline{B}}$ & $\overline{A} \cap B$\\
         $ $ & $f_5 \equiv B$ & $B$ & $B$\\
         XOR & $f_6 \equiv (A \cap \overline{B}) \cup (\overline{A} \cap B)$ & $\overline{(\overline{A} \cup B)} \cup \overline{(A \cup \overline{B})}$ & $\overline{\overline{(A \cap \overline{B})} \cap \overline{(\overline{A} \cap B)}}$\\
         OR & $f_7 \equiv A \cup B$ & $A \cup B$ & $\overline{\overline{A} \cap \overline{B}}$\\
         NOR & $f_8 \equiv \overline{A \cup B}$ & $\overline{A \cup B}$ & $\overline{A} \cap \overline{B}$\\
         XNOR & $f_9 \equiv (A \cup \overline{B}) \cap (\overline{A} \cup B)$ & $\overline{\overline{(A \cup \overline{B})} \cup \overline{(\overline{A} \cup B)}}$ & $\overline{(\overline{A} \cap B)} \cap \overline{(A \cap \overline{B})}$\\
         $ $ & $f_{10} \equiv \overline{B}$ & $\overline{B}$ & $\overline{B}$\\
         $\subset$ & $f_{11} \equiv A \cup \overline{B}$ & $A \cup \overline{B}$ & $\overline{\overline{A} \cap B}$\\
         $ $ & $f_{12} \equiv \overline{A}$ & $\overline{A}$ & $\overline{A}$\\
         $\supset$ & $f_{13} \equiv \overline{A} \cup B$ & $\overline{A} \cup B$ & $\overline{A \cap \overline{B}}$\\
         NAND & $f_{14} \equiv \overline{A \cap B}$ & $\overline{A} \cup \overline{B}$ & $\overline{A \cap B}$\\
         $ $ & $f_{15} \equiv A \cup \overline{A}$ & $A \cup \overline{B}$ & $\overline{\overline{A} \cap A}$\\
         \hline
    \end{tabularx}
    \caption{I 16 connettivi binari espressi rispettivamente mediante AND, OR, NOT, mediante OR, NOT e mediante AND, NOT}
    \label{tab:connettivi_espressi_con_AND_OR_NOT_OR_NOT_AND_NOT}
\end{table}

\noindent
\textbf{Osservazione}: Quindi non solo √® possibile esprimere le \(16\) possibili funzioni logiche attraverso le tre sole funzioni logiche \textbf{AND}, \textbf{OR} e \textbf{NOT}, ma addirittura √® possibile farlo solo con \textbf{AND} e \textbf{NOT} o solo con \textbf{OR} e \textbf{NOT}, grazie al teorema di \textbf{De Morgan}.

\newpage
\begin{center}
    6 Ottobre 2021
\end{center}

\subsection{Riassunto}
L'algebra booleana √® atta a gestire le combinazioni dei due valori logici VERO e FALSO, mentre i sensori sono gli strumenti pratici che vengono utilizzati per ottenere la validazione di certe condizioni logiche al fine di estrapolarne il corrispettivo valore logico.\\
La combinazione di tali condizioni avviene attraverso i connettivi logici:
\begin{itemize}
    \item AND: Produce il valore VERO se entrambe le condizioni sono vere.
    \item OR: Produce il valore VERO se almeno una delle due condizioni √® vera.
    \item XOR: che produce il valore VERO se le due condizioni hanno un diverso valore logico.
\end{itemize}
Naturalmente oltre a queste funzioni vi sono le corrispettive negazioni NAND, NOR e XNOR. Poich√© per ciascuna coppia di valori delle variabili √® possibile associare solamente due valori, ovvero VERO e FALSO, si possono avere fino a \(2^{4} = 16\) possibili combinazioni; da ci√≤ si evince che, oltre ai connettivi logici principali, ve ne sono anche degli altri che possono essere ottenuti attraverso la combinazioni dei connettivi binari noti, per i quali, al fine di verificare la corretta creazione di una nuova funzione di verit√† √® possibile utilizzare il metodo dell'induzione perfetta.\\
Per poter capire come √® possibile creare le \(16\) funzioni logiche non √® possibile procedere attraverso la combinazione delle sole funzioni AND e OR, ma deve essere utilizzato anche il NOT. Non solo, ma attraverso il teorema di \textbf{De Morgan} √® possibile anche impiegare solamente AND e NOT, oppure OR e NOT per la creazione di tutte le \(16\) possibili funzioni logiche.\\
Ancora una volta, la correttezza di quanto affermato da \textbf{De Morgan} pu√≤ essere verificata attraverso il metodo dell'\textbf{induzione perfetta}, come si √® visto in Tabella \ref{tab:dimostrazione_teorema_de_morgan}.

\subsection{Insieme minimo}
Si osservi che l‚Äôinsieme minimo che consente di rappresentare tutti i connettivi pu√≤ essere ulteriormente ridotto al solo connettivo NOR, oppure al solo connettivo NAND. Per farlo √® sufficiente esprimere AND, OR e NOT in funzione del solo NOR oppure del solo NAND. Per questo motivo i connettivi NOR e NAND sono chiamati \textbf{connettivi universali}, in quanto da soli sono in grado di creare tutti i \(16\) connettivi logici, come si vede di seguito per la porta NOR:

\begin{itemize}
    \item \(\overline{A} \equiv \overline{A \cup A} \equiv A \downarrow A\)
    \item \(A \cup B \equiv \overline{\overline{A \cup B}} \equiv \overline{A \downarrow B} \equiv (A \downarrow B) \downarrow (A \downarrow B)\)
    \item \(A \cap B \equiv \overline{\overline{A \cap B}} \equiv \overline{\overline{A} \cup \overline{B}} \equiv \overline{A} \downarrow \overline{B} \equiv (A \downarrow A) \downarrow (B \downarrow B)\)
\end{itemize}
E la stessa cosa accade anche per la porta NAND:
\begin{itemize}
    \item \(\overline{A} \equiv \overline{A \cap A} \equiv A | A\)
    \item \(A \cup B \equiv \overline{\overline{A \cup B}} \equiv \overline{\overline{A} \cap \overline{B}} \equiv \overline{A} | \overline{B} \equiv (A | A) | (B | B)\)
    \item \(A \cap B \equiv \overline{\overline{A \cap B}} \equiv \overline{A \vert B} \equiv (A | B) | (A | B)\)
\end{itemize}

\noindent
Tale risultato √® straordinario e pu√≤ avere dei risvolti molti vantaggiosi, specialmente di natura economica, in quanto √® possibile impiegare solamente una porta per realizzare un'intera rete logica.

\subsection{Impostazione assiomatica dell'algebra booleana}
Il calcolo booleano costruito in precedenza in forma puramente euristica deve essere rielaborato in forma pi√π rigorosa in modo tale da manipolare complicate espressioni logiche in maniera semiautomatica e pi√π semplificata.\\
Per la costruzione di uno strumento operativo che abbia una infrastruttura logica solida e affidabile √® necessario formulare una teoria, di tipo algebrico, che sia ben costituita dal punto di vista formale, ovvero una teoria assiomatica che si articola in una sequenza di assiomi fondamentali.\\
In generale, √® possibile affermare che gli \textbf{assiomi} siano delle \textbf{verit√† primitive, non contestabili, non dimostrabili e date una volta per tutte}.\\
A partire dalle verit√† primitive si possono costruire (attraverso la tecnica di inferenza o il principio di induzione) delle nuove verit√†, ovvero i teoremi, e la combinazione di tali strumenti costituisce una \textbf{teoria}.\\
Di seguito si espone la definizione di \textbf{Algebra Booleana}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{ALGEBRA BOOLEANA}}\\
    \parbox{\linewidth}{Un'Algebra Booleana √® un insieme \(\mathcal{B}\) caratterizzato dagli assiomi (univocamente determinati) che vengono esposti di seguito.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\subsubsection{Assioma 0 (A0) - Leggi di composizione}
Vi sono due leggi di composizione interna di-arie, denominate rispettivamente AND e OR, e una legge di composizione interna unaria, denominata NOT; tali leggi (od \quotes{operatori Booleani}) sono definite come segue:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{l|l|c|P}
         \textbf{Operatore} & \textbf{Nome} & \textbf{Simboli usati} & \textbf{che soddisfa}\\
         \hline
         AND(x, y) & congiunzione & \(x \wedge y\) \hspace{0.5em} o \hspace{0.5em} \(x \cdot y\) & \parbox{\linewidth}{\(x \cdot y = 1\) se \(x = 1, y = 1\)\\ \(x \cdot y = 0\) altrimenti}\\
         OR(x, y) & disgiunzione & \hspace{0.2em} \(x \vee y\) \hspace{0.5 em} o \hspace{0.5em} \(x + y\) & \parbox{\linewidth}{\(x + y = 0\) se \(x = 0, y = 0\)\\ \(x + y = 1\) altrimenti}\\
         NOT(x) & negazione & \(\neg x\) \hspace{1em} o \hspace{1em} \(\overline{x}\) & \parbox{\linewidth}{\(\overline{x} = 0\) se \(x = 1\) \\ \(\overline{x} = 1\) se \(x = 0\)}\\
    \end{tabularx}
    \caption{Leggi di composizione interna dell'Algebra Booleana}
    \label{tab:leggi_composizione_interna}
\end{table}

\noindent
Inoltre, per gli elementi dell'insieme \(\mathcal{B}\) valgono i seguenti assiomi:

\subsubsection{Assioma 1 (A1) - Esistenza}
Esistono due elementi \(x, y \in \mathcal{B}\) tali che \(x \neq y\).

\subsubsection{Assioma 2 (A2) - Chiusura}
Se \(x, y \in \mathcal{B}\) allora \hspace{1em} \(x \cdot y \in \mathcal{B}\), \hspace{1em} \(x + y \in \mathcal{B}\), \hspace{1em} \(\overline{x} \in \mathcal{B}\), \hspace{1em} \(\overline{y} \in \mathcal{B}\).

\subsubsection{Assioma 3 (A3) - Elemento neutro}
Esiste un elemento neutro per la disgiunzione, indicato con \(0\), tale che
\[x + 0 = x\]
Esiste un elemento neutro per la congiunzione, indicato con \(1\), tale che
\[x \cdot 1 = x\]

\subsubsection{Assioma 4 (A4) - Commutativit√†}
\(\forall x, y \in \mathcal{B}\) valgono le seguenti relazioni:
\[x + y = y + x\]
\[x \cdot y = y \cdot x\]

\subsubsection{Assioma 5 (A5) - Associativit√†}
\(\forall x, y \in \mathcal{B}\) valgono le seguenti relazioni:
\[x + (y + z) = (x + y) + z\]
\[x \cdot (y \cdot z) = (x \cdot y) \cdot z\]

\subsubsection{Assioma 6 (A6) - Distributivit√†}
\(\forall x, y \in \mathcal{B}\) valgono le seguenti relazioni:
\[x + (y \cdot z) = (x+ z) \cdot (x + z)\]
\[x \cdot (y + x) = (x \cdot y) + (x \cdot z)\]

\subsubsection{Assioma 7 (A7) - Complementariet√†}
\(\forall x \in \mathcal{B}\) vale:
\[x \cdot \overline{x} = 0\]
\[x + \overline{x} = 1\]

\vspace{1em}
\noindent
Il pi√π semplice insieme \(\mathcal{B}\) che soddisfa i postulati di cui sopra √® rappresentato dalla cosiddetta \textbf{Algebra Booleana a due elementi}, o \textbf{Algebra Binaria}, basata sugli elementi \(0\) e \(1\) e caratterizzata dalle seguenti tre leggi di composizione

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{PPP}
        {
            \setlength{\tabcolsep}{12pt}
            \renewcommand{\arraystretch}{1.7}
            \begin{tabularx}{0.22 \textwidth}{c|cc}
                \(\cdot\) & \(0\) & \(1\)\\
                \hline
                \(0\) & \(0\) & \(0\)\\
                \(1\) & \(0\) & \(1\)\\
            \end{tabularx}
        }
        &
        {
            \setlength{\tabcolsep}{12pt}
            \renewcommand{\arraystretch}{1.7}
            \begin{tabularx}{0.22 \textwidth}{c|cc}
                \(+\) & \(0\) & \(1\)\\
                \hline
                \(0\) & \(0\) & \(1\)\\
                \(1\) & \(1\) & \(1\)\\
            \end{tabularx}
        }
        &
        {
            \setlength{\tabcolsep}{12pt}
            \renewcommand{\arraystretch}{1.7}
            \begin{tabularx}{0.22 \textwidth}{c|cc}
                \(A\) & \(0\) & \(1\)\\
                \hline
                \(\overline{A}\) & \(1\) & \(0\)

            \end{tabularx}
        }\\
        AND & OR & NOT
    \end{tabularx}
    \caption{Le \(3\) leggi di composizione fondamentali}
    \label{tab:tre_leggi_composizione}
\end{table}

\noindent
L‚ÄôAlgebra Booleana a due elementi e quella impiegata per la progettazione delle reti logiche; i suoi due elementi \(1\) e \(0\) corrispondono alle costanti logiche VERO e FALSO (V e F) prima introdotte, e le tre leggi di composizione interna sono rispettivamente AND, OR e NOT e corrispondono ai connettivi precedentemente introdotti nelle tavole di verit√†. In questo contesto la simbologia che si usa √® per√≤ diversa; in particolare si osservi che i simboli \(+\) e \(\cdot\) nulla hanno a che vedere con gli stessi simboli usati nel contesto dell‚Äôaritmetica.\\
Un altro importante esempio di Algebra Booleana e quello derivante dalla teoria degli insiemi; si consideri un insieme \(S\) e il corrispondente insieme delle parti \(\mathcal{P}(S)\), costituito dall‚Äôinsieme di tutti i sottoinsiemi costruiti con elementi di \(S\). Allora \(\mathcal{P}(S)\) √® un'Algebra Booleana, nella quale sono definite tre leggi di composizione interna date dall‚Äôintersezione \(\cap\), dall‚Äôunione \(\cup\) e dalla complementazione tra insiemi \(\overline{A}\). L‚Äôelemento neutro per la disgiunzione, o \(0\) dell‚Äôinsieme, √® costituito dall‚Äôinsieme vuoto, mentre l‚Äôelemento neutro per la congiunzione, o \(1\) dell‚Äôinsieme, √® l‚Äôinsieme \(S\) stesso.\\
Disponendo degli operatori Booleani e agendo sugli elementi di \(\mathcal{B}\), si potrebbero ricavare infinite relazioni notevoli, dette \textbf{leggi Booleane} o \textbf{teoremi}, alcune delle quali sono gi√† state viste precedentemente con le tavole di verit√†; un esempio potrebbe essere il Teorema di De Morgan (¬ß \ref{sec:teorema_de_morgan}). Una legge Booleana √® dunque un‚Äôidentit√† tra due termini Booleani, costruiti su un insieme di variabili e sulle costanti \(0\) e \(1\) a partire dagli operatori \(\wedge\), \(\vee\), \(\neg\). Per verificare una legge √® sufficiente procedere con la cosiddetta \textbf{induzione perfetta}, che consiste nella sostituzione di tutti i possibili valori per le variabili, verificando che l‚Äôuguaglianza sia sempre soddisfatta.\\
Le leggi Booleane sono ovviamente infinite, ma poich√© l‚ÄôAlgebra Booleana √® un insieme \textbf{finitamente assiomatizzabile}, √® possibile descrivere compiutamente l‚ÄôAlgebra Booleana usando solamente un insieme finito di leggi base, che sono gli assiomi precedentemente descritti. Ci√≤ significa che partendo dagli assiomi si possono poi ricavare tutte le leggi (o teoremi) dell‚ÄôAlgebra Booleana, combinando gli assiomi e i teoremi che ne derivano in tutti i modi possibili.\\
Gli assiomi non sono soggetti a verifica, nel senso che sono \textbf{verit√† primitive} che costituiscono il punto di partenza di una teoria matematica. Essi devono inoltre essere \textbf{non contradditori} tra loro e possibilmente \textbf{indipendenti}.\
Quest‚Äôultima caratteristica √® in qualche modo legata al problema di determinare se, assegnato un insieme di assiomi, esso sia il minimo possibile o se ne esista uno pi√π piccolo.\\
Per esempio, si pu√≤ osservare che l‚Äôoperatore disgiunzione \(\cdot\), usato come operatore base nel quadro assiomatico appena analizzato, pu√≤ essere definito in funzione degli altri due operatori \(+\) e \(\neg\), come gi√† verificato nel teorema di De Morgan (¬ß \ref{sec:teorema_de_morgan}). Ecco allora che si potrebbe rimuovere tale operatore, pervenendo a un quadro assiomatico pi√π sintetico. Tale problema fu affrontato da Edward V. Huntington, che nel 1933 riusc√¨ a formulare un insieme minimo di assiomi tra loro indipendenti, che partono dai soli operatori \(+\) e \(\neg\) e che prevedono, oltre alla commutativit√† e all‚Äôassociativit√†, anche la cosiddetta equazione di Huntington:
\[\overline{(\overline{x} + y)} + \overline{(\overline{x} + \overline{y})} = x\]

\subsection{Teoremi principali dell'Algebra Booleana}
A partire dagli assiomi sopra esposti, si potrebbero ricavare tutti i possibili teoremi dell‚ÄôAlgebra Booleana; tra questi ve ne sono alcuni molto semplici e utili nella manipolazione delle formule, di seguito elencati, che sono validi sia in forma base che in forma duale:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{l|P|P}
        Teorema & \textbf{Base (a)} & \textbf{Duale (d)} \\
        \hline
        \textbf{T1 - Idempotenza} & \(x + x = x\) & \(x \cdot x = x\)\\
        \textbf{T2 - Nullifico} &\(x + 1 = 1\) & \(x \cdot 0 = 0\)\\
        \textbf{T3 - Doppia negazione} & \(\overline{\overline{x}} = x\) & $ $\\
        \textbf{T4 - Assorbimento 1} & \(x + x \cdot y = x\) & \(x \cdot (x + y) = x\)\\
        \textbf{T5 - Assorbimento 2} & \(x + \overline{x} \cdot y = x + y\) & \(x \cdot (\overline{x} + y) = x \cdot y\)\\
        \textbf{T6 - Assorbimento 3} & \(x \cdot y + \overline{x} \cdot z + y \cdot z = x \cdot y + \overline{x} \cdot z\) & \((x + y) \cdot (\overline{x} + z) \cdot (y + z) = (x + y) \cdot (\overline{x} + z)\)\\
        \textbf{T7 - De Morgan} & \(\overline{x + y} = \overline{x} \cdot \overline{y}\) & \(\overline{x \cdot y} = \overline{x} + \overline{y}\)\\
        \textbf{T8} & \(x \cdot ( x + y + z) = x\) & \(x + (x \cdot y \cdot z) = x\)\\
        \textbf{T9} & \((x + y) \cdot (\overline{x} + y) = y\) & \((x \cdot y) + (\overline{x} \cdot y) = y\)\\
        \textbf{T10} & \((x + y) \cdot (\overline{x} + z) = x \cdot z + \overline{x} \cdot y\) & \((x \cdot y) + (\overline{x} \cdot z) = (x + z) \cdot (\overline{x} + y)\)\\
    \end{tabularx}
    \caption{Teoremi principali dell'Algebra Booleana}
    \label{tab:teoremi_principali}
\end{table}

\vspace{1em}
\noindent
La dimostrazione di uno qualunque di questi teoremi pu√≤ essere fatta per induzione perfetta, che che √® la via pi√π lunga e tediosa, oppure sfruttando gli assiomi e/o i teoremi gi√† dimostrati.\\ Si considerino alcune dimostrazioni dei teoremi pi√π importanti, giacch√© i primi (da T1 a T3) sono banali, poich√© √® sufficiente operare una verifica diretta tramite \textbf{induzione perfetta}.\\
Si analizzi, invece, la dimostrazione di T4, T5 e T6, ponendo tra parentesi, subito dopo il segno di uguaglianza, l‚Äôassioma o il teorema usato. Per la dimostrazione di tali teoremi, √® possibile naturalmente ricorrere al metodo dell'\textbf{induzione perfetta}, ma quando i casi si complicano √® necessario ricorrere a dei teoremi precedentemente dimostrati:\\

\rowcolors{1}{white}{white}
\noindent
\renewcommand{\arraystretch}{1.5}
\begin{tabularx}{\textwidth}{>{\hsize=0.2\textwidth}P>{\hsize=0.001\textwidth}ll}
    \textbf{Teorema} & $ $ & \textbf{Dimostrazione} \\
    \hline
    \multirow{2}{10em}{T4 - Assorbimento 1} & Base & $x + xy \overset{(A3)}{=} x \cdot 1 + xy \overset{(A6)}{=} x \cdot (1 + y) \overset{(T2)}{=} x$\\
    & Duale & $x (x + y) \overset{(A6)}{=} xx + xy \overset{(T1)}{=} x + xy \overset{(T4.b)}{=} x$\\
    \hline
    \multirow{2}{10em}{T5 - Assorbimento 2} & Base & \parbox{\linewidth}{$x + \overline{x}y \overset{(T2)}{=} x (1 + y) + \overline{x}y \overset{(A6)}{=} x + xy + \overline{x}y \overset{(A6)}{=}$ \\ $x + (x + \overline{x})y \overset{(A7)}{=} x + y$}\\
    & Duale & $x(\overline{x} + y) \overset{(A6)}{=} x \overline{x} + xy \overset{(A7)}{=} xy$\\
    \hline
    \multirow{2}{10em}{T6 - Assorbimento 3} & Base & \parbox{\linewidth}{$xy + \overline{x}z + yz \overset{(A7)}{=} xy + \overline{x}z + yz(x + \overline{x}) \overset{(A6)}{=} xy + \overline{x}z + $ \\ $ xyz + \overline{x}yz \overset{(A6)}{=} xy(z + 1) + \overline{x}z(y + 1) \overset{(T2)}{=} xy + \overline{x}z$}\\
    & Duale & \parbox{\linewidth}{$(x + y)(\overline{x} + z)(y + z) \overset{(A7)}{=} (x + y)(\overline{x} + z)(y + z + x \overline{x}) \overset{(A6)}{=}$ \\ $(x + y)(\overline{x} + z)(y + z + x)(y + z + \overline{x}) \overset{(A4)}{=}$ \\ $(x + y)(x + y + z)(\overline{x} + z)(\overline{x} + z + y) \overset{(T4)}{=} (x + y)(\overline{x} + z)$}\\
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Il teorema dell'idempotenza viene utilizzato frequentemente, non tanto nel senso da sinistra verso destra, ma pi√π che altro per clonare una variabile ed ottenerne una identica.

\vspace{1em}
\noindent
\textbf{Dimostrazione del teorema di De Morgan}:
La verifica del \textbf{T7 - Teorema di De Morgan} basata l‚Äôinduzione perfetta, e gi√† stata effettuata nella dimostrazione nella Tabella \ref{tab:dimostrazione_teorema_de_morgan}, ma si coglie l'occasione per rinnovare l'importanza fondamentale di questo teorema, per le applicazioni e per la semplificazione delle espressioni complesse.

\subsection{Logica duale}
Se si osserva l‚Äôelenco dei teoremi di Tabella \ref{tab:teoremi_principali}, √® possibile notare che le proposizioni della colonna di destra possono essere ottenute dalla colonna centrale semplicemente scambiando \quotes{\(0\)} con \quotes{\(1\)} e \quotes{\(+\)} con \quotes{\(\cdot\)} e viceversa.
Questa √® una manifestazione del cosiddetto \textbf{Principio di dualit√†}.\\
Per comprenderlo si considerino le seguenti tabelle di verit√†, limitatamente ai valori di AND e OR, e si operi una sostituzione \quotes{\(0\)} con \quotes{\(1\)} e \quotes{\(+\)} con \quotes{\(\cdot\)}. Si ottiene

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{PP}
        {
            \begin{tabularx}{0.45 \textwidth}{cc|cc}
                 \(x\) & \(y\) & \(x + y\) & \(x \cdot y\)\\
                 \hline
                 \(0\) & \(0\) & \(0\) & \(0\)\\
                 \(0\) & \(1\) & \(1\) & \(0\)\\
                 \(1\) & \(0\) & \(1\) & \(0\)\\
                 \(1\) & \(1\) & \(1\) & \(1\)\\
            \end{tabularx}
        }
        &
        {
            \begin{tabularx}{0.45 \textwidth}{cc|cc}
                 \(x\) & \(y\) & \(x \cdot y\) & \(x + y\)\\
                 \hline
                 \(1\) & \(1\) & \(1\) & \(1\)\\
                 \(1\) & \(0\) & \(0\) & \(1\)\\
                 \(0\) & \(1\) & \(0\) & \(1\)\\
                 \(0\) & \(0\) & \(0\) & \(0\)\\
            \end{tabularx}
        }
    \end{tabularx}
    \caption{Principio di dualit√†}
    \label{tab:principio_dualita}
\end{table}

\noindent
Si pu√≤ osservare che la tavola di verit√† a che ne deriva conserva la propria validit√†, sia pur con una permutazione delle righe, del tutto ininfluente. Il principio di dualit√† consente allora di trasformare in modo duale le espressioni Booleane, realizzando nuove espressioni che continuano a valere. Si osservi tuttavia che i valori delle espressioni cos√¨ ottenute sono in generale diversi da quelle di partenza.\\
Si consideri, a tal proposito, il teorema T10: l‚Äôespressione Booleana \((x + y) \cdot (\overline{x} + z)\) ha come duale la \(x \cdot y + \overline{x} \cdot z\).

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{lr}
        {
            \setlength{\tabcolsep}{8pt}
            \begin{tabularx}{0.5 \textwidth}{ccc|c|c}
                 \(1\) & \(2\) & \(3\) & \(4\) & \(5\)\\
                 \hline
                 \(x\) & \(y\) & \(z\) & \((x + y) \cdot (\overline{x} + z)\) & \(x \cdot y + \overline{x} \cdot z\)\\
                 \hline
                 \(0\) & \(0\) & \(0\) & \(0\) & \(0\)\\
                 \(0\) & \(0\) & \(1\) & \(0\) & \(1\)\\
                 \(0\) & \(1\) & \(0\) & \(1\) & \(0\)\\
                 \(0\) & \(1\) & \(1\) & \(1\) & \(1\)\\
                 \(1\) & \(0\) & \(0\) & \(0\) & \(0\)\\
                 \(1\) & \(0\) & \(1\) & \(1\) & \(0\)\\
                 \(1\) & \(1\) & \(0\) & \(0\) & \(1\)\\
                 \(1\) & \(1\) & \(1\) & \(1\) & \(1\)\\
            \end{tabularx}
        }
        &
        {
            \setlength{\tabcolsep}{8pt}
            \begin{tabularx}{0.3 \textwidth}{ccc|c}
                 \(6\) & \(7\) & \(8\) & \(9\)\\
                 \hline
                 \(x\) & \(y\) & \(z\) & \(x \cdot y + \overline{x} \cdot z\)\\
                 \hline
                 \(0\) & \(0\) & \(0\) & \(0\)\\
                 \(0\) & \(0\) & \(1\) & \(1\)\\
                 \(0\) & \(1\) & \(0\) & \(0\)\\
                 \(0\) & \(1\) & \(1\) & \(1\)\\
                 \(1\) & \(0\) & \(0\) & \(0\)\\
                 \(1\) & \(0\) & \(1\) & \(0\)\\
                 \(1\) & \(1\) & \(0\) & \(1\)\\
                 \(1\) & \(1\) & \(1\) & \(1\)\\
            \end{tabularx}
        }
    \end{tabularx}
    \caption{Principio di dualit√† applicato all'espressione Booleana \((x + y) \cdot (\overline{x} + z)\)}
    \label{tab:principio_dualita_espressione_booleana}
\end{table}

\noindent
Nella Tabella \ref{tab:principio_dualita_espressione_booleana} sono riportati, in colonna \(4\) e \(5\), i valori di queste due espressioni duali, e come si vede sono diversi. Per verificare la validit√† del principio di dualit√† √® necessario operare una sostituzione di \quotes{\(0\)} con \quotes{\(1\)} e di \quotes{\(+\)} con \quotes{\(\cdot\)} nelle colonne \(1, 2, 3\) e nella colonna \(4\), che riporta i valori dell‚Äôespressione; cos√¨ facendo si ottengono rispettivamente le colonne \(6, 7, 8\) e \(9\).\\
Si pu√≤ verificare che a ciascuna terna delle colonne duali \(6, 7, 8\) corrisponde un valore duale di colonna \(9\) che √® esattamente il valore attribuito dall‚Äôespressione di colonna \(5\) alla stessa terna letta nelle colonne primitive \(2, 3, 4\). Per esempio, a \(011\) delle colonne \(6, 7, 8\) corrisponde \(1\) in colonna \(9\); questo √® lo stesso valore attribuito dalla colonna \(5\) alla terna \(011\) delle colonne primitive \(1, 2, 3\).

\vspace{1em}
\noindent
\textbf{Osservazione}: La logica duale √® estremamente importante e vantaggiosa, in quanto se in una espressione √® presente il \quotes{\(+\)} ed ad esso si sostituisce il \quotes{\(\cdot\)}, si ottiene una espressione ancora vera.\\
Tutto ci√≤ trova spiegazione nel fatto che il principio di dualit√† √® un fondamento base della manipolazione booleana, che permette di trasformare proposizioni vere in altre proposizioni vere, pur tenendo presente che le espressioni che si ottengono attraverso lo strumento della dualit√† sono pur sempre delle espressioni diverse da quelle di partenza.

\subsection{Variabili, funzioni Booleane e porte logiche}
Data una funzione di verit√†, √® possibile associare alla combinazione di \(n\) variabili logiche uno e un solo valore logico. Se dunque \(x_1, x_2, ..., x_n\) sono \(n\) variabili Booleane (o binarie) che possono assumere l‚Äôuno o l‚Äôaltro dei due valori possibili \(0\) e \(1\), si indica con
\[f(x_1, x_2, ..., x_n)\]
una \textbf{generica funzione Booleana} del tipo:
\[f : 2^n \rightarrow 2\]
che a ogni valore della n-upla \(x_1, x_2, ..., x_n\) associa un valore dell‚Äôinsieme \(\{0, 1\}\). La tabella di verit√† di una simile funzione √® rappresentata nella tabella che segue:

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{ccccc|P}
         \(x_1\) & \(x_2\) & \(...\) & \(x_{n - 1}\) & \(x_n\) & \(f(x_1, x_2, ..., x_n)\)\\
         \hline
         \(0\) & \(0\) & \(...\) & \(0\) & \(0\) & \(f(0, 0, ..., 0, 0)\)\\
         \(0\) & \(0\) & \(...\) & \(0\) & \(1\) & \(f(0, 0, ..., 0, 1)\)\\
         \(...\) & \(...\) & \(...\) & \(...\) & \(...\) & \(...\)\\
         \(1\) & \(1\) & \(...\) & \(1\) & \(0\) & \(f(1, 1, ..., 1, 0)\)\\
         \(1\) & \(1\) & \(...\) & \(1\) & \(1\) & \(f(1, 1, ..., 1, 1)\)\\
    \end{tabularx}
    \caption{Tabella di verit√† di una generica funzione Booleana n-aria}
    \label{tab:tabella_verita_funzione_naria}
\end{table}

\noindent
Si osservi che il numero di n-uple binarie dell‚Äôinsieme \(2^n\) cresce in modo esponenziale. In generale, poich√© l‚Äôinsieme \(2^n\) contiene \(2^n\) n-uple binarie, e a ciascuna di esse si associa un valore della funzione (che pu√≤ essere o \(0\) o \(1\)), il numero totale di funzioni Booleane n-arie che si possono realizzare risulta essere:
\[2^{2^{n}}\]
Risulta fondamentale, pi√π specificatamente, studiare in particolare le funzioni Booleane per \(n = 1\) (a una variabile, o \textbf{unarie}) e \(n = 2\) (a due variabili, o \textbf{di-arie}).

\subsubsection{Funzioni a una variabile (unarie)}
Le funzioni ad una variabile (in cui \(n = 1\)) che si possono costruire sono in tutto
\[2^{2^1} = 2^2 = 4\]
e sono funzioni del tipo \(y = f(x)\).

\begin{table}[H]
    \centering
    \noindent
    \setlength{\tabcolsep}{1.8pt}
    \begin{tabularx}{\textwidth}{>{\hsize=0.28\textwidth}PPPPP}
         {
            \setlength{\tabcolsep}{7pt}
            \begin{tabular}{c|cccc}
                 $ $ & $f_0$ & $f_1$ & $f_2$ & $f_3$\\
                 \hline
                 $x$ & $0$ & $x$ & $\overline{x}$ & $1$\\
                 \hline
                 $0$ & $0$ & $0$ & $1$ & $1$\\
                 $1$ & $0$ & $1$ & $0$ & $1$\\
            \end{tabular}
         }
         &
         {
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{c|c}
                 $ $ & \textbf{Nulla}\\
                 \hline
                 $x$ & $z$\\
                 \hline
                 $0$ & $0$\\
                 $1$ & $0$
            \end{tabular}
         }
         &
         {
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{c|c}
                 $ $ & \textbf{Unitaria}\\
                 \hline
                 $x$ & $z$\\
                 \hline
                 $0$ & $1$\\
                 $1$ & $1$
            \end{tabular}
         }
         &
         {
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{c|c}
                 $ $ & \textbf{Buffer}\\
                 \hline
                 $x$ & $z$\\
                 \hline
                 $0$ & $0$\\
                 $1$ & $1$
            \end{tabular}
         }
         &
         {
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{c|c}
                 $ $ & \textbf{NOT}\\
                 \hline
                 $x$ & $z$\\
                 \hline
                 $0$ & $1$\\
                 $1$ & $0$
            \end{tabular}
         }
    \end{tabularx}
    \caption{Tutte le possibili \(2^{2^1} = 4\) funzioni Booleane a \(1\) variabile}
    \label{tab:funzioni_una_variabile}
\end{table}

\noindent
\begin{enumerate}
    \item La prima funzione fornisce sempre \(0\) in uscita, qualunque sia l‚Äôingresso; √® dunque la \textbf{funzione nulla}, che si nota con \(\textbf{0}\).

    \item Un discorso analogo vale per la seconda funzione, che fornisce sempre \(1\) in uscita, qualunque sia l'ingresso; √® dunque la \textbf{funzione unitaria}, che si denota con \(\textbf{1}\).

    \item La terza funzione replica il valore di \(x\) in uscita, cio√® \(y = x\) e si tratta dunque della \textbf{funzione identit√†}. Poich√© la logica Booleana √® connessa, come gi√† anticipato, all‚Äôambito circuitale, per la rappresentazione della funzione identit√† si usa il termine \textbf{Buffer}, e le si attribuisce lo schema circuitale dato da un triangolo:

        % Contenitore per immagini
            \begin{figure}[H]
                \centering
                    \begin{tikzpicture}
                        \node (A) at (0,0) {$x$};
                        \node (Y) at (2,0) {$y$};
                        \node[buffer gate US, draw, logic gate inputs=n] at (1,0) (TS) {};
                        \draw (A) -- (TS.input);
                        \draw (TS.output) -- (Y);
                    \end{tikzpicture}
                \caption{Buffer}
                \label{fig:buffer}
            \end{figure}

    \noindent
    Esso corrisponde a un dispositivo che fornisce sull‚Äôuscita a destra esattamente ci√≤ che si presenta in ingresso a sinistra.

    \item La quarta funzione √® la pi√π importante dal punto di vista della logica Booleana, poich√© √® uno dei connettivi base gi√† analizzati, cio√® il NOT. Esso fornisce in uscita la negazione di quanto sta all‚Äôingresso; si pu√≤ dunque scrivere \(y = \overline{x}\).\\
    Per la sua rappresentazione circuitale si usa il triangolo di prima concatenato con un piccolo circoletto, che in tutta la circuiteria logica ha sempre il significato di una \textbf{negazione} o \textbf{complementazione}:

        % Contenitore per immagini
        \begin{figure}[H]
        \centering
            \begin{tikzpicture}
                \node (A) at (0,0) {$x$};
                \node (Y) at (2.2,0) {$y$};
                \node[not gate US, draw, logic gate inputs=n] at (1,0) (TS) {};
                \draw (A) -- (TS.input);
                \draw (TS.output) -- (Y);
            \end{tikzpicture}
        \caption{Negazione (o complementazione)}
        \label{fig:negazione_o_complementazione}
        \end{figure}
\end{enumerate}

\subsubsection{Funzioni a due variabili}
Le funzioni a due variabili (in cui \(n = 2\)) che si possono costruire sono
\[2^{2^2} = 2^4 = 16\]
Sono funzioni Booleane di-arie del tipo \(z = f(x, y)\) e sono cos√¨ importanti da meritare una descrizione anche circuitale.\\
Di seguito vengono riportate usando il linguaggio dell'Algebra Booleana:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{PP|P>{\hsize=0.015\textwidth}PPPPPPP>{\hsize=0.03\textwidth}P>{\hsize=0.03\textwidth}PPPPPPPPPPP>{\hsize=0.03\textwidth}PP}
         $ $ & $ $ & $f_0$ & $f_1$ & $f_2$ & $f_3$ & $f_4$ & $f_5$ & $f_6$ & $f_7$ & $f_8$ & $f_9$ & $f_{10}$ & $f_{11}$ & $f_{12}$ & $f_{13}$ & $f_{14}$ & $f_{15}$\\
         \hline
         $ $ & $ $ & $ $ & $\hspace{-0.75em} \text{AND}$ & $ $ & $ $ & $ $ & $ $ & $\hspace{-0.95em} \text{XOR}$ & $\hspace{-0.45em}  \text{OR}$ & $\hspace{-0.5em} \text{NOR}$ & $\hspace{-1em} \text{XNOR} \hspace{1em}$ & $ $ & $ $ & $ $ & $ $ & \multicolumn{2}{P}{$\hspace{-3.5em} \text{NAND}$}\\
         $A$ & $B$ & $\textbf{0}$ & $\cdot$ & $ $ & $ $ & $ $ & $ $ & $\oplus$ & $+$ & $\downarrow$ & $\odot$ & $ $ & $ $ & $ $ & $ $ & $\hspace{0.4em} \vert$ & $\textbf{1}$\\
         \hline
         $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$\\
         $F$ & $V$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$\\
         $V$ & $F$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$\\
         $V$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$\\
    \end{tabularx}
    \caption{Tutte le possibili \(2^{2^2} = 16\) funzioni Booleane a due variabili}
    \label{tab:16_funzioni_due_variabili}
\end{table}

\noindent
Tra tutte queste funzioni √® noto che alcune sono particolarmente significative, precisamente le sei gi√† evidenziate in Tabella \ref{tab:16_funzioni_due_variabili}, che sono rispettivamente AND, OR, XOR, NAND, NOR e XNOR; nella tabella seguente esse sono espresse, assieme alle rimanenti, mediante i simboli \(\cdot, +, \oplus, \vert, \downarrow\) e \(\odot\) che si usano tradizionalmente nell‚Äôambito dell‚ÄôAlgebra Booleana; si noti che \(+, \cdot\) e \(\odot\) stanno rispettivamente per \(\cup, \cap\) e \(\equiv\), visti nella precedente Tabella \ref{tab:tavola_verit√†_connettivi_binari} parlando di connettivi.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{|l|P||l|P|}
    \hline
        \(f_0 = \textbf{0} \hspace{5em}\) & $ $ & \(f_8 = x \downarrow y \hspace{5em}\) & NOR\\
        \(f_1 = x \cdot y \hspace{5em}\) & AND & \(f_9 = x \odot y \hspace{5em}\) & XNOR\\
        \(f_2 = x \cdot \overline{y} \hspace{5em}\) & $ $ & \(f_{10} = \overline{y} \hspace{5em}\) & $ $\\
        \(f_3 = x \hspace{5em}\) & $ $ & \(f_{11} = x + \overline{y} \hspace{5em}\) & $ $\\
        \(f_4 = \overline{x} \cdot y \hspace{5em}\) & $ $ & \(f_{12} = \overline{x} \hspace{5em}\) & $ $\\
        \(f_5 = y \hspace{5em}\) & $ $ & \(f_{13} = \overline{x} + y \hspace{5em}\) & $ $\\
        \(f_6 = x \oplus y \hspace{5em}\) & XOR & \(f_{14} = x | y \hspace{5em}\) & NAND\\
        \(f_7 = x + y \hspace{5em}\) & OR & \(f_{15} = \textbf{1}\) & $ $\\
        \hline
    \end{tabularx}
    \caption{Le \(16\) funzione Booleane espresse mediante \(\cdot, +, \oplus, \odot, \downarrow, \vert\) e complementazione}
    \label{tab:16_funzioni_booleane_con_connettivi_proincipali}
\end{table}

\noindent
Come anticipato, data l‚Äôestrema importanza, in ambito circuitale, delle funzioni AND, OR, XOR, NAND, NOR e XNOR, dette anche operatori Booleani, vengono analizzate singolarmente di seguito:

\begin{itemize}
    \item \textbf{Porta AND}\\
    √à detta anche \textbf{prodotto logico}. La porta AND restituisce \(0\) in uscita se anche uno solo dei due valori d‚Äôingresso √® pari a \(0\); restituisce \(1\) solo quando entrambi gli ingressi sono a \(1\). Il simbolo circuitale √®:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
        \begin{tikzpicture}
            \node [and gate US, draw, logic gate inputs =nn] (and){};
            \draw (and.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
            \draw (and.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
            \draw (and.output) -- node[at end,right]{$x \cdot y$} ++(right:4mm);
        \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \cdot y\)\\
             \hline
             $0$\\
             $0$\\
             $0$\\
             $1$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}
    \noindent

    \item \textbf{Porta OR}\\
    √à detta anche \textbf{somma logica}. La porta OR restituisce \(1\) in uscita se almeno uno dei due valori d‚Äôingresso √® pari a \(1\); restituisce \(0\) solo quando entrambi gli ingressi sono a \(0\). Il simbolo circuitale √®:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
    \begin{tikzpicture}
        \node [or gate US, draw, logic gate inputs =nn] (or){};
        \draw (or.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
        \draw (or.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
        \draw (or.output) -- node[at end,right]{$x + y$} ++(right:4mm);
    \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x + y\)\\
             \hline
             $0$\\
             $1$\\
             $1$\\
             $1$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}
    \noindent

    \item \textbf{Porta XOR}\\
    √à l‚ÄôOR esclusivo. La porta XOR restituisce \(1\) in uscita se o uno o l‚Äôaltro dei due valori d‚Äôingresso √® pari a \(1\), ma non entrambi; restituisce \(0\) quando entrambi gli ingressi sono a \(0\) o a \(1\). Il simbolo circuitale √®

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
      \begin{tikzpicture}
          \node [xor gate US, draw, logic gate inputs =nn] (xor){};
          \draw (xor.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
          \draw (xor.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
          \draw (xor.output) -- node[at end,right]{$x \oplus y$} ++(right:4mm);
      \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \oplus y\)\\
             \hline
             $0$\\
             $1$\\
             $1$\\
             $0$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}
    \noindent
\end{itemize}

\newpage
\begin{center}
    11 Ottobre 2021
\end{center}

\subsection{Riassunto}
L'algebra booleana √® l'apparato teorico che costituisce le fondamenta della logica binaria. Attraverso il teorema di De Morgan, in particolare, l'insieme minimo dei connettivi in grado di esprimere le \(16\) espressioni booleane pu√≤ essere ristretto a AND, NOT oppure a OR, NOT.\\
Non solo, ma impiegando i connettivi universali NOR e NAND √® possibile impiegare un solo connettivo per costruire ogni funzione logica.\\
Gli assiomi che si pongono alla base dell'algebra booleana sono verit√† assolute, incontestabili e non dimostrabili e costituiscono le fondamenta della teoria assiomatica quale quella booleana. L'algebra booleana, tuttavia, non √® solo quella delle porte logiche, ma anche quella delle operazioni insiemistiche, secondo \textbf{Kantor}; esse, infatti, rispettano tutti i dettami dell'algebra booleana.\\
A partire dagli assiomi fondamentali si possono, poi, formulare dei teoremi che permettono la semplificazione di espressioni logiche, tramite il \textbf{principio di inferenza}. Il \textbf{principio di dualit√†}, invece, permette di trasformare una proposizione vera con la congiunzione in un'altra proposizione vera con la disgiunzione. Naturalmente, si ottiene una seconda espressione sempre vera, ma che risulta comunque differente rispetto alla funzione di partenza.\\
Le funzioni booleane vanno da \(2^n \rightarrow 2\), ovvero ad ogni n-upla viene associato uno dei \(2\) possibili valori (VERO o FALSO).\\
Con \(n = 1\), si possono avere solamente \(2^2 = 4\) funzioni unarie del tipo \(y = f(x)\), mentre con \(n = 2\) ci sono \(2^{2^2} = 16\) funzioni booleane di-arie del tipo \(z = f(x, y)\). Tali funzioni sono le \(16\) funzioni logiche precedentemente esposte, ma che presentano dei simboli circuitali differenti rispetto ai connettivi analizzati.\\
Pertanto, dopo aver discusso ampiamente le due porte principali dell'Algebra Booleana (AND e OR), √® doveroso rivolgere un'importante attenzione alle porte solo in apparenza secondarie, di seguito esposte:

\begin{itemize}
    \item \textbf{Porta XOR}\\
    √à l‚ÄôOR esclusivo. La porta XOR restituisce \(1\) in uscita se uno o l‚Äôaltro dei due valori d‚Äôingresso √® pari a \(1\), ma non entrambi; restituisce \(0\) quando entrambi gli ingressi sono a \(0\) o a \(1\). Il simbolo circuitale √®

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
      \begin{tikzpicture}
          \node [xor gate US, draw, logic gate inputs =nn] (xor){};
          \draw (xor.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
          \draw (xor.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
          \draw (xor.output) -- node[at end,right]{$x \oplus y$} ++(right:4mm);
      \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \oplus y\)\\
             \hline
             $0$\\
             $1$\\
             $1$\\
             $0$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}
    \noindent

    \noindent
    Si osservi che una porta XOR √® in grado di realizzare la somma binaria modulo \(2\) e che costituisce un \textbf{rilevatore di differenza} tra i due valori d'ingresso.\\
    Inoltre, si osserva che:
    \[x \oplus y = x \overline{y} + \overline{x} y\]
    che corrisponde a un OR di due AND. Mediante manipolazione algebrica si ottiene anche la seguente espressione:
    \[x \oplus y = x \overline{y} + \overline{x} y = x \overline{y} + \overline{x} y + x \overline{x} + y \overline{y} = (x + y) \cdot (\overline{x} + \overline{y})\]
    che corrisponde a un AND di due OR. Si possono pertanto realizzare due circuiti del tutto equivalenti, visibili in Figura \ref{fig:XOR_espressa_AND_OR}:

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
        \hspace{2.5em}
        \begin{tikzpicture}
            \coordinate (start) at (-1.5,0);
            \node [and gate US, draw, logic gate inputs=ni] (and1){};
            \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=in] (and2){};
            \node [or gate US, draw, right=of and1, xshift=-3mm, yshift=-5mm, logic gate inputs=nn] (or){};

            \draw (and1.input 1) -- node[at end, left]{$x$} (and1.input 1 -| start);
            \draw (and2.input 2) -- node[at end, left]{$y$} (and2.input 2 -| start);
            \draw (and1.input 1) ++(-0.8,0) node [branch]{} |- (and2.input 1);
            \draw (and2.input 2) ++(-0.5,0) node [branch]{} |- (and1.input 2);
            \draw (and1.output) -- ([xshift=0.3cm] and1.output) |- (or.input 1);
            \draw (and2.output) -- ([xshift=0.3cm] and2.output) |- (or.input 2);
            \draw (or.output) -- ([xshift=0.5cm] or.output) node [right] {{$x\overline{y} + \overline{x}y$}};
        \end{tikzpicture}
        \hspace{3em}
        \begin{tikzpicture}
          \coordinate (start) at (-1.5,0);
          \node [or gate US, draw, logic gate inputs=ii] (or1){};
          \node [or gate US, draw, below=of or1, yshift=5.5mm, logic gate inputs=nn] (or2){};
          \node [and gate US, draw, right=of and1, xshift=-3mm, yshift=-5mm, logic gate inputs=nn] (and){};

          \draw (or1.input 1) -- node[at end, left]{$x$} (or1.input 1 -| start);
          \draw (or2.input 2) -- node[at end, left]{$y$} (or2.input 2 -| start);
          \draw (or1.input 1) ++(-0.8,0) node [branch]{} |- (or2.input 1);
          \draw (or2.input 2) ++(-0.5,0) node [branch]{} |- (or1.input 2);
          \draw (or1.output) -- ([xshift=0.3cm] or1.output) |- (and.input 1);
          \draw (or2.output) -- ([xshift=0.3cm] or2.output) |- (and.input 2);
          \draw (and.output) -- ([xshift=0.5cm] and.output) node [right] {{$(x + y) \cdot (\overline{x} + \overline{y})$}};
        \end{tikzpicture}
        \caption{La funzione XOR realizzata mediante porte AND e OR}
        \label{fig:XOR_espressa_AND_OR}
    \end{figure}

    \item \textbf{Porta XNOR}\\
    √à la negazione della porta XOR. La porta XNOR restituisce \(1\) in uscita solo quando entrambe le variabili d'ingresso hanno lo stesso valore, o entrambe a \(0\) oppure entrambe a \(1\). Il simbolo circuitale si ottiene concatenando la porta XOR con la porta NOT:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
      \begin{tikzpicture}
          \node [xnor gate US, draw, logic gate inputs =nn] (xnor){};
          \draw (xnor.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
          \draw (xnor.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
          \draw (xnor.output) -- node[at end,right]{$x \odot y$} ++(right:4mm);
      \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \odot y\)\\
             \hline
             $1$\\
             $0$\\
             $0$\\
             $1$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}

    \noindent
    Si osservi che una porta XNOR costituisce un \textbf{rilevatore di identit√†} tra i due valori d'ingresso. Per trovare una rappresentazione circuitale mediante porte AND e OR bisogna partire dal fatto che si tratta di uno XOR negato, traendone le conseguenze sempre usando il Teorema di De Morgan (¬ß \ref{sec:teorema_de_morgan}):
    \[x \odot y = \overline{x \oplus y} = \overline{\overline{x}y + x \overline{y}} = \overline{(\overline{x}y)} \cdot \overline{(x\overline{y})} = (x + \overline{y}) \cdot (\overline{x} + y) = x\overline{x} + xy + \overline{x}\overline{y} + \overline{y}y = xy + \overline{x}\overline{y}\]
    Nella prima parte dello svolgimento si ottiene \((x + \overline{y}) \cdot (\overline{x} + y)\), e quindi l‚ÄôAND di due OR, mentre nella seconda parte si ottiene \(xy + \overline{x} \overline{y}\) le quali portano alla realizzazione circuitale seguente

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
        \hspace{2.5em}
        \begin{tikzpicture}
            \coordinate (start) at (-1.5,0);
            \node [and gate US, draw, logic gate inputs=ii] (and1){};
            \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=nn] (and2){};
            \node [or gate US, draw, right=of and1, xshift=-3mm, yshift=-5mm, logic gate inputs=nn] (or){};

            \draw (and1.input 1) -- node[at end, left]{$x$} (and1.input 1 -| start);
            \draw (and2.input 2) -- node[at end, left]{$y$} (and2.input 2 -| start);
            \draw (and1.input 1) ++(-0.8,0) node [branch]{} |- (and2.input 1);
            \draw (and2.input 2) ++(-0.5,0) node [branch]{} |- (and1.input 2);
            \draw (and1.output) -- ([xshift=0.3cm] and1.output) |- (or.input 1);
            \draw (and2.output) -- ([xshift=0.3cm] and2.output) |- (or.input 2);
            \draw (or.output) -- ([xshift=0.5cm] or.output) node [right] {{$xy + \overline{xy}$}};
        \end{tikzpicture}
        \hspace{3em}
        \begin{tikzpicture}
            \coordinate (start) at (-1.5,0);
            \node [or gate US, draw, logic gate inputs=ni] (or1){};
            \node [or gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=in] (or2){};
            \node [and gate US, draw, right=of and1, xshift=-3mm, yshift=-5mm, logic gate inputs=nn] (and){};

            \draw (or1.input 1) -- node[at end, left]{$x$} (or1.input 1 -| start);
            \draw (or2.input 2) -- node[at end, left]{$y$} (or2.input 2 -| start);
            \draw (or1.input 1) ++(-0.8,0) node [branch]{} |- (or2.input 1);
            \draw (or2.input 2) ++(-0.5,0) node [branch]{} |- (or1.input 2);
            \draw (or1.output) -- ([xshift=0.3cm] or1.output) |- (and.input 1);
            \draw (or2.output) -- ([xshift=0.3cm] or2.output) |- (and.input 2);
            \draw (and.output) -- ([xshift=0.5cm] and.output) node [right] {{$(x + \overline{y}) \cdot (\overline{x} + y)$}};
        \end{tikzpicture}
        \caption{La funzione XNOR realizzata mediante porte AND e OR}
        \label{fig:XNOR_espressa_AND_OR}
    \end{figure}

    \noindent
    Dal punto di vista ingegneristico, non vi √® una sostanziale differenza tra le due, dal momento che il numero di operazioni binarie e di negazioni sono esattamente identici.

    \item \textbf{Porta NAND}\\
    √à la negazione della porta AND, rappresentata dal seguente simbolo circuitale:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
      \begin{tikzpicture}
          \node [nand gate US, draw, logic gate inputs =nn] (nand){};
          \draw (nand.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
          \draw (nand.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
          \draw (nand.output) -- node[at end,right]{$x \vert y$} ++(right:4mm);
      \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \vert y\)\\
             \hline
             $1$\\
             $1$\\
             $1$\\
             $0$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}

    \noindent
    Com'√® noto, la porta NAND √® un \textbf{operatore universale}, nel senso che da sola consente di costruire una qualunque tra le \(16\) possibili funzioni. Per declinare le relazioni succitate nei termini del linguaggio dell'Algebra Booleana √® sufficiente usare gli assiomi e i teoremi visti in precedenza:
    \begin{align*}
        \overline{x} = \overline{x \cdot x} = x | x\\
        x + y = \overline{\overline{x} \cdot \overline{y}} = \overline{x} | \overline{y}\\
        x \cdot y = \overline{\overline{x \cdot y}} = \overline{x | y}
     \end{align*}
     Da cui derivano le seguenti rappresentazioni circuitali:

     % Contenitore per immagini
     \rowcolors{1}{white}{white}
     \noindent
     \begin{table}[H]
         \centering
         \noindent
         \begin{tabularx}{\textwidth}{PPP}
              {
                \begin{tikzpicture}
                    \coordinate (start) at (-1.5,-0.8);
                    \node [nand gate US, draw, logic gate inputs=nn] (nand){};

                    \draw (-0.6,0) -- node[at end, left]{$x$} (-0.8,0);
                    \draw (nand.input 2) ++(-0.3,0.08) node [branch]{} |- (nand.input 1);
                    \draw (nand.input 1) ++(-0.3,-0.08) node []{} |- (nand.input 2);
                    \draw (nand.output) -- ([xshift=0.3cm] nand.output) node [right] {{$\overline{x}$}};
                \end{tikzpicture}
              }
              &
              {
                \hspace{-2em}
                \begin{tikzpicture}
                  \node [nand gate US, draw, logic gate inputs=nn] (nand1){};
                  \node [nand gate US, draw, below=of nand1, yshift=5.5mm, logic gate inputs=nn] (nand2){};
                  \node [nand gate US, draw, right=of nand1, xshift=-3mm, yshift=-5mm, logic gate inputs=nn] (nand3){};

                  \draw (-0.6,0) -- node[at end, left]{$x$} (-0.8,0);
                  \draw (nand1.input 2) ++(-0.3,0.08) node [branch]{} |- (nand1.input 1);
                  \draw (nand1.input 1) ++(-0.3,-0.08) node []{} |- (nand1.input 2);

                  \draw (-0.6,-0.97) -- node[at end, left]{$y$} (-0.8,-0.97);
                  \draw (nand2.input 2) ++(-0.3,0.08) node [branch]{} |- (nand2.input 1);
                  \draw (nand2.input 1) ++(-0.3,-0.08) node []{} |- (nand2.input 2);

                  \draw (nand1.output) -- ([xshift=0.3cm] nand1.output) |- (nand3.input 1);
                  \draw (nand2.output) -- ([xshift=0.3cm] nand2.output) |- (nand3.input 2);
                  \draw (nand3.output) -- ([xshift=0.3cm] nand3.output) node [right] {{$x + y$}};
                \end{tikzpicture}
              }
              &
              {
                \begin{tikzpicture}
                  \coordinate (start) at (-0.7,0);
                  \node [nand gate US, draw, logic gate inputs=nn] (nand1){};
                  \node [nand gate US, draw, right=of nand1, logic gate inputs=nn] (nand2){};

                  \draw (nand1.input 1) -- node[at end, above left]{$x$} (nand1.input 1 -| start);
                  \draw (nand1.input 2) -- node[at end, below left]{$y$} (nand1.input 2 -| start);

                  \draw (nand1.output) -- ([xshift=0.3cm] nand1.output) node [branch]{} |- (nand2.input 1);
                  \draw (nand1.output) -- ([xshift=0.3cm] nand1.output) node []{} |- (nand2.input 2);

                  \draw (nand2.output) -- ([xshift=0.3cm] nand2.output) node [right] {{$x \cdot y$}};
                \end{tikzpicture}
              }
         \end{tabularx}\\
         \caption{Funzioni NOT, OR e AND realizzazate mediante la porta universale NAND}
         \label{tab:NOT_OR_AND_tramite_NAND}
     \end{table}

    \item \textbf{Porta NOR}\\
    √à la negazione della porta OR, rappresentata dal seguente simbolo circuitale:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
      \begin{tikzpicture}
          \node [nor gate US, draw, logic gate inputs =nn] (nor){};
          \draw (nor.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
          \draw (nor.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
          \draw (nor.output) -- node[at end,right]{$x \downarrow y$} ++(right:4mm);
      \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \downarrow y\)\\
             \hline
             $1$\\
             $0$\\
             $0$\\
             $0$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}

    \noindent
    Com'√® noto, anche la porta OR √® un \textbf{operatore universale}, nel senso che da sola consente di costruire una qualunque tra le \(16\) possibili funzioni. Per declinare le relazioni succitate nei termini del linguaggio dell'Algebra Booleana √® sufficiente usare gli assiomi e i teoremi visti in precedenza:
    \begin{align*}
        \overline{x} = \overline{x + x} = x \downarrow x\\
        x + y = \overline{\overline{x + y}} = \overline{x \downarrow y}\\
        x \cdot y = \overline{\overline{x} + \overline{y}} = \overline{x} \downarrow \overline{y}
     \end{align*}
     Da cui derivano le seguenti rappresentazioni circuitali:

     % Contenitore per immagini
     \rowcolors{1}{white}{white}
     \noindent
     \begin{table}[H]
         \centering
         \noindent
         \begin{tabularx}{\textwidth}{PPP}
              {
                \begin{tikzpicture}
                    \coordinate (start) at (-1.5,-0.8);
                    \node [nor gate US, draw, logic gate inputs=nn] (nor){};

                    \draw (-0.6,0) -- node[at end, left]{$x$} (-0.8,0);
                    \draw (nor.input 2) ++(-0.3,0.08) node [branch]{} |- (nor.input 1);
                    \draw (nor.input 1) ++(-0.3,-0.08) node []{} |- (nor.input 2);
                    \draw (nor.output) -- ([xshift=0.3cm] nor.output) node [right] {{$\overline{x}$}};
                \end{tikzpicture}
              }
              &
              {
                \hspace{-3em}
                \begin{tikzpicture}
                  \coordinate (start) at (-0.7,0);
                  \node [nor gate US, draw, logic gate inputs=nn] (nor1){};
                  \node [nor gate US, draw, right=of nor1, logic gate inputs=nn] (nor2){};

                  \draw (nor1.input 1) -- node[at end, above left]{$x$} (nor1.input 1 -| start);
                  \draw (nor1.input 2) -- node[at end, below left]{$y$} (nor1.input 2 -| start);

                  \draw (nor1.output) -- ([xshift=0.3cm] nor1.output) node [branch]{} |- (nor2.input 1);
                  \draw (nor1.output) -- ([xshift=0.3cm] nor1.output) node []{} |- (nor2.input 2);

                  \draw (nor2.output) -- ([xshift=0.3cm] nor2.output) node [right] {{$x + y$}};
                \end{tikzpicture}
              }
              &
              {
                \begin{tikzpicture}
                  \node [nor gate US, draw, logic gate inputs=nn] (nor1){};
                  \node [nor gate US, draw, below=of nand1, yshift=5.5mm, logic gate inputs=nn] (nor2){};
                  \node [nor gate US, draw, right=of nand1, xshift=-3mm, yshift=-5mm, logic gate inputs=nn] (nor3){};

                  \draw (-0.6,0) -- node[at end, left]{$x$} (-0.8,0);
                  \draw (nor1.input 2) ++(-0.3,0.08) node [branch]{} |- (nor1.input 1);
                  \draw (nor1.input 1) ++(-0.3,-0.08) node []{} |- (nor1.input 2);

                  \draw (-0.6,-0.97) -- node[at end, left]{$y$} (-0.8,-0.97);
                  \draw (nor2.input 2) ++(-0.3,0.08) node [branch]{} |- (nor2.input 1);
                  \draw (nor2.input 1) ++(-0.3,-0.08) node []{} |- (nor2.input 2);

                  \draw (nor1.output) -- ([xshift=0.3cm] nor1.output) |- (nor3.input 1);
                  \draw (nor2.output) -- ([xshift=0.3cm] nor2.output) |- (nor3.input 2);
                  \draw (nor3.output) -- ([xshift=0.3cm] nor3.output) node [right] {{$x \cdot y$}};
                \end{tikzpicture}
              }
         \end{tabularx}\\
         \caption{Funzioni NOT, OR e AND realizzazate mediante la porta universale NOR}
         \label{tab:NOT_OR_AND_tramite_NOR}
     \end{table}


\end{itemize}
E questo √® un risultato molto importante dal punto di vista tecnico industriale, dal momento che potrebbero comportare significativi vantaggi dal punto di vista economico-produttivo.

\subsubsection{Funzioni a tre variabili}
Finora sono state trattate solamente porte associate a funzioni a due variabili. La generalizzazione a \(n\) variabili ha pieno senso solo per le porte AND e OR; si tratter√† per esteso il caso con \(n = 3\), poich√© gli altri sono la banale generalizzazione di questo. Le tavole di verit√† delle funzioni AND e OR a \(3\) variabili sono riportate nella successiva Tabella \ref{tab:AND_OR_3_variabili}:

\rowcolors{1}{white}{white}
\noindent
\begin{table}[H]
    \centering
    \noindent
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{PP}
    {
        \begin{tabular}{c|c|c|c}
             \(x\) & \(y\) & \(z\) & AND\\
             \hline
             $0$ & $0$ & $0$ & $0$\\
             $0$ & $0$ & $1$ & $1$\\
             $0$ & $1$ & $0$ & $0$\\
             $1$ & $0$ & $0$ & $1$\\
             $1$ & $0$ & $1$ & $0$\\
             $1$ & $1$ & $0$ & $0$\\
             $1$ & $1$ & $1$ & $0$\\
             $1$ & $1$ & $1$ & $1$
        \end{tabular}
    }
    &
    {
        \begin{tabular}{c|c|c|c}
             \(x\) & \(y\) & \(z\) & OR\\
             \hline
             $0$ & $0$ & $0$ & $0$\\
             $0$ & $0$ & $1$ & $1$\\
             $0$ & $1$ & $0$ & $1$\\
             $1$ & $0$ & $0$ & $1$\\
             $1$ & $0$ & $1$ & $1$\\
             $1$ & $1$ & $0$ & $1$\\
             $1$ & $1$ & $1$ & $1$\\
             $1$ & $1$ & $1$ & $1$
        \end{tabular}
    }\\
    \end{tabularx}
    \caption{Funzioni AND e OR  a $3$ variabili}
    \label{tab:AND_OR_3_variabili}
\end{table}

\noindent
Naturalmente, la funzione AND vale \(1\) solo quando tutte le variabili in ingresso hanno valore \(1\); la funzione OR vale \(0\) solo quando tutte le variabili in ingresso hanno valore \(0\).

\subsection{Realizzazione circuitale delle porte logiche}
Le funzioni logiche di base, a \(1\) e \(2\) variabili, possono essere facilmente realizzate impiegando i transistor. Tuttavia, in fase di realizzazione √® necessario tenere conto di alcuni fondamentali obiettivi:
\begin{enumerate}
    \item Minimizzazione della potenza dissipata. Infatti, la deriva termica dei transistor rappresenta un esito deleterio per il dispositivo, in quanto verso i \(200 ^{\circ}\)C il cristallino di silicio si fonde e il transistor si brucia.

    \item Minimizzazione dei tempi di risposta. Infatti, la variazione di tensione dei transistor determina la generazione di un impulso che deve transitare per il circuito e deve essere validato dalle porte logiche, anche in cascata. Non √® ammissibile che vi siano tempi di risposta differenti in quanto la validazione delle variabili logiche ne potrebbe risentire.

    \item Minimizzazione dei costi

    \item Aumento progressivo della densit√† di integrazione sui relativi circuiti integrati.
\end{enumerate}

\noindent
Nel tempo si sono succedute numerose \textbf{famiglie logiche}, che a seconda del periodo in cui sono state introdotte e dello sviluppo tecnologico corrente hanno privilegiato l‚Äôuso di uno o dell‚Äôaltro dei vari dispositivi a semiconduttore per la realizzazione delle funzioni di base, quali diodi, transistor, CMOS, ecc...\\
Anche se in pratica sono molte di pi√π, le principali famiglie logiche sono le seguenti (in ordine cronologico):

\begin{itemize}
    \item Resistor-Transistor Logic (RTL) √® una classe di porte logiche costruite usando resistenze nella rete d‚Äôingresso e transistors bipolari a giunzione (BJT) come dispositivi di commutazione. La RTL √® stata la prima classe di circuito logico digitale basata sull‚Äôimpiego dei transistor. Le prime porte RTL furono costruite con elementi discreti, ma nel 1961 divenne la prima famiglia logica a esser realizzata su un circuito integrato monolitico. Circuiti integrati RTL sono stati utilizzati nel computer Apollo Guidance, il cui progetto risale al 1961 con un primo volo fatto nel 1966.

    \item Diode-Transistor Logic (DTL) √® la classe di porte logiche che precede la grande famiglia TTL. Si chiama cos√¨ perch√© la funzione logica viene eseguita da una rete di diodi, mentre la funzione di inversione-amplificazione viene eseguita da un transistor.

    \item Transistor-Transistor Logic (TTL) √® senza dubbio la classe pi√π nota e famosa, poich√© ha avuto un larghissimo impiego. Fa uso di transistors bipolari a giunzione (BJT) e resistenze. Si chiama logica transistor-transistor perch√© il transistor svolge sia la funzione logica che la funzione di inversione-amplificazione. I circuiti integrati basati sulla famiglia TTL sono stati ampiamente usati in applicazioni quali computer, controlli industriali, apparecchiature di prova, strumentazione elettronica, elettronica di consumo, sintetizzatori e molto altro. Dopo la loro introduzione come circuito integrato a opera di Sylvania nel 1963, i circuiti integrati TTL sono stati prodotti da diverse aziende di semiconduttori. La serie 7400 (chiamato anche 74xx) della Texas Instruments e diventata particolarmente popolare. I produttori di porte basati sulla tecnologia TTL hanno offerto una vasta gamma di porte logiche, flip-flop, contatori, multiplexer e altri circuiti.

    \item Complementary Metal-Oxide-Semiconductor (CMOS) √® la tecnologia pi√π recente per la costruzione di porte logiche inserite in circuiti integrati. La tecnologia CMOS viee usata in microprocessori, microcontrollori, nella RAM statica e in molti altri circuiti logici digitali. √à la tecnologia piu raffinata, che consente un abbattimento dei consumi e dei tempi di risposta, congiuntamente alla possibilit√† di realizzare un‚Äôaltissima densit√† di integrazione.\\
    I transistor CMOS sono chiamati transistor MOS-FET a effetto di campo (dall'inglese FET - Field Effect Transistor), richiedono molta meno potenza e non dissipano potenza in ingresso, sono molto pi√π piccoli e garantiscono un minore tempo di risposta e sono diversi dai transistor a giunzione (VJT).
\end{itemize}

\noindent
Si consideri la realizzazione tramite transistor delle principali porte logiche.

\begin{itemize}
    \item \textbf{Porta NOT}\\

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
        \begin{circuitikz}[]
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,0) node[npn, tr circle](Q1){};
          \draw (Q1.B) to[R, l_=$R_0$] ++(-2,0) node[circ]{\hspace{-1em}$x$};
          \draw (Q1.C) node[circ](y){} to[R, l_=$R_1$] ++(0,2) node[vcc]{$+V_{CC}$};
          \draw (Q1.E) -- ++(0,-0.5) node[ground](GND){};
          \draw (y) -- ++(1,0) node[flowarrow]{$y = \overline{x}$};
        \end{circuitikz}
        \caption{Porta NOT realizzata tramite transistor}
        \label{fig:NOT_tramite_transistor}
    \end{figure}

    Nella porta NOT bisogna realizzare un‚Äôinversione del valore logico. Questa funzione si realizza mediante un singolo transistor, nel quale la variabile d‚Äôingresso va ad alimentare la base, mentre quella di uscita si ricava sul collettore del transistor. Se si associa la costante 1 a un livello alto di tensione, come la tensione di alimentazione \(V_{CC}\) di Figura \ref{fig:NOT_tramite_transistor}, e la costante \(0\) a un livello basso, cio√® la tensione di massa pari a \(0\)V, il funzionamento dell‚Äôinvertitore √® il seguente: quando la variabile \(x\) assume valore logico 1, e cio√® viene portata a tensione \(V_{CC}\), il transistor si polarizza direttamente ed entra in piena conduzione. Tale condizione corrisponde alla saturazione del transistor; in questa configurazione la tensione \(V_{CE}\) crolla idealmente a \(0\)V, portando la variabile \(y\) in uscita nello stato logico \(0\).\\
    Quando, viceversa, la variabile \(x\) assume valore logico \(0\), e cio√® viene portata a tensione \(0\)V (connessione a massa), il transistor blocca la conduzione e la \(I_{C}\) diventa (praticamente) nulla. Tale condizione corrisponde all‚Äôinterdizione del transistor; in questa configurazione, pertanto, la tensione \(V_{CE}\) diventa pari alla \(V_{CC}\), quindi viene portato all'\(1\) logico il valore dell‚Äôuscita.
    Infatti, con corrente in ingresso, il transistor va in saturazione, per cui la tensione √® nulla; se, invece, la corrente in ingresso √® nulla, il transistor va in interdizione, per cui la tensione √® massima.\\
    La resistenza in ingresso deve essere ovviamene commisurata per non bruciare il circuito, cos√¨ come √® fondamentale il ruolo della \textbf{resistenza di carico} che permette di separare la tensione di alimentazione e avere una corrente variabile.\\
    La tensione di saturazione \(V_{SAT}\) non √® mai nulla, nella realt√†, ma se la corrente in ingresso √® significativamente maggiore di \(0\), allora in uscita si avr√† il valore logico \(0\), a causa di un \textbf{cortocircuito} che si viene a determinare.\\
    Se, invece, la corrente in ingresso √® nulla, allora il transistor va in \textbf{interdizione}, per cui la corrente in uscita viene \textbf{interdetta}, pertanto la tensione in uscita sar√† pari a quella di alimentazione. Pertanto, l'uscita corrisponde al valore \(1\) logico.\\
    In questo modo si sta usando il transistor in modo digitale, come se fosse un vero interruttore, in quanto si opera ai suoi valori estremi, \(0\) e \(1\); un transistor che opera, invece, in modo analogico, viene usato come amplificatore, e pu√≤ assumere anche valori intermedi.\\
    Se si utilizzasse un transistor CMOS, per esempio, il funzionamento sarebbe esattamente analogico, solo che viene comandato in tensione, con significativi vantaggi in termini di \textbf{dissipazione di potenza}. Inoltre, i CMOS possono essere anche realizzati in modo molto pi√π microscopico.

    \vspace{1em}
    \noindent
    \item \textbf{Porta AND}\\

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
        \begin{circuitikz}[]
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,0) node[npn, tr circle](Q1){};
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,-2) node[npn, tr circle](Q2){};

          \draw (Q1.B) to[R, l_=$R_0$] ++(-2,0) node[circ]{\hspace{-1em}$x$};
          \draw (Q2.B) to[R, l_=$R_1$] ++(-2,0) node[circ]{\hspace{-1em}$y$};
          \draw (Q1.C) -- ++(0,0.5) node[vcc]{$+V_{CC}$};
          \draw (Q1.E) -- (Q2.C);
          \draw (Q2.E) node[circ](z){} to[R, l_={$R_2$}] ++(0,-2) node[ground](GND){};
          \draw (z) -- ++(1,0) node[flowarrow]{$z = x \cdot y$};
        \end{circuitikz}
        \caption{Porta AND realizzata tramite transistor}
        \label{fig:AND_tramite_transistor}
    \end{figure}

    Nella porta AND bisogna fare in modo che se anche uno solo degli ingressi √® a \(0\), l‚Äôuscita resti a \(0\). Il circuito di Figura \ref{fig:AND_tramite_transistor} realizza questa condizione. Poich√® l‚Äôuscita a \(1\) significa livello alto di tensione, per realizzarla bisogna che entrambi i due transistor associati ai due ingressi, che sono posti in serie, siano in piena conduzione. Per realizzare ci√≤ √® necessario portare le variabili \(x\) e \(y\) d‚Äôingresso a \(V_{CC}\).\\
    Se anche uno solo dei due ingressi rimane a livello basso, uno dei due transistor va in interdizione e la tensione di uscita resta a livello basso, il che corrisponde a \(0\) logico.\\
    Se in ingresso \(x\) e \(y\) sono a valore logico \(1\), allora entrambi i transistor vanno in saturazione, pertanto diventano dei cortocircuiti, e lasciano passare la tensione di alimentazione, quindi l'uscita avr√† valore \(1\).\\
    Se almeno uno dei due transistor va in interdizione, allora si forma un circuito aperto e quindi l'uscita ha valore \(0\).

    \newpage
    \noindent
    \item \textbf{Porta OR}\\

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
        \begin{circuitikz}[]
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,0) node[npn, tr circle](Q1){};
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,-2) node[npn, tr circle](Q2){};

          \draw (Q1.B) to[R, l_=$R_0$] ++(-2,0) node[circ]{\hspace{-1em}$x$};
          \draw (Q2.B) to[R, l_=$R_1$] ++(-2,0) node[circ]{\hspace{-1em}$y$};
          \draw (Q1.C) -- ++(0.5,0) ++(0,0.5) node[vcc](VCC){$+V_{CC}$};
          \draw (Q2.E) -- ++(1,0) node[circ](z){} to[R, l_={$R_2$}] ++(0,-2) node[ground](GND){};
          \draw (Q2.C) -- ++(0.5,0) -- (VCC);
          \draw (Q1.E) -- ++(1,0) -- (z);
          \draw (z) -- ++(1,0) node[flowarrow]{$z = x + y$};
        \end{circuitikz}
        \caption{Porta OR realizzata tramite transistor}
        \label{fig:OR_tramite_transistor}
    \end{figure}

    Nella porta OR bisogna fare in modo che se anche uno solo degli ingressi √® a \(1\), l‚Äôuscita resti a 1. Il circuito di Figura \ref{fig:OR_tramite_transistor} realizza questa condizione. Poich√® l‚Äôuscita a \(1\) significa livello alto di tensione, per realizzarla basta che anche uno solo dei due transistor associati ai due ingressi, che sono posti in parallelo, sia in piena conduzione. Per realizzare ci√≤ √® sufficiente portare o l‚Äôingresso \(x\) o l‚Äôingresso \(y\) al valore \(V_{CC}\). Solo se entrambi gli ingressi rimangono a livello basso i transistors sono in interdizione e la tensione di uscita resta a livello basso, il che corrisponde a \(0\) logico.\\
    Effettivamente, essendo i due transistor posti in \textbf{parallelo}, a differenza della porta AND, √® sufficiente che almeno uno dei due vada in saturazione perch√© l'uscita sia a \(1\).\\
    Inoltre, solamente quando entrambi i transistor sono interdetti, ovvero sono a valore \(0\), allora anche in uscita sar√† valore \(1\).

    \newpage
    \noindent
    \item \textbf{Porta NAND}\\

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
        \begin{circuitikz}[]
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,0) node[npn, tr circle](Q1){};
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,-2) node[npn, tr circle](Q2){};

          \draw (Q1.B) to[R, l_=$R_0$] ++(-2,0) node[circ]{\hspace{-1em}$x$};
          \draw (Q2.B) to[R, l_=$R_1$] ++(-2,0) node[circ]{\hspace{-1em}$y$};
          \draw (Q1.C) node[circ](z){} to[R, l_={$R_2$}] ++(0,2) node[vcc]{$+V_{CC}$};
          \draw (Q1.E) -- (Q2.C);
          \draw (Q2.E) -- ++(0,-0.5) node[ground](GND){};
          \draw (z) -- ++(1,0) node[flowarrow]{$z = x \vert y$};
        \end{circuitikz}
        \caption{Porta NAND realizzata tramite transistor}
        \label{fig:NAND_tramite_transistor}
    \end{figure}

    La porta NAND viene realizzata a partire dal circuito della porta AND, spostando semplicemente la resistenza \(R_2\) di carico dall‚Äôemettitore del secondo transistor al collettore del primo. In questo modo, quando entrambi i transistor sono in piena conduzione grazie al fatto che entrambi gli ingressi sono a \(1\), l‚Äôuscita va a \(0\); e questa rimane l‚Äôunica condizione per la quale si ha uscita bassa. Infatti se anche uno solo degli ingressi va a \(0\), uno dei due transistor va in interdizione e l‚Äôuscita resta a 1.

    \vspace{1em}
    \noindent
    \item \textbf{Porta NOR}\\

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
        \begin{circuitikz}[]
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,0) node[npn, tr circle](Q1){};
          \ctikzset{transistors/thickness=4, transistors/fill=cyan!30, transistor circle/relative thickness=0.25,}
          \draw (0,-2) node[npn, tr circle](Q2){};

          \draw (Q1.B) to[R, l_=$R_0$] ++(-2,0) node[circ]{\hspace{-1em}$x$};
          \draw (Q2.B) to[R, l_=$R_1$] ++(-2,0) node[circ]{\hspace{-1em}$y$};
          \draw (Q1.C) -- ++(0.5,0) node[circ](z){} to[R, l_={$R_2$}] ++(0,2) node[vcc](VCC){$+V_{CC}$};
          \draw (Q2.E) -- ++(1,0) ++(0,-0.5) node[ground](GND){};
          \draw (Q2.C) -- ++(0.5,0) -- (z);
          \draw (Q1.E) -- ++(1,0) -- (GND);
          \draw (z) -- ++(1,0) node[flowarrow]{$z = x \downarrow y$};
        \end{circuitikz}
        \caption{Porta NOR realizzata tramite transistor}
        \label{fig:NOR_tramite_transistor}
    \end{figure}

    Anche in questo caso si parte della porta negata, che √® la OR, spostando semplicemente la resistenza \(R_2\) di carico dall‚Äôemettitore del secondo transistor al collettore del primo. In questo modo, quando entrambi i transistor sono in interdizione grazie al fatto che entrambi gli ingressi sono a \(0\), l‚Äôuscita va a 1; e questa rimane l‚Äôunica condizione per la quale si ha uscita alta. Infatti se anche uno solo degli ingressi va a \(1\), uno dei due transistor va in saturazione e l‚Äôuscita collassa a \(0\).
\end{itemize}

\newpage
\begin{center}
    12 Ottobre 2021
\end{center}

\subsection{Riassunto}
Una funzione a \(3\) variabili √® una funzione che va dall'insieme \(2^3\) a \(2\), pertanto il numero di funzioni che si possono costruire con \(n\) variabili cresce molto velocemente, in quanto √® dato da:
\[2^{2^n}\]
Considerando le funzioni pi√π semplici, ad una sola variabile, si distinguono \(4\) sole possibile funzioni, quella \textbf{nulla}, quella \textbf{identica}, la funzione \textbf{buffer} che trasmette a distanza il valore della variabile \(x\), mentre la funzione \textbf{complementare} trasmette a distanza il valore complementare della variabile \(x\).\\
Le funzioni a due variabili sono \(2^{2^2} = 16\) e sono le pi√π comuni e importanti, tali da giustificarne una dignit√† circuitale. In particolare si considerano le porte AND e OR, a cui si aggiungono:
\begin{itemize}
    \item XOR, la quale pu√≤ essere espressa come:
    \[x \oplus y = (A \cap \overline{B}) \cup (\overline{A} \cap B)\]
    che, in termini di logica binaria si esprime anche come
    \[x \oplus y = x\overline{y} + \overline{x}y \]
    ma anche
    \[x \oplus y = x\overline{y} + \overline{x}y = x\overline{y} + \overline{x}y + x\overline{x} + y \overline{y} = (x + y) \cdot (\overline{x} + \overline{y})\]
    che, dal punto di vista logico, circuitale ed economico sono perfettamente equivalenti.

    \item XNOR, ovvero la negazione della porta XOR, la quale pu√≤ essere espressa come:
    \[x \odot y = \overline{x \oplus y} = \overline{\overline{x}y + x \overline{y}} = \overline{\overline{x}y} \cdot \overline{x\overline{y}} = (x + \overline{y}) \cdot (\overline{x} + y)\]
    ma anche
    \[x \odot y = \overline{(x + y) \cdot (\overline{x} + \overline{y})} = \overline{x + y} + \overline{\overline{x} + \overline{y}} = \overline{x} \overline{y} + xy\]

    \item NAND, ovvero la negazione della porta AND.

    \item NOR, ovvero la negazione della porta OR.
\end{itemize}

\noindent
Queste ultime due funzioni logiche sono definite connettivi universali, in quanto da soli sono in grado di costruire tutte e \(16\) le possibili funzioni logiche a \(2\) variabili.

\vspace{1em}
\noindent
\textbf{Osservazione}: Il principio di funzionamento della porta NOT prevede l'utilizzo di un solo transistor, il quale, quando viene polarizzato direttamente con una corrente (opportunamente commisurata alle caratteristiche tecniche del transistor stesso) va in \textbf{saturazione} e la tensione \(V_{CE}\), ovvero la differenza di potenziale tra collettore ed emettitore, in uscita collassa al valore \(0\).\\
Se il transitors, invece, non viene polarizzato, allora esso va in \textbf{interdizione} e la tensione sul collettore si trova allo stesso valore della tensione di alimentazione (\(V_{CC}\)), per cui la tensione di uscita ha valore \(1\).

\vspace{1em}
\noindent
\textbf{Osservazione}: Il principio di funzionamento della porta AND si prevede l'utilizzo di due transistors a giunzione posti in serie, o anche di tipo MOS, o MOS FET, con un principio di funzionamento analogo. Solamente quando entrambi i transistor sono in piena conduzione, ossia in saturazione, allora la tensione in uscita assume il valore \(1\) logico; in tutti gli altri casi, quando anche un solo transistor viene interdetto, a causa di una tensione di alimentazione pressoch√© nulla, la tensione in uscita assume il valore \(0\) logico.

\vspace{1em}
\noindent
\textbf{Osservazione}: Il principio di funzionamento della porta OR prevede l'utlizzo di due transistors posti in parallelo, pertanto solamente quando ambedue i transistors sono in interdizione allora la tensione in uscita avr√† valore basso.\\
Altrimenti, se almeno uno dei due √® in \textbf{saturazione}, allora la tensione in uscita sar√† a valore alto.

\subsection{Forme canoniche: \textit{minterm}}
L'obiettivo di questa sezione si traduce nel formulare una struttura logica tale da poter semplificare nei minimi termini una funzione logica, riducendo il numero di connettivi (e porte) logiche necessari per la realizzazione di una rete logica, con significativi vantaggi in termini di latenza e tempi di risposta.\\
Le modalit√† per raggiungere tali fini sono \(3\): la prima di tipo squisitamente algebrico e dal risultato dubbio (o incerto), in quanto vi possono essere diverse linee di semplificazione che producono espressioni booleane diverse, ma perfettamente equivalenti dal punto di vista algebrico. Dopodich√© vi √® la \textbf{mappa di Karnaugh} e infine il \textbf{metodo tabellare di Quine-McCluskey}.\\
Ricapitolando, l'obiettivo di questa sezione √® quello di poter manipolare e gestire qualunque tipo di funzione logica, con qualunque numero di variabili.\\
Si consideri, per semplciit√†, la seguente funzione
\[f = (x + z) \cdot (\overline{x} + z)\]
di cui si espone, per chiarezza, la tavola di verit√† corrispondente nella Tabella \ref{tab:esempio_funzione_boolena}:

\begin{table}[H]
  \centering
  \begin{tabular}{ccc|c}
    $x$ & $y$ & $z$ & $f = (x + z) \cdot (\overline{x} + z)$\\
    \hline
    $0$ & $0$ & $0$ & $0$\\
    $0$ & $0$ & $1$ & $0$\\
    $0$ & $1$ & $0$ & $1$\\
    $0$ & $1$ & $1$ & $1$\\
    $1$ & $0$ & $0$ & $0$\\
    $1$ & $0$ & $1$ & $1$\\
    $1$ & $1$ & $0$ & $0$\\
    $1$ & $1$ & $1$ & $1$\\
  \end{tabular}
  \caption{Esempio di funzione booleana}
  \label{tab:esempio_funzione_boolena}
\end{table}

\noindent
Com'√® evidente, tale funzione assumer√† il valore in uscita \(1\) solamente in corrispondenza di specifiche terne di valori delle variabili in ingresso, ovvero \(010\), \(011\), \(101\) e \(111\) che prendono il nome di \textbf{termini minimi}, o \textbf{minterm}: ci√≤ consente di costruire la funzione considerata in principio a partire dalla somma logica di funzioni elementari, cio√® quelle funzioni che valgono \(1\) esattamente in corrispondenza di una e una sola configurazione d‚Äôingresso, precisamente quella che entra nella somma logica.\\
Per poter comporre in una funzione tali \textbf{minterm} bisogna sommarli logicamente, in modo tale che la funzione risultante produca il valore logico \(1\) solamente in una di tali \(4\) possibili casi (per la funzione oggetto di studio, ovviamente). La funzione di partenza, allora, si pu√≤ esprimere come somma di prodotti delle variabili d‚Äôingresso, nella forma
\[f = \overline{x}y\overline{z} + \overline{x}yz + x\overline{y}z + xyz\]
ovvero si √® costruita la \textbf{somma dei termini minimi}, ovvero una \textbf{somma logica dei \textit{minterm}}, ovverosia uan funzione che vale sempre \(0\), tranne che per le configurazioni per le quali vale \(1\). La \textbf{somma di \textit{minterm}} √® in grado di rappresentare una qualunque funzione logica. Infatti, la tecnica esposta pu√≤ essere generalizzata a qualunque funzione \(y = f(x_1, x_2, ..., x_n)\)
di \(n\) variabili, tenuto conto che i termini minimi \(m_i\) sono in tutto tanti quante sono le possibili configurazioni
d‚Äôingresso, cio√® \(2^n\). Se si codificano le $n$-ple d‚Äôingresso associate a ciascun termine minimo con il corrispondente
intero rappresentato in notazione posizionale in base 2, √® possibile indicare i termini minimi che compongono la
sommatoria usando gli interi compresi tra \(0\) e \(2^{n-1}\).\\
Pertanto la generica funzione si rappresenta come segue
\[f(x_1, x_2, ..., x_n) = \underset{i = 0}{\overset{2^n - 1}{\sum}} \mu_i m_i = \underset{i: \mu_i = 1}{\sum} m_i\]
dove \(\mu_i\) √® il valore assunto dalla funzione in corrispondenza del termine minimo \(m_i\) e \(0 \leq i \leq 2^n -1\).\\
Nel caso analizzato, si ha \(m_2 = \overline{x}y\overline{z}, m_3 = \overline{x}yz, m_5 = x\overline{y}z, m_7 = xyz, \mu_2 = \mu_3 = \mu_5 = \mu_7 = 1, \mu_0 = \mu_1 = \mu_4 = \mu_6 = 0\).\\
La sommatoria cos√¨ ottenuta rappresenta la funzione nei termini della cosiddetta \textbf{prima forma canonica} (o \textbf{somma di prodotti}). Se nella tavola di verit√† della funzione si pone in evidenza la codifica dei termini minimi si ottiene:

\begin{table}[H]
  \centering
  \begin{tabular}{c|c||ccc||c|c}
    $ $ & $ $ & $x$ & $y$ & $z$ & $f$\\
    \hline
    $m_0$ & $\overline{x}\overline{y}\overline{z}$ & $0$ & $0$ & $0$ & $0$ & $\mu_0$\\
    $m_1$ & $\overline{x}\overline{y}z$ & $0$ & $0$ & $1$ & $0$ & $\mu_1$\\
    $m_2$ & $\overline{x}y\overline{z}$ & $0$ & $1$ & $0$ & $1$ & $\mu_2$\\
    $m_3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$ & $\mu_3$\\
    $m_4$ & $x\overline{y}\overline{z}$ & $1$ & $0$ & $0$ & $0$ & $\mu_4$\\
    $m_5$ & $x\overline{y}z$ & $1$ & $0$ & $1$ & $1$ & $\mu_5$\\
    $m_6$ & $xy\overline{z}$ & $1$ & $1$ & $0$ & $0$ & $\mu_6$\\
    $m_7$ & $xyz$ & $1$ & $1$ & $1$ & $1$ & $\mu_7$\\
  \end{tabular}
  \caption{Codifica dei termini minimi}
  \label{tab:codifica_termini_minimi}
\end{table}

\noindent
Per cui si ottiene
\[f(x, y, z) = \sum_{i \in \{2, 3, 5, 7\}} m_i = m_2 + m_3 + m_5 + m_7 = \overline{x}y\overline{z} + \overline{x}yz + x\overline{y}z + xyz\]
poich√© \(2, 3, 5\) e \(7\) sono le codifiche in base \(2\) di \(010, 011, 101\) e \(111\).

\vspace{1em}
\subsection{Forme canoniche: \textit{maxterm}}
Un discorso del tutto analogo si pu√≤ formulare procedendo per dualit√†, e realizzando un \textbf{prodotto di somme}. Ci√≤ richiede di analizzare i termini per i quali la funzione vale 0; dalla Tabella \ref{tab:esempio_funzione_boolena} si osserva che ci√≤ accade in corrispondenza delle terne \(000, 001, 100\) e \(110\), cio√® \(0, 1, 4\) e \(6\) con la codifica impiegata in precedenza.\\
L‚Äôidea √® quella di esprimere il valore della funzione come prodotto di somme che sono sempre a 1, tranne che per una singola configurazione che le manda a 0; una funzione che soddisfa tale condizione (ossia vale sempre 1, tranne che per una singola configurazione per la quale vale 0) si chiama \textbf{termine massimo} (o \textbf{\textit{maxterm}}), e viene indicata con \(M_i\).\\
Il modo pi√π semplice per esprimere un termine massimo √® quello di ricorrere alla somma logica di variabili dirette e negate, le prime in corrispondenza delle variabili che in ingresso valgono 0, le seconde in corrispondenza delle variabili che in ingresso valgono 1.\\
Tenendo presente quanto gi√† esposo, si perviene alla \textbf{seconda forma canonica} (o \textbf{prodotti di somme}), nella quale la generica funzione si rappresenta come
\[f(x_1, x_2, ..., x_n) = \prod_{i = 0}^{2^n - 1} (\mu_i + M_i) = \prod_{i : \mu_i = 0} M_i\]
dove \(0 \leq i \leq 2^n - 1\), mentre \(\mu_i\) √® il valore della funzione in corrispondenza del termine massimo \(M_i\), il quale si codifica secondo la procedura prima descritta: nel caso analizzato si ha \(M_0 = x + y + z, M_1 = x + y + \overline{z}, M_4 = \overline{x} + y + z, M_6 = \overline{x} + \overline{y} + z\) e cos√¨ via.\\
Se nella tavola di verit√† della funzione si pone in evidenza la codifica dei termini massimi si ottiene:

\begin{table}[H]
  \centering
  \begin{tabular}{c|c||ccc||c|c}
    $ $ & $ $ & $x$ & $y$ & $z$ & $f$\\
    \hline
    $M_0$ & $x + y + z$ & $0$ & $0$ & $0$ & $0$ & $\mu_0$\\
    $M_1$ & $x + y + \overline{z}$ & $0$ & $0$ & $1$ & $0$ & $\mu_1$\\
    $M_2$ & $x + \overline{y} + z$ & $0$ & $1$ & $0$ & $1$ & $\mu_2$\\
    $M_3$ & $x + \overline{y} + \overline{z}$ & $0$ & $1$ & $1$ & $1$ & $\mu_3$\\
    $M_4$ & $\overline{x} + y + z$ & $1$ & $0$ & $0$ & $0$ & $\mu_4$\\
    $M_5$ & $\overline{x} + y + \overline{z}$ & $1$ & $0$ & $1$ & $1$ & $\mu_5$\\
    $M_6$ & $\overline{x} + \overline{y} + z$ & $1$ & $1$ & $0$ & $0$ & $\mu_6$\\
    $M_7$ & $\overline{x} + \overline{y} + \overline{z}$ & $1$ & $1$ & $1$ & $1$ & $\mu_7$\\
  \end{tabular}
  \caption{Codifica dei termini minimi}
  \label{tab:codifica_termini_minimi}
\end{table}

\noindent
Per cui si ottiene
\[f(x, y, z) = \prod_{i \in \{0, 1, 4, 6\}} M_i = M_0 \cdot M_1  \cdot M_4 \cdot M_6 = (x + y + z) \cdot (x + y + \overline{z}) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{y} + z)\]
poich√© \(0, 1, 4\) e \(6\) sono le codifiche in base \(2\) di \(000, 001, 100\) e \(110\).\\
La realizzazione operativa delle funzioni di cui sopra (\emph{somma di minterm} e \emph{prodotto di maxterm}) mediante porte AND, OR, NOT e basata sui circuiti di Tabella \ref{tab:somme_minterm_prodotti_maxterm_circuito}. Poich√® ogni porta AND, OR a $n$ ingressi richiede $n - 1$ porte a $2$ ingressi, per il circuito rappresentante somme di prodotti servono \(2 \cdot 4 = 8\) porte AND e $3$ porte OR a $2$ ingressi; per l‚Äôaltro circuito, rappresentante prodotti di somme, servono \(2 \cdot 4 = 8\) porte
OR e $3$ porte AND a $2$ ingressi; in entrambi i casi servono dunque $11$ porte a $2$ ingressi:

% Contenitore per immagini
\rowcolors{1}{white}{white}
\noindent
\begin{table}[H]
    \centering
    \noindent
    \begin{tabularx}{\textwidth}{PP} {
        \begin{tikzpicture}
          % Variabili
          \coordinate (x) at (0,0);
          \coordinate (y) at (0.5,0);
          \coordinate (z) at (1,0);

          % Porte logiche
          \node [and gate US, draw, logic gate inputs=ini] (and1) at (2,-1){};
          \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=inn] (and2){};
          \node [and gate US, draw, below=of and2, yshift=5.5mm, logic gate inputs=nin] (and3){};
          \node [and gate US, draw, below=of and3, yshift=5.5mm, logic gate inputs=nnn] (and4){};
          \node [or gate US, draw, right=of and2, xshift=7mm, yshift=-5mm, logic gate inputs=nnnn] (or){};

          % INPUT
          \draw (x) ++(0,-5) -- node[at end, above]{$x$} (x);
          \draw (y) ++(0,-5) -- node[at end, above]{$y$} (y);
          \draw (z) ++(0,-5) -- node[at end, above]{$z$} (z);

          % AND 1
          \draw (and1.input 1) -- (and1.input 1 -| x) node [branch]{};
          \draw (and1.input 2) -- (and1.input 2 -| y) node [branch]{};
          \draw (and1.input 3) -- (and1.input 3 -| z) node [branch]{};

          % AND 2
          \draw (and2.input 1) -- (and2.input 1 -| x) node [branch]{};
          \draw (and2.input 2) -- (and2.input 2 -| y) node [branch]{};
          \draw (and2.input 3) -- (and2.input 3 -| z) node [branch]{};

          % AND 3
          \draw (and3.input 1) -- (and3.input 1 -| x) node [branch]{};
          \draw (and3.input 2) -- (and3.input 2 -| y) node [branch]{};
          \draw (and3.input 3) -- (and3.input 3 -| z) node [branch]{};

          % AND 4
          \draw (and4.input 1) -- (and4.input 1 -| x) node [branch]{};
          \draw (and4.input 2) -- (and4.input 2 -| y) node [branch]{};
          \draw (and4.input 3) -- (and4.input 3 -| z) node [branch]{};

          % OUTPUT
          \draw (and1.output) node [above right] {{$\overline{x}y\overline{z}$}} -- ([xshift=1.1cm] and1.output) |- (or.input 1);
          \draw (and2.output) node [above right] {{$\overline{x}yz$}} -- ([xshift=0.9cm] and2.output) |- (or.input 2);
          \draw (and3.output) node [above right] {{$x\overline{y}z$}} -- ([xshift=0.9cm] and3.output) |- (or.input 3);
          \draw (and4.output) node [above right] {{$xyz$}} -- ([xshift=1.1cm] and4.output) |- (or.input 4);
          \draw (or.output) -- ([xshift=0.3cm] or.output);
        \end{tikzpicture}
    } & {
        \begin{tikzpicture}
          % Variabili
          \coordinate (x) at (0,0);
          \coordinate (y) at (0.5,0);
          \coordinate (z) at (1,0);

          % Porte logiche
          \node [or gate US, draw, logic gate inputs=nnn] (or1) at (2,-1){};
          \node [or gate US, draw, below=of or1, yshift=5.5mm, logic gate inputs=nni] (or2){};
          \node [or gate US, draw, below=of or2, yshift=5.5mm, logic gate inputs=inn] (or3){};
          \node [or gate US, draw, below=of or3, yshift=5.5mm, logic gate inputs=iin] (or4){};
          \node [and gate US, draw, right=of or2, xshift=14mm, yshift=-5mm, logic gate inputs=nnnn] (and){};

          % INPUT
          \draw (x) ++(0,-5) -- node[at end, above]{$x$} (x);
          \draw (y) ++(0,-5) -- node[at end, above]{$y$} (y);
          \draw (z) ++(0,-5) -- node[at end, above]{$z$} (z);

          % OR 1
          \draw (or1.input 1) -- (or1.input 1 -| x) node [branch]{};
          \draw (or1.input 2) -- (or1.input 2 -| y) node [branch]{};
          \draw (or1.input 3) -- (or1.input 3 -| z) node [branch]{};

          % OR 2
          \draw (or2.input 1) -- (or2.input 1 -| x) node [branch]{};
          \draw (or2.input 2) -- (or2.input 2 -| y) node [branch]{};
          \draw (or2.input 3) -- (or2.input 3 -| z) node [branch]{};

          % OR 3
          \draw (or3.input 1) -- (or3.input 1 -| x) node [branch]{};
          \draw (or3.input 2) -- (or3.input 2 -| y) node [branch]{};
          \draw (or3.input 3) -- (or3.input 3 -| z) node [branch]{};

          % OR 4
          \draw (or4.input 1) -- (or4.input 1 -| x) node [branch]{};
          \draw (or4.input 2) -- (or4.input 2 -| y) node [branch]{};
          \draw (or4.input 3) -- (or4.input 3 -| z) node [branch]{};

          % OUTPUT
          \draw (or1.output) node [above right] {{$x + y + z$}} -- ([xshift=1.9cm] or1.output) |- (and.input 1);
          \draw (or2.output) node [above right] {{$x + y + \overline{z}$}} -- ([xshift=1.7cm] or2.output) |- (and.input 2);
          \draw (or3.output) node [above right] {{$\overline{x} + y + z$}} -- ([xshift=1.7cm] or3.output) |- (and.input 3);
          \draw (or4.output) node [above right] {{$\overline{x} + \overline{y} + z$}} -- ([xshift=1.9cm] or4.output) |- (and.input 4);
          \draw (and.output) -- ([xshift=0.3cm] and.output);
        \end{tikzpicture}
    }\\
    \end{tabularx}
    \caption{Porte NOT, AND e OR per realizzare la funzione studiata secondo \emph{minterm} e \emph{maxterm}}
    \label{tab:somme_minterm_prodotti_maxterm_circuito}
\end{table}

\noindent
\textbf{Osservazione}: Naturalmente la \emph{somma di prodotti} e il \emph{prodotto di somme} rappresentano la stessa funzione, come si pu√≤ verificare facilmente.\\
Infatti, prendendo in considerazione la somma di prodotti, impiegando gli assiomi e i teoremi introdotti in precedenza, si perviene facilmente al risultato seguente:
\[\overline{x}y\overline{z} + \overline{x}yz + x\overline{y}z + xyz \overset{(A6)}{=} \overline{x}y(\overline{z} + z) + xz(\overline{y} + y) \overset{(A7)}{=} \overline{x}y \cdot 1 + xz \cdot 1 \overset{(A3)}{=} \overline{x}y + xz\]
Se, invece, si considera il prodotto di somme si ottiene:
\[(x + y + z) \cdot (x + y + \overline{z}) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{y} + z) \overset{(T9)}{=} (x + y) \cdot (\overline{x} + z) \overset{(T10)}{=} \overline{x}z + xz\]
In questo caso si √® ottenuta la medesima espressione, anche dal punto di vista formale, ma potrebbe accadere che, con funzioni pi√π complesse e, con un maggior numero di variabili si ottenga un risultato logicamente equivalente, ma formalmente differente. A tal proposito, sempre sfruttando i teoremi precedentemente esplicati, si dovr√† dimostrare che sono equivalenti anche formalmente.\\
A seguito della semplificazione, tuttavia, la complessit√† del circuito associato alla funzione si riduce drasticamente, come si pu√≤ notare dalla Figura \ref{fig:circuito_semplificato}; servono in tutto \(3\) porte a \(2\) ingressi al posto di \(11\) porte a \(2\) ingressi.\\

\begin{figure}[H]
    \centering
    \scalebox{1.2}{
        \begin{tikzpicture}[circuit logic US, scale=1]
          % Variabili
          \coordinate (x) at (0,0);
          \coordinate (y) at (0.5,0);
          \coordinate (z) at (1,0);

          % Porte logiche
          \node [and gate US, draw, logic gate inputs=in] (and1) at (2,-1){};
          \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=nn] (and2){};
          \node [or gate US, draw, right=of and1, xshift=3mm, yshift=-4.5mm, logic gate inputs=nn] (or){};

          % INPUT
          \draw (x) ++(0,-2.5) -- node[at end, above]{$x$} (x);
          \draw (y) ++(0,-2.5) -- node[at end, above]{$y$} (y);
          \draw (z) ++(0,-2.5) -- node[at end, above]{$z$} (z);

          % AND 1
          \draw (and1.input 1) -- (and1.input 1 -| x) node [branch]{};
          \draw (and1.input 2) -- (and1.input 2 -| y) node [branch]{};

          % AND 2
          \draw (and2.input 1) -- (and2.input 1 -| x) node [branch]{};
          \draw (and2.input 2) -- (and2.input 2 -| z) node [branch]{};

          % OUTPUT
          \draw (and1.output) node [above right] {{$\overline{x}y$}} -- ([xshift=0.7cm] and1.output) |- (or.input 1);
          \draw (and2.output) node [above right] {{$xz$}} -- ([xshift=0.7cm] and2.output) |- (or.input 2);
          \draw (or.output) -- ([xshift=0.3cm] or.output);
        \end{tikzpicture}
    }
    \caption{Circuito semplificato equivalente ai circuiti precedenti}
    \label{fig:circuito_semplificato}
\end{figure}

\noindent
La semplificazione certamente apporta vantaggi enormi alla rete logica ottenuta, in quanto viene \textbf{ridotta la dissipazione} (che comunque non sar√† mai nulla), cos√¨ come si \textbf{riduce la probabilit√† di un guasto alla rete}, grazie alla minor quantit√† di componenti impiegati nella sua realizzazione: naturalmente, infatti, maggiore √® il numero di porte, maggiori saranno le transizioni a cui la rete logica sar√† soggetta; ad ogni transizione corrisponde una commutazione di stato del transistor, e quindi per una frazione di secondo si avr√† sia tensione che corrente e quindi si rilevano dei picchi di dissipazione deleteri per le componenti circuitali.\\
La \emph{somma di prodotti} e il \emph{prodotto di somme}, che portano entrambe alla forma semplificata \(\overline{x}y + xz\) per la funzione appena analizzata, aprono il problema della ricerca della forma algebrica minima, che consenta, cio√®, di realizzare la funzione usando il minimo numero possibile di porte logiche.\\
Si osservi inoltre che √® sempre possibile passare dal prodotto di somme alla somma di prodotti e viceversa, sfruttando il Teorema di De Morgan (¬ß \ref{sec:teorema_de_morgan}), a partire dalla doppia negazione T3
\begin{align*}
  \overline{\overline{(x + y + z) \cdot (x + y + \overline{z}) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{y} + z)}} \overset{(T7)}{=}\\
  \overset{(T7)}{=} \overline{\overline{(x + y + z)} + \overline{(x + y + \overline{z})} + \overline{(\overline{x} + y + z)} + \overline{(\overline{x} + \overline{y} + z)}} \overset{(T7)}{=} \overline{\overline{x} \overline{y} \overline{z} + \overline{x} \overline{y} z + x \overline{y} \overline{z} + x y \overline{z}}
\end{align*}
La semplificazione si pu√≤ a questo punto concludere nel modo seguente
\begin{align*}
  \overline{\overline{x} \overline{y} \overline{z} + \overline{x} \overline{y} z + x \overline{y} \overline{z} + x y \overline{z}} \overset{(A6)}{=} \overline{\overline{x} \overline{y}(z + \overline{z}) + x \overline{z}(y + \overline{y})} \overset{(A7)}{=} \overline{\overline{x} \overline{y} + x \overline{z}} \overset{(T7)}{=} \overline{\overline{x} \overline{y}} \cdot \overline{x \overline{z}} \overset{(T7)}{=}\\
  \overset{(T7)}{=} (x + y) \cdot (\overline{x} + z) \overset{(T10)}{=} \overline{x}y + xz
\end{align*}

\vspace{1em}
\subsection{Interpretazione circuitale}
Come gi√† accennato in precedenza, la prima applicazione circuitale dell‚ÄôAlgebra Booleana si deve a Shannon, che la us√≤ nella progettazione di circuiti complessi per la commutazione a contatti. Questo tipo di applicazione √® ancora largamente usata, anche se i contatti dei rel√® sono oggi sostituiti da dispositivi a stato solido (SCR, TRIAC). Tuttavia l‚Äôimportanza dell‚ÄôAlgebra Booleana √® legata soprattutto all‚Äôimpiego nell‚Äôambito dei circuiti logici, il cui peso e oggid√¨ preponderante.\\
Nello stesso periodo di Shannon, Bush stava progettando un calcolatore analogico che venne utilizzato per la risoluzione di equazioni differenziali mediante la progettazione di circuiti di resistenze retti proprio dall'equazione differenziale di interesse. L'evoluzione del circuito, poi, avrebbe permesso di rilevare tutte le soluzioni dell'equazione analizzata.\\
Nell'interpretazione di Shannon le costanti logiche \(0\) e \(1\) indicano rispettivamente un circuito aperto o uno chiuso (mediante, per esempio, un interruttore), mentre le variabili indicano il contatto di un interrutore o di un rel√®.\\
Con i simboli \(x\) e \(\overline{x}\) si indicano due contati azionati contemporaneamente, me sempre tali che quando uno √® aperto, l'altro √® chiuso e viceversa. Si consideri, ora un assieme di contatti \(x_1, x_2, ..., x_n\) in parallelo tra loro, come illustrato in Figura \ref{fig:contatti_parallelo}:

\begin{figure}[H]
    \centering
    \scalebox{1.2}{
        \begin{tikzpicture}[circuit logic US, scale=1]
          % Variabili
          \coordinate (start) at (0,0);

          \draw (start) -- ++(1,0) node [branch](dot){} -- ++(0,1) |- ++(1,0) node[at end, above left]{$x_1$} node [branch]{} -- ++(0.5,0.5) ++(0,-0.5) node [branch]{} -- ++(1,0) -- ++(0,-1) node [branch]{} -- ++(1,0);

          \draw (dot) ++(0,0.3) |- ++(1,0) node[at end, above left]{$x_2$} node [branch](etc){} -- ++(0.5,0.5) ++(0,-0.5) node [branch]{} -- ++(1,0);

          \draw (etc) ++(0,-0.35) node[]{$\cdot$};
          \draw (etc) ++(0,-0.45) node[]{$\cdot$};
          \draw (etc) ++(0,-0.85) node[]{$\cdot$};
          \draw (etc) ++(0,-0.95) node[]{$\cdot$};

          \draw (dot) -- ++(0,-1) |- ++(1,0) node[at end, above left]{$x_n$} node [branch]{} -- ++(0.5,0.5) ++(0,-0.5) node [branch]{} -- ++(1,0) -- ++(0,1);

        \end{tikzpicture}
    }
    \caption{$n$ contatti in parallelo realizzano la funzione Booleana \(x_1 + x_2 + ... + x_n\)}
    \label{fig:contatti_parallelo}
\end{figure}

\noindent
Il circuito presentera continuit√† elettrica tra i punti $a$ e $b$ quando almeno uno dei contatti √® chiuso. Ne consegue che la somma logica
\[x_1 + x_2 + .. + x_n\]
descrive, secondo l‚Äôanalogia di Shannon, il comportamento elettrico di $n$ contatti in parallelo.
Se invece i contatti \(x_1, x_2, ..., x_n\) sono in serie tra loro, come illustrato in Figura \ref{fig:contatti_serie}:

\begin{figure}[H]
    \centering
    \scalebox{1.2}{
        \begin{tikzpicture}[circuit logic US, scale=1]
          % Variabili
          \coordinate (start) at (0,0);

          \draw (start) -- ++(1,0) node[at end, above left]{$x_1$} node [branch]{} -- ++(0.5,0.5) ++(0,-0.5) node [branch]{} -- ++(1,0) node[at end, above left]{$x_2$} node [branch]{} -- ++(0.5,0.5) ++(0,-0.5) node [branch]{} -- ++(1,0) coordinate(a);
          \draw [dashed] (a) -- ++(1,0);
          \draw (a) ++(1,0) -- ++(1,0) node[at end, above left]{$x_n$} node [branch]{} -- ++(0.5,0.5) ++(0,-0.5) node [branch]{} -- ++(1,0);
        \end{tikzpicture}
    }
    \caption{$n$ contatti in serie realizzano la funzione Booleana \(x_1 \cdot x_2 \cdot ... \cdot x_n\)}
    \label{fig:contatti_serie}
\end{figure}

\noindent
il circuito presenter√† continuit√† elettrica tra i punti $a$ e $b$ solo quando tutti i contatti sono chiusi. Ne consegue che il prodotto logico
\[x_1 \cdot x_2 \cdot ... \cdot x_n\]
descrive, secondo l‚Äôanalogia di Shannon, il comportamento elettrico di $n$ contatti in serie.\\
L‚Äôassociazione tra stato di apertura di un contatto e variabile Booleana apre alla possibilit√† di progettare reti complesse ricorrendo all‚ÄôAlgebra Booleana.\\
Pertanto, se si pongono degli interruttori in parallelo, si ottiene un circuito che simula una porta logica OR, mentre se gli interrutori vengono posti in serie si ottiene un circuito perfettamemte equivalente ad una porta logica AND.\\
La stessa cosa accade con un circuito deviatore che permette di ottenere la negazione di una variabile.\\
In questo modo √® possibile esprimere una funzione logica complicata che sia attraverso la realizzazione di un circuito equivalente, e viceversa.

\newpage
\begin{center}
    13 Ottobre 2021
\end{center}

\subsection{Riassunto}
√à stata precedentemente introdotta una duplice modalit√† per manipolare le espressioni logiche, ovvero la \textbf{prodotto dei termini massimi} (o \textit{maxterm}, che valgono sempre \(1\), tranne che per una sola combinazione per cui valgono \(0\)) e \textbf{somma dei termini minimi} (o \textit{minterm}, che valgono sempre \(0\) tranne che per una sola combinazione per la quale valgono \(1\)).\\
Naturalmente, le espressioni sono \textbf{mutuamente escludenti}, per cui √® chiaro che in ambedue i casi, sia che si considerino i \emph{maxterm} o i \emph{minterm}, in ingresso si pu√≤ presentare solamente una combinazione possibile, ossia uno solo dei \textit{minterm} (o \textit{maxterm}) individuati.\\
Il discernimento tra una o l'altra configurazione √® assolutamente ininfluente: certo √® che, se la funzione logica da semplificare assume un numero maggiore \(1\) rispetto allo \(0\), allora sar√† pi√π conveniente procedere alla trasformazione della funzione in \textbf{prodotti di somme}, o di \textit{maxterm}.\\
Naturalmente, per√≤, come si √® detto, i due procedimenti conducono al medesimo risultato, pertanto sar√† sempre possibile ricondurre una somma di \textit{minterm} ad un prodotto di \textit{maxterm} e viceversa. √à chiaro che √® possibile che vi siano pi√π forme minime equivalenti, che differiscono solamente dal punto di vista formale: in tale circostanza, un procedimento atto a passare dal prodotto di somme alla somma di prodotti e viceversa, √® proprio il Teorema di De Morgan (¬ß \ref{sec:teorema_de_morgan}) a partire dalla doppia negazione T3.

\vspace{1em}
\noindent
\textbf{Osservazione}: L'interpretazione circuitale dell'algebra booleana si deve a Claude Shannon, il quale osserv√≤, molto semplicemente che:

\begin{itemize}
    \item Interruttori posti in serie simulano il funzionamento di una porta AND;
    \item Interruttori posti in parallelo simulano il funzionamento di una porta OR;
    \item Un deviatore permette di simulare il funzionamento di una porta NOT;
\end{itemize}

\vspace{1em}
\noindent
\textbf{Esempio 1}: Tale osservazione pu√≤ avere dei risvolti particolarmente interessanti dal punto di vista pratico. Si consideri, come esempio concreto, il problema seguente: in un appartamento c‚Äôe un corridoio; quando si entra si vuole accendere la luce dall‚Äôinterruttore \(x\) prossimo all‚Äôingresso, sulla destra. Uscendo, invece, si vuole spegnere la luce dall‚Äôinterruttore \(y\) prossimo all‚Äôuscita sulla sinistra.\\
Dal momento che si hanno due variabili binarie \(x\) e \(y\), √® possibile costruire una tavola di verit√† che permetta di rappresentare tutti i possibili stati della luce (accesa o spenta) in funzione del valore delle variabili in ingresso, come illustrato nella Tabella \ref{tab:circuito_comando_luce_due_punti_e_tavola_verita} seguente:

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{PP}
      {
          \begin{circuitikz}[]
            \draw (1,0) node[draw,minimum width=5mm,minimum height=5mm](x){$x$} ++(1,0) node[draw,minimum width=5mm,minimum height=5mm](y){$y$} ++(1,0) ++(0,-1) node[lampshape](L){\hspace{4em}$L$};
            \draw (0,0) -- (x.west) (x.east) -- (y.west) (y.east) -| (L.north) (L.south) -- ++(0,-0.6) -- ++(-3,0);
          \end{circuitikz}
      } & {
          \begin{tabular}{cc|c}
               \(x\) & \(y\) & \(L\)\\
               \hline
               \(0\) & \(0\) & \(0\)\\
               \(0\) & \(1\) & \(1\)\\
               \(1\) & \(0\) & \(1\)\\
               \(1\) & \(1\) & \(0\)\\
          \end{tabular}
      }
    \end{tabularx}
    \caption{Circuito di comando di una luce da due punti e relativa tavola di verit√†}
    \label{tab:circuito_comando_luce_due_punti_e_tavola_verita}
\end{table}

\noindent
Naturalmente, ciascuno dei due interruttori pu√≤ trovarsi in una sola tra due posizioni, che vengono associate alle due variabili $0$ e $1$. Anche la luce $L$ pu√≤ essere spenta ($0$) o accesa ($1$). Ecco allora che la tavola di verit√† appena costruita presenta due variabili d‚Äôingresso ($x$ e $y$) e una variabile $L$ che assumera dei valori che sono funzione di $x$ e $y$; si √®, cos√¨, ottenuta una funzione Booleana \(f : 2^2 \rightarrow 2\).\\
Ovviamente, entrando in corridoio con la luce ancora spenta e supponendo entrambi gli interruttori nello stato $0$, la luce $L$ sar√† ancora spenta; pertanto, a questa configurazione d‚Äôingresso corrisponde $L = 0$. Se, invece, si entra in corridoio da sinistra, all‚Äôatto di accendere la luce, viene commutata la posizione dell‚Äôinterruttore $x$, che passa da $0$ a $1$; in corrispondenza la luce deve accendersi, e dunque alla coppia $01$ corrisponde $L = 1$. Uscendo dal corridoio a destra si muove l‚Äôinterruttore $y$, che comanda lo spegnimento della luce; e dunque a $11$ corrisponde $L = 0$. La configurazione che manca, $01$, √® quella che si viene a creare quando si entra in corridoio da destra con la luce spenta e si muove l‚Äôinterruttore; dunque a $01$ corrisponde $L = 1$.\\
Si proceda, ora, alla traduzione di tale funzione logica in forma canonica. Pertanto, tale funzione espressa come \textbf{somma di \textit{mintern}}:
\[\overline{x}y + x\overline{y}\]
che, dal punto di vista circuitale, corrisponde ad un circuito in parallelo con due deviatori, dimodoch√© sia soddisfatta la funzione logica di partenza, come illustrato di seguito:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{circuitikz}[]
      \draw (0,0) -- ++(1,0) node[circ](start){} -- ++(0.5,0.5) node[circ]{} -- ++(0,0.5) -- ++(1,0) -- ++(0,-0.5) node[circ]{} ++(0.5,-0.5) node[circ](end){} -- ++(1,0) coordinate(a) ++(0,-1) node[lampshape](L){\hspace{4em}$L$} (L.north) -- (a) (L.south) -- ++(0,-0.6) -- ++(-4,0);
      \draw (start) ++(0.5,-0.5) node[circ]{} -- ++(0,-0.5) -- ++(1,0) -- ++(0,0.5) node[circ]{} -- (end);
      \draw (start) ++(0,0.5) node[]{$\overline{x}$} (start) ++(0,-0.5) node[]{$x$} (end) ++(0,0.5) node[]{$\overline{y}$} (end) ++(0,-0.5) node[]{$y$};
    \end{circuitikz}
    \caption{Gli interruttori $x$ e $y$ che risolvono il problema dell‚Äôaccensione della luce nel corridoio sulla base della prima forma canonica}
    \label{fig:interruttori_prima_forma_canonica}
\end{figure}

\noindent
Mentre come \textbf{prodotto di \textit{maxterm}}:
\[(\overline{x} + \overline{y}) \cdot (x + y)\]
che, dal punto di vista circuitale, corrisponde ad un circuito in serie, in cui sono sempre presenti due deviatori, come mostrato nella Figura \ref{fig:interruttori_seconda_forma_canonica}:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{circuitikz}[]
      \draw (0,0) -- ++(1,0) node[circ](start){} -- ++(0,0.75) -- ++(0.5,0) node[circ](a){} ++(1,0) node[circ](b){} -- ++(0.5,0) -- ++(0,-0.75) node[circ](end){} -- ++(1,0) coordinate(n) ++(0,-1) node[lampshape](L){\hspace{4em}$L$} (L.north) -- (n) (L.south) -- ++(0,-0.6) -- ++(-4,0);
      \draw (start) -- ++(0,-0.75) -- ++(0.5,0) node[circ](c){} ++(1,0) node[circ](d){} -- ++(0.5,0) -- (end) ++(-1,0.25) node[circ]{} -- ++(0.5,0.5) ++(-0.5,-0.5) -- ++(0,-0.5) node[circ]{} -- ++(0.5,-0.5);
      \draw (a) ++(-0.25,0.25) node[]{$x$} (b) ++(0.25,0.25) node[]{$\overline{x}$} (c) ++(-0.25,-0.25) node[]{$y$} (d) ++(0.25,-0.25) node[]{$\overline{y}$};
    \end{circuitikz}
    \caption{Gli interruttori $x$ e $y$ che risolvono il problema dell‚Äôaccensione della luce nel corridoio sulla base alla seconda forma canonica}
    \label{fig:interruttori_seconda_forma_canonica}
\end{figure}

\noindent
Tuttavia, tale soluzione non √® conveniente, in quanto si necessita di un un cavo in pi√π per la connessione tra i due deviatori.

\vspace{1em}
\noindent
\textbf{Osservazione}: La realizzazione mediante interruttori consente di incarnare la funzione Booleana direttamente al livello base dei circuiti di commutazione, in modo tale che ogni variabile Booleana sia immersa nel circuito; quella basata sulla porta XOR costituisce invece una sorta di interfaccia tra variabili d‚Äôingresso, che determinano il comportamento del circuito, e la variabile d‚Äôuscita, che deve comandare la lampadina.\\
Questo secondo approccio √® concettualmente pi√π elegante, ma soprattutto consente di svincolare il carico dalla rete logica. Se infatti il carico assorbe molta corrente, tutti gli interruttori della rete dovranno essere
dimensionati di conseguenza; ci√≤ potrebbe essere poco funzionale, visto che gli interruttori in grado di gestire correnti maggiori sono piu grossi, costosi e pi√π difficili da azionare. Usando invece un circuito simile a quello di Figura \ref{fig:controllo_lampadina_mediante_rete_logica} solo l‚Äôinterruttore del rel√© deve essere dimensionato in modo tale da poter gestire la corrente del carico; gli altri due deviatori, relativi ai due comandi $x$ e $y$, possono essere anche a bassa corrente.

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{circuitikz}[]
      \draw (0,1) node[circ](start){} ++(0,1) node[circ]{} -- ++(0,1) -- ++(1,0) node[circ](a){} -- ++(6.5,0) node[circ](b){} -- ++(0,1) node[circ]{} ++(0,0.5) node[]{$+V_{CC}$} (b) ++(0,-1.3) node[cutechokeshape, rotate=-90](L){} (b) -- (L) ++(0,-1.5) node[npn, tr circle](Q1){} (L) -- (Q1.C) (Q1.E) -- ++(0,-1.5) -- ++(-6.5,0) node[circ](c){} -- ++(-1,0) -- (start) (c) -- ++(0,-0.1) node[ground](GND){} (c) -- ++(0,0.5) node[circ]{} ++(0,1) node[circ]{} -- (a);
      \draw (0,1) ++(0,1) -- ++(0.5,-0.5) node[circ](x){} ++(-0.2,0.5) node[]{$x$};
      \draw (c) ++(0,1.5) -- ++(0.5,-0.5) node[circ](y){} ++(-0.2,0.5) node[]{$y$};
      \draw (Q1.B) ++(-0.7,0) node[ieeestd or port, xscale=0.7, yscale=0.7](or){} (or.out) -- (Q1.B);
      \draw (x) ++(2.5,0) node[ieeestd and port, xscale=0.7, yscale=0.7, anchor=in 1](and1){} (x) -- (and1.in 1);
      \node at (and1.bin 2) [ocirc, left]{};
      \draw (y) ++(1.5,0) node[ieeestd and port, xscale=0.7, yscale=0.7, anchor=in 2](and2){} (y) -- (and2.in 2);
      \node at (and2.bin 1) [ocirc, left]{};
      \draw (y) ++(0.5,0) node[circ]{} |- (and1.in 2);
      \draw (x) ++(2,0) node[circ]{} |- (and2.in 1);
      \draw (and1.out) |- (or.in 1) (and2.out) |- (or.in 2);
      \draw (b) ++(1,0) -- ++(0,-0.8) node[circ]{} -- ++(0.5,-0.5) ++(-0.5,-0.5) node[circ](d){} (c) ++(7.5,0) -- (d);
      \draw (b) ++(1,0) -- ++(2,0) coordinate(e) ++(0,-1.8) node[lampshape](La){\hspace{4em}$L$} (La.north) -- (e) (La.south) -- ++(0,-1) node[circ]{} ++(0,-0.5) node[]{$220$V} ++(0,-0.5) node[circ](f){} (c) ++(7.5,0) -- ++(2,0) -- (f);
      \draw [dashed] (d) ++(0.5,0.5) -- ++(-2,0);
    \end{circuitikz}
    \caption{Controllo di una lampadina di potenza mediante una rete logica asservita a un transistor che controlla rel√©}
    \label{fig:controllo_lampadina_mediante_rete_logica}
\end{figure}

\noindent
Si noti che nel circuito l‚Äôuscita della porta OR controlla direttamente la base di un transistor; quando l‚Äôuscita OR va a $1$, il transistor entra
in saturazione, la $V_{CE}$ crolla al valore di saturazione e tutta la tensione $V_{CC}$ di alimentazione va sul rel√©, che, commutando, chiude il circuito d‚Äôuscita e accende la lampadina.\\
Pertanto, come si √® detto, in questo caso si palesa la necessit√† di prevedere l'adeguamento degli interruttori in funzione della tipologia di carico da azionare.\\
Infatti, quando le lamine dei conduttori vengono poste a contatto, per quanto possa essere irrilevante, si ha una resistenza  di contatto che comporta la dissipazione di potenza. Ma non solo, quando le lamine vengono avvicinate per la chiusura del contatto, si ha una \textbf{carica disruttiva} che comporta la generazione di una scarica elettrica che, con successivi e multipli utilizzi, determina un danneggiamento dell'interruttore. Per tale ragione, occorre impiegare un interruttore che viene azionato esercitando una maggiore pressione fra le lamine, il quale presenta un maggior costo rispetto ad un interrutore ordinario.\\
Nel caso analizzato, in particolare, si necessita la presenza di un \textit{transistor} e di un rel√®, in modo tale che la \textbf{circuiteria di potenza} (ovvero il grosso interruttore e la lampada) sia separata dalla \textbf{circuiteria di controllo logico}, che viene realizzata con delle porte logiche.\\
Questo, chiaramente, comporta un maggior costo, ma con due grandi vantaggi:
\begin{enumerate}
  \item il primo rappresentato dal fatto che si ha una netta separazione tra i due circuiti;
  \item il secondo √® rappresentato dalla sicurezza, in quanto si ha una barriera tra il circuito ad elevata tensione e quello che opera ai livelli di tensione propri delle porte logiche.
\end{enumerate}
Pertanto, nel malaugurato caso in cui vi sia una perdita dell'interruttore, l'utente √® separato e protetto da eventuali scariche di alta tensione.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri, ora, il caso in cui al posto di avere due soli interruttori per comandare un carico, ve ne siano tre. Si vuole, pertanto, progettare un circuito capace di accendere o di spegnere una lampada mediante uno qualsiasi di tre interruttori indipendenti. Indicando al solito con $L = 1$ la condizione di lampada accesa, viene fissata come specifica che quando i tre interruttori sono aperti $L = 0$. Chiudendo uno qualsiasi degli interruttori $L$ dovra assumere il valore $1$, mentre torner√†al valore $0$ azionando un qualsiasi altro interruttore. Infine essa assumer√† nuovamente il valore $1$ quando tutti i tre interruttori saranno chiusi. Anche questa situazione √® molto frequente in pratica, per esempio in un ampio salone nel quale si vogliano avere pi√π punti luce.\\
In questo secondo caso, com'√® intuibile, si avranno tre variabili binarie \(x, y\) e \(z\) per le quali si costruisce la seguente tabella di verit√†:

\begin{table}[H]
    \centering
    \begin{tabular}{ccc|c}
         \(x\) & \(y\) & \(L\)\\
         \hline
         \(0\) & \(0\) & \(0\) & \(0\)\\
         \(0\) & \(0\) & \(1\) & \(1\)\\
         \(0\) & \(1\) & \(0\) & \(1\)\\
         \(0\) & \(1\) & \(1\) & \(0\)\\
         \(1\) & \(0\) & \(0\) & \(1\)\\
         \(1\) & \(0\) & \(1\) & \(0\)\\
         \(1\) & \(1\) & \(0\) & \(0\)\\
         \(1\) & \(1\) & \(1\) & \(1\)\\
    \end{tabular}
    \caption{Circuito di comando di una luce da tre punti e relativa tavola di verit√†}
    \label{tab:circuito_luce_tre_punti_tavola_verita}
\end{table}

\noindent
La sintesi del circuito mediante termini minimi fornisce
\[\overline{x} \overline{y} z + \overline{x} y \overline{z} + x \overline{y} \overline{z} + xyz\]
Prima di procedere alla realizzazione circuitale, √® per√≤ opportuno semplificare il pi√π possibile l'espressione, ottenendo
\[\overline{x} (\overline{y}z + y \overline{z}) + x (\overline{y} \overline{z} + yz)\]
Il circuito che si ricava √® rappresentato nella Tabella \ref{tab:circuito_comando_luce_tre_punti_e_invertitore}:

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{PP}
      {
          \begin{circuitikz}[]
            \draw (0,0) -- ++(1,0) node[circ](x){} -- ++(0.5,0.5) node[circ]{} ++(0,-1) node[circ]{} -- ++(0,-0.5) -- ++(1,0) node[circ](y2){} -- ++(0.5,0.5) node[circ]{} ++(0,-1) node[circ]{} -- ++(0,-0.5) -- ++(1,0) -- ++(0,4) node[circ]{};
            \draw (x) ++(0.5,0.5) -- ++(0,0.5) -- ++(1,0) node[circ](y1){} -- ++(0.5,0.5) node[circ]{} ++(0,-1) node[circ]{} -- ++(0,-0.5) node[circ]{} -- ++(0,-0.5) ++(0,0.5) -- ++(2,0) -- ++(0,0.5) node[circ]{} ++(0.5,0.5) node[circ](z){} -- ++(-0.5,0.5) node[circ]{} -- ++(0,0.5) -- ++(-2,0) -- ++(0,-0.5) (z) -- ++(1,0);
            \draw (x) ++(0,0.5) node[]{$x$} ++(0,-1) node[]{$\overline{x}$};
            \draw (y1) ++(0,0.5) node[]{$y$} ++(0,-1) node[]{$\overline{y}$};
            \draw (y2) ++(0,0.5) node[]{$y$} ++(0,-1) node[]{$\overline{y}$};
            \draw (z) ++(0,0.5) node[]{$z$} ++(0,-1) node[]{$\overline{z}$};
          \end{circuitikz}
      } & {
          \begin{circuitikz}[]
            \draw (0,0) -- ++(1,0) node[circ](x){} -- ++(0.5,0.5) node[circ]{} ++(0,-1) node[circ]{} -- ++(0,-0.5) -- ++(1,0) -- ++(0,0.75) -- ++(0.5,0) node[circ](y){} -- ++(0.5,0.5) node[circ]{} -- ++(0.5,0) -- ++(0,0.75) -- ++(1,0) -- ++(0,-0.5) node[circ]{} -- ++(0.5,-0.5) node[circ](z){} -- ++(1,0);
            \draw (x) ++(0.5,0.5) -- ++(0,0.5) -- ++(1,0) -- ++(0,-0.75) -- ++(0.5,0) node[circ]{} -- ++(0.5,-0.5) node[circ]{} -- ++(0.5,0) -- ++(0,-0.75) -- ++(1,0) -- ++(0,0.5) node[circ]{};
            \draw [dashed] (y) ++(-0.25,-0.25) -- ++(0,1) -- ++(1,0) -- ++(0,-1) -- ++(-1,0);
            \draw (x) ++(0,0.5) node[]{$x$} ++(0,-1) node[]{$\overline{x}$};
            \draw (z) ++(0,0.5) node[]{$z$} ++(0,-1) node[]{$\overline{z}$};
            \draw (y) ++(0.25,1) node[]{$y$} ++(0,-1.5) node[]{$\overline{y}$};
          \end{circuitikz}
      }
    \end{tabularx}
    \caption{Circuito con tre interruttori ottenuto da una sintesi basata sui termini minimi: realizzazione teorica e circuito commerciale, facente uso di un invertitore}
    \label{tab:circuito_comando_luce_tre_punti_e_invertitore}
\end{table}

Si noti che i circuiti ottenuti presentano un numero di invertitori maggiore del numero di interruttori richiesti dal problema. Si osservi, tuttavia, che i due interruttori associati alla variabile $z$, quando sono chiusi (come in Tabella \ref{tab:circuito_comando_luce_tre_punti_e_invertitore}) portano allo
stesso potenziale le variabili $y$ e $\overline{y}$ della parte centrale del circuito; dunque i due rami pi√π interni si possono fondere; poich√® lo stesso discorso vale anche per gli interruttori della variabile $z$, il risultato finale √® che si semplifica il circuito e si risparmia un deviatore.\\
Si necessita, allora, l'impiego di un dispositivo commerciale, noto con il nome di \textbf{invertitore}, ovvero un \textbf{doppio deviatore} che si pu√≤ trovare solamente in due possibili stati \(=\), oppure \(\times\).\\
L'invertitore consente, fra l‚Äôaltro, di generalizzare il problema a \(n \geq 4\) interruttori; in tutti questi casi il circuito risolutivo √® dato da due deviatori in testa alla catena e da \(n - 2\) invertitori in cascata nelle posizioni intermedie.

\vspace{1em}
\noindent
Si provi, ora, a realizzare la rete logica mediante i termini massimi, per cui si ottiene
\[(x + y + z) \cdot (x + y + \overline{z}) \cdot (\overline{x} + y + \overline{z}) \cdot (\overline{x} + \overline{y} + z) = [x + (y +z) \cdot (\overline{y} + \overline{z})] \cdot [(\overline{x} + (y + \overline{z}) \cdot (\overline{y} + z)]\]
che con la semplificazione porta al circuito della figura seguente:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{circuitikz}[]
      \draw (0,0) -- ++(1,0) node[circ](start){} -- ++(0,-0.75) -- ++(0.5,0) node[circ]{} ++(0.5,0.5) node[circ](z1){} -- ++(0.5,-0.5) node[circ]{} -- ++(0.5,0) -- ++(0,0.75) node[circ]{} -- ++(0.5,0) node[circ]{} -- ++(0.5,0) node[circ]{} -- ++(0,-0.75) -- ++(0.5,0) node[circ]{} -- ++(0.5,0.5) node[circ](z2){} ++(0.5,-0.5) node[circ]{} -- ++(0.5,0) -- ++(0,0.75) node[circ](end){} -- ++(1,0);
      \draw (start) -- ++(0,0.75) node[circ]{} -- ++(0.5, 0) node[circ]{} ++(0.5,-0.5) node[circ](y1){} -- ++(0,-0.5) (y1) -- ++(0.5,0.5) node[circ]{} -- ++(0.5,0) -- ++(0,-0.75) ++(1,0) -- ++(0,0.75) -- ++(0.5,0) node[circ]{} ++(0.5,-0.5) node[circ](y2){} -- ++(0,-0.5) (y2) -- ++(0.5,0.5) node[circ]{} -- ++(0.5,0) node[circ]{} -- (end);
      \draw (start) ++(0,0.75) -- ++(0,0.75) -- ++(2,0) node[circ]{} ++(0.5,-0.5) node[circ](x){} -- ++(0,-1) (x) -- ++(0.5,0.5) node[circ]{} -- ++(2,0) -- ++(0,-0.75);
      \draw (x) ++(-0.25,0.15) node[]{$x$} ++(0.8,0) node[]{$\overline{x}$};
      \draw (y1) ++(-0.25,0.15) node[]{$y$} ++(0.8,0) node[]{$\overline{y}$};
      \draw (y2) ++(-0.25,0.15) node[]{$y$} ++(0.8,0) node[]{$\overline{y}$};
      \draw (z1) ++(-0.25,-0.15) node[]{$z$} ++(0.8,0) node[]{$\overline{z}$};
      \draw (z2) ++(-0.45,-0.15) node[]{$z$} ++(0.8,0) node[]{$\overline{z}$};
      \draw [dashed] (y1) ++(0,0.25) -- ++(3.25,0) (z1) ++(0,-0.25) -- ++(3.25,0);
    \end{circuitikz}
    \caption{Circuito con tre interruttori ottenuto da una sintesi basata sui termini massimi}
    \label{fig:circuito_comando_luce_tre_punti_maxterm}
\end{figure}

\noindent
Anche in questo caso la soluzione basata sui termini massimi √® meno vantaggiosa, poich√© richiede \(5\) deviatori invece di \(4\), ma tale circuito √® del tutto analogo a quello precedente, ma differente dal punto di vista topologico.\\
Al di l√† della straordinaria importanza applicativa del metodo formale basato sull‚ÄôAlgebra Booleana, √® importante riflettere, soprattutto alla luce di quest‚Äôultimo esempio, che molto spesso in ambito ingegneristico la teoria offre diverse soluzioni tra loro equivalenti; sta poi al progettista scegliere la migliore, tenuto conto della razionalit√† e semplicit√† delle soluzioni prospettate, dei costi, del numero di componenti impiegati ecc.

\subsection{Semplificazione delle espressioni Booleane}
Si e gi√† visto, dagli esempi che precedono, che le forme canoniche non esauriscono le espressioni analitiche di una funzione; anzi, come per qualsiasi relazione algebrica, anche quelle logiche possono essere trasformate in un certo numero di espressioni formalmente diverse, ma equivalenti dal punto di vista matematico.\\
Ad esempio:
\[f = \overline{x} \overline{y} \overline{z} + \overline{x} \overline{y} z + \overline{x}yz + xyz = \overline{x} \overline{z} (\overline{z} + z) + yz (\overline{x} + x) = \overline{x} \overline{y} + yz\]

\subsubsection{Funzioni Booleane equivalenti}
Di seguito si espone la definzione di funzioni Booleane equivalenti:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{FUNZIONI BOOLEANE EQUIVALENTI}}\\
    \parbox{\linewidth}{Si diranno \textbf{equivalenti} due funzioni che abbiano la stessa tavola di verit√†, forma semplificata di una funzione ogni sua espressione non canonica, forma minima quella in cui ogni variabile, diretta o negata che sia, compare il minor numero di volte.\vspace{3mm}}\\
    \hline
\end{tabularx}
\vspace{1em}

\noindent
Espressioni semplificate si possono ottenere applicando le relazioni fondamentali dell‚ÄôAlgebra Booleana alle espressioni canoniche, ma questa strada richiede una notevole pratica, si applica facilmente solo a funzioni di un limitato numero di variabili e non fornisce alcuna garanzia di pervenire effettivamente alla forma minima, dato il carattere artigianale del procedimento.\\
Le tecniche di semplificazione pi√π sistematiche che vengono analizzate nel seguito sono principalmente due:
\begin{enumerate}
    \item Mappe di Karnaugh
    \item Metodo tabellare di Quine - Mc Cluskey
\end{enumerate}

\subsubsection{Mappe di Karnaugh}
Il metodo proposto da \emph{Karnaugh} √® un metodo grafico di semplificazione che permette di ottenere molto semplicemente la forma minima di una funzione espressa come somma di prodotti (\textit{minterm}), facendo ricorso a particolari mappe di rappresentazione. Quale limitazione si ha che, sebbene il metodo sia concettualmente applicabile a funzioni di qualsiasi numero di variabili, esso diviene difficoltoso gi√† per \(5 - 6\) variabili.\\
Le mappe di Karnaugh, che possono essere considerate un ulteriore metodo di rappresentazione di una funzione logica e consistono in matrici di \(m\) righe e \(k\) colonne, in cui \(m = 2^i\) e \(k = 2^j\) per qualche \(i, j\), col vincolo che
\[2^i \cdot 2^j = 2^n\]
ovvero pari al numero di elementi della matrice, in cui \(n\) √® il numero delle variabili. Di conseguenza, le mappe di Karnaugh presentano \(4\) celle nel caso di funzioni di due variabili, \(8\) per quelle di tre variabili, \(16\) per quelle di quattro e cos√¨ via.\\
Ogni elemento della matrice rappresenta un termine minimo, che entra in un‚Äôespressione \textit{minterm} di somma di prodotti; infatti, il concetto alla base delle mappe di Karnaugh prevede di disporre i termini minimi nello spazio in modo tale che i termini minimi da semplificare si trovino vicini fra di loro.\\
In particolare, le mappe devono essere costruita in modo tale che nel passaggio da una cella all'altra ci sia sempre e solo un'unica variabile che viene a modificarsi. Ci√≤ implica che la tabella √® chiusa in se stessa tanto in senso orizzontale, quanto in senso verticale.\\
Per questo motivo, infatti, nella disposizione dei numeri binari sulle righe e sulle colonne si utilizza la sequenza \(00, 01, 11, 10\) dimodoch√© nel passaggio da una colonna/riga all'altra vi sia il cambio di una sola variabile.\\
Nella Figura \ref{fig:mappa_karnaugh_2_3_4_0} sono riprodotte le strutture delle mappe per 2, 3 e 4 variabili.

% Contenitore per immagini
\hspace{5em}
\begin{figure}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{4pt}
    \renewcommand{\arraystretch}{2}
    \noindent
    \begin{tabularx}{\textwidth}{>{\hsize=0.55\textwidth}PP}
      {
        \begin{Karnaughquatre}
            \contingut{\overline{x} \overline{y}, x \overline{y}, \overline{x}y, xy}
        \end{Karnaughquatre}
        \hspace{1em}
        \begin{Karnaughvuit}
            \contingut{\overline{x}\overline{y}\overline{z}, \overline{x}y\overline{z}, x\overline{y}\overline{z}, xy\overline{z}, \overline{x}\overline{y}z, \overline{x}yz, x\overline{y}z, xyz}
        \end{Karnaughvuit}
      } & {
        \begin{KarnaughExample}
              \contingut{\overline{x}\overline{y}\overline{z}\overline{w},\overline{x}y\overline{z}\overline{w},x\overline{y}\overline{z}\overline{w},xy\overline{z}\overline{w},\overline{x}\overline{y}\overline{z}w,\overline{x}y\overline{z}w,x\overline{y}\overline{z}w,xy\overline{z}w,\overline{x}\overline{y}z\overline{w},\overline{x}yz\overline{w},x\overline{y}z\overline{w},xyz\overline{w},\overline{x}\overline{y}zw,\overline{x}yzw,x\overline{y}zw,xyzw}
        \end{KarnaughExample}
      }
    \end{tabularx}
    \vspace{-4em}
    \caption{Mappe di Karnaugh per $2$, $3$ e $4$ variabili}
    \label{fig:mappa_karnaugh_2_3_4_0}
\end{figure}

\newpage
\begin{center}
    18 Ottobre 2021
\end{center}
\subsection{Riassunto}
Le forme canoniche sono di due tipi: \textit{minterm} e \textit{maxterm}. In particolare considerando la funzione che vale sempre \(1\) tranne per un solo caso in cui vale \(0\) prende il nome di \textit{maxterm}, mentre la funzione che vale sempre \(0\) e vale \(1\) solamente per un solo caso, ovvero quello oggetto di studio, prende il nome di \textit{minterm}. Talune forme sono esattamente equivalenti per l'espressione di una funzione logica: \textbf{prodotto di \textit{maxterm}} oppure \textbf{somma di \textit{minterm}}.\\
Dal punto di vista pratico, come si √® detto, sono perfettamente equivalentiu: certo √® che, se una funzione presenta pi√π \(0\) che \(1\), sar√† pi√π conveniente ricorrere al \textbf{prodotto di \textit{maxterm}} anzich√© una \textbf{somma di \textit{minterm}}.\\
Attraverso l'applicazione dei teoremi fondanti dell'Algebra Booleana, cos√¨ come attraverso i Teoremi di De Morgan (¬ß \ref{sec:teorema_de_morgan}), √® possibile passare da una forma all'altra in modo molto equivalente, giungendo ad una semplificazione decisamente vantaggiosa, sia in termini circuitali che in termini logici.\\
L'interpretazione circuitale dell'Algebra Booleana si deve a Shannon, che la scelse come tema del suo master. La chiave centrale di tale interpretazione sono gli interruttori che rappresentano le variabili booleane e che possono essere poste in serie per simulare il funzionamento di una porta AND; se sono poste in parallelo simulano il funzionamento di una porta OR.\\
La commutazione di ciascun interruttore rappresentante una variabile determina una particolare configurazione del circuito da cui √® possibile estrarre la corrispondente funzione logica. L'utilizzo dell'Algebra Booleana e delle tavole di verit√† √® fondamentale nella progettazione di un circuito e per la determinazione della soluzione pi√π conveniente e pratica dal punto di vista circuitale.\\
Dal punto di vista tecnico, inoltre, si √® osservato che il carico che √® necessario comandare potrebbe comportare, a seconda della sua entit√†, la necessit√† di dimensionare tutti gli interruttori esposti all'elevata tensione del carico, con un significativo costo associato per ciascun interruttore. Attraverso l'utilizzo di un rel√® e di un transistor, invece, si ha una separazione netta tra la parte del circuito ad elevata tensione e quella di controllo: gli interruttori con cui interagisce l'utente lavorano alla tensione delle porte logiche, ovvero pochi Volt, eliminando il rischio delle perdite di elevate tensioni.\\
Inoltre, gli interruttori che operano ad elevata tensione sono molto costosi e pesanti e presentano una molla di richiamo che sarebbe stato difficile azionare, anche dal punto di vista meccanico. Implementando, invece, interruttori che operano sui \(5 V\) si agevola anche l'azione di accensione e spegnimento da parte dell'utente. L'accessione di un punto luce da pi√π di \(2\) interruttori, invece, richiederebbe l'uso di un dispositivo denominato \textbf{invertitore}, che pu√≤ essere installato in molteplice quantit√† per assolvere al compito richiesto.\\
Si √® visto, infine, che le semplificazioni booleane effettuate ricorrendo ai teoremi dell'Algebra Booleana o ai teoremi di De Morgan sono molto complesse e dal basso tasso di successo. Le mappe di Karnaugh, invece, sono delle mappe \textbf{bidimensionali} (fatto che, comunque, ne limita le applicazioni) che presentano un numero di righe $m = 2^i$ e di colonne $k = 2^j$ che deve essere sempre tale per cui \(2^i \times 2^j = 2^n\), per qualche $i$ e $j$, ove \(n\) √® il numero delle variabili di cui si sta analizzando l'equazione logica. Inoltre, le n-uple di variabili devono essere disposte in modo tale che tra due n-uple successive vi sia la variazione di una sola variabile.\\
Si presti particolare attenzione che la mappa deve essere considerata \textbf{chiusa} sia in senso orizzontale che in senso verticale, pertanto la combinazione \(00, 01, 11, 10\) rispetta la regola precedentemente esposta, in quanto la dupla \(10\) √® considerata adiacente a \(00\), ma comunque tra le due si ha il cambiamento di una sola variabile.\\
Nella Figura \ref{fig:mappa_karnaugh_2_3_4_1} sono riprodotte le strutture delle mappe per \(2\), \(3\) e \(4\) variabili.

% Contenitore per immagini
\hspace{5em}
\begin{figure}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{4pt}
    \renewcommand{\arraystretch}{2}
    \noindent
    \begin{tabularx}{\textwidth}{>{\hsize=0.55\textwidth}PP}
      {
        \begin{Karnaughquatre}
            \contingut{\overline{x} \overline{y}, x \overline{y}, \overline{x}y, xy}
        \end{Karnaughquatre}
        \hspace{1em}
        \begin{Karnaughvuit}
            \contingut{\overline{x}\overline{y}\overline{z}, \overline{x}y\overline{z}, x\overline{y}\overline{z}, xy\overline{z}, \overline{x}\overline{y}z, \overline{x}yz, x\overline{y}z, xyz}
        \end{Karnaughvuit}
      } & {
        \begin{KarnaughExample}
              \contingut{\overline{x}\overline{y}\overline{z}\overline{w},\overline{x}y\overline{z}\overline{w},x\overline{y}\overline{z}\overline{w},xy\overline{z}\overline{w},\overline{x}\overline{y}\overline{z}w,\overline{x}y\overline{z}w,x\overline{y}\overline{z}w,xy\overline{z}w,\overline{x}\overline{y}z\overline{w},\overline{x}yz\overline{w},x\overline{y}z\overline{w},xyz\overline{w},\overline{x}\overline{y}zw,\overline{x}yzw,x\overline{y}zw,xyzw}
        \end{KarnaughExample}
      }
    \end{tabularx}
    \vspace{-4em}
    \caption{Mappe di Karnaugh per $2$, $3$ e $4$ variabili}
    \label{fig:mappa_karnaugh_2_3_4_1}
\end{figure}

\noindent
Nella mappa di Karnaugh, com'√® intuibile, viene inserito $1$ in corrispondenza delle terne per le quali la funzione vale $1$ e $0$ in corrispondenza delle terne per le quali la funzione vale $0$. L‚Äôassegnazione delle coordinate delle caselle della tabella dev‚Äôessere tale che passando da ciascuna casella a una adiacente, sia in senso orizzontale che verticale, vari il valore di una sola variabile. Si noti che devono essere considerate adiacenti anche le caselle terminali, come se la mappa fosse chiusa circolarmente su se stessa, sia in senso orizzontale che verticale.\\
Ricapitolando, √® possibile asserire che ciascun elemento della matrice corrisponde a un termine minimo di $n$ variabili, e che la rappresentazione di una qualsiasi funzione di $n$ variabili si ottiene contrassegnando con $1$ o con $0$ le posizioni corrispondenti ai termini minimi da cui la funzione √® composta.\\
Una funzione riportata sulla mappa di Karnaugh pu√≤ essere semplificata osservando che due caselle adiacenti, sia in senso orizzontale che verticale, differiscono per il valore di una sola variabile, che in una delle due caselle
apparir√† come variabile affermata, nell‚Äôaltra come negata; si ricava dunque
\[fx + f\overline{x} = f(x + \overline{x}) = f\]
per l'assioma A7 della complementariet√†.\\
Grazie al fatto che le mappe sono costruite in modo tale che due celle contigue differiscano solamente per una sola variabile √® possibile costruire il \textbf{prodotto di \textit{maxterm}} e la \textbf{somma di \textit{minterm}} osservando dove la funzione vale \(0\) o \(1\) rispettivamente.\\
Se si designa con \emph{sottocubo} il ricoprimento associato a un implicante, la regola pratica per individuare l‚Äôimplicante a esso associato √® quella che prevede che esso sia costiuito dal prodotto dalle variabili che rimangono costanti su $0$ o su $1$ all‚Äôinterno del sottocubo stesso, sempre ricordando che i sottocupi, per Karnaugh, devono avere $2^i$ elementi, per qualche $i$.\\
Costruendo, quindi, i \textbf{sottocubi} come multipli di \(2\) √® possibile costruire il \textbf{determinante} semplicemente osservando sulle righe e sulle colonne interessate le variabili che rimangono costanti.\\
Per esempio, considerando la mappa di Karnaugh di Figura \ref{fig:mappa_karnaugh_3_0} seguente:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,0,0,1,0,1,0}
        \implicant{0}{4}{green}
        \implicantcostats{4}{6}{red}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a \(3\) variabili}
    \label{fig:mappa_karnaugh_3_0}
\end{figure}

\noindent
La funzione semplificata si ottiene allora come somma degli implicanti necessari e sufficienti a coprire tutti i \emph{minterm} della funzione; nel caso di cui sopra si ha:
\[f = \overline{xy} + \overline{y}z\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Da questi esempi si evince che un implicante di $n - 1$ variabili implica i termini minimi associati a $2$ caselle adiacenti, un
implicante di $n - 2$ variabili implica i termini minimi associati a $2^2$ caselle adiacenti (appartenenti alla stessa riga o alla stessa colonna o raccolti attorno allo stesso vertice) e in generale un implicante di $n - i$ variabili implica i termini minimi associati a un sottocubo di $2^i$ caselle adiacenti.\\
In tale contesto, allora, un \textbf{implicante} si dice \textbf{primo} se corrisponde a un sottocubo non completamente coperto da altri sottocubi, mentre si dir√† \textbf{massimale} se non √® possibile aumentare ulteriormente la sua dimensione; si definisce, infine, \textbf{copertura} della funzione un insieme di sottocubi tali da coprire tutti gli $1$ della funzione. La minimizzazione della funzione si ricava a partire da una \textbf{copertura minima}, cio√® una copertura formata dal pi√π piccolo insieme di sottocubi primi massimali.\\
Una regola pratica da adottare, quindi, quando si costruiscono i \textbf{sottocubi} √® quella che prevede di evitare il  pi√π possibile di includere dei termini gi√† considerati in altri sottocubi, per cui si costruirebbero degli \textbf{implicanti \textit{non primi}}.\\
In particolare, al fine di ottenere la massima semplficazione possibile della funzione, vige la regola dei \textbf{sottocubi massimali} e della \textbf{copertura minima}.

\vspace{1em}
\noindent
\textbf{Osservazione}: Naturalmente, attraverso la costruzione degli implicanti √® possibile ottenere, in conclusione, delle semplificazioni corrette, ma formalmente diverse, tali per cui deve essere sempre possibile passare dall'una all'altra, senza perdita di generalit√†.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri la seguente mappa di Karnaugh:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0}
        \implicant{0}{0}{red}
        \implicant{12}{13}{blue}
        \implicant{13}{9}{green}
    \end{Karnaugh}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a \(4\) variabili}
    \label{fig:mappa_karnaugh_4_0}
\end{figure}

\noindent
Pertanto costruendo i tre implicanti corrispondenti a tre \textit{minterm} si ha:
\[f = \overline{xyzw} + \overline{x}z\overline{w} + \overline{x}yz\]

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri, infine, la seguente mappa di Karnaugh:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{1,0,1,0,1,1,1,0,1,0,1,0,1,1,1,0}
        \implicantcostats{0}{10}{green}
        \implicant{4}{13}{red}
    \end{Karnaugh}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a \(4\) variabili}
    \label{fig:mappa_karnaugh_4_1}
\end{figure}

\noindent
Pertanto costruendo i due implicanti corrispondenti a due \textit{minterm} si ha:
\[f = \overline{y} + \overline{x}w\]

\vspace{1em}
\subsubsection{Mappa di Karnaugh sui termini massimi}
Le mappe di Karnaugh possono essere usate anche per costruire la funzione semplificata secondo la II forma canonica, basata, quindi, sul prodotto di somme. In tal caso i sottocubi e la relativa copertura minima vanno costruiti sugli \(0\). Ciascun sottocubo sar√† l‚Äôimplicante dei relativi termini massimi e verr√† rappresentato in forma simbolica dalla somma logica delle variabili che rimangono costanti sul sottoinsieme, \emph{dirette se le relative
coordinate valgono $0$, negate se valgono $1$}. Tutto ci√≤ deriva dalla circostanza seguente
\[\left(f + x\right) \cdot \left(f + \overline{x}\right) = f + x \cdot \overline{x} = f\]
Si consideri, a tal proposito, la seguente mappa di Karnaugh:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{0,1,0,0,0,1,1,1}
        \implicant{0}{4}{red}
        \implicant{3}{2}{green}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a \(3\) variabili per la semplificazione dei \emph{maxterm}}
    \label{fig:mappa_karnaugh_3_1}
\end{figure}

\noindent
La funzione semplificata che ne deriva √®
\[f = \left(x + y\right) \cdot \left(\overline{x} + z\right) = xz + \overline{x}y\]
che corrisponde alla funzione semplificata cercata, ottenuta, per√≤, basandosi sull'individuazione dei due implicanti corrispondenti a due \emph{maxterm}.

\vspace{1em}
\subsubsection{Mappe di Karnaugh a \(5\) o pi√π variabili}
Il metodo delle mappe di Karnaugh pu√≤ essere applicato, come gi√† accennato, anche a funzioni di $5$ o $6$ variabili. In tal caso non si potr√† pi√π realizzare una mappa piana, in cui ogni casella sia adiacente a caselle le cui coordinate differiscano per un‚Äôunica variabile. La mappa per cinque variabili viene pertanto realizzata mediante due mappe da quattro variabili, una associata al valore $0$ della quinta variabile, l‚Äôaltra al valore $1$. Le adiacenze vanno, quindi, ricercate anche tra caselle occupanti posizioni omologhe sulle due mappe.\\
Si voglia, ad esempio, semplificare la seguente funzione:
\begin{flalign*}
  f & = x\overline{y}zwr + x\overline{y}zw\overline{r} + x\overline{y}z\overline{w}r + x\overline{y}z\overline{w}\overline{r} + \\
  & + x\overline{y}\overline{z}wr + x\overline{y}\overline{z}w\overline{r} + x\overline{y}\overline{z}\overline{w}r + x\overline{y}\overline{z}\overline{w}\overline{r} +\\
  & + \overline{x}yzwr + xyzwr + \overline{x}\overline{y}zwr + \overline{x}y\overline{z}\overline{w}r
\end{flalign*}
Le due mappe da $4$ variabili, che si ottengono, una per $r=0$ e una per $r=1$ sono le seguenti

\begin{figure}[H]
    \hspace{15.8em}
    \begin{tikzpicture}[anchor=left]
        \draw [dashed, stealth-stealth] (0,0) -- ++(0,1) -- ++(6.05,0) -- ++(0,-1);
    \end{tikzpicture}\\
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{5pt}
    \renewcommand{\arraystretch}{0.5}
    \begin{tabularx}{\textwidth}{P}{
      \rowcolors{1}{white}{white}
      \setlength{\tabcolsep}{5pt}
      \renewcommand{\arraystretch}{0.5}
      \begin{tabularx}{0.8\textwidth}{PP}
        {
          \begin{Karnaugh}
              \contingut{0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0}
              \implicant{2}{10}{red}
          \end{Karnaugh}
        } & {
          \begin{Karnaugh}
              \contingut{0,1,1,0,0,0,1,0,0,0,1,0,1,1,1,1}
              \implicant{1}{1}{green}
              \implicant{12}{14}{violet}
              \implicant{2}{10}{orange}
          \end{Karnaugh}
        }\\
        $r = 0$ & $r = 1$\\
        \end{tabularx}
    }
    \end{tabularx}
    \caption{Uso della mappa di Karnaugh per una funzione di 5 variabili}
    \label{fig:mappa_karnaugh_5_0}
\end{figure}

\noindent
La funzione semplificata risulta
\[f = x\overline{y} + \overline{x}y\overline{z}\overline{w}r + zwr\]
in quanto le due mappe sono da considerarsi adiacenti rispetto alla colonna $10$ corrispondente alla coppia $xy$.\\
Se le variabili fossero $6$, come $x$, $y$, $z$, $w$, $r$ e $t$ sarebbe necessario usare quattro mappe nelle quattro variabili $x$, $y$, $z$, $w$ e una per ogni coppia possibile di valori associati alle variabili $r$ e $t$.

\vspace{1em}
\subsubsection{Condizioni non specificate}
Nella sintesi di una funzione logica di \(n\) variabili si pu√≤ presentare il caso in cui per \(k\) configurazioni delle variabili di ingresso la funzione vale \(1\), per \(m\) configurazioni vale \(0\), ma \(k + m < 2^n\). Le restanti \(2^n - (m + k)\) configurazioni vengono dette \textbf{condizioni non specificate} (o anche \emph{d.c.c.}, acronimo di \textit{don‚Äôt care condition}).\\
In pratica questa situazione si verifica ogni qualvolta in un circuito certe configurazioni di ingresso sono fisicamente impossibili, o rendono privo di significato il valore dell‚Äôuscita. Da un punto di vista strettamente analitico ci√≤ accade quando una funzione \(F\) √® funzione delle variabili \(\phi_1, \phi_2, \phi_3, ..., \phi_m\), ognuna delle quali √® a sua volta funzione delle variabili \(x_1, x_2, ..., x_n\), cio√©
\[F = f \left(\phi_1, \phi_2, \phi_3, ..., \phi_m\right) \hspace{2em} \phi_i = f \left(x_1, x_2, ..., x_n\right) \hspace{2em} i = 1, 2..., m\]
Le condizioni non specificate si ricavano dalle tavole di verit√† delle $\phi_i$, e sono tutte e sole le configurazioni delle $\phi_i$ che non compaiono in tali tabelle. Sia ad esempio:

\vspace{1em}
\noindent
\begin{figure}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabular}{cl}
     & \(\phi_1 = x \cdot \left(yz + \overline{y}\overline{z}\right)\)\\
     \(F \left(\phi_1, \phi_2, \phi_3\right)\) & \(\phi_2 = w \cdot \left(y\overline{x} + \overline{y}z\right)\)\\
     & \(\phi_3 = xyz + \overline{x}\overline{y}\overline{z}\)\\
    \end{tabular}
    \vspace{1em}
\end{figure}

\noindent
La tavola di verit√† delle $\phi_i$ √® riportata nella Figura \ref{fig:tavola_verita_fi_e_F} seguente, cos√¨ come i valori assunti dalla funzione $F$ considerata:

\vspace{1em}
\noindent
\begin{figure}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{PP}
      {
        \rowcolors{1}{white}{white}
        \setlength{\tabcolsep}{8pt}
        \renewcommand{\arraystretch}{1.2}
        \begin{tabular}{cccc|ccc}
          $x$ & $y$ & $z$ & $w$ & $\phi_1$ & $\phi_2$ & $\phi_3$\\
          \hline
          $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $1$\\
          $0$ & $0$ & $0$ & $1$ & $0$ & $0$ & $1$\\
          $0$ & $0$ & $1$ & $0$ & $0$ & $0$ & $0$\\
          $0$ & $0$ & $1$ & $1$ & $0$ & $1$ & $0$\\
          $0$ & $1$ & $0$ & $0$ & $0$ & $0$ & $0$\\
          $0$ & $1$ & $0$ & $1$ & $0$ & $1$ & $0$\\
          $0$ & $1$ & $1$ & $0$ & $0$ & $0$ & $0$\\
          $0$ & $1$ & $1$ & $1$ & $0$ & $0$ & $0$\\
          $1$ & $0$ & $0$ & $0$ & $1$ & $0$ & $0$\\
          $1$ & $0$ & $0$ & $1$ & $1$ & $0$ & $0$\\
          $1$ & $0$ & $1$ & $0$ & $0$ & $0$ & $0$\\
          $1$ & $0$ & $1$ & $1$ & $0$ & $1$ & $0$\\
          $1$ & $1$ & $0$ & $0$ & $0$ & $0$ & $0$\\
          $1$ & $1$ & $0$ & $1$ & $0$ & $1$ & $0$\\
          $1$ & $1$ & $1$ & $0$ & $1$ & $0$ & $1$\\
          $1$ & $1$ & $1$ & $1$ & $1$ & $0$ & $1$\\
        \end{tabular}
      } & {
          \rowcolors{1}{white}{white}
          \setlength{\tabcolsep}{8pt}
          \renewcommand{\arraystretch}{1.2}
          \begin{tabular}{ccc|c}
            $\phi_1$ & $\phi_2$ & $\phi_3$ & $F$\\
            \hline
            $0$ & $0$ & $0$ & $1$\\
            $0$ & $0$ & $1$ & $0$\\
            $0$ & $1$ & $0$ & $1$\\
            $0$ & $1$ & $1$ & $-$\\
            $1$ & $0$ & $0$ & $1$\\
            $1$ & $0$ & $1$ & $0$\\
            $1$ & $1$ & $0$ & $-$\\
            $1$ & $1$ & $1$ & $-$\\
          \end{tabular}
      }
    \end{tabularx}
    \caption{Le tavole di verit√† delle funzioni $\phi_1$, $\phi_2$ e $\phi_3$ e quella della funzione $F$}
    \label{fig:tavola_verita_fi_e_F}
\end{figure}

\noindent
Si nota immediatamente che le terne di possibili valori \(\phi_1, \phi_2, \phi_3\) sono \(000, 001, 010, 100, 101\), mentre le configurazioni rimanenti \(011, 110, 111\) non compaiono. Ne consegue che la tavola di verit√† della \(F\) conterr√† condizioni non specificate in corrispondenza di queste configurazioni d‚Äôingresso.\\
Sulla tavola di verit√† le condizioni non specificate vengono indicate con un trattino, nella forma canonica raccogliendo in parentesi i termini minimi corrispondenti, sulle mappe di Karnaugh contrassegnando con il simbolo $\times$ la casella corrispondente a ciascuna condizione non specificata.\\
Le condizioni non specificate possono venir sfruttate nelle semplificazioni, in modo da pervenire ad espressioni minime pi√π semplici. Se si opera con le mappe di Karnaugh, le semplificazioni vanno ancora fatte in modo da coprire tutte le caselle contrassegnate con un $1$, ma se serve si possono aggregare anche le caselle associate a condizioni non specificate, che si possono contrassegnare con $\times$; in pratica si tratta di utilizzare le condizioni non specificate per allargare al massimo i sottocubi di copertura della funzione, assegnando a ciascuna di loro il valore $1$ o $0$ a seconda che torni o meno utile per ottenere sottocubi piu ampi. Nell‚Äôesempio di sopra si ottiene

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{KarnaughvuitPhi}
        \contingut{1,1,1,\times,0,\times,0,\times}
        \implicant{0}{2}{green}
    \end{KarnaughvuitPhi}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a \(3\) variabili}
    \label{fig:mappa_karnaugh_3_2}
\end{figure}

\newpage
\begin{center}
    19 Ottobre 2021
\end{center}
\subsection{Riassunto}
La semplificazione delle espressioni booleane pu√≤ avvenire in tre modi egualmente validi:
\begin{enumerate}
    \item Teoremi dell'Algebra Booleana
    \item Mappa di Karnaugh
    \item Metodo tabellare Quine-McCluskey
\end{enumerate}
Le mappe di Karnaugh sono delle \textbf{tabelle piane} che presentano un numero di celle pari a \(2^n\), ove \(n\) √® il numero di variabili oggetto di studio. Il numero delle righe $m$ e delle colonne $k$ devono essere tali per cui
\[m \cdot k = 2^i \cdot 2^j = 2^n\]
per qualche $i$ e $j$. La realizzazione di una mappa di Karnaugh prevede di disporre le variabili sulle righe e sulle colonne in modo tale che tra una cella all'altra, tanto in senso orizzontale quanto in quello verticale, si registri la variazione di una sola variabile, nel senso della sua complementariet√†.\\
L'individuazione dei blocchi di \textit{minterm} deve avvenire rispettando due importanti condizioni: \textbf{sottocubi massimali} e della \textbf{copertura minima}.\\
Per determinare, poi, a quale \textbf{implicante} corrisponde al sottocubo evidenziato √® sufficiente rilevare quelle variabili che nel sottocubo rimangono costanti sia in orizzontale che in verticale, nel senso della loro complementariet√†.\\
Si ricordi, ancora, che le mappe di Karnaugh devono essere considerate chiuse in senso circolare (si parla, in tal senso, di \textbf{adiacenza per circolarit√†}), per cui, nel caso di due variabili, √® necessario disporle come segue \(00, 01, 11, 10\), dimodoch√© tra \(00 - 01\), \(01 - 11\), \(11 - 10\) e \(10 - 00\) vi sia la variazione di una sola variabile.\\
Naturalmente, con questa modalit√† √® possibile anche individuare \textbf{sottocubi \textit{non primi}}, ovvero sottocubi che includono minterm gi√† inglobati in altri sottocubi. Certo √® che la somma di \emph{minterm} risultante sar√† comunque correttamente espressa, solamente sar√† presente una ridondanza superflua, che pu√≤ essere semplificata tramite i teoremi dell'Algebra Booleana. Naturalmente, per√≤, √® sufficiente evitare di considerare sottocubi non primi per ottenere, alla fine, la formula minima di espressione della funzione booleana.\\
Naturalmente, in forza del \textbf{principio di dualit√†}, cos√¨ com'√® possibile ottenere una somma di \textit{minterm} tramite le mappe di Karnaugh, sar√† anche possibile ottenere un prodotto di \textit{maxterm}, che pu√≤ rivelarsi pi√π conveniente qualora nella tabella siano maggiormente presenti gli \(0\) piuttosto che gli \(1\).\\
Naturalmente, √® possibile procedere all'applicazione delle mappe di Karnaugh anche a \(5\), \(6\) variabili, con un sensibile aumento della complicazione della procedura di semplificazione. In questi casi, sar√† maggiormente conveniente operare tramite il metodo tabellare di Quine-Mc Cluskey (il quale, essendo un vero e proprio algoritmo, + anche pi√π facilmente programmabile).\\
√à possibile, inoltre, che la funzione analizzata non possa presentare determinate combinazioni di variabili in ingresso, le quali sarebbero prive di significato. Allora, nella procedura di semplificazione tramite mappa di Karnaugh, laddove figurano le combinazioni di variabili in ingresso di cui sopra, chiamate \emph{condizioni non specificate}, si pone una \(\times\) che pu√≤ tramutarsi in \(1\) o \(0\) al fine di \textbf{massimizzare i sottocubi} e garantire una \textbf{copertura minima}.

\newpage
\noindent
\textbf{Esercizio}: Si costruisca una funzione \(f\) a \(n = 3\) variabili, la quale presenta la tabela di verit√† riportata nella Tabella \ref{tab:funzione_3_variabili_0} seguente:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{ccc|c}
      $x$ & $y$ & $z$ & $f(x, y, z)$\\
      \hline
      $0$ & $0$ & $0$ & $1$\\
      $0$ & $0$ & $1$ & $1$\\
      $0$ & $1$ & $0$ & $0$\\
      $0$ & $1$ & $1$ & $1$\\
      $1$ & $0$ & $0$ & $1$\\
      $1$ & $0$ & $1$ & $0$\\
      $1$ & $1$ & $0$ & $1$\\
      $1$ & $1$ & $1$ & $1$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_0}
\end{table}

\noindent
Considerando la \textbf{somma di \textit{minterm}} si ottiene
\[f = \overline{x}\overline{y}\overline{z} + \overline{x}\overline{y}z + \overline{x}yz + x\overline{y}\overline{z} + xy\overline{z} + xyz\]
Che si pu√≤ semplificare come segue, sfruttando i \textbf{teoremi di assorbimento} e dell'\textbf{idempotenza}:
\[f = \overline{x}\overline{y} \cdot (\overline{z} + z) + yz \cdot (\overline{x} + x) + \overline{y} \overline{z} \cdot (\overline{x} + x) + xy \cdot (\overline{z} + z)\]
ottenendo
\[f = \overline{x}\overline{y} + yz + \overline{y}\overline{z} + xy = \overline{y} \cdot (\overline{x} + \overline{z}) + y \cdot (x + z)\]

\vspace{1em}
\noindent
Considerando il \textbf{prodotto di \textit{maxterm}}, invece, si ottiene
\[f = (\overline{x} + y + \overline{z}) \cdot (x + \overline{y} + z)\]
ovvero
\[f = \overline{x}x + \overline{x}y + \overline{x}z + xy + \overline{y}y + xz + \overline{x}\overline{z} + y\overline{z} + z\overline{z}\]
da cui si ottiene
\[f = xy + x\overline{z} + \overline{x}\overline{y} + \overline{y}\overline{z} + \overline{x}z + yz\]
Ma per il \textbf{teorema dell'Assorbimento 3} T6, \(x\overline{y} + \overline{x}\overline{z} + \overline{y}\overline{z} = x\overline{y} + \overline{x}\overline{z}\) cos√¨ come \(xy + \overline{x}z + yz = xy + \overline{x}z\), pertanto si ottiene:
\[f = x\overline{z} + \overline{x}\overline{y} + xy + \overline{x}z\]

\vspace{1em}
\noindent
Si realizzi, allora, la mappa di Karnaugh corrispondente, scegliendo i \textit{minterm}
\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,1,1,1,0,1}
        \implicant{4}{5}{red}
        \implicantcostats{0}{2}{green}
        \implicant{3}{7}{blue}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a $3$ variabili}
    \label{fig:mappa_karnaugh_8_0}
\end{figure}

\noindent
Per cui si ottiene
\[f = \overline{y}\overline{z} + \overline{x}z + xy\]
la quale √® differente dalla espressione ottenuta tramite procedure algebriche. Tuttavia, quest'ultima √® la forma minima cercata, in quanto sono stati individuati sottocubi massimali primi al fine di garantire una copertura minima.\\
Per capire come si √® giunti alla forma minima individuata in principio, si costruisce un'ulteriore mappa di Karnaugh e si individuano, in essa, tutti i termini presenti nell'espressione di partenza, ovvero
\[f = x\overline{z} + \overline{x}\overline{y} + xy + \overline{x}z\]
come mostrato nella Figura \ref{fig:mappa_karnaugh_8_1} seguente:

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,1,1,1,0,1}
        \implicant{3}{2}{red}
        \implicant{3}{7}{green}
        \implicant{0}{4}{blue}
        \implicant{4}{5}{violet}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a $3$ variabili}
    \label{fig:mappa_karnaugh_8_1}
\end{figure}

\noindent
Grazie a questa seconda mappa di Karnaugh √® facile capire che nella semplificazione di partenza sono stati scelti dei sottocubi \textit{non primi}, pertanto vi sono \(4\) termini al posto di \(3\), come formula minima.\\
Pertanto si deve cercare di eliminare i due sottocubi non primi \(\overline{x}\overline{y}\) e \(x\overline{z}\) che deve divenire \(\overline{y}\overline{z}\), ovvero
\[\overline{x}\overline{y} + x\overline{z} = \overline{y}\overline{z}\]
Ma ci√≤ √® facile da capire in forza dell'\textbf{teorema dell'Assorbimento $3$} T6, che permette di scrivere
\[f = x\overline{z} + \overline{x}\overline{y} + xy + \overline{x}z = \left(x\overline{z} + \overline{x}\overline{y} + \overline{y}\overline{z}\right) + \left(xy + \overline{x}z + yz\right)\]
in quanto
\[x\overline{z} + \overline{x}\overline{y} + \overline{y}\overline{z} = x\overline{z} + \overline{x}\overline{y} \hspace{1em} \text{e} \hspace{1em} xy + \overline{x}z + yz = xy + \overline{x}z\]
Applicando nuovamente il teorema dell'\textbf{teorema dell'Assorbimento $3$} T6, la \textbf{propriet√† commutativa} A4 e la \textbf{propriet√† associativa} A5 si perviene al risultato seguente:
\[\left(x\overline{z} + \overline{x}\overline{y} + \overline{y}\overline{z}\right) + \left(xy + \overline{x}z + yz\right) = \overline{y}\overline{z} + xy + \overline{x}z + yz + \overline{x}\overline{y}\]
in quanto
\[xy + \overline{y}z + x\overline{z} = xy + \overline{y}z\]
Giunti a questo punto, applicando per due volte consecutive il teorema dell'\textbf{teorema dell'Assorbimento $3$} T6, la \textbf{propriet√† commutativa} A4 e la \textbf{propriet√† associativa} A5 si perviene al risultato seguente:
\[\overline{y}\overline{z} + xy + \overline{x}z + yz + \overline{x}\overline{y} = \overline{y}\overline{z} + \left(xy + \overline{x}z + yz\right) + \overline{x}\overline{y} = \left(\overline{x}z + \overline{y}\overline{z} + \overline{x}\overline{y}\right) + xy = \overline{y}\overline{z} + xy + \overline{x}z\]
giacch√©
\[xy + \overline{x}z + yz = xy + \overline{x}z \hspace{1em} \text{e} \hspace{1em} \overline{x}z + \overline{y}\overline{z} + \overline{x}\overline{y} = \overline{x}z + \overline{y}\overline{z}\]
come volevasi dimostrare.

\vspace{2em}
\noindent
\textbf{Esercizio}: Si consideri, ora, una seconda funzione \(f\) a \(n = 3\) variabili, la quale presenta la tabela di verit√† riportata nella Tabella \ref{tab:funzione_3_variabili_1} seguente:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{ccc|c}
      $x$ & $y$ & $z$ & $f(x, y, z)$\\
      \hline
      $0$ & $0$ & $0$ & $1$\\
      $0$ & $0$ & $1$ & $0$\\
      $0$ & $1$ & $0$ & $1$\\
      $0$ & $1$ & $1$ & $0$\\
      $1$ & $0$ & $0$ & $1$\\
      $1$ & $0$ & $1$ & $0$\\
      $1$ & $1$ & $0$ & $0$\\
      $1$ & $1$ & $1$ & $0$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_1}
\end{table}

\noindent
Considerando la \textbf{somma di \textit{minterm}} si ottiene
\[f = \overline{x}\overline{y}\overline{z} + \overline{x}y\overline{z} + x\overline{y}\overline{x}\]
che per il \textbf{teorema dell'Idempotenza} T1 si pu√≤ scrivere come segue:
\[f = \overline{x}\overline{y}\overline{z} + \overline{x}y\overline{z} + x\overline{y}\overline{x} + \overline{x} \overline{y} \overline{z}\]
Per cui, per il \textbf{teorema dell'Assorbimento} T9 si traduce in
\[f = \overline{x}\overline{z} \cdot (\overline{y} + y) + \overline{y}\overline{z} \cdot (x + \overline{x}) = \overline{x} \overline{z} + \overline{y}\overline{z}\]

\vspace{1em}
\noindent
Considerando, invece, il \textbf{prodotto di \textit{maxterm}} si ottiene
\[f = (y + \overline{z}) \cdot (\overline{y} + \overline{z}) \cdot (\overline{x} + \overline{y}) = (y \overline{y} + y \overline{z} + \overline{y}\overline{z} + \overline{z} \overline{z}) \cdot (\overline{x} + \overline{y}) = \overline{z} \cdot (\overline{x} + \overline{y}) = \overline{x} \overline{z} + \overline{y} \overline{z}\]
semplificando grazie all'\textbf{assioma di complementariet√†} A7 e al \textbf{teorema dell'Assorbimento} T9.\\
Realizzando la funzione considerata tramite la mappa di Karnaugh Figura \ref{fig:mappa_karnaugh_8_2} seguente si ottiene:

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,1,1,0,0,0,0,0}
        \implicant{0}{1}{red}
        \implicantcostats{1}{2}{green}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a $3$ variabili}
    \label{fig:mappa_karnaugh_8_2}
\end{figure}

\noindent
E analizzando gli implicanti ottenuti si perviene al risultato gi√† ottenuto:
\[f = \overline{x}\overline{z} + \overline{y}\overline{z}\]

\vspace{2em}
\noindent
\textbf{Esercizio}: Si consideri, ora, una terza funzione \(f\) a \(n = 3\) variabili, la quale presenta la tabela di verit√† riportata nella Tabella \ref{tab:funzione_3_variabili_2} seguente:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{ccc|c}
      $x$ & $y$ & $z$ & $f(x, y, z)$\\
      \hline
      $0$ & $0$ & $0$ & $1$\\
      $0$ & $0$ & $1$ & $1$\\
      $0$ & $1$ & $0$ & $0$\\
      $0$ & $1$ & $1$ & $1$\\
      $1$ & $0$ & $0$ & $0$\\
      $1$ & $0$ & $1$ & $0$\\
      $1$ & $1$ & $0$ & $1$\\
      $1$ & $1$ & $1$ & $0$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_2}
\end{table}

\noindent
Considerando la \textbf{somma di \textit{minterm}} si ottiene
\[f = \overline{x}\overline{y}\overline{z} + \overline{x}\overline{y}z + \overline{x}yz + xy\overline{z}\]
Procedendo alla semplificazione tramite il \textbf{teorema dell'Assorbimento} T9 si ottiene
\[f = \overline{x}\overline{y}(\overline{z} + z) + \overline{x}yz + xy\overline{z}\]
Applicando il \textbf{teorema dell'Idempotenza} T1, si ottiene
\[f = \overline{x}\overline{y}(\overline{z} + z) + \overline{x}\overline{y}z + \overline{x}yz + xy\overline{z} = \overline{x}\overline{y}(\overline{z} + z) + \overline{x}z (\overline{y} + y) + xy\overline{z}\]
che equivale a
\[f = \overline{x}\overline{y} + \overline{x}z + xy\overline{z}\]
sempre per il \textbf{teorema dell'Assorbimento} T9.

\vspace{1em}
\noindent
Considerando il \textbf{prodotto di \textit{maxterm}} si ottiene:
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y + z) \cdot (\overline{x} + y + \overline{z}) \cdot (\overline{x} + \overline{y} + \overline{z})\]
che per il \textbf{teorema dell'Assorbimento} T9 equivale a
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{z})\]
Procedendo applicando il \textbf{teorema dell'Idempotenza} T1 si effettua la duplicazione di \(\overline{x} + y + \overline{z}\) per cui si ottiene:
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y + z) \cdot (\overline{x} + y + \overline{z}) \cdot (\overline{x} + \overline{z})\]
da cui, sempre per il \textbf{teorema dell'Assorbimento} T9,  si ottiene
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y) \cdot (\overline{x} + \overline{z})\]
Come nel primo caso, si √® ottenuto un risultato di semplificazione differente tra le due forme canonice di \textbf{somma di \textit{minterm}} e \textbf{prodotto di \textit{maxterm}}. Al fine di dimostrarne l'equivalenza si procede allo sviluppo dell'ultima espressione come segue:
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y) \cdot (\overline{x} + \overline{z}) = (x + \overline{y} + z) \cdot (\overline{x} + \overline{x} \overline{z} + \overline{x}y + y \overline{z})\]
Applicando il \textbf{teorema dell'Assorbimento 1} T4 si ottiene:
\[f = (x + \overline{y} + z) \cdot (\overline{x} + \overline{x} \overline{z} + \overline{x}y + y \overline{z}) = (x + \overline{y} + z) \cdot (\overline{x} + \overline{x}y + y \overline{z}) = (x + \overline{y} + z) \cdot (\overline{x} + y \overline{z})\]
Per cui, sviluppando l'espressione si ottiene
\[f = x \overline{x} + xy\overline{z} + \overline{x}\overline{y} + y\overline{y}\overline{z} + \overline{x}z + yz\overline{z}\]
Naturalmente, per l'\textbf{assioma di complementariet√†} A7 si ottiene
\[f = xy\overline{z} + \overline{x}\overline{y} + \overline{x}z\]
Di fatto, come si osserva, si √® ottenuto il medesimo risultato di partenza. Realizzando la funzione considerata tramite la mappa di Karnaugh Figura \ref{fig:mappa_karnaugh_8_3} seguente si ottiene:

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,0,1,1,1,0,0}
        \implicant{3}{3}{red}
        \implicant{4}{5}{blue}
        \implicant{0}{4}{green}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a $3$ variabili}
    \label{fig:mappa_karnaugh_8_3}
\end{figure}

\noindent
E analizzando gli implicanti ottenuti si perviene al risultato gi√† ottenuto:
\[f = \overline{x} \overline{y} + \overline{x} z + xy\overline{z}\]

\newpage
\noindent
\textbf{Esercizio}: Si costruisca una nuova funzione \(f\) a \(n = 3\) variabili, la quale presenta la tabela di verit√† riportata nella Tabella \ref{tab:funzione_3_variabili_5} seguente:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{ccc|c}
      $x$ & $y$ & $z$ & $f(x, y, z)$\\
      \hline
      $0$ & $0$ & $0$ & $1$\\
      $0$ & $0$ & $1$ & $0$\\
      $0$ & $1$ & $0$ & $1$\\
      $0$ & $1$ & $1$ & $1$\\
      $1$ & $0$ & $0$ & $0$\\
      $1$ & $0$ & $1$ & $1$\\
      $1$ & $1$ & $0$ & $1$\\
      $1$ & $1$ & $1$ & $0$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_5}
\end{table}

\noindent
Considerando la \textbf{somma di \textit{minterm}} si ottiene
\[f = \overline{x} \overline{y} \overline{z} + \overline{x} y \overline{z} + \overline{x} y z + x \overline{y}z + xy \overline{z}\]
Procedendo alla semplificazione, tramite il \textbf{teorema dell'Assorbimento} T9 si ottiene
\[f = \overline{x}\overline{z}(\overline{y} + y) + \overline{x} y z + x \overline{y}z + xy \overline{z} = \overline{x}\overline{z} + \overline{x} y z + x\overline{y}z + xy \overline{z}\]
Applicando il \textbf{teorema dell'Assorbimento 2} T5:
\[f = \overline{x}(\overline{z} + yz) + x\overline{y}z + xy\overline{z} = \overline{x}\overline{z} + \overline{x}y + x \overline{y}z + xy\overline{z}\]
Applicando nuovamente il \textbf{teorema dell'Assorbimento 2} T5:
\[f = \overline{x}\overline{z} + x\overline{y}z + y(\overline{x} + x\overline{z}) = \overline{x}\overline{z} + x\overline{y}z + \overline{x}y  y\overline{z}\]

\vspace{1em}
\noindent
Considerando, ora, il \textbf{prodotto di \textit{maxterm}} si ottiene
\[f = (x + y + \overline{z}) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{y} + \overline{z})\]
Non potendo semplificare in maniera immediata, si procede allo sviluppo dei prodotti:
\[f = \left(x\overline{x} + xy + xz + \overline{x}y + y + yz + \overline{x}\overline{z} + y\overline{z} + \overline{z}\right) \cdot (\overline{x} + \overline{y} + z\overline{z})\]
Applicando l'\textbf{assioma di complementariet√†} A7, il \textbf{teorema dell'Idempotenza} T1, il \textbf{teorema dell'Assorbimento} T9 e il \textbf{teorema dell'Assorbimento 1} T4, si semplifica come segue
\[f = \left(xz + y + \overline{x}\overline{z}\right) \cdot (\overline{x} + \overline{y} + \overline{z})\]
Ancora una volta si sviluppa l'espressione, ottenendo:
\[f = x\overline{x}z + x\overline{y}z + xz\overline{z} + \overline{x}y + y\overline{y} + y\overline{z} + \overline{x}\overline{z} + \overline{x}\overline{y}\overline{z} + \overline{x}\overline{z}\]
Ancora una volta, applicando l'\textbf{assioma di complementariet√†} A7, il \textbf{teorema dell'Idempotenza} T1, il \textbf{teorema dell'Assorbimento} T9 e il \textbf{teorema dell'Assorbimento 1} T4, si semplifica come segue
\[f = x\overline{y}z + \overline{x}y + y\overline{z} + \overline{x}\overline{z}\]
come volevasi dimostrare. Realizzando la funzione considerata tramite la mappa di Karnaugh Figura \ref{fig:mappa_karnaugh_8_4} seguente si ottiene:

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,1,0,1,0,1,1,0}
        \implicant{0}{1}{red}
        \implicant{1}{3}{green}
        \implicant{1}{5}{blue}
        \implicant{6}{6}{violet}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a $3$ variabili}
    \label{fig:mappa_karnaugh_8_4}
\end{figure}

\noindent
E analizzando gli implicanti ottenuti si perviene al risultato gi√† ottenuto:
\[f = \overline{x}\overline{z} + \overline{x}y + y\overline{z} + x\overline{y}z\]

\newpage
\begin{center}
    20 Ottobre 2021
\end{center}
\subsection{Metodo tabellare di Quine - Mc Cluskey}
Il \emph{metodo tabellare di Quine - Mc Cluskey} √® un procedimento tabellare che consente di ottenere la forma minima come somma di prodotti per qualsiasi funzione logica. Esso si basa sulla relazione:
\[f \cdot x + f \cdot \overline{x} = f\]
gi√† usata in precedenza per le mappe di Karnaugh; solo che ora essa viene applicata in modo sistematico a tutti i termini minimi della funzione.\\
Per capirne la logica si consideri la seguente funzione logica:

\begin{table}[H]
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabularx}{\textwidth}{ccc}
    {
        \hspace{-1em}
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|ccc|cc}
             & & $x$ & $y$ & $z$ & $f$\\
             \hline
             $0$ & $\overline{x}\overline{y}\overline{z}$ & $0$ & $0$ & $0$ & $0$\\
             $1$ & $\overline{x}\overline{y}z$ & $0$ & $0$ & $1$ & $0$\\
             $2$ & $\overline{x}y\overline{z}$ & $0$ & $1$ & $0$ & $1$ & $\color{red}{\ast}$\\
             $3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$ & $\color{red}{\ast}$\\
             $4$ & $x\overline{y}\overline{z}$ & $1$ & $0$ & $0$ & $0$\\
             $5$ & $x\overline{y}z$ & $1$ & $0$ & $1$ & $1$ & $\color{blue}{\ast}$\\
             $6$ & $xy\overline{z}$ & $1$ & $1$ & $0$ & $0$\\
             $7$ & $xyz$ & $1$ & $1$ & $1$ & $1$ & $\color{blue}{\ast}$\\
        \end{tabular}
    }
    &
    {
        \hspace{-1em}
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|c|ccc|cc}
             \textbf{Livello} & & & $x$ & $y$ & $z$ & $f$\\
             \hline
             $0$ & $0$ & $\overline{x}\overline{y}\overline{z}$ & $0$ & $0$ & $0$ & $0$\\
             \hline
              & $1$ & $\overline{x}\overline{y}z$ & $0$ & $0$ & $1$ & $0$\\
              \(1\) & $2$ & $\overline{x}y\overline{z}$ & $0$ & $1$ & $0$ & $1$ & $\color{red}{\ast}$\\
              & $4$ & $x\overline{y}\overline{z}$ & $1$ & $0$ & $0$ & $0$\\
             \hline
              &
             $3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$ & $\color{red}{\ast}$\\
             \(2\) & $5$ & $x\overline{y}z$ & $1$ & $0$ & $1$ & $1$ & $\color{blue}{\ast}$\\
             & $6$ & $xy\overline{z}$ & $1$ & $1$ & $0$ & $0$\\
             \hline
             $3$ & $7$ & $xyz$ & $1$ & $1$ & $1$ & $1$ & $\color{blue}{\ast}$\\
        \end{tabular}
    }
    &
    {
        \hspace{-1em}
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|c|ccc|cc}
             \textbf{Livello} & & & $x$ & $y$ & $z$ & $f$\\
             \hline
             $1$ & $2$ & $\overline{x}y\overline{z}$ & $0$ & $1$ & $0$ & $1$ & $\color{red}{\ast}$\\
             \hline
             \parbox{3em}{\multirow{2}{3em}{\centering \(2\)}} &
             $3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$ & $\color{red}{\ast}$\\
             & $5$ & $x\overline{y}z$ & $1$ & $0$ & $1$ & $1$ & $\color{blue}{\ast}$\\
             \hline
             $3$ & $7$ & $xyz$ & $1$ & $1$ & $1$ & $1$ & $\color{blue}{\ast}$\\
        \end{tabular}
    }
    \end{tabularx}
    \caption{Trasformazione della tavola di verit√† della funzione logica \(f\) per ottenere la tabella di Quine-Mc Cuskey}
    \label{tab:tavola_verita_Quine_Mc_Cuskey}
\end{table}

\noindent
La semplificazione per via algebrica di tale funzione $f$ porta a:
\[f = \overline{x}y\overline{z} + \overline{x}yz + x\overline{y}z + xyz = \overline{x}y(\overline{z} + z) + xz(\overline{y} + y) = \overline{x}y + xz\]
√à ben evidente che la struttura della semplificazione
\[\overline{x}y\overline{z} + \overline{x}yz = \overline{x}y(\overline{z} + z)\]
che riguarda i termini minimi contrassegnati con $\color{red}{\ast}$ in tabella, √® del tipo
\[f\overline{z} + fz = f\]
e riguarda due termini minimi che differiscono per la sola variabile \(z\), che si trova diretta in uno dei due termini e negata nell'altro. La stessa cosa si pu√≤ dire per i due termini minimi contrassegnati con $\color{blue}{\ast}$.\\
Si procede, quindi, all'ordinamento delle righe della tabella in modo da mettere su livelli adiacenti le n-uple che differiscono per una sola variabile.\\
Una possibilit√† √® quella di procedere per peso crescente delle n-uple binarie associate ai termini minimi (dove per peso di un'n-upla √® da intendersi il numero di $1$ in essa presenti) in modo che a ciascun peso corrisponda un livello; cos√¨ facendo si ottiene la seconda tabella riportata in Figura \ref{tab:tavola_verita_Quine_Mc_Cuskey}.\\
Se ora si eliminano le righe che corrispondono a termini minimi per i quali la funzione vale $0$ (che non rientrano nella somma di prodotti) si ottiene la terza tabella di Figura \ref{tab:tavola_verita_Quine_Mc_Cuskey}, che corrisponde alla tabella di Quine-Mc Cuskey.\\
A questo punto si pu√≤ procedere con le semplificazioni, che generano una seconda tabella. Poich√© \(\overline{x} y \overline{z}\) si semplifica con \(\overline{x}yz\) per ottenere \(\overline{x}y\), su questa tabella viene contrassegnata con una lineetta la variabile \(z\) che √® stata oggetto di semplificazione; vengono, inoltre, contrassegnati a lato i termini minimi che sono coinvolti nella semplificazione, cio√® \(2 - 3\); viceversa la coppia \(2 - 5\) non porta ad alcuna semplificazione. Esaurito il confronto tra i livelli \(1\) e \(2\), √® possibile ora controllare le semplificazioni tra i livelli \(2\) e \(3\); in questo caso si trovano semplificazioni per entrambe le coppie, cio√® \(3 - 7\) e \(5 - 7\).\\
La tabella che si ottiene √® la seguente:

\rowcolors{1}{white}{white}
\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{c|c|ccc|cc}
         & $ $ & $x$ & $y$ & $z$ & $ $ & \\
         \hline
         & $2 - 3$ & $0$ & $1$ & $-$ & $A$ & \\
         \hline
         & $3 - 7$ & $-$ & $1$ & $1$ & $B$ & \\
         & $5 - 7$ & $1$ & $-$ & $1$ & $C$ & \\
    \end{tabular}
    \caption{Tabella di semplificazione}
    \label{tab:semplificazione_quine_mc_cuskey_0}
\end{table}

\noindent
Poich√© non √® possibile fare altre semplificazioni ci si ferma, contrassegnando con delle lettere progressive gli implicanti che non si possono pi√π semplificare.\\
L‚Äôespressione finale deriva dalla somma degli implicanti coinvolti:
\[f = A + B + C = \overline{x}y + yz + xz\]
Si osservi, tuttavia, che l‚Äôespressione che √® stata ottenuta non √® in forma minima, poich√©, com'√® noto, il termine \(yz\) si pu√≤ eliminare per il \textbf{teorema dell'Assorbimento 3} T6.\\
Infatti, ci√≤ si pu√≤ facilmente osservare anche attraverso la realizzazione della mappa di Karnaugh della funzione considerata

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{0,1,0,0,0,1,1,1}
        \implicant{1}{5}{red}
        \implicant{7}{6}{green}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a $3$ variabili}
    \label{fig:mappa_karnaugh_8_5}
\end{figure}

\noindent
Dall'analisi degli implicanti individuati appare evidente come si possa esprimere $f$ come segue:
\[f = \overline{x}y + xz\]
Per individuare il minimo numero di implicanti che implicano tutti i termini minimi √® necessario costruire il \textbf{reticolo del metodo}, disponendo sulle righe gli implicanti, sulle colonne i termini minimi, e ponendo un segno (quale un pallino) in corrispondenza dei termini minimi che formano ciascun implicante. In particolare si osserva che:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{tikzpicture}
    \tikzset{dot/.style={fill=black,circle}}

    \foreach \l [count=\y] in {C,...,A} {
      \draw (0,\y) -- (5,\y);
      \node at (-0.5,\y){\l};
    }

    \foreach \x [count=\i] in {2,3,5,7} {
        \draw (\i,0) -- (\i,4);
        \node at (\i,-0.5){\x};
    }

    % A
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (1,3){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (2,3){};

    % B
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (2,2){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (4,2){};

    % C
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (3,1){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (4,1){};
    \end{tikzpicture}
    \caption{Reticolo di semplificazione}
    \label{fig:reticolo_semplificazione_0}
\end{figure}

\noindent
Procedendo per colonne √® facile osservare che il termine minimo $2$ √® coperto solo dall'implicante $A$ e dunque questo implicante √® indispensabile; il termine minimo $5$ viene coperto solo da $C$ e, dunque, anche questo implicante √® indispensabile.\\
L‚Äôimplicante $B$, invece, non √® necessario alla composizione della funzione, poich√© i termini minimi a lui associati, ossia $3$ e $7$, sono gi√† coperti rispettivamente da $A$ e da $C$. Dunque la funzione semplificata, come gi√† anticipato, √®
\[f = \overline{x}y + xz\]

\newpage
\subsubsection{Procedura di Quine-Mc Cluskey}
La procedura completa per la semplificazione mediante il metodo tabellare di Quine-Mc Cluskey √® la seguente:

\begin{enumerate}
  \item si esprimono i termini minimi che sono a $1$ sostituendo ogni variabile diretta con $1$ e ogni variabile negata con $0$. Ad esempio, il termine minimo $\overline{x}yz$ viene rappresentato con $011$;
  \item si ordinano tutti i termini minimi in gruppi aventi lo stesso peso, cio√® lo stesso numero di $1$; tali raggruppamenti vengono chiamati \textbf{livelli};
  \item si costruisce una tabella disponendo i livelli in ordine crescente e associando a ciascun termine minimo il corrispondente numero decimale. Ad esempio i termini minimi
  \[\overline{x}\overline{y}\overline{z} \hspace{2em} \overline{x}\overline{y} \hspace{2em} \overline{x}y\overline{z} \hspace{2em} \overline{x}yz \hspace{1em} xyz\]
  generano la seguente tabella

  \begin{table}[H]
      \centering
      \setlength{\tabcolsep}{3.5pt}
      \begin{tabular}{c|c|c|c}
        $ $ & \text{Livello} & \text{Numero} & \text{Termine minimo}\\
        \hline
        $\sqrt{}$ & $0$ & $0$ & $000$\\
        \hline
        $\sqrt{}$ & $1$ & $1$ & $001$\\
        $\sqrt{}$ & $1$ & $2$ & $010$\\
        \hline
        $\sqrt{}$ & $2$ & $3$ & $011$\\
        \hline
        $\sqrt{}$ & $3$ & $7$ & $111$\\
      \end{tabular}
      \caption{Divisione dei termini minimi in livelli e riordinamento degli stessi}
      \label{tab:divisione_minterm_livello}
  \end{table}

  \item a partire dal primo termine minimo del primo livello disponibile, si confrontano tutti i termini minimi del livello $k$ con tutti quelli del livello $k + 1$, semplificando tra loro i termini che differiscono per un solo bit.\\
  Si costruisce in tal modo una seconda tabella, nella quale le semplificazioni avvenute si indicano con una lineetta, mentre gli implicanti vengono contraddistinti con i numeri dei termini minimi che li hanno generati.\\
  Nella tabella si contrassegnano tutti i termini minimi che hanno dato luogo ad almeno una semplificazione, mentre i termini minimi che non hanno portato a semplificazioni vengono contrassegnati con lettere progressive dell‚Äôalfabeto. Riferendosi all‚Äôesempio riportato sopra, si ottiene la Tabella \ref{tab:semplificazione_quine_mc_cuskey_1} seguente:

  \rowcolors{1}{white}{white}
  \begin{table}[H]
      \centering
      \rowcolors{1}{white}{white}
      \setlength{\tabcolsep}{8pt}
      \renewcommand{\arraystretch}{1.2}
      \begin{tabular}{c|c|c}
           $\sqrt{}$ & $0,1$ & $00-$\\
           $\sqrt{}$ & $0,2$ & $0-0$\\
           \hline
           $\sqrt{}$ & $1,3$ & $0-1$\\
           $\sqrt{}$ & $2,3$ & $01-$\\
           \hline
           $A$ & $3,7$ & $-11$\\
      \end{tabular}
      \caption{Tabella di semplificazione}
      \label{tab:semplificazione_quine_mc_cuskey_1}
  \end{table}

  \item con lo stesso procedimento di prima, nella seconda tabella si confrontano tutti i termini del livello $k$ con tutti quelli del livello $k + 1$. Sono semplificabili tra loro i termini che \emph{differiscono per un solo bit} e che siano \emph{gi√† stati semplificati rispetto alla stessa variabile}. Si costruisce in tal modo una terza tabella con le stesse modalit√† esposte per la costruzione della seconda tabella. Nell‚Äôesempio che si sta trattando si ha la Tabella \ref{tab:semplificazione_quine_mc_cuskey_2} che segue:

  \rowcolors{1}{white}{white}
  \begin{table}[H]
      \centering
      \rowcolors{1}{white}{white}
      \setlength{\tabcolsep}{8pt}
      \renewcommand{\arraystretch}{1.2}
      \begin{tabular}{c|c|c}
           $B$ & $0,1,2,3$ & $0--$\\
      \end{tabular}
      \caption{Tabella di semplificazione}
      \label{tab:semplificazione_quine_mc_cuskey_2}
  \end{table}

  \noindent
  mentre nella seconda tabella il termine $3,7$ non d√† luogo a semplificazioni e viene quindi contrassegnato con $A$.
  \item si prosegue in modo analogo, con la costruzione di tabelle successive, finch√® non √® pi√π possibile eseguire semplificazioni. Tutti i termini che nelle successive tabelle non sono stati contrassegnati vengono chiamati implicanti primi e la loro somma logica realizza la funzione desiderata. Pu√≤ per√≤ accadere che l‚Äôespressione minima di tale funzione si realizzi con un numero di implicanti inferiore a quello degli implicanti primi: essa, infatti, si ricava come somma del minimo numero di implicanti primi con cui vengono implicati tutti i termini minimi della funzione. Nell‚Äôesempio che si sta esaminando gli implicanti primi sono
  \[A = -11 \hspace{2em} B = 0--\]
  \item la scelta pi√π opportuna degli implicanti primi necessari, che pu√≤ divenire complessa gi√† con un numero di variabili relativamente ridotto, avviene mediante la costruzione di un semplice reticolo, avente i termini minimi sulle colonne e gli implicanti primi sulle righe. Su ogni riga, cio√® in corrispondenza di ciascun implicante, si contrassegnano opportunamente i termini minimi implicati. Nell‚Äôesempio trattato si ottiene il seguente reticolo

  % Contenitore per immagini
  \begin{figure}[H]
      \centering
      \begin{tikzpicture}
      \tikzset{dot/.style={fill=black,circle}}

      \foreach \l [count=\y] in {B,A} {
        \draw (0,\y) -- (6,\y);
        \node at (-0.5,\y){\l};
      }

      \foreach \x [count=\i] in {0,1,2,3,7} {
          \draw (\i,0) -- (\i,3);
          \node at (\i,-0.5){\x};
      }

      % A
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (4,2){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (5,2){};

      % B
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (1,1){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (2,1){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (3,1){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (4,1){};
      \end{tikzpicture}
      \caption{Reticolo di semplificazione}
      \label{fig:reticolo_semplificazione_1}
  \end{figure}

  \noindent
  Dall‚Äôesame del reticolo si individuano poi i termini minimi che sono implicati da un unico implicante primo. Ciascuno di essi diviene evidentemente essenziale nella realizzazione della funzione. Ogni implicante essenziale cos√¨ individuato implica d‚Äôaltra parte altri termini minimi che risultano automaticamente coperti e pertanto non vanno piu considerati.\\
  √à semplice, infine, trovare, sia pure per tentativi, la copertura minima dei termini rimasti. Nell‚Äôesempio che si sta trattando ambedue gli implicanti primi $A$ e $B$ sono essenziali; l‚Äôespressione semplificata √® allora
  \[f = A + B = yz + \overline{x}\]
  Facilmente ravvisabile anche attraverso la mappa di Karnaugh associata, riportata nella Figura \ref{fig:mappa_karnaugh_8_6}

  \begin{figure}[H]
      \centering
      \begin{Karnaughvuit}
          \contingut{1,1,0,0,1,1,0,1}
          \implicant{0}{5}{red}
          \implicant{5}{7}{green}
      \end{Karnaughvuit}
      \vspace{-1.5em}
      \caption{Mappa di Karnaugh a $3$ variabili}
      \label{fig:mappa_karnaugh_8_6}
  \end{figure}
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esempio}: Pi√π significativo, soprattutto per quanto riguarda la realizzazione della copertura minima, √® l‚Äôesempio seguente. Si voglia semplificare la funzione
\[f = \sum \left(1,3,4,6,7,9,10,11,12,13,14,15\right)_m\]
nella quale la notazione binaria associata a ciascun numero intero rappresenta la codifica dei termini minimi. La divisione dei termini minimi in livelli e il riordinamento dei livelli d√† luogo alla tabella di sinistra, mentre al centro e sulla destra ci sono le successive tabelle di semplificazione

\begin{table}[H]
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabularx}{\textwidth}{ccc}
    {
        \hspace{-1em}
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|c|c}
        $ $ & \text{Livello} & \text{Numero} & \text{Termine minimo}\\
        \hline
        $\sqrt{}$ & $1$ & $1$ & $0001$\\
        $\sqrt{}$ & $1$ & $4$ & $0100$\\
        \hline
        $\sqrt{}$ & $2$ & $3$ & $0011$\\
        $\sqrt{}$ & $2$ & $6$ & $0110$\\
        $\sqrt{}$ & $2$ & $9$ & $0101$\\
        $\sqrt{}$ & $2$ & $10$ & $1010$\\
        $\sqrt{}$ & $2$ & $12$ & $1100$\\
        \hline
        $\sqrt{}$ & $3$ & $7$ & $0111$\\
        $\sqrt{}$ & $3$ & $11$ & $1011$\\
        $\sqrt{}$ & $3$ & $13$ & $1101$\\
        $\sqrt{}$ & $3$ & $14$ & $1110$\\
        \hline
        $\sqrt{}$ & $4$ & $15$ & $1111$\\
      \end{tabular}
    }
    &
    {
        \hspace{-1em}
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|c}
             $\sqrt{}$ & $1,3$ & $00-1$\\
             $\sqrt{}$ & $1,9$ & $-0001$\\
             $\sqrt{}$ & $4,6$ & $01-0$\\
             $\sqrt{}$ & $4,12$ & $-100$\\
             \hline
             $\sqrt{}$ & $3,7$ & $0-11$\\
             $\sqrt{}$ & $3,11$ & $-011$\\
             $\sqrt{}$ & $6,7$ & $011-$\\
             $\sqrt{}$ & $5,14$ & $-110$\\
             $\sqrt{}$ & $9,11$ & $10-1$\\
             $\sqrt{}$ & $9,13$ & $1-01$\\
             $\sqrt{}$ & $10,11$ & $101-$\\
             $\sqrt{}$ & $10,14$ & $1-10$\\
             $\sqrt{}$ & $12,13$ & $110-$\\
             \hline
             $\sqrt{}$ & $7,15$ & $-111$\\
             $\sqrt{}$ & $11,15$ & $1-111$\\
             $\sqrt{}$ & $13,15$ & $11-1$\\
             $\sqrt{}$ & $14,15$ & $111-$\\
        \end{tabular}
    }
    &
    {
        \hspace{-1em}
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|c}
             $A$ & $1,3,9,11$ & $-0-1$\\
             $B$ & $4,6,12,14$ & $-1-0$\\
             \hline
             $C$ & $3,7,11,15$ & $--11$\\
             $D$ & $6,7,14,15$ & $-11-$\\
             $E$ & $9,11,13,15$ & $1--1$\\
             $F$ & $10,11,14,15$ & $1-1-$\\
             $G$ & $12,13,14,15$ & $11--$\\
        \end{tabular}
    }
    \end{tabularx}
    \caption{Trasformazione della tavola di verit√† della funzione logica di \(4\) variabili per ottenere la tabella di Quine-Mc Cuskey}
    \label{tab:tavola_verita_Quine_Mc_Cuskey_4_variabili}
\end{table}

\noindent
A cui fa seguito immediato il reticolo di Figura \ref{fig:reticolo_semplificazione_2}:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{tikzpicture}
    \tikzset{dot/.style={fill=black,circle}}

    \foreach \l [count=\y] in {G,...,A} {
      \draw (0,\y) -- (13,\y);
      \node at (-0.5,\y){\l};
    }

    \foreach \x [count=\i] in {1,3,4,6,7,9,10,11,12,13,14,15} {
        \draw (\i,0) -- (\i,8);
        \node at (\i,-0.5){\x};
    }

    % A
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (1,7){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (2,7){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (6,7){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (8,7){};

    % B
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (3,6){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (4,6){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (9,6){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (11,6){};

    % C
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (2,5){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (5,5){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (8,5){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (12,5){};

    % D
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (4,4){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (5,4){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (11,4){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (12,4){};

    % E
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (6,3){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (8,3){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (10,3){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (12,3){};

    % F
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (7,2){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (8,2){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (11,2){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (12,2){};

    % G
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (9,1){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (10,1){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (11,1){};
    \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (12,1){};
    \end{tikzpicture}
    \caption{Reticolo di semplificazione}
    \label{fig:reticolo_semplificazione_2}
\end{figure}

\noindent
Dall‚Äôesame del reticolo risulta che il termine minimo $1$ √® implicato solamente da $A$, quello $4$ solo da $B$ e quello $10$ solo da $F$. Di conseguenza $A$, $B$, $F$ sono implicanti primi essenziali. La loro scelta copre i termini minimi
$1$, $3$, $4$, $6$, $9$, $10$, $11$, $12$, $14$, $15$. Per coprire i rimanenti termini minimi $7$ e $13$ si pu√≤ scegliere per il primo l‚Äôimplicante $C$ o quello $D$, per il secondo quello $E$ o quello $G$.\\
Ci sono, pertanto, quattro realizzazioni equivalenti della funzione assegnata
\begin{flalign*}
  f & = A + B + F + D + E = \overline{y}w + y\overline{w} + xz + yz + xw\\
  f & = A + B + F + D + G = \overline{y}w + y\overline{w} + xz + yz + xy\\
  f & = A + B + F + C + E = \overline{y}w + y\overline{w} + xz + zw + xw\\
  f & = A + B + F + C + G = \overline{y}w + y\overline{w} + xz + zw + xy
\end{flalign*}
Tali realizzazioni si comprendono non appena si valuta attentamente la mappa di Karnaugh di Figura \ref{fig:mappa_karnaugh_16_2} associata alla
funzione considerata
\noindent
Tali realizzazioni si comprendono non appena si valuta attentamente la mappa di Karnaugh associata alla funzione a \(n  = 4\) variabili:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{0,1,0,1,1,0,1,1,0,1,1,1,1,1,1,1}
        \implicantcostats{4}{14}{red}
        \implicant{13}{11}{blue}
        \implicant{13}{10}{yellow}
        \implicant{7}{10}{green}
        \implicantdaltbaix{1}{11}{violet}
        \implicant{7}{14}{orange}
    \end{Karnaugh}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh della funzione a $4$ variabili}
    \label{fig:mappa_karnaugh_16_2}
\end{figure}

\noindent
In cui vi sono solamente $3$ sottocubi primi, mentre i restanti $2$ non sono primi e sono fra loro interdipendenti. Da tale configurazione segue la molteplicit√† delle soluzioni individuate in precedenza.

\newpage
\section{Circuiti combinatori}

\subsection{Introduzione}
Nella realt√† pratica, l'Algebra Booleana non sempre viene impiegata per raggiungere la \textbf{forma minima} di una funzione logica, in quanto se cos√¨ si procedesse non si potrebbe sfruttare il \textbf{fattore di scala}.\\
Infatti, quando si deve realizzare una rete logica, molto spesso √® pi√π conveniente impiegare dei \textbf{moduli precostituiti}, anche ridondanti, piuttosto che richiedere la realizzazione di un modulo \textit{custom}, costruito appositamente per lo scopo.\\
In questi termini si parla di \textbf{circuiti combinatori}. Si chiamano \emph{combinatori} quei circuiti dotati di uno o pi√π ingressi e uno o pi√π uscite, il cui funzionamento √® descritto da una funzione logica; in questi circuiti gli ingressi e le uscite possono assumere solo uno di due valori binari previsti ($0$ e $1$); inoltre, in ogni istante, l‚Äôuscita √® funzione deterministica unicamente degli ingressi.

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \draw (0,0) -- (0,3) -- (2,3) -- (2,0) -- (0,0);
      \draw (0,2.5) -- ++(-1,0) ++(-0.3,0) node[]{$x_1$};
      \draw (0,2) -- ++(-1,0) ++(-0.3,0) node[]{$x_2$};
      \draw (-0.5,1.7) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (-0.5,1.5) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (-0.5,1) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (-0.5,0.8) node[fill,circle,inner sep=0pt,minimum size=2pt]{};
      \draw (0,0.5) -- ++(-1,0) ++(-0.3,0) node[]{$x_n$};

      \draw (2,2.5) -- ++(1,0) ++(0.3,0) node[]{$y_1$};
      \draw (2,2) -- ++(1,0) ++(0.3,0) node[]{$y_2$};
      \draw (2.5,1.7) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (2.5,1.5) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (2.5,1) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (2.5,0.8) node[fill,circle,inner sep=0pt,minimum size=2pt]{};
      \draw (2,0.5) -- ++(1,0) ++(0.3,0) node[]{$y_m$};

      \draw (1,1.5) node[]{$F$};
    \end{tikzpicture}
    \caption{Struttura generale di un circuito combinatorio}
    \label{fig:struttura_generale_circuito_combinatorio}
\end{figure}

\noindent
La Figura \ref{fig:struttura_generale_circuito_combinatorio} precedente illustra la struttura generale di un circuito combinatorio con \(n\) ingressi e \(m\) uscite, il cui funzionamento √® descritto dalla funzione
\[F : 2^n \rightarrow 2^m\]
che √® una funzione Booleana da \(2^n\) a \(2^m\) realizzata mediante \(m\) funzioni Booleane
\[f_i : 2^n \rightarrow 2\]
mostrate di seguito:
\[y_1 = f_1 (x_1, x_2, ..., x_n)\]
\[y_2 = f_2 (x_1, x_2, ..., x_n)\]
\[...\]
\[y_m = f_m (x_1, x_2, ..., x_n)\]
Nei circuiti elettronici i due stati $0$ e $1$ sono realizzati mediante due livelli caratteristici di tensione, detti \textbf{livello alto} ($h$) e \textbf{livello basso} ($l$). L‚Äôeffettiva corrispondenza tra $h$ e $l$ e le costanti logiche $0$ e $1$ √® convenzionale e va precisata di volta in volta. In tal senso, √® detta \textbf{logica positiva} la convenzione secondo la quale il valore $1$ viene associato al livello alto $h$; simmetricamente, si chiama \textbf{logica negativa} quella in cui il valore $1$ √® associato al livello basso $l$.\\
Si chiama \textbf{circuito logico elementare} o \textbf{porta logica} un circuito a $1$ o $2$ ingressi e un‚Äôuscita il cui valore √® $1$ in corrispondenza delle configurazioni degli ingressi descritte dalle funzioni logiche NOT (per $1$ ingresso), OR, AND, NAND, NOR, XOR, XNOR (per $2$ ingressi).

\newpage
\begin{center}
    25 Ottobre 2021
\end{center}

\subsection{Riassunto}
Il metodo di semplificazione di Quine-Mc Cluskey si basa su una semplice propriet√†:
\[f \cdot x + f \cdot \overline{x} = f\]
Una volta che √® nota la tabella di verit√† della funzione logica oggetto di interesse si rilevano tutte le combinazioni delle variabili in ingresso che producono il valore logico \(1\) e si classificano tali combinazioni sulla base del peso, (ovvero \quotes{quanti \(1\) sono presenti in ciascuna combinazione delle variabili in ingresso}).\\
Classificate le combinazioni in ingresso, si confrontano tutte le combinazioni di ciascun peso con quelle di tutti gli altri pesi al fine di verificare se vi sono delle coppie di variabili che si conservano e che, quindi, si possono semplificare, in modo tale da raggiungere la forma minima, maggiormente semplificata.\\
Quando non si pu√≤ pi√π procedere ad un'ulteriore semplificazione si √®, di fatto, ottenuto l'insieme di tutti gli \textbf{implicanti}. Tuttavia, aver individuato gli implicanti non significa aver concluso l'operazione di semplificazione, in quanto questi ultimi non sono necessariamente primi, in quanto possono essere ancora ridondanti.\\
Infatti, gli implicanti ottenuti tramite la tabella di Quine Mc Cluskey devono essere analizzati ulteriormente tramite il cosiddetto \textbf{reticolo}, al fine di determinare la \textbf{copertura essenziale e minima}, e mai sovrabbondante.\\
Infatti, realizzando successivamente la mappa di Karnaugh ci si rende conto, effettivamente, della presenza di sottocubi non primi che vengono comunque ottenuti anche attraverso il metodo di Quine-Mc Cluskey e che vanno a costituire, a tutti gli effetti, delle alternative di semplificazione. Al fine di ottenere la forma minima, si deve procedere attravero l'analisi del reticolo, essattamente come accadeva con la mappa di Karnaugh, nella quale era fondamentale osservare che alcuni \textit{minterm} potevano essere \quotes{coperti} da altri sottocubi precedentemente individuati.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si presti particolare attenzione che, nella fase di confronto e di semplificazione, ogni qualvolta si semplificano dei \textit{minterm}, questi vengono \quotes{spuntati}, per tenere conto che sono stati considerati.\\
Se, infatti, un \textit{minterm} non viene considerato in fase di semplificazione (per un'intrinseca impossibilit√† derivante dal confronto con tutti i termini del livello successivo) allora bisogner√† tenerne conto, in quanto diventer√† un \textbf{implicante} nella fase finale di semplificazione (per quanto esso sia modesto, in quanto implicher√† solamente se stesso).

\vspace{1em}
\noindent
\textbf{Esercizio}: Si consideri la seguente funzione logica:

\vspace{1em}
\noindent
Si consideri una nuova funzione a \(n = 3\) variabili
\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{ccc|c}
         $x$ & $y$ & $z$ & $f(x, y, z)$\\
         \hline
         $0$ & $0$ & $0$ & $1$\\
         $0$ & $0$ & $1$ & $1$\\
         $0$ & $1$ & $0$ & $0$\\
         $0$ & $1$ & $1$ & $1$\\
         $1$ & $0$ & $0$ & $1$\\
         $1$ & $0$ & $1$ & $0$\\
         $1$ & $1$ & $0$ & $1$\\
         $1$ & $1$ & $1$ & $1$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_3}
\end{table}

\noindent
Inserendo ciscun termine all'interno della mappa di Karnaugh si ottiene la seguente mappa, nella quale si palesano due alternative di semplificazione:

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,1,1,1,0,1}
        \implicant{3}{2}{red}
        \implicant{5}{7}{blue}
        \implicant{0}{4}{green}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a \(3\) variabili}
    \label{fig:mappa_karnaugh_8_7}
\end{figure}

\noindent
A cui corrisponde la seguente formula minima:
\[f = \overline{x}\overline{y} + yz + x\overline{z}\]
Oppure, equivalentemente

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,1,1,1,0,1}
        \implicantcostats{0}{2}{red}
        \implicant{4}{5}{blue}
        \implicant{3}{7}{green}
    \end{Karnaughvuit}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh a \(3\) variabili}
    \label{fig:mappa_karnaugh_8_8}
\end{figure}

\noindent
A cui corrisponde, invece, la seguente formula minima:
\[f = \overline{y}\overline{z} + xy + \overline{x}z\]
Procedendo, invece, tramite il metodo tabellare di Quine-Mc Clusky, si individuano tutti i minterm della funzione data, i quali vengono divisi in opportuni livelli e mappati nella Tabella \ref{tab:tabella_quine_mc_cluskey} seguente, secondo peso crescente:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{5pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{c|c|c|ccc|cc}
         \textbf{Livello} & & & $x$ & $y$ & $z$ & $f$\\
         \hline
         $0$ & $0$ & $\overline{x}\overline{y}\overline{z}$ & $0$ & $0$ & $0$ & $1$\\
         \hline
         \parbox{3em}{\multirow{2}{3em}{\centering \(1\)}} & $1$ & $\overline{x}\overline{y}z$ & $0$ & $0$ & $1$ & $1$\\
          & $4$ & $x\overline{y}\overline{z}$ & $1$ & $0$ & $0$ & $1$\\
         \hline
         \parbox{3em}{\multirow{2}{3em}{\centering \(2\)}} &
         $3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$\\
         & $6$ & $xy\overline{z}$ & $1$ & $1$ & $0$ & $1$\\
         \hline
         $3$ & $7$ & $xyz$ & $1$ & $1$ & $1$ & $1$\\
    \end{tabular}
    \caption{Tabella di Quine-Mc Cuskley}
    \label{tab:tabella_quine_mc_cluskey}
\end{table}

\noindent
Una volta suddiviso in livelli ciascun minterm, si procede a confrontare ciascun termine del livello $k$ con ogni termine del livello $k + 1$ per effettuare delle semplificazioni: saranno semplificabili quei termini che differiscono per un solo bit, il quale viene contrassegnato con un trattino in fase di semplifcazione, come mostrato nella Tabella \ref{tab:semplificazione_quine_mc_cuskey_3}. Ovviamente, i termini che non possono essere semplificati vengono contrassegnati con una lettera alfabetica crescente e andranno a costituire gli implicanti atti alla definizione della formula minima della funzione:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \setlength{\tabcolsep}{5pt}
    \renewcommand{\arraystretch}{1.2}
    \begin{tabular}{c|c|ccc|cc}
         & $ $ & $x$ & $y$ & $z$ & $ $ & \\
         \hline
         & $0 - 1$ & $0$ & $0$ & $-$ & $A$ & \\
         & $0 - 4$ & $-$ & $0$ & $0$ & $B$ & \\
         \hline
         & $1 - 3$ & $0$ & $-$ & $1$ & $C$ & \\
         & $4 - 6$ & $1$ & $-$ & $0$ & $D$ & \\
         \hline
         & $3 - 7$ & $-$ & $1$ & $1$ & $E$ & \\
         & $6 - 7$ & $1$ & $1$ & $-$ & $F$ & \\
    \end{tabular}
    \caption{Tabella di semplificazione}
    \label{tab:semplificazione_quine_mc_cuskey_3}
\end{table}

\vspace{1em}
\noindent
La realizzazione del reticolo conduce al seguente risultato:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{tikzpicture}
      \tikzset{dot/.style={fill=black,circle}}

      \foreach \l [count=\y] in {F,...,A} {
        \draw (0,\y) -- (7,\y);
        \node at (-0.5,\y){\l};
      }

      \foreach \x [count=\i] in {0,1,3,4,6,7} {
          \draw (\i,0) -- (\i,7);
          \node at (\i,-0.5){\x};
      }

      % A
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (1,6){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (2,6){};

      % B
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (1,5){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (4,5){};

      % C
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (2,4){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (3,4){};

      % D
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (4,3){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (5,3){};

      % E
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (3,2){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (6,2){};

      % F
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (5,1){};
      \draw node[fill,circle,inner sep=0pt,minimum size=5pt] at (6,1){};
    \end{tikzpicture}
    \caption{Reticolo di semplificazione}
    \label{fig:reticolo_semplificazione_3}
\end{figure}

\noindent
Dalla Figura \ref{fig:reticolo_semplificazione_3} appare evidente come, in questo caso, non vi siano termini essenziali, ma necessariamente due possibile alternative di semplificazione, in quanto ogni termine pu√≤ essere coperto tramite due implicanti distinti. Da ci√≤ segue che:
\begin{flalign*}
  f_1 & = A + D + E\\
  f_2 & = B + C + F
\end{flalign*}
al fine di garantire la copertura minima ed essenziale, senza che vi siano termini ridondanti.\\
Le formule minime associato sono:
\begin{flalign*}
  f_1 & = \overline{x} \overline{y} + x \overline{z} + yz\\
  f_2 & = \overline{y} \overline{z} + \overline{x}z + xy
\end{flalign*}

\vspace{1em}
\subsection{Itinerari e livelli}
Ogni rete logica e formata da un certo numero di porte (AND, OR, ecc.) tra loro variamente interconnesse, da un certo numero di ingressi e da un certo numero di uscite.\\
Si dice \textbf{itinerario} tra due elementi \(X\) e \(Y\) qualsiasi un percorso che colleghi $X$ con $Y$.\\
Si dice, invece, \emph{livello di un elemento $X$} rispetto all‚Äôuscita $B_j$ e a un determinato itinerario $I$, il numero di elementi, $X$ compreso, disposti lungo l‚Äôitinerario a partire dall‚Äôuscita $B_j$.\\
Si dice \emph{livello di una variabile} rispetto all‚Äôuscita $B_j$ e all‚Äôitinerario $I$ il numero di elementi compresi tra il rispettivo ingresso e l‚Äôuscita $B_j$ lungo l‚Äôitinerario $I$.\\
In Figura \ref{fig:esempi_livelli_reti_logiche} sono riportati due esempi.

\begin{figure}[H]
    \centering
    \begin{tabularx}{\textwidth}{>{\hsize=0.3\textwidth}PP}
      {
        \hspace{-1.5em}
        \begin{tikzpicture}
          \node [circle, draw, minimum size=0.5cm] (G1) at (0,0) {$G_1$};
          \node [circle, draw, minimum size=0.5cm] (G2) at (0,-1.5) {$G_2$};
          \node [circle, draw, minimum size=0.5cm] (G3) at (0,-3) {$G_3$};
          \node [circle, draw, minimum size=0.5cm] (G4) at (2,-1.5) {$G_4$};
          \draw (G1) -- ++(1,0) |- (G4.135);
          \draw (G2) -- (G4);
          \draw (G3) -- ++(1,0) |- (G4.225);
          \draw (G1.135) -- ++(-0.5,0) coordinate(a) ++(-0.25,0) node[]{$A_1$};
          \draw (G1.225) -- ++(-0.5,0) ++(-0.25,0) node[]{$A_2$};

          \draw (G2.125) -- (a |- G2.125) ++(-0.25,0) node[]{$A_3$};
          \draw (G2.180) -- (a |- G2) ++(-0.25,0) node[]{$A_4$};
          \draw (G2.235) -- (a |- G2.235) ++(-0.25,0) node[]{$A_5$};

          \draw (G3.135) -- ++(-0.5,0) ++(-0.25,0) node[]{$A_6$};
          \draw (G3.225) -- ++(-0.5,0) ++(-0.25,0) node[]{$A_7$};

          \draw (G4) -- ++(0.75,0) ++(0.25,0) node[]{$B$};
          \draw (G1) ++(0,1) node[]{II livello};
          \draw (G4) ++(0,1) node[]{I livello};
        \end{tikzpicture}
      } & {
        \hspace{0.5em}
        \begin{tikzpicture}
          \node [circle, draw, minimum size=0.5cm] (G1) at (-1,0) {$G_1$};
          \node [circle, draw, minimum size=0.5cm] (G2) at (1.25,1) {$G_2$};
          \node [circle, draw, minimum size=0.5cm] (G3) at (3.25,0) {$G_3$};
          \node [circle, draw, minimum size=0.5cm] (G4) at (5.5,0) {$G_4$};
          \draw (G1.125) -- ++(-0.5,0) coordinate(a) ++(-0.25,0) node[]{$A_1$};
          \draw (G1.180) -- (a |- G1) ++(-0.25,0) node[]{$A_2$};
          \draw (G1.235) -- ++(-0.5,0) ++(-0.25,0) node[]{$A_3$};

          \draw (G1.0) -- ++(1,0) node[circ](b){} |- (G2) (G2.0) -- ++(0.5,0) |- (G3.125) (b) -- (G3) (G3.235) -- ++(-0.5,0) -- ++(0,-0.5) -- ++(-0.25,0) ++(-0.25,0) node[]{$A_4$};
          \draw (G3) -- (G4) (G4.125) -- ++(-0.5,0) -- ++(0,0.5) -- ++(-0.25,0) ++(-0.25,0) node[]{$A_5$} (G4.235) -- ++(-0.5,0) -- ++(0,-0.5) -- ++(-0.25,0) ++(-0.25,0) node[]{$A_6$} (G4.0) -- ++(0.25,0) ++(0.25,0) node[]{$B$};

          \draw (G1) ++(0,1) node[]{III e IV livello};
          \draw (G2) ++(0,1) node[]{III livello};
          \draw (G3) ++(0,1) node[]{II livello};
          \draw (G4) ++(0,1) node[]{I livello};
        \end{tikzpicture}
      }
    \end{tabularx}
    \caption{Esempi di livelli in due reti logiche}
    \label{fig:esempi_livelli_reti_logiche}
\end{figure}

\noindent
Si noti che uno stesso elemento puo avere pi√π livelli a secondo dell‚Äôitinerario scelto. Ad esempio, in Figura \ref{fig:esempi_livelli_reti_logiche} il gate $G_1$ √® di III livello secondo l‚Äôitinerario $G_4$, $G_3$, $G_1$ e di IV livello secondo l‚Äôitinerario $G_4$, $G_3$, $G_2$, $G_1$.

\vspace{1em}
\noindent
\textbf{Osservazione}: La presenza di pi√π livelli all'interno di un circuito √® molto critica, in quanto pi√π livelli introducono pi√π latenze che potrebbero determinare una scorretta analisi degli ingressi logici, in quanto le porte logiche presenti in un circuito introducono un tempo di propagazione che non necessariamente √® trascurabile.\\
Tali ritardi prendo il nome di \textbf{alee}, ovvero dei ritardi che non sono ammissibili, in quanto le variabili di uscita devono essere processati senza eterogeneit√† di ritardi in ingresso.

\vspace{1em}
\noindent
Per i circuiti combinatori, come per ogni altro tipo di circuito, si pongono due problemi opposti: da un lato quello dell‚Äô\textbf{analisi}, cio√® della \emph{descrizione del funzionamento del circuito}, una volta che sia nota la sua configurazione, il che significa la definizione della funzione che realizza; dall‚Äôaltro quello della \textbf{sintesi}, cio√® del \emph{progetto di un circuito che realizzi una certa funzione logica}, comunque descritta.\\
Pertanto, i circuiti combinatori devono essere studiati attraverso due procedure, essenzialmente:
\begin{itemize}
    \item L'\textbf{analisi logica}, al fine di determinarne il funzionamento e i componenti;
    \item La \textbf{sintesi logica}, al fine di ottimizzarne il funzionamento o semplicemente modificarlo.
\end{itemize}

\subsection{Analisi dei circuiti combinatori}
L‚Äôanalisi di un circuito combinatorio tende a ottenere una rappresentazione della funzione d‚Äôuscita \(y\) o nella sua forma analitica, oppure sotto forma di tavola di verit√†. Poich√© la rappresentazione circuitale √® simbolica, l‚Äôanalisi non √® legata a considerazioni di logica positiva o negativa.\\
Per effettuare l‚Äôanalisi, nel caso di circuiti AND-OR-NOT, √® sufficiente partire dagli elementi su cui entrano le variabili e procedere verso il terminale di uscita secondo tutti i possibili itinerari, usando la funzione di uscita di ciascun elemento come variabile di ingresso dell‚Äôelemento successivo.

\begin{figure}[H]
    \centering
    \begin{tabularx}{\textwidth}{P>{\hsize=0.38\textwidth}P}
      {
        \begin{tikzpicture}
          % Porte logiche
          \node [and gate US, draw, logic gate inputs=nnn] (and1) at (0,0){};
          \node [and gate US, draw, right=of and1, yshift=8.5mm, logic gate inputs=nn] (and2){};
          \node [not gate US, draw, right=of and1] (not1){};
          \node [not gate US, draw, below=of not1, yshift=5mm] (not2){};
          \node [and gate US, draw, right=of not1, anchor=input 1, logic gate inputs=nn] (and3){};
          \node [or gate US, draw, right=of and3, anchor=input 2, logic gate inputs=nnn] (or){};

          % INPUT
          \draw (and1.input 1) -- ++(-0.5,0) coordinate(start) ++(0,0.15) node[left]{$x_1$};
          \draw (and1.input 2) -- ++(-0.5,0) node[at end, left]{$x_2$};
          \draw (and1.input 3) -- ++(-0.5,0) ++(0,-0.15) node[left]{$\overline{x_3}$};
          \draw (and2.input 1) -- (start |- and2.input 1) node[at end, left]{$x_4$};

          \draw (and1.output) -- ++(0.5,0) node[circ](a){} -- (not1.input) (a) |- (and2.input 2);
          \draw (not2.input) -- ([xshift=2.5mm] and1.output |- not2.input) coordinate(c) -- (c |- and2.input 1) node[circ](b){};
          \draw (not1.output) -| (and3.input 1) (not2.output) -- ++(0.5,0) |- (and3.input 2);
          \draw (and2.output) -- ([xshift=5mm] and3.output |- and2.output) |- (or.input 1) (and3.output) -- (or.input 2) (or.input 3) -- ++(-0.5,0) -- ++(0,-0.25) node[at end, below]{$x_5$};
          \draw (or.output) -- ++(0.5,0) node[at end, right]{$y$} ([xshift=2.5mm] and3.output) ++(0,0.25) node[]{$y_c$};
          \draw ([xshift=2.5mm] not1.output) ++(0,0.25) node[]{$y_{a_1}$} ([xshift=2.5mm] not2.output) ++(0,-0.25) node[]{$y_{a_2}$};
          \draw (a) ++(0,-0.25) node[]{$y_a$};
        \end{tikzpicture}
      } & {
        \renewcommand{\arraystretch}{1.1}
        $\begin{array}{l@{}}
          y_a = x_1 \cdot x_2 \cdot \overline{x_3} \\
          y_{a_1}  = \overline{y_a} = \overline{x_1 \cdot x_2 \cdot \overline{x_3}} = \overline{x_1} + \overline{x_2} + x_3\\
          y_{a_2}  = \overline{x_4}\\
          y_b  = x_4 \cdot y_a = x_1 \cdot x_2 \cdot \overline{x_3} \cdot x_4\\
          y_c  = y_{a_1} \cdot y_{a_2} = \overline{x_4} \cdot \left(\overline{x_1} + \overline{x_2} + x_3\right)\\
          y  = y_b + y_c + x_5 = x_1 \cdot x_2 \cdot \overline{x_3} \cdot x_4 + \\
          + \overline{x_4} \cdot \left(\overline{x_1} + \overline{x_2} + x_3\right) + x_5
        \end{array}$
      }
      \end{tabularx}
    \caption{Rete AND-OR-NOT ed equazioni che si ottengono dall‚Äôanalisi}
    \label{fig:analisi_circuito}
\end{figure}

\noindent
Com'√® intuibile, l‚Äôanalisi dei circuiti basati su porte NAND e NOR √® notevolmente pi√π complessa, a causa della non associativit√† degli operatori.

\vspace{1em}
\subsection{Sintesi dei circuiti combinatori}
Eseguire la sintesi di un circuito combinatorio consiste, come gi√† accennato, nel progettare un circuito a \(n\) ingressi che soddisfi una determinata funzione di uscita \(y\) di progetto. La funzione \(y\) che il circuito deve soddisfare pu√≤ essere assegnata in diverse forme. Pi√π precisamente:

\begin{itemize}
    \item con la \textbf{descrizione a parole} del funzionamento del circuito. √à questa la forma di assegnazione pi√π comune, ma anche la pi√π imprecisa. √à necessario porre un‚Äôestrema attenzione alla corretta interpretazione di eventuali condizioni implicite e all‚Äôesistenza di vincoli di qualsiasi natura. Dalla descrizione verbale √® necessario passare poi alla tavola di verit√†, assegnando il valore della funzione per ognuna delle \(2^n\) configurazioni degli ingressi;

    \item con una vera e propria \textbf{tavola di verit√†}, che √® in definitiva l‚Äôeffettivo punto di partenza della sintesi cui tutti gli altri tipi di assegnazione devono essere ricondotti;

    \item con un‚Äô\textbf{espressione analitica}, che √® il modo pi√π conciso, anche se non univoco, di descrivere il funzionamento di un circuito;

    \item con uno \textbf{schema logico}, che √® una procedura generalmente usata quando un determinato circuito logico debba essere riprogettato con componenti diversi. In tal caso, con le regole dell‚Äôanalisi si ricava un‚Äôespressione analitica della funzione $y$.
\end{itemize}

\noindent
Qualunque sia il metodo di assegnazione, la sintesi procede partendo dalla tavola di verit√† o da un‚Äôespressione analitica; applicando i metodi di semplificazione delle funzioni logiche si perviene alla forma pi√π conveniente per gli scopi che ci si propone.\\
Si noti, inoltre, che non sempre la forma pi√π conveniente corrisponde alla forma minima della funzione. Ad esempio, non √® sempre opportuno realizzare circuitalmente la forma minima algebrica, in quanto vi possono essere dei vincoli sul numero massimo di livelli. Infatti, se √® ben vero quanto esposto precedentemente, e cio√® che nei circuiti combinatori l‚Äôuscita √®, istante per istante, funzione unicamente degli ingressi, non significa che la variazione degli ingressi sia avvertita immediatamente in uscita; tale affermazione sta piuttosto a significare che ogni configurazione di ingresso d√† luogo a una determinata uscita e che eventuali transitori di commutazione possono ritardare, ma non modificare, questa uscita.\\
Poich√© il tempo di commutazione \(\Delta\) di qualsiasi porta logica, per quanto piccolo, non √® mai nullo, il tempo di risposta di un circuito a \(n\) livelli, al variare della configurazione d‚Äôingresso, √® \(n \cdot \Delta\).\\
In definitiva, il ritardo totale tra ingresso e uscita √® proporzionale al numero di livelli e potendo la forma minima di una funzione contenere un numero di livelli molto elevato, la sua diretta realizzazione circuitale potrebbe dar luogo a ritardi intollerabili.\\
La forma in cui si ha il minimo ritardo √® quella a due livelli, che d‚Äôaltra parte √® quella che si ottiene con i metodi di semplificazione che sono stati esposti in precedenza.\\
Inoltre si osservi che, molto spesso, anche dal punto di vista economico, √® pi√π conveniente introdurre nel circuito delle componenti ridondanti piuttosto che progettare una rete custom, al fine di ottimizzare anche i costi di produzione della propria rete logica. La convenienza di eventuali fattorizzazioni va valutata caso per caso. Si pu√≤ dunque concludere che la sintesi di un circuito combinatorio procede attraverso i seguenti passi:

\begin{enumerate}
    \item Descrizione del funzionamento del circuito
    \item Determinazione della tavola di verit√†
    \item Sintesi della funzione Booleana
    \item Semplificazione della funzione logica relativa
    \item Determinazione della forma minima pi√π conveniente
    \item Disegno del circuito
\end{enumerate}

\noindent
Si osservi che il passo \(5\) non pu√≤ essere attuato secondo un procedimento sistematico, e l‚Äôeffettiva forma minima pi√π conveniente andr√† valutata di volta in volta, eventualmente facendo uso di tecniche basate sul concetto di decomponibilit√†.

\vspace{1em}
\noindent
\textbf{Esempio}: Si voglia realizzare un circuito a tre ingressi e quattro uscite; sugli ingressi si pu√≤ presentare un numero binario compreso tra $0$ e $5$. All‚Äôuscita di tale circuito si deve ottenere il prodotto per \(3\) del numero in ingresso.\\
Il massimo numero di uscita rappresentabile con \(4\) bit √® \(15\) e sar√† necessario sintetizzare quattro funzioni logiche.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{5pt}
    \renewcommand{\arraystretch}{1.1}
    \begin{tabular}{l||ccc|cccc}
         & & $\boldsymbol{x}$ & & & $\boldsymbol{y}$ &\\
         \hline
         \(3 \cdot \boldsymbol{x} = \boldsymbol{y} \) & \(x_2\) & \(x_1\) & \(x_0\) & \(y_3\) & \(y_2\) & \(y_1\) & \(y_0\)\\
         \hline
         $3 \cdot 0 = 0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$ & $0$\\
         $3 \cdot 1 = 3$ & $0$ & $0$ & $1$ & $0$ & $0$ & $1$ & $1$\\
         $3 \cdot 2 = 6$ & $0$ & $1$ & $0$ & $0$ & $1$ & $1$ & $0$\\
         $3 \cdot 3 = 9$ & $0$ & $1$ & $1$ & $1$ & $0$ & $0$ & $1$\\
         $3 \cdot 4 = 12$ & $1$ & $0$ & $0$ & $1$ & $1$ & $0$ & $0$\\
         $3 \cdot 5 = 15$ & $1$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$\\
         $3 \cdot 6 = -$ & $1$ & $1$ & $0$ & $-$ & $-$ & $-$ & $-$\\
         $3 \cdot 7 = -$ & $1$ & $1$ & $1$ & $-$ & $-$ & $-$ & $-$\\
    \end{tabular}
    \caption{Tavola di verita del circuito che moltiplica per $3$}
    \label{tab:tavola_verita_circuito_moltiplica_per_3}
\end{table}

\noindent
A cui corrispondono le seguenti tavole di Karnaugh, ciascuna per ogni funzione $y_0$, $y_1$, $y_2$ e $y_3$:

\begin{figure}[H]
    \centering
    \begin{tabularx}{\textwidth}{PP}
      {
        \begin{KarnaughvuitFunction}
          \contingut{0,0,1,\times,0,1,1,\times}
          \implicant{5}{7}{red}
          \implicant{3}{6}{green}
        \end{KarnaughvuitFunction}
      } & {
        \begin{KarnaughvuitFunction}
          \contingut{0,1,1,\times,0,0,1,\times}
          \implicant{1}{3}{red}
          \implicant{3}{6}{green}
        \end{KarnaughvuitFunction}
      }\\
      $y_3$ & $y_2$\\
      {
        \begin{KarnaughvuitFunction}
          \contingut{0,1,0,\times,1,0,1,\times}
          \implicant{1}{3}{red}
          \implicantcostats{4}{6}{green}
        \end{KarnaughvuitFunction}
      } & {
        \begin{KarnaughvuitFunction}
          \contingut{0,0,0,\times,1,1,1,\times}
          \implicant{4}{6}{red}
        \end{KarnaughvuitFunction}
      }\\
      $y_1$ & $y_0$
      \end{tabularx}
    \caption{Mappe di Karnaugh per le quattro funzioni $y_3$, $y_2$, $y_1$ e $y_0$ considerate}
    \label{fig:mappe_karnaugh_quattro_funzioni}
\end{figure}

\noindent
In cui √® fondamentale considerare la presenza di \emph{condizioni non specificate} che comportano una limitazione dell'utilizzo della rete logica: se, naturalmente, il circuito viene impiegato rispettando le specifiche di progetto, allora esso funzioner√† come previsto. Altrimenti il circuito risponder√† erroneamente, fornendo risultati irregolari e scorretti.\\
Se, tuttavia, vengono utilizzate opportunamente le condizioni non specificate si ottiene:

\begin{figure}[H]
  \centering
  \noindent
  \begin{tabular}{ll}
    $y_3 = x_2 + x_0 \cdot x_1$ & $y_1 = \overline{x_0} \cdot x_1 + x_0 \cdot \overline{x_1}$\\
    $y_2 = x_2 + \overline{x_0} \cdot x_1$ & $y_0 = x_0$
  \end{tabular}
\end{figure}

\noindent
A cui corrisponde il circuito di Figura \ref{fig:moltiplicatore_per_3}, ottenuto mettendo in comune il termine $c_0 \cdot x_1$ tra le funzioni $y_1$ e $y_2$.

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
      % Porte logiche
      \node [and gate US, draw, logic gate inputs=nnn] (and1) at (0,0){};
      \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=nnn] (and2){};
      \node [and gate US, draw, below=of and2, yshift=5.5mm, logic gate inputs=nnn] (and3){};
      \node [or gate US, draw, right=of and1, anchor=input 3, logic gate inputs=nnn] (or1){};
      \node [or gate US, draw, right=of and2, anchor=input 3, logic gate inputs=nnn] (or2){};
      \node [or gate US, draw, right=of and3, anchor=input 3, logic gate inputs=nnn] (or3){};

      % INPUT
      \draw (and1.input 1) -- ++(-0.5,0) coordinate(start) node[at end, left]{$x_0$};
      \draw (and1.input 3) -- ++(-0.5,0) node[at end, left]{$x_1$};
      \draw (and2.input 1) -- ++(-0.5,0) node[at end, left]{$\overline{x_0}$};
      \draw (and2.input 3) -- ++(-0.5,0) node[at end, left]{$x_1$};
      \draw (and3.input 1) -- ++(-0.5,0) node[at end, left]{$\overline{x_1}$};
      \draw (and3.input 3) -- ++(-0.5,0) node[at end, left]{$x_0$};
      \draw (or1.input 1) -- ++(-0.5,0) node[circ](circ1){} -- ++(0,0.5) coordinate(a) -- (start |- a) node[at end, left]{$x_2$};
      \draw (and1.output) -- (or1.input 3) (and2.output) -- (or2.input 3) (circ1) |- (or2.input 1);
      \draw (or3.input 1) -- ++(-0.5,0) coordinate(b) -- (b |- or2.input 3) node[circ]{} (and3.output) -- (or3.input 3);
      \draw (or1.output) -- ++(0.5,0) coordinate(c) node[at end, right]{$y_3$};
      \draw (or2.output) -- ++(0.5,0) node[at end, right]{$y_2$};
      \draw (or3.output) -- ++(0.5,0) node[at end, right]{$y_1$};
      \draw (or3.input 3) ++(0,-0.75) coordinate(d) -- (c |- d) node[at end, right]{$y_0$} (d) -- ([xshift=2.5mm]start |- d) -- ([xshift=2.5mm] start |- d |- and3.input 3) node[circ]{};
    \end{tikzpicture}
    \caption{Moltiplicatore per 3 di un numero compreso tra 0 e 5}
    \label{fig:moltiplicatore_per_3}
\end{figure}

\vspace{1em}
\noindent
\textbf{Esempio}: Si voglia sintetizzare un circuito con la stessa funzione Booleana di quello illustrato nella Figura \ref{fig:semplificazione_circuito_mappa_karnaugh}, ma possibilmente pi√π economico.

\begin{figure}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1}
    \begin{tabularx}{\textwidth}{P>{\hsize=0.4\textwidth}P}
      {
        \begin{tikzpicture}
          % Porte logiche
          \node [and gate US, draw, logic gate inputs=nnnnn] (and1) at (0,0){};
          \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=nnnnn] (and2){};
          \node [and gate US, draw, below=of and2, yshift=5.5mm, logic gate inputs=nnnnn] (and3){};
          \node [or gate US, draw, above=of and1, yshift=-5.5mm, logic gate inputs=nnnnn] (or1){};
          \node [not gate US, draw, right=of or1] (not){};
          \node [or gate US, draw, right=of and1, anchor=input 1, xshift=20mm, yshift=-3.5mm, logic gate inputs=nnnnn] (or2){};

          % INPUT
          \draw (or1.input 1) -- ++(-1,0) coordinate(start) node[at end, left]{$\overline{x_1}$};
          \draw (or1.input 3) -- (start |- or1.input 3) node[at end, left]{$\overline{x_3}$};
          \draw (or1.input 5) -- (start |- or1.input 5) node[at end, left]{$\overline{x_4}$};

          \draw (and1.input 1) -- (start |- and1.input 1) node[at end, left]{$\overline{x_4}$};
          \draw (and1.input 3) -- (start |- and1.input 3) node[at end, left]{$\overline{x_2}$};
          \draw (and1.input 5) -- ++(-0.25,0) coordinate(a) -- coordinate[midway](m1) (a |- and2.input 1) -- (and2.input 1);
          \draw (m1) node[circ]{} -- (start |- m1) node[at end, left]{$\overline{x_3}$};

          \draw (and2.input 3) -- (start |- and2.input 3) node[at end, left]{$x_1$};
          \draw (and2.input 5) -- ++(-0.25,0) coordinate(b) -- coordinate[midway](m2) (b |- and3.input 1) -- (and3.input 1);
          \draw (m2) node[circ]{} -- (start |- m2) node[at end, left]{$x_4$};

          \draw (and3.input 3) -- (start |- and3.input 3) node[at end, left]{$\overline{x_2}$};
          \draw (and3.input 5) -- (start |- and3.input 5) node[at end, left]{$\overline{x_3}$};

          \draw (or1.output) -- (not.input) (not.output) -- ++(1,0) coordinate(c) |- (or2.input 1);
          \draw (and1.output) -- ++(1,0) |- (or2.input 2) (and2.output) -- ++(1,0) |- (or2.input 4) (and3.output) -- (c |- and3.output) |- (or2.input 5);
          \draw (or2.output) -- ++(0.5,0) node[at end, right]{$y$};
        \end{tikzpicture}
      } & {
        \begin{KarnaughSemplification}
          \contingut{0,0,0,0,1,0,1,0,1,0,1,1,0,0,1,1}
          \implicantcostats{4}{6}{red}
          \implicantcostats{8}{10}{green}
          \implicant{15}{10}{blue}
        \end{KarnaughSemplification}
      }\\
    \end{tabularx}
    \caption{Semplificazione di un circuito mediante mappa di Karnaugh}
    \label{fig:semplificazione_circuito_mappa_karnaugh}
\end{figure}

\noindent
L‚Äôespressione analitica della funzione di trasmissione √®
\[y = \overline{\overline{x_1} + \overline{x_3} + x_4} + \overline{x_2} x_3 \overline{x_4} + \overline{x_2} \overline{x_3} x_4 = x_1 x_3 \overline{x_4} + \overline{x_2} x_3 \overline{x_4} + x_1 x_3 x_4 + \overline{x_2} \overline{x_3} x_4\]
Dalla mappa di Karnaugh di Figura \ref{fig:semplificazione_circuito_mappa_karnaugh} si ricava l‚Äôespressione minima a due livelli
\[y = x_1 x_3 + \overline{x_2} \overline{x_3} x_4 + \overline{x_2} x_3 \overline{x_4}\]
e fattorizzando si ottiene:
\[y = x_1 x_3 + \overline{x_2} \cdot \left(\overline{x_3} x_4 + x_3 \overline{x_4}\right)\]
Tuttavia, per la funzione cos√¨ semplificata, il numero delle porte necessarie per la sua realizzazione aumenta, passando da $4$ a $6$ a seguito dela fattorizzazione. Ecco, allora, come la funzione pi√π conveniente da realizzare sia la prima che √® stata ottenuta, la quale produce il circuito di Figura \ref{fig:circuito_economico_funzione_semplificata}:

\begin{figure}[H]
    \centering
    \begin{tikzpicture}
      % Porte logiche
      \node [and gate US, draw, logic gate inputs=nnnnn] (and1) at (0,0){};
      \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=nnnnn] (and2){};
      \node [and gate US, draw, below=of and2, yshift=5.5mm, logic gate inputs=nnnnn] (and3){};
      \node [or gate US, draw, right=of and2, xshift=5.5mm, logic gate inputs=nnnnn] (or){};

      % INPUT
      \draw (and1.input 1) -- ++(-1,0) coordinate(start) node[at end, left]{$x_1$};
      \draw (and1.input 5) -- ++(-0.25,0) coordinate(a) -- coordinate[midway](m1) (a |- and2.input 1) -- (and2.input 1);
      \draw (m1) node[circ]{} -- (start |- m1) node[at end, left]{$\overline{x_3}$};

      \draw (and2.input 3) -- (start |- and2.input 3) node[at end, left]{$\overline{x_4}$};
      \draw (and2.input 5) -- ++(-0.25,0) coordinate(b) -- coordinate[midway](m2) (b |- and3.input 1) -- (and3.input 1);
      \draw (m2) node[circ]{} -- (start |- m2) node[at end, left]{$\overline{x_2}$};

      \draw (and3.input 3) -- (start |- and3.input 3) node[at end, left]{$\overline{x_3}$};
      \draw (and3.input 5) -- (start |- and3.input 5) node[at end, left]{$x_4$};

      \draw (and1.output) -- ++(1,0) coordinate(c) |- (or.input 1) (and2.output) -- (or.input 3) (and3.output) -- (c |- and3.output) |- (or.input 5);
      \draw (or.output) -- ++(0.5,0) node[at end, right]{$y$};
    \end{tikzpicture}
    \caption{Circuito piu economico che realizza la funzione Booleana semplificata}
    \label{fig:circuito_economico_funzione_semplificata}
\end{figure}

\noindent
Si noti, naturalmente, che negli esempi fatti si √® supposto di avere a disposizione all‚Äôingresso del circuito sia le variabili dirette che la loro negazione. Quando questa situazione non si verifica, anche il numero di invertitori va minimizzato.

\newpage
\begin{center}
    26 Ottobre 2021
\end{center}

\subsection{Riassunto}
I circuiti combinatori sono dei dispositivi che permettono di realizzare delle funzioni booleane della forma
\[F : 2^n \rightarrow 2^m\]
Le modalit√† per realizzare tali funzioni si dipartono in due tipi:
\begin{itemize}
    \item \textbf{Logica positiva}: Al valore \(1\) logico viene associato il valore di tensione alto, a \(0\) il valore di tensione basso.

    \item \textbf{Logica negativa}: Al valore \(1\) logico viene associato il valore di tensione basso, a \(0\) il valore di tensione alto.
\end{itemize}

\noindent
I circuiti che vengono realizzati possono presentare pi√π livelli di itinerario che pu√≤ comportare una latenza, ovvero un ritardo di propagazione al variare delle variabili in ingresso.\\
Pertanto, √® possibile che ad una porta giunga il valore della variabile \(y_1\) istantaneamente, mentre il valore della variabile \(y_2\) giunge con un ritardo di \(2\Delta\), ove \(\Delta\) √® il tempo di assestamento di una porta logica, variabile a seconda della tecnologica impiegata.\\
Se tali variazioni sono infinitesime, possono essere trascurate, ma se non sono trascurabili determinano una instabilit√† della rete, a causa di continue ed irregolari oscillazioni di valori delle medesime variabili: tale fenomeno prende il nome di \textbf{Alea} ed √® cruciale nella creazione delle porte logiche.\\
Lo studio e la manipolazione dei circuiti logici, inoltre, prevede due operazioni
\begin{itemize}
    \item Lo \textbf{studio della rete logica}: ovvero determinare ed estrapolare la funzione logica a partire dalla rete logica realizzata.

    \item La \textbf{sintesi della rete logica}: Semplificare un circuito o riprogettarlo con delle nuove porte, oppure con un diverso numero di livelli a seguito della constatazione della presenza di ritardi e conseguente instabilit√† del circuito.
\end{itemize}

\noindent
Eseguire la sintesi di un circuito combinatorio consiste, come gi√† accennato, nel progettare un circuito a \(n\) ingressi che soddisfi una determinata funzione di uscita \(y\) di progetto. La funzione \(y\) che il circuito deve soddisfare pu√≤ essere assegnata in diverse forme. Pi√π precisamente:

\begin{itemize}
    \item con la \textbf{descrizione a parole} del funzionamento del circuito. √à questa la forma di assegnazione pi√π comune, ma anche la pi√π imprecisa. √à necessario porre un‚Äôestrema attenzione alla corretta interpretazione di eventuali condizioni implicite e all‚Äôesistenza di vincoli di qualsiasi natura. Dalla descrizione verbale √® necessario passare poi alla tavola di verit√†, assegnando il valore della funzione per ognuna delle \(2^n\) configurazioni degli ingressi;

    \item con una vera e propria \textbf{tavola di verit√†}, che √® in definitiva l‚Äôeffettivo punto di partenza della sintesi cui tutti gli altri tipi di assegnazione devono essere ricondotti;

    \item con un‚Äô\textbf{espressione analitica}, che √® il modo pi√π conciso, anche se non univoco, di descrivere il funzionamento di un circuito;

    \item con uno \textbf{schema logico}, che √® una procedura generalmente usata quando un determinato circuito logico debba essere riprogettato con componenti diversi. In tal caso, con le regole dell‚Äôanalisi si ricava un‚Äôespressione analitica della funzione $y$.
\end{itemize}

\noindent
Indipendentemente dalla modalit√† di assegnazione della funzione logica, si deve sempre giungere ad una tabella di verit√†, da cui si pu√≤ ricavare la mappa di Karnaugh.\\
Dopodich√© si dovr√† verificare caso per caso se sia effettivamente pi√π conveniente creare un circuito attraverso la semplificazione massimale, in quanto molto spesso il costo di un circuito \quotes{customizzato} √® pi√π elevato rispetto a moduli standard e precostituiti.

\[\text{Ultimo esempio superfluo}\]

\vspace{1em}
\subsection{Moduli combinatori}
L‚ÄôAlgebra Booleana permette di analizzare e progettare qualunque tipo di rete combinatoria, di qualunque complessit√†. In precedenza sono state esposte le tecniche per semplificare le reti ottenute direttamente dalle espressioni delle forme canoniche, basate sulla somma di prodotti o sui prodotti di somme.\\
Sebbene in linea di principio quei metodi possano essere utilizzati per reti combinatorie di qualunque estensione, nella pratica si preferisce affrontare il progetto di una rete complessa secondo una tecnica di scomposizione della rete in blocchi funzionali, detti \textbf{moduli combinatori}. In questo modo si rinuncia alla soluzione teoricamente ottima, a favore di una maggiore comprensibilit√†, gestibilit√† e soprattutto modularit√† del progetto. Ci√≤ porta anche a un effettivo risparmio economico, poich√© i moduli combinatori, se prodotti in larga scala, hanno prezzi via via sempre pi√π bassi; dunque non sempre un numero minore di porte implica un risparmio economico.\\
Gi√† a partire dagli anni '\(70\) vennero prodotti moduli integrati, che svolgendo precise funzionalit√† di carattere combinatorio trovarono impiego nello sviluppo di progetti complessi. Nella parte che segue vengono esaminati alcuni moduli combinatori di uso corrente.

\vspace{1em}
\subsubsection{Decodificatori}
I \textbf{decodificatori} convertono un numero espresso in notazione posizionale in base \(2\) in un numero intero in base \(10\). Un decodificatore accetta in ingresso \(n\) bit e presenta in uscita \(m = 2^n\) linee, numerate da \(0\) a \(2^n - 1\), in modo tale che va a \(1\) la sola linea \(y_j\) che corrisponde all‚Äôintero \(j\) codificato in notazione posizionale dagli \(n\) bit d‚Äôingresso. Se dunque si indicano con \(y_0, y_1, ..., y_m\) le uscite del decodificatore, la generica uscita \(y_j\) ottenuta come AND delle \(n\) variabili che compongono il \textit{minterm} \(j\).\\
Nella Figura \ref{fig:tabella_verita_circuito_decodificatore_2_bit} vengono riportati, rispettivamente, la tavola di verit√† e il circuito di un decodificatore a \(2\) bit:

\begin{figure}[H]
  \begin{tabularx}{\textwidth}{PP}
      {
        \setlength{\tabcolsep}{8pt}
        \renewcommand{\arraystretch}{1}
        \begin{tabular}{cc|cccc}
          \multicolumn{2}{c|}{$\boldsymbol{x}$} & \multicolumn{4}{c}{$\boldsymbol{y}$}\\
          \hline
          $x_1$ & $x_0$ & $y_0$ & $y_1$ & $y_2$ & $y_3$\\
          \hline
          $0$ & $0$ & $1$ & $0$ & $0$ & $0$\\
          $0$ & $1$ & $0$ & $1$ & $0$ & $0$\\
          $1$ & $0$ & $0$ & $0$ & $1$ & $0$\\
          $1$ & $1$ & $1$ & $0$ & $0$ & $1$\\
        \end{tabular}
        \begin{tabular}{ccccccccccc}
          $ $ & $ $ & $ $ & $ $ & $ $ & $ $ & $ $ & $ $ & $ $ & $ $ & $ $\\
        \end{tabular}
        \renewcommand{\arraystretch}{1.1}
        $\begin{array}{l@{}}
            y_0 = \overline{x_1} \overline{x_0}\\
            y_1 = \overline{x_1} x_0\\
            y_2 = x_1 \overline{x_0}\\
            y_3 = x_1 x_2
        \end{array}$
      } & {
        \begin{tikzpicture}
          % Variabili
          \coordinate (x1) at (0,0);
          \coordinate (x0) at (1.5,0);

          % Porte logiche
          \node [not gate US, draw, rotate=270] (notx1) at ([xshift=6mm,yshift=-8mm]x1){};
          \node [not gate US, draw, rotate=270] (notx0) at ([xshift=6mm,yshift=-8mm]x0){};

          \node [and gate US, draw, logic gate inputs=nn] (and1) at (4,-2.5){$\overline{x_1}\overline{x_0}$};
          \node [and gate US, draw, below=of and1, yshift=3.5mm, logic gate inputs=nn] (and2){$\overline{x_1}x_0$};
          \node [and gate US, draw, below=of and2, yshift=3.5mm, logic gate inputs=nn] (and3){$x_1\overline{x_0}$};
          \node [and gate US, draw, below=of and3, yshift=3.5mm, logic gate inputs=nn] (and4){$x_1 x_0$};

          % INPUT
          \draw (x1) node[at start, above]{$x_1$} |- (and4.input 1);
          \draw (x0) |- (and4.input 2) (x0) node[above]{$x_0$};
          \draw (notx1.output) |- (and2.input 1);
          \draw (notx0.output) |- (and3.input 2);
          \draw (notx1.input) -- ++(0,3mm) -- ([yshift=3mm] notx1.input -| x1) node [branch]{};
          \draw (notx0.input) -- ++(0,3mm) -- ([yshift=3mm] notx0.input -| x0) node [branch]{};
          \draw (and1.input 1) -- (and1.input 1 -| notx1.output) node[circ]{};
          \draw (and1.input 2) -- (and1.input 2 -| notx0.output) node[circ]{};
          \draw (and2.input 2) -- (and2.input 2 -| x0) node[circ]{};
          \draw (and3.input 1) -- (and3.input 1 -| x1) node[circ]{};

          % OUTPUT
          \draw (and1.output) -- ++(0.5,0) node[at end, right]{$y_0$};
          \draw (and2.output) -- ++(0.5,0) node[at end, right]{$y_1$};
          \draw (and3.output) -- ++(0.5,0) node[at end, right]{$y_2$};
          \draw (and4.output) -- ++(0.5,0) node[at end, right]{$y_3$};
        \end{tikzpicture}
      }
  \end{tabularx}
  \caption{Tabella di verit√† e circuito di un decodificatore a $2$ bit}
  \label{fig:tabella_verita_circuito_decodificatore_2_bit}
\end{figure}

\newpage
\noindent
In Figura \ref{fig:simbolo_circuitale_decodificatore_n_bit} viene invece rappresentato il simbolo circuitale per un generico decodificatore a \(n\) bit:

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \draw (0,0) -- (1.25,0.5) -- (1.25,-3) -- (0,-2.5) -- (0,0);
    \draw[-stealth] (-1,-0.5) -- (0,-0.5) node[at start, left]{$0$};
    \draw[-stealth] (-1,-1) -- (0,-1) node[at start, left]{$1$};
    \draw (-0.5,-1.33) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (-0.5,-1.66) node[fill,circle,inner sep=0pt,minimum size=2pt]{};
    \draw[-stealth] (-1,-2) -- (0,-2) node[at start, left]{$n-1$};
    \draw (0.625,-1.25) node[]{Dec};
    \draw[-stealth] (1.25,0) -- (2.25,0) node[at end, right]{$0$};
    \draw[-stealth] (1.25,-0.5) -- (2.25,-0.5) node[at end, right]{$1$};
    \draw[-stealth] (1.25,-1) -- (2.25,-1) node[at end, right]{$2$};
    \draw[-stealth] (1.25,-1.5) -- (2.25,-1.5) node[at end, right]{$3$};
    \draw (1.75,-1.9) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (1.75,-2.2) node[fill,circle,inner sep=0pt,minimum size=2pt]{};
    \draw[-stealth] (1.25,-2.5) -- (2.25,-2.5) node[at end, right]{$2^n - 1$};
  \end{tikzpicture}
  \caption{Simbolo circuitale per un generico decodificatore a $n$ bit}
  \label{fig:simbolo_circuitale_decodificatore_n_bit}
\end{figure}

\noindent
\textbf{Osservazione}: Si noti che questo processo di decodifica, da binario a decimale, non deve creare confusione. Infatti, essendo i calcolatori binari, si sarebbe portati a rappresentare ogni valore, in ingresso come in uscita, sfruttando la logica binaria. Ma allora, se si hanno \(n\) bit in ingresso, che possono produrre \(2^n\) combinazioni di valori, che corrispondono a \(2^n\) numeri decimali. Allora, sar√† sufficiente attivare solamente l'uscita corrispondente e si √® ottenuto il valore da decodificare.

\vspace{1em}
\subsubsection{Codificatore}
I codificatori convertono un numero intero in base \(10\) in un numero espresso in notazione posizionale in base \(2\). Un codificatore svolge dunque la funzione inversa di un decodificatore, nel senso che esso prevede \(m = 2^n\) ingressi e \(n\) uscite. Le uniche configurazioni ammesse per gli ingressi sono quelle in cui c‚Äô√® esattamente un solo \(1\) in corrispondenza della linea \(x_j\); dunque \(x_j = 1\) e \(x_i = 0\) per ogni \(i \neq j\). Indicando con \(x_0, x_1, ..., x_{m - 1}\) gli ingressi, la corrispondente configurazione di uscita sulle variabili \(y_{n - 1}, y_{n - 2}, ..., y_0\) √® tale che esse codificano \(j\) in notazione posizionale in base \(2\).\\
Nella Figura \ref{fig:tabella_verita_mappa_karnaugh_codificatore_2_bit} vengono riportate, rispettivamente, la tavola di verit√† e le due mappe di Karnaugh associate alle variabili \(y_1\) e \(y_0\).

\begin{figure}[H]
  \begin{tabularx}{\textwidth}{>{\hsize=0.24\textwidth}P>{\hsize=0.28\textwidth}P>{\hsize=0.25\textwidth}P}
      {
        \hspace{-2em}
        \setlength{\tabcolsep}{5pt}
        \renewcommand{\arraystretch}{1}
        \begin{tabular}{cccc|cc}
          \multicolumn{4}{c|}{$\boldsymbol{x}$} & \multicolumn{2}{c}{$\boldsymbol{y}$}\\
          \hline
          $x_0$ & $x_1$ & $x_2$ & $x_3$ & $y_1$ & $y_0$\\
          \hline
          $1$ & $0$ & $0$ & $0$ & $0$ & $0$\\
          $0$ & $1$ & $0$ & $0$ & $0$ & $1$\\
          $0$ & $0$ & $1$ & $0$ & $1$ & $0$\\
          $0$ & $0$ & $0$ & $1$ & $1$ & $1$\\
        \end{tabular}
      } & {
        \centering
        \begin{KarnaughFunction}
          \contingut{\times,0,0,\times,1,\times,\times,\times,1,\times,\times,\times,\times,\times,\times,\times}
          \implicant{0}{8}{red}
          \implicant{4}{14}{green}
          \implicant{12}{10}{blue}
        \end{KarnaughFunction}
        \hspace{2em}
        \renewcommand{\arraystretch}{1.1}
        $\begin{array}{ccccccl@{}}
             & & & & & & y_1 = x_2 + x_3\\
             & & & & & & y_1 = \overline{x_1}\overline{x_0}
        \end{array}$
      } & {
        \centering
        \begin{KarnaughFunction}
          \contingut{\times,1,0,\times,1,\times,\times,\times,0,\times,\times,\times,\times,\times,\times,\times}
          \implicant{0}{5}{red}
          \implicant{4}{14}{green}
          \implicant{1}{11}{blue}
        \end{KarnaughFunction}
        \hspace{2em}
        \renewcommand{\arraystretch}{1.1}
        $\begin{array}{ccccccl@{}}
             & & & & & & y_0 = x_1 + x_3\\
             & & & & & & y_0 = \overline{x_0} \overline{x_2}
        \end{array}$
      }
  \end{tabularx}
  \caption{Tavola di verita e mappe di Karnaugh del codificatore a $2$ bit}
  \label{fig:tabella_verita_mappa_karnaugh_codificatore_2_bit}
\end{figure}

\noindent
Si noti che nella tabella di verit√† sono state riportate le sole configurazioni di ingresso definite; le altre danno luogo a \textbf{condizioni non specificate}, che consentono un amplissimo margine di libert√† nella realizzazione effettiva del circuito. Ci√≤ √® evidente dalle mappe di Karnaugh di Figura \ref{fig:tabella_verita_mappa_karnaugh_codificatore_2_bit}, che consentono almeno \(2\) soluzioni: la prima implica l‚Äôuso di due porte OR e la seconda due porte AND e due NOT.\\

\newpage
\noindent
Nella Figura \ref{fig:codificatore_2_bit_simbolo_circuitale_decodificatore_n_bit} vengono riprodotti, rispettivamente, il circuito del codificatore a \(2\) bit associato alla soluzione con le porte OR e il simbolo circuitale di un generico codificatore a $n$ bit.

\begin{figure}[H]
  \begin{tabularx}{\textwidth}{PP}
    {
      \begin{tikzpicture}
        \node [or gate US, draw, logic gate inputs=nnn] (or1){};
        \node [or gate US, draw, below=of or1, yshift=5.5mm, logic gate inputs=nnn] (or2){};

        \draw (or1.input 1) -- ++(-1,0) coordinate(start) node[at end, left]{$x_1$};
        \draw (start) ++(0,0.5) -- ++(0.5,0) node[at start, left]{$x_0$};
        \draw (or2.input 1) -- (or2.input 1 -| start) node[at end, left]{$x_2$};
        \draw (or2.input 3) -- (or2.input 3 -| start) node[at end, left]{$x_3$};
        \draw (or2.input 3) ++(-0.5,0) node[circ]{} |- (or1.input 3);

        \draw (or1.output) -- ++(0.5,0) node[at end, right]{$y_0$};
        \draw (or2.output) -- ++(0.5,0) node[at end, right]{$y_1$};
      \end{tikzpicture}
    } & {
      \begin{tikzpicture}
        \draw (0,0) -- (1.25,-0.5) -- (1.25,-2.5) -- (0,-3) -- (0,0);
        \draw[-stealth] (-1,-0.5) -- (0,-0.5) node[at start, left]{$0$};
        \draw[-stealth] (-1,-1) -- (0,-1) node[at start, left]{$1$};
        \draw[-stealth] (-1,-1.5) -- (0,-1.5) node[at start, left]{$2$};
        \draw (-0.5,-1.88) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (-0.5,-2.21) node[fill,circle,inner sep=0pt,minimum size=2pt]{};
        \draw[-stealth] (-1,-2.5) -- (0,-2.5) node[at start, left]{$2^n - 1$};
        \draw (0.625,-1.5) node[]{Cod};
        \draw[-stealth] (1.25,-0.75) -- (2.25,-0.75) node[at end, right]{$0$};
        \draw[-stealth] (1.25,-1.25) -- (2.25,-1.25) node[at end, right]{$1$};
        \draw (1.75,-1.58) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (1.75,-1.91) node[fill,circle,inner sep=0pt,minimum size=2pt]{};
        \draw[-stealth] (1.25,-2.25) -- (2.25,-2.25) node[at end, right]{$n - 1$};
      \end{tikzpicture}
    }\\
  \end{tabularx}
  \caption{Codificatore a $2$ bit e simbolo circuitale di un decodificatore a $n$ bit}
  \label{fig:codificatore_2_bit_simbolo_circuitale_decodificatore_n_bit}
\end{figure}

\vspace{1em}
\subsubsection{Selettori}
Un \textbf{selettore d‚Äôingresso (o Multiplexer o Mux)} √® un modulo che permette di selezionare uno tra \(2^n\) ingressi e presentarlo sull‚Äôunica uscita. La selezione si effettua attraverso \(n\) linee di comando.\\

\begin{figure}[H]
  \begin{tabularx}{\textwidth}{>{\hsize=0.25\textwidth}P>{\hsize=0.25\textwidth}P>{\hsize=0.45\textwidth}P}
    {
        \setlength{\tabcolsep}{5pt}
        \renewcommand{\arraystretch}{1}
        \begin{tabular}{c|cc||c}
          $\boldsymbol{s}$ & \multicolumn{2}{c||}{$\boldsymbol{x}$} & $\boldsymbol{y}$\\
          \hline
          $s_0$ & $x_0$ & $x_1$ & $y$\\
          \hline
          $0$ & $0$ & $0$ & $0$\\
          $0$ & $0$ & $1$ & $0$\\
          $0$ & $1$ & $0$ & $1$\\
          $0$ & $1$ & $1$ & $1$\\
          $1$ & $0$ & $0$ & $0$\\
          $1$ & $0$ & $1$ & $1$\\
          $1$ & $1$ & $0$ & $0$\\
          $1$ & $1$ & $1$ & $1$\\
        \end{tabular}
    } & {
        \renewcommand{\arraystretch}{1.1}
        $\begin{array}{rcl}
            y & = & \overline{s_0}x_0\overline{x_1} + \overline{s_0}x_0x_1\\
              & + & s_0\overline{x_0}x_1 + s_0x_0x_1\\
              & = & \overline{s_0}x_0 + s_0x_1
        \end{array}$
    } & {
      \hspace{-3em}
      \begin{tikzpicture}
        \node [and gate US, draw, logic gate inputs=inn] (and1){};
        \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=nnn] (and2){};
        \node [or gate US, draw, right=of and1, yshift=-5.5mm, logic gate inputs=nnn] (or){};

        \draw (and1.input 3) -- ++(-1,0) coordinate(start) node[at end, left]{$x_0$};
        \draw (and2.input 3) -- (and2.input 3 -| start) node[at end, left]{$x_1$};
        \draw (and1.input 1) -- ++(-0.5,0) node[circ]{} ++(0,0.5) |- (and2.input 1) node[at start, above]{$s_0$};

        \draw (and1.output) -- ++(0.5,0) |- (or.input 1);
        \draw (and2.output) -- ++(0.5,0) |- (or.input 3);
        \draw (or.output) -- ++(0.5,0) node[at end, right]{$y$};
      \end{tikzpicture}
    }\\
  \end{tabularx}
  \caption{Selettore d‚Äôingresso (o \emph{Multiplexer}) a $2$ vie}
  \label{fig:multiplexer_2_vie}
\end{figure}

\noindent
Nella Figura \ref{fig:multiplexer_2_vie} viene fornita la tavola di verit√† del \emph{Multiplexer} a \(2\) vie (\(2:1\) \emph{Mux}), che si ricava tenendo conto che per \(s_0 = 0\) viene riportato in uscita il contenuto di \(x_0\), mentre per \(s_0 = 1\) si porta in uscita il contenuto di \(x_1\); la semplificazione tramite minterm di figura Figura \ref{fig:multiplexer_2_vie} porta alla soluzione circuitale di figura Figura \ref{fig:multiplexer_2_vie}.\\
La Figura \ref{fig:simbolo_circuitale_selettore_ingresse_2_^_n_vie}, invece, illustra il simbolo circuitale di un generico \emph{Multiplexer} a \(2^n\) vie.

\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \draw (0,0) -- coordinate[midway](m) (1.25,-0.5) -- (1.25,-2.5) -- (0,-3) -- (0,0);
    \draw[-stealth] (-1,-0.5) -- (0,-0.5) node[at start, left]{$0$};
    \draw[-stealth] (-1,-1) -- (0,-1) node[at start, left]{$1$};
    \draw[-stealth] (-1,-1.5) -- (0,-1.5) node[at start, left]{$2$};
    \draw (-0.5,-1.88) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (-0.5,-2.21) node[fill,circle,inner sep=0pt,minimum size=2pt]{};
    \draw[-stealth] (-1,-2.5) -- (0,-2.5) node[at start, left]{$2^n - 1$};
    \draw (0.625,-1.5) node[]{Mux};
    \draw[-stealth] (1.25,-1.5) -- (2.25,-1.5) node[at end, right]{$y$};
    \draw[-stealth] (m) ++(0,0.5) coordinate(a) ++(0,0.5) -- (m) node[at start, above]{Sel};
    \draw (a) ++(0.1,0.1) -- ++(-0.2,-0.2);
  \end{tikzpicture}
  \caption{Simbolo circuitale di un selettore d‚Äôingresso a $2^n$ vie}
  \label{fig:simbolo_circuitale_selettore_ingresse_2_^_n_vie}
\end{figure}

\newpage
\noindent
Un \textbf{selettore d‚Äôuscita} (o \textbf{Demultiplexer} o \textbf{Demux}) √®, al contrario, un dispositivo che permette di dirottare l‚Äôunico ingresso su una delle possibili $2^n$ uscite.\\
La Figura \ref{fig:demultiplexer_2_vie_simbolo_circuitale} mostra un Demultiplexer a $2$ vie ($1:2$ \emph{Demux}) oltre al simbolo grafico di un generico selettore d‚Äôuscita a $2^n$ vie.

\begin{figure}[H]
  \begin{tabularx}{\textwidth}{PP}
    {
        \hspace{-3em}
        \begin{tikzpicture}
          \node [and gate US, draw, logic gate inputs=nnn] (and1){};
          \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=inn] (and2){};

          \draw (and1.input 3) -- ++(-0.7,0) node[circ](dot1){} -- ++(-0.3,0) node[at end, left]{$x$};
          \draw (dot1) |- (and2.input 3);
          \draw (and1.input 1) -- ++(-0.3,0) node[circ](dot2){} -- ++(0,0.5) node[at end, above]{$s_0$};
          \draw (dot2) |- (and2.input 1);

          \draw (and1.output) -- ++(0.5,0) node[at end, right]{$y_0$};
          \draw (and2.output) -- ++(0.5,0) node[at end, right]{$y_1$};
        \end{tikzpicture}
    } & {
    \begin{tikzpicture}
        \draw (0,0) -- coordinate[midway](m) (1.25,0.5) -- (1.25,-3) -- (0,-2.5) -- (0,0);
        \draw[-stealth] (-1,-1.25) -- (0,-1.25) node[at start, left]{$x$};
        \draw (0.625,-1.25) node[]{DMX};
        \draw[-stealth] (1.25,0) -- (2.25,0) node[at end, right]{$0$};
        \draw[-stealth] (1.25,-0.5) -- (2.25,-0.5) node[at end, right]{$1$};
        \draw[-stealth] (1.25,-1) -- (2.25,-1) node[at end, right]{$2$};
        \draw[-stealth] (1.25,-1.5) -- (2.25,-1.5) node[at end, right]{$3$};
        \draw (1.75,-1.85) node[fill,circle,inner sep=0pt,minimum size=2pt]{} (1.75,-2.15) node[fill,circle,inner sep=0pt,minimum size=2pt]{};
        \draw[-stealth] (1.25,-2.5) -- (2.25,-2.5) node[at end, right]{$2^n -1$};
        \draw[-stealth] (m) ++(0,0.5) coordinate(a) ++(0,0.5) -- (m) node[at start, above]{Sel};
        \draw (a) ++(0.1,0.1) -- ++(-0.2,-0.2);
      \end{tikzpicture}
    }\\
  \end{tabularx}
  \caption{Selettori d‚Äôuscita (o \emph{Demultiplexer}) a $2$ vie e relativo simbolo circuitale}
  \label{fig:demultiplexer_2_vie_simbolo_circuitale}
\end{figure}

\noindent
Si noti che nel caso di selettore di uscita, l‚Äôingresso viene presentato sulla via selezionata, mentre tutti gli altri ingressi sono a $0$.\\
In entrambi i selettori (d‚Äôingresso e d‚Äôuscita) l‚Äô$n$-pla binaria della linea \emph{Sel} seleziona quale, tra le $2^n$ linee, √® interessata alla connessione con l‚Äôuscita (o l‚Äôingresso).

\newpage
\begin{center}
    27 Ottobre 2021
\end{center}
Si consideri un \textbf{display \(7\) segmenti} e si realizzi un sistema per rappresentare dei numeri attraverso proprio \(7\) diodi emettitori di luce, contrassegnati dalle lettere da \textbf{a} a \textbf{g}, come esposto in Figura \ref{fig:schema_display_7_segmenti}:

\begin{figure}[H]
  \centering
  \begin{tikzpicture}[scale=2.5]
    \draw[gray,opacity=.3,line width=4pt] (0,0) --+ (0,.5);
    \draw (-0.25,0.25) node[]{e};

    \draw[gray,opacity=.3,line width=4pt] (0,.6) --+ (0,.5);
    \draw (-0.25,0.85) node[]{f};

    \draw[xshift=.7cm,gray,opacity=.3,line width=4pt] (0,0) --+ (0,.5);
    \draw (0.95,0.25) node[]{c};

    \draw[xshift=.7cm,gray,opacity=.3,line width=4pt] (0,.6) --+ (0,.5);
    \draw (0.95,0.85) node[]{b};

    \draw[gray,opacity=.3,line width=4pt] (.1,1.18) --+ (.5,0);
    \draw (0.35,1.43) node[]{a};

    \draw[gray,opacity=.3,line width=4pt] (.1,-.05) --+ (.5,0);
    \draw (0.35,0.2) node[]{d};

    \draw[gray,opacity=.3,line width=4pt] (.1,.55) --+ (.5,0);
    \draw (0.35,0.8) node[]{g};
  \end{tikzpicture}
  \vspace{0.5em}
  \caption{Schema display $7$ segmenti}
  \label{fig:schema_display_7_segmenti}
\end{figure}

\noindent
Si ottiene, rappresentando le diverse configurazioni decimali, da $0$ a $9$ sul diuslay, una tabella come quella seguente:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{1.1}
    \begin{tabular}{c|cccc|ccccccc}
         Numero & $x$ & $y$ & $z$ & $w$ & a & b & c & d & e & f & g\\
         \hline
         $0$ & $0$ & $0$ & $0$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ & $0$\\
         $1$ & $0$ & $0$ & $0$ & $1$ & $0$ & $1$ & $1$ & $0$ & $0$ & $0$ & $0$ \\
         $2$ & $0$ & $0$ & $1$ & $0$ & $1$ & $0$ & $0$ & $1$ & $1$ & $0$ & $1$ \\
         $3$ & $0$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ & $0$ & $0$ & $1$ \\
         \hline
         $4$ & $0$ & $1$ & $0$ & $0$ & $0$ & $1$ & $1$ & $0$ & $0$ & $1$ & $1$ \\
         $5$ & $0$ & $1$ & $0$ & $1$ & $1$ & $0$ & $1$ & $1$ & $0$ & $1$ & $1$ \\
         $6$ & $0$ & $1$ & $1$ & $0$ & $1$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ \\
         $7$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ & $0$ & $0$ & $0$ & $0$ \\
         \hline
         $8$ & $1$ & $0$ & $0$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$ & $1$\\
         $9$ & $1$ & $0$ & $0$ & $1$ & $1$ & $1$ & $1$ & $1$ & $0$ & $1$ & $1$\\
         $-$ & $1$ & $0$ & $1$ & $0$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ \\
         $-$ & $1$ & $0$ & $1$ & $1$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ \\
         \hline
         $-$ & $1$ & $1$ & $0$ & $0$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ \\
         $-$ & $1$ & $1$ & $0$ & $1$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ \\
         $-$ & $1$ & $1$ & $1$ & $0$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ \\
         $-$ & $1$ & $1$ & $1$ & $1$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ \\
    \end{tabular}
    \caption{Tabella di verit√† display \(7\) segmenti}
    \label{tab:tabella_verita_display_7_segmenti}
\end{table}

\noindent
Se, ora, si realizzano le mappe di Karnaugh per ciascuna delle \(7\) funzioni di uscita (\quotes{a}, \quotes{b}, \quotes{c}, \quotes{d}, \quotes{e}, \quotes{f} e \quotes{g}), al fine di semplificare la funzione logica associata, si otterrebbero due alternative di rappresentaizone delle medesime, come accade, normalmente, per i codificatori, a seconda che si scelga di semplificare i minterm o i maxterm.

\newpage
\noindent
Si, consideri, a titolo esemplificativo, la funzione logica \quotes{a}, a cui viene associata la mappa di Karnaugh di Figura \ref{fig:mappa_karnaugh_16_3} seguente:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{1,0,1,\times,0,1,1,\times,1,1,\times,\times,1,1,\times,\times}
        \implicantcantons[2pt]{red}
        \implicant{3}{10}{green}
        \implicant{12}{10}{blue}
        \implicant{5}{15}{violet}
    \end{Karnaugh}
    \vspace{-1.5em}
    \caption{Mappa di Karnaugh associata alla funzione a}
    \label{fig:mappa_karnaugh_16_3}
\end{figure}

\noindent
Che produce la semplificazione seguente:
\begin{flalign*}
  \text{a} & = \overline{y} \overline{w} + x + z + yw\\
  \text{a} & = \left(x + y + z + \overline{w}\right) \cdot \left(\overline{y} + z + w\right)
\end{flalign*}

\noindent
Tale sistema, poteva essere effettivamente realizzato anche sfruttando i \textbf{codificatori}. Infatti, com'√® noto, un codificatore presenta i ingresso una sola linea a \(1\) corrispondente al numero naturale compreso tra \([0, 9]\) che si vuole rappresentare in binario. Il codificatore provveder√† a rappresentare il numero in ingresso in base decimale nella base binaria. E le \(4\) uscite del codificatore rappresenteranno i \(4\) ingressi della rete logica che si √® proprio realizzata in questo esercizio che, a sua volta, piloter√† il display \(7\) segmenti.\\
Ci√≤ agevoler√† l'operazione di input che non sar√† pi√π composta da \(4\) linee, ma da una sola, quella del codificatore, che a sua volta provveder√† a convertire il numero richiesto in binario.

\vspace{1em}
\subsection{Riassunto}
I moduli combinatori sono stati introdotti per razionalizzare la realizzazione dei circuiti logici. I pi√π importanti circuiti combinatori sono i seguenti:
\begin{itemize}
    \item \textbf{Decodificatori}, che presentano \(n\) bit in ingresso e \(2^n\) bit in uscita, permettendo la rappresentazione di numeri in base \(10\), espressi, in ingresso, in forma binaria. Naturalmente verr√† attivata solamente \(1\) delle \(2^n\) possibili uscite del decodificatore per indicare il valore decimale corrispondente.

    \item \textbf{Codificatori}, che presentano \(2^n\) bit in ingresso e \(n\) bit in uscita, in cui solamente una linea in ingresso verr√† portata ad \(1\) per indicare il valore da codificare, mentre saranno \(n\) le uscite che produrranno il valore decimale codificato in binario.\\
    Naturalmente, in questo caso, se vi sono \(2^n\) ingressi si potranno rappresentare solamente \(n\) valori binari, pertanto \(2^{n} - n\) configurazioni degli ingressi saranno inutilizzate e costituiranno delle condizione non specificate.

    \item \textbf{Multiplexer}, che presenta \(2^n\) ingressi e \(n\) selettori per selezionare, ovvero dirottare, uno dei \(2^n\) ingressi in un'unica uscita.

    \item \textbf{Demultiplexer}, che che presentano un solo ingresso, \(2^n\) uscite e \(n\) selettori.
\end{itemize}

\vspace{1em}
\subsection{Costruzione modulare di una funzione Booleana}
Un impiego particolarmente interessante dei selettori d‚Äôingresso, o \emph{multiplexer}, √® il seguente: la costruzione di qualunque funzione Booleana di \(n\) variabili attraverso un selettore d‚Äôingresso a \(2^n\) vie.\\
Una qualunque funzione di \(n\) variabili, com'√® noto, pu√≤ essere ricondotta a una somma di \textit{minterm} (o prodotto di \emph{maxterm}). Allora, se si considera una funzione Booleana
\[f : n \rightarrow 2^n\]
con \(n = 3\) e, quindi, \(2^n = 8\) uscite, sar√† sufficiente porre in ingresso al multiplexer a \(8\) vie le \(8\) costanti dei valori della funzione, mentre gli \(n = 3\) selettori comanderanno quale degli \(8\) ingressi dovr√† essere dirottato in uscita.\\
Si consideri, a titolo esemplificativo, la funzione Booleana rappresentata nella Tabella \ref{tab:funzione_booleana_multiplexer} seguente:

\begin{table}[H]
  \centering
  \setlength{\tabcolsep}{8pt}
  \renewcommand{\arraystretch}{1.1}
  \begin{tabular}{c|c||ccc||cc}
    $ $ & $ $ & $x$ & $y$ & $z$ & $f$\\
    \hline
    $m_0$ & $\overline{x}\overline{y}\overline{z}$ & $0$ & $0$ & $0$ & $1$ & $\mu_0$\\
    $m_1$ & $\overline{x}\overline{y}z$ & $0$ & $0$ & $1$ & $0$ & $\mu_1$\\
    $m_2$ & $\overline{x}y\overline{z}$ & $0$ & $1$ & $0$ & $0$ & $\mu_2$\\
    $m_3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$ & $\mu_3$\\
    $m_4$ & $x\overline{y}\overline{z}$ & $1$ & $0$ & $0$ & $0$ & $\mu_4$\\
    $m_5$ & $x\overline{y}z$ & $1$ & $0$ & $1$ & $0$ & $\mu_5$\\
    $m_6$ & $xy\overline{z}$ & $1$ & $1$ & $0$ & $1$ & $\mu_6$\\
    $m_7$ & $xyz$ & $1$ & $1$ & $1$ & $1$ & $\mu_7$\\
  \end{tabular}
  \caption{Funzione Booleana da realizzare con il \emph{Multiplexer}}
  \label{tab:funzione_booleana_multiplexer}
\end{table}

\noindent
Com'√® noto, naturalmente, tale funzione pu√≤ essere scritta come segue:

\begin{flalign*}
  f(x,y,z) & = \sum_{i \in \{0,3,6,7\}} m_i = m_0 + m_3 + m_6 + m_7 = \overline{x}\overline{y}\overline{z} + \overline{x}yz + xy\overline{z} + xyz\\
   & = 1 \cdot \overline{x}\overline{y}\overline{z} + 0 \cdot \overline{x}\overline{y}z + 0 \cdot \overline{x}y\overline{z} + 1 \cdot \overline{x}yz + 0 \cdot x\overline{y}\overline{z} + 0 \cdot x\overline{y}z + 1 \cdot xy\overline{z} + 1 \cdot xyz
\end{flalign*}

\noindent
Poich√© $0$, $3$, $6$ e $7$ sono le codifiche in base due di $000$, $011$, $110$ e $111$; attraverso tale approccio, nella sommatoria di cui sopra si pone $1$ in corrispondenza dei \emph{minterm} che compaiono nella funzione e $0$ in corrispondenza di quelli che non vi compaiono.\\
Con un selettore a otto vie la funzione $f$ si ottiene impiegando $x$, $y$, $z$ come linee di selezione e ponendo le otto linee di ingresso a $0$ o a $1$ a seconda che il coefficiente del corrispondente minterm, che corrisponde al valore della funzione per la terna binaria associata, sia a $0$ o a $1$.\\
In Figura \ref{fig:modulo_selettore_realizzazione_funzione} si vede il circuito per l‚Äôattuazione della funzione in oggetto.\\
Poich√® ogni funzione logica pu√≤ essere ricondotta alla sua prima forma canonica, ne deriva che √® possibile realizzare qualunque funzione con il metodo sopra esposto.\\
Tuttavia, si capisce bene che un multiplexer a \(2^n\) vie presenta \(2^n\) porte AND e \(1\) porta OR di uscita, che sono, generalmente, in numero maggiore delle porte che si impiegherebbe per realizzare la medesima funzione logica riducendola in forma minima.\\
Ma allo stesso tempo si osservano due \textbf{significativi vantaggi}:
\begin{enumerate}
    \item anche se il circuito da realizzare √® molto complesso, tale metodo garantisce una straordinaria versatilit√†: infatti gli ingressi corrispondenti ai coefficienti possono essere considerati come ingressi di programmazione e possono essere aggiustati sulla piastra elettronica anche attraverso collegamenti ad hoc (verso $V_{CC}$ o verso massa, che in logica positiva corrispondono rispettivamente a $1$ e $0$ logico);

    \item un \emph{multiplexer} √® un dispositivo molto comune e prodotto \textbf{in larga scala}, quindi il suo costo sar√† inferiore rispetto a quello di un circuito personalizzato e costruito appositamente per il proprio scopo.\\
    Si consideri, inoltre, che se non si volesse realizzare un circuito con esclusivamente le porte ottenute tramite semplificazione (AND-OR-NOT), si dovrebbe ripiegare su circuiti integrati con un numero di porte AND e OR che, in ogni caso, sono ormai standardizzati. Pertanto, anche nella realizzazione del circuito con questa modalit√†, ovvero la semplificazione, si avrebbe un risparmio solamente apparente.
\end{enumerate}

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{tikzpicture}
      % Variabili
      \coordinate (x) at (0,0);
      \coordinate (y) at (0.5,0);
      \coordinate (z) at (1,0);

      % Porte logiche
      \node [and gate US, draw, logic gate inputs=niii] (and1) at (2,-1){};
      \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=niin] (and2){};
      \node [and gate US, draw, below=of and2, yshift=5.5mm, logic gate inputs=nini] (and3){};
      \node [and gate US, draw, below=of and3, yshift=5.5mm, logic gate inputs=ninn] (and4){};
      \node [and gate US, draw, below=of and4, yshift=5.5mm, logic gate inputs=nnii] (and5){};
      \node [and gate US, draw, below=of and5, yshift=5.5mm, logic gate inputs=nnin] (and6){};
      \node [and gate US, draw, below=of and6, yshift=5.5mm, logic gate inputs=nnni] (and7){};
      \node [and gate US, draw, below=of and7, yshift=5.5mm, logic gate inputs=nnnn] (and8){};
      \node [or gate US, draw, right=of and4, xshift=10mm, yshift=-5.5mm, logic gate inputs=nnnnnnnn] (or){};

      % INPUT
      \draw (x) ++(0,-11) -- node[at end, above]{$x$} (x);
      \draw (y) ++(0,-11) -- node[at end, above]{$y$} (y);
      \draw (z) ++(0,-11) -- node[at end, above]{$z$} (z);

      % AND 1
      \draw (and1.input 1) -- ++(-2,0) node[at end, left]{$1$};
      \draw (and1.input 2) -- (and1.input 2 -| x) node[circ]{};
      \draw (and1.input 3) -- (and1.input 3 -| y) node[circ]{};
      \draw (and1.input 4) -- (and1.input 4 -| z) node[circ]{};

      % AND 2
      \draw (and2.input 1) -- ++(-2,0) node[at end, left]{$0$};
      \draw (and2.input 2) -- (and2.input 2 -| x) node[circ]{};
      \draw (and2.input 3) -- (and2.input 3 -| y) node[circ]{};
      \draw (and2.input 4) -- (and2.input 4 -| z) node[circ]{};

      % AND 3
      \draw (and3.input 1) -- ++(-2,0) node[at end, left]{$0$};
      \draw (and3.input 2) -- (and3.input 2 -| x) node[circ]{};
      \draw (and3.input 3) -- (and3.input 3 -| y) node[circ]{};
      \draw (and3.input 4) -- (and3.input 4 -| z) node[circ]{};

      % AND 4
      \draw (and4.input 1) -- ++(-2,0) node[at end, left]{$1$};
      \draw (and4.input 2) -- (and4.input 2 -| x) node[circ]{};
      \draw (and4.input 3) -- (and4.input 3 -| y) node[circ]{};
      \draw (and4.input 4) -- (and4.input 4 -| z) node[circ]{};

      % AND 5
      \draw (and5.input 1) -- ++(-2,0) node[at end, left]{$0$};
      \draw (and5.input 2) -- (and5.input 2 -| x) node[circ]{};
      \draw (and5.input 3) -- (and5.input 3 -| y) node[circ]{};
      \draw (and5.input 4) -- (and5.input 4 -| z) node[circ]{};

      % AND 6
      \draw (and6.input 1) -- ++(-2,0) node[at end, left]{$0$};
      \draw (and6.input 2) -- (and6.input 2 -| x) node[circ]{};
      \draw (and6.input 3) -- (and6.input 3 -| y) node[circ]{};
      \draw (and6.input 4) -- (and6.input 4 -| z) node[circ]{};

      % AND 7
      \draw (and7.input 1) -- ++(-2,0) node[at end, left]{$1$};
      \draw (and7.input 2) -- (and7.input 2 -| x) node[circ]{};
      \draw (and7.input 3) -- (and7.input 3 -| y) node[circ]{};
      \draw (and7.input 4) -- (and7.input 4 -| z) node[circ]{};

      % AND 8
      \draw (and8.input 1) -- ++(-2,0) node[at end, left]{$1$};
      \draw (and8.input 2) -- (and8.input 2 -| x) node[circ]{};
      \draw (and8.input 3) -- (and8.input 3 -| y) node[circ]{};
      \draw (and8.input 4) -- (and8.input 4 -| z) node[circ]{};

      \draw (and1.output) -- ++(1.5,0)  |- (or.input 1);
      \draw (and2.output) -- ++(1.25,0) |- (or.input 2);
      \draw (and3.output) -- ++(1,0)    |- (or.input 3);
      \draw (and4.output) -- ++(0.75,0) |- (or.input 4);
      \draw (and5.output) -- ++(0.75,0) |- (or.input 5);
      \draw (and6.output) -- ++(1,0)    |- (or.input 6);
      \draw (and7.output) -- ++(1.25,0) |- (or.input 7);
      \draw (and8.output) -- ++(1.5,0)  |- (or.input 8);
      \draw (or.output)   -- ++(0.5,0) node[at end, right]{$y$};
    \end{tikzpicture}
    \caption{Modulo selettore per la realizzazione della funzione considerata}
    \label{fig:modulo_selettore_realizzazione_funzione}
\end{figure}

\noindent
\textbf{Osservazione}: Esiste, tuttavia, un metodo pi√π economico per costruire, in modo \textbf{modulare}, una qualunque funzione Booleana di \(n\) variabili. Facendo sempre riferimento alla I forma canonica, la sua realizzazione richiede un numero di porte AND a \(n\) ingressi pari al numero di \emph{minterm} (cio√® \(2^n\)) e una porta OR con un numero di ingressi pari al numero di porte AND (cio√® sempre \(2^n\)).\\
La semplificazione che si potrebbe attuare, in tal senso, prevederebbe di \quotes{prolungare} le uscite delle porte AND agli ingressi della porta OR per i soli \emph{minterm} che entrano nella funzione.\\

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{tabularx}{\textwidth}{PP}
      {
        \begin{tikzpicture}
          % Variabili
          \coordinate (x) at (0,0);
          \coordinate (y) at (0.5,0);
          \coordinate (z) at (1,0);

          % Porte logiche
          \node [and gate US, draw, logic gate inputs=iii] (and1) at (2,-1){};
          \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=iin] (and2){};
          \node [and gate US, draw, below=of and2, yshift=5.5mm, logic gate inputs=ini] (and3){};
          \node [and gate US, draw, below=of and3, yshift=5.5mm, logic gate inputs=inn] (and4){};
          \node [and gate US, draw, below=of and4, yshift=5.5mm, logic gate inputs=nii] (and5){};
          \node [and gate US, draw, below=of and5, yshift=5.5mm, logic gate inputs=nin] (and6){};
          \node [and gate US, draw, below=of and6, yshift=5.5mm, logic gate inputs=nni] (and7){};
          \node [and gate US, draw, below=of and7, yshift=5.5mm, logic gate inputs=nnn] (and8){};
          \node [or gate US, draw, rotate=270, right=of and8, xshift=15mm, yshift=12.6mm, logic gate inputs=nnnnnnnn] (or){};

          % INPUT
          \draw (x) ++(0,-10) -- node[at end, above]{$x$} (x);
          \draw (y) ++(0,-10) -- node[at end, above]{$y$} (y);
          \draw (z) ++(0,-10) -- node[at end, above]{$z$} (z);

          % AND 1
          \draw (and1.input 1) -- (and1.input 1 -| x) node[circ]{};
          \draw (and1.input 2) -- (and1.input 2 -| y) node[circ]{};
          \draw (and1.input 3) -- (and1.input 3 -| z) node[circ]{};

          % AND 2
          \draw (and2.input 1) -- (and2.input 1 -| x) node[circ]{};
          \draw (and2.input 2) -- (and2.input 2 -| y) node[circ]{};
          \draw (and2.input 3) -- (and2.input 3 -| z) node[circ]{};

          % AND 3
          \draw (and3.input 1) -- (and3.input 1 -| x) node[circ]{};
          \draw (and3.input 2) -- (and3.input 2 -| y) node[circ]{};
          \draw (and3.input 3) -- (and3.input 3 -| z) node[circ]{};

          % AND 4
          \draw (and4.input 1) -- (and4.input 1 -| x) node[circ]{};
          \draw (and4.input 2) -- (and4.input 2 -| y) node[circ]{};
          \draw (and4.input 3) -- (and4.input 3 -| z) node[circ]{};

          % AND 5
          \draw (and5.input 1) -- (and5.input 1 -| x) node[circ]{};
          \draw (and5.input 2) -- (and5.input 2 -| y) node[circ]{};
          \draw (and5.input 3) -- (and5.input 3 -| z) node[circ]{};

          % AND 6
          \draw (and6.input 1) -- (and6.input 1 -| x) node[circ]{};
          \draw (and6.input 2) -- (and6.input 2 -| y) node[circ]{};
          \draw (and6.input 3) -- (and6.input 3 -| z) node[circ]{};

          % AND 7
          \draw (and7.input 1) -- (and7.input 1 -| x) node[circ]{};
          \draw (and7.input 2) -- (and7.input 2 -| y) node[circ]{};
          \draw (and7.input 3) -- (and7.input 3 -| z) node[circ]{};

          % AND 8
          \draw (and8.input 1) -- (and8.input 1 -| x) node[circ]{};
          \draw (and8.input 2) -- (and8.input 2 -| y) node[circ]{};
          \draw (and8.input 3) -- (and8.input 3 -| z) node[circ]{};

          \draw (and1.output) -- ++(5,0);
          \draw (and2.output) -- ++(5,0);
          \draw (and3.output) -- ++(5,0);
          \draw (and4.output) -- ++(5,0);
          \draw (and5.output) -- ++(5,0);
          \draw (and6.output) -- ++(5,0);
          \draw (and7.output) -- ++(5,0);
          \draw (and8.output) -- ++(5,0);
          \draw (and1.output) ++(0.5,0.5) |- ([yshift=-10mm] or.input 8 |- and8.output) -| (or.input 8);
          \draw (and1.output) ++(1,0.5)   |- ([yshift=-7.5mm] or.input 7 |- and8.output) -| (or.input 7);
          \draw (and1.output) ++(1.5,0.5) |- ([yshift=-5mm] or.input 6 |- and8.output) -| (or.input 6);
          \draw (and1.output) ++(2,0.5)   |- ([yshift=-2.5mm] or.input 5 |- and8.output) -| (or.input 5);
          \draw (and1.output) ++(2.5,0.5) |- ([yshift=-2.5mm] or.input 4 |- and8.output) -| (or.input 4);
          \draw (and1.output) ++(3,0.5)   |- ([yshift=-5mm] or.input 3 |- and8.output) -| (or.input 3);
          \draw (and1.output) ++(3.5,0.5) |- ([yshift=-7.5mm] or.input 2 |- and8.output) -| (or.input 2);
          \draw (and1.output) ++(4,0.5)   |- ([yshift=-10mm] or.input 1 |- and8.output) -| (or.input 1);
          \draw (or.output)   -- ++(0,-0.5) node[at end, below]{$y$};
          \ctikzset{diodes/scale=0.2}
          \draw (and1.output) ++(0.75,0) node[circ]{} to [full diode] ([xshift=5mm,yshift=-2.5mm]and1.output) node[circ]{};
          \draw (and4.output) ++(2.25,0) node[circ]{} to [full diode] ([xshift=20mm,yshift=-2.5mm]and4.output) node[circ]{};
          \draw (and7.output) ++(3.75,0) node[circ]{} to [full diode] ([xshift=35mm,yshift=-2.5mm]and7.output) node[circ]{};
          \draw (and8.output) ++(4.25,0) node[circ]{} to [full diode] ([xshift=40mm,yshift=-2.5mm]and8.output) node[circ]{};
        \end{tikzpicture}
      } & {
        \begin{tikzpicture}
          % Variabili
          \coordinate (x) at (0,0);
          \coordinate (y) at (0.5,0);
          \coordinate (z) at (1,0);

          % Porte logiche
          \node [nand gate US, draw, logic gate inputs=niii] (and1) at (2,-1){};
          \node [nand gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=niin] (and2){};
          \node [nand gate US, draw, below=of and2, yshift=5.5mm, logic gate inputs=nini] (and3){};
          \node [nand gate US, draw, below=of and3, yshift=5.5mm, logic gate inputs=ninn] (and4){};
          \node [nand gate US, draw, below=of and4, yshift=5.5mm, logic gate inputs=nnii] (and5){};
          \node [nand gate US, draw, below=of and5, yshift=5.5mm, logic gate inputs=nnin] (and6){};
          \node [nand gate US, draw, below=of and6, yshift=5.5mm, logic gate inputs=nnni] (and7){};
          \node [nand gate US, draw, below=of and7, yshift=5.5mm, logic gate inputs=nnnn] (and8){};

          % INPUT
          \draw (x) ++(0,-11) -- node[at end, above]{$x_2$} (x);
          \draw (y) ++(0,-11) -- node[at end, above]{$x_1$} (y);
          \draw (z) ++(0,-11) -- node[at end, above]{$x_0$} (z);

          % AND 1
          \draw (and1.input 1) -- (and1.input 1 -| x) node[circ]{};
          \draw (and1.input 2) -- (and1.input 2 -| y) node[circ]{};
          \draw (and1.input 3) -- (and1.input 3 -| z) node[circ]{};

          % AND 2
          \draw (and2.input 1) -- (and2.input 1 -| x) node[circ]{};
          \draw (and2.input 2) -- (and2.input 2 -| y) node[circ]{};
          \draw (and2.input 3) -- (and2.input 3 -| z) node[circ]{};

          % AND 3
          \draw (and3.input 1) -- (and3.input 1 -| x) node[circ]{};
          \draw (and3.input 2) -- (and3.input 2 -| y) node[circ]{};
          \draw (and3.input 3) -- (and3.input 3 -| z) node[circ]{};

          % AND 4
          \draw (and4.input 1) -- (and4.input 1 -| x) node[circ]{};
          \draw (and4.input 2) -- (and4.input 2 -| y) node[circ]{};
          \draw (and4.input 3) -- (and4.input 3 -| z) node[circ]{};

          % AND 5
          \draw (and5.input 1) -- (and5.input 1 -| x) node[circ]{};
          \draw (and5.input 2) -- (and5.input 2 -| y) node[circ]{};
          \draw (and5.input 3) -- (and5.input 3 -| z) node[circ]{};

          % AND 6
          \draw (and6.input 1) -- (and6.input 1 -| x) node[circ]{};
          \draw (and6.input 2) -- (and6.input 2 -| y) node[circ]{};
          \draw (and6.input 3) -- (and6.input 3 -| z) node[circ]{};

          % AND 7
          \draw (and7.input 1) -- (and7.input 1 -| x) node[circ]{};
          \draw (and7.input 2) -- (and7.input 2 -| y) node[circ]{};
          \draw (and7.input 3) -- (and7.input 3 -| z) node[circ]{};

          % AND 8
          \draw (and8.input 1) -- (and8.input 1 -| x) node[circ]{};
          \draw (and8.input 2) -- (and8.input 2 -| y) node[circ]{};
          \draw (and8.input 3) -- (and8.input 3 -| z) node[circ]{};

          \draw (and1.output) -- ++(3,0) node[at end, right]{$0$ $(8)$};
          \draw (and2.output) -- ++(3,0) node[at end, right]{$1$ $(13)$};
          \draw (and3.output) -- ++(3,0) node[at end, right]{$2$ $(2)$};
          \draw (and4.output) -- ++(3,0) node[at end, right]{$3$ $(9)$};
          \draw (and5.output) -- ++(3,0) node[at end, right]{$4$ $(0)$};
          \draw (and6.output) -- ++(3,0) node[at end, right]{$5$ $(10)$};
          \draw (and7.output) -- ++(3,0) node[at end, right]{$6$ $(0)$};
          \draw (and8.output) -- ++(3,0) node[at end, right]{$7$ $(4)$};

          \ctikzset{resistors/scale=0.4}
          \draw (and1.output) ++(1,1.5) ++(3,0) coordinate(start) ++(-0.5,0) node[above]{$+V_{CC}$} ++(0.5,0) -- ++(-3,0) -- ++(0,-0.25) to[R] ++(0,-0.5) -- ++(0,-11) coordinate(n1);
          \draw (start) ++(-2.5,0) node[circ]{} -- ++(0,-0.25) to[R] ++(0,-0.5) -- ++(0,-11) coordinate(n2);
          \draw (start) ++(-2,0) node[circ]{} -- ++(0,-0.25) to[R] ++(0,-0.5) -- ++(0,-11) coordinate(n3);
          \draw (start) ++(-1.5,0) node[circ]{} -- ++(0,-0.25) to[R] ++(0,-0.5) -- ++(0,-11) coordinate(n4);

          \node [not gate US, draw, rotate=270](not1) at ([yshift=-5mm]n1){};
          \node [not gate US, draw, rotate=270](not2) at ([yshift=-5mm]n2){};
          \node [not gate US, draw, rotate=270](not3) at ([yshift=-5mm]n3){};
          \node [not gate US, draw, rotate=270](not4) at ([yshift=-5mm]n4){};

          \draw (n1) -- (not1.input) (not1.output) -- ++(0,-0.5) node[at end, below]{$z_3$};
          \draw (n2) -- (not2.input) (not2.output) -- ++(0,-0.5) node[at end, below]{$z_2$};
          \draw (n3) -- (not3.input) (not3.output) -- ++(0,-0.5) node[at end, below]{$z_1$};
          \draw (n4) -- (not4.input) (not4.output) -- ++(0,-0.5) node[at end, below]{$z_0$};

          \ctikzset{diodes/scale=0.2}
          \draw (and1.output) ++(1,0.25) node[circ]{} to [full diode] ([xshift=7.5mm]and1.output) node[circ]{};
          \draw (and2.output) ++(1,0.25) node[circ]{} to [full diode] ([xshift=7.5mm]and2.output) node[circ]{};
          \draw (and2.output) ++(1.5,0.25) node[circ]{} to [full diode] ([xshift=12.5mm]and2.output) node[circ]{};
          \draw (and2.output) ++(2.5,0.25) node[circ]{} to [full diode] ([xshift=22.5mm]and2.output) node[circ]{};
          \draw (and3.output) ++(2,0.25) node[circ]{} to [full diode] ([xshift=17.5mm]and3.output) node[circ]{};
          \draw (and4.output) ++(1,0.25) node[circ]{} to [full diode] ([xshift=7.5mm]and4.output) node[circ]{};
          \draw (and4.output) ++(2.5,0.25) node[circ]{} to [full diode] ([xshift=22.5mm]and4.output) node[circ]{};
          \draw (and6.output) ++(1,0.25) node[circ]{} to [full diode] ([xshift=7.5mm]and6.output) node[circ]{};
          \draw (and6.output) ++(2,0.25) node[circ]{} to [full diode] ([xshift=17.5mm]and6.output) node[circ]{};
          \draw (and8.output) ++(1.5,0.25) node[circ]{} to [full diode] ([xshift=12.5mm]and8.output) node[circ]{};
        \end{tikzpicture}
      }
    \end{tabularx}
    \caption{Matrice di contatti e memoria ROM derivabile da essa}
    \label{fig:matrice_contatti_e_memoria_ROM}
\end{figure}

\noindent
La Figura \ref{fig:matrice_contatti_e_memoria_ROM} mostra un circuito di questo genere, chiamato \textbf{matrice di contatti}, nel quale si evidenzia la presenza di un contatto per i soli minterm che servono per realizzare la funzione
\[z = \overline{x}\overline{y}\overline{z} + \overline{x}yz + xy\overline{z} + xyz\]
La struttura di tale circuito √® estremamente vantaggiosa se viene realizzata direttamente dal costruttore di integrati, che privilegia un‚Äô\textbf{alta uniformit√†} nella struttura circuitale.\\
Il confronto con la soluzione a selettori di Figura \ref{fig:modulo_selettore_realizzazione_funzione} √® chiarificatore: in quel caso, per realizzare una qualunque funzione di tre variabili occorre un integrato che abbia almeno $3 + 8 + 1 = 12$ piedini (a parte l‚Äôalimentazione e la massa); con la soluzione ora illustrata il numero di piedini sarebbe pari a soli $3 + 1 = 4$.\\
La struttura di Figura \ref{fig:matrice_contatti_e_memoria_ROM} fa uso di diodi per realizzare le connessioni della matrice; inoltre essa puo essere estesa in modo tale
da fornire non una, ma piu funzioni di uscita, passando, per esempio, a una rete con $n$ ingressi e $k$ uscite. Una simile rete fornisce, per ogni configurazione degli $n$ ingressi, una configurazione sulle $k$ uscite e viene a costituire quella che
si chiama una \textbf{memoria ROM}, acronimo di \emph{Read Only Memory} (memoria di sola lettura): la memoria in questione presenta $M = 2^n$ celle da $k$ bit ciascuna, che vengono indirizzate dalle $n$ linee di indirizzamento.\\
Tenendo conto della realizzazione circuitale appena esposta, si espone in Figura \ref{fig:matrice_contatti_e_memoria_ROM} la struttura di una memoria ROM con $2^3$ celle di memoria da $4$ bit ciascuna. Nella parte destra della Figura \ref{fig:matrice_contatti_e_memoria_ROM} viene riportato l‚Äôindirizzo di ciascuna cella e, tra parentesi, il suo contenuto.\\
Per capirne il funzionamento, si supponga che si voglia leggere il contenuto della memoria all‚Äôindirizzo 3; ci√≤ significa che deve essere $x_2x_1x_0 = 011$. In tal caso ci sar√† una sola porta NAND che presenter√† un‚Äôuscita bassa, ovvero la porta della riga $3$, mentre tutte le altre porte NAND presenteranno un'uscita alta. I catodi dei diodi relativi alle due colonne $z_3$ e $z_0$ andranno, allora a massa, inducendo una polarizzazione diretta per i corrispondenti diodi; sui rispettivi anodi si avr√†, allora, una tensione virtualmente nulla (in pratica ci sara solo la $V_{AK}$ di saturazione, pari a $0.3 \div 0.6$V). Le linee $z_3$ e $z_0$ sono allora basse e, a seguito della complementazione finale, diventeranno alte. Gli altri diodi sulle colonne $z_2$ e $z_1$ risultano, invece, interdetti, per cui linee rimangono allo stato alto ($V_{CC}$) e quindi c‚Äô√® $0$ in uscita, a seguito della complementazione finale. Dunque $z_3 = 1$ e $z_0 = 1$, mentre le altre due linee $z_2$ e $z_1$ si trovano a zero, e dunque $z = 1001$.

\subsubsection{Diodi}
L'idea alla base dell'ottimizzazione appena analizzata √® costituita dai diodi. I diodi, in teoria, sono di due tipologie:
\begin{enumerate}
    \item \textbf{Diodo a vuoto}, basata sulle ormai inutilizzate valvole termoioniche
    \item \textbf{Diodo a giunzione}, che pu√≤ essere a giunzione \(PNP\) oppure \(NPN\) a seconda del drogaggio a cui √® sottoposto.
\end{enumerate}

\vspace{1em}
\noindent
I diodi sono dei dispositivi che permettono di essere attraversati dalla corrente in un solo verso. Quando il diodo viene attraversato dalla corrente con \textbf{polarizzazione diretta} si ha un cortocircuito, quindi il diodo va in \textbf{interdizione}.\\
Se il diodo viene attraversato dalla corrente con \textbf{polarizzazione inversa} si ha un circuito aperto, quindi il diodo va in \textbf{saturazione}.\\
In figura 5.26 viene dato lo schema a blocchi di una memoria ROM; di fatto si tratta di un decodificatore seguito da una \textbf{matrice di contatti}. Il numero binario corrispondente alla combinazione degli \(n\) ingressi rappresenta l‚Äôindirizzo della corrispondente cella.\\
Si noti che fissare i contatti della matrice equivale a programmare il comportamento della rete. Nelle ROM propriamente dette, la matrice non ha inizialmente alcun punto di contatto tra righe e colonne. √à il costruttore che esegue le connessioni in base alla matrice di bit desiderata dal committente. Per le memorie ROM, che sono appunto di sola lettura, non √® possibile variare il contenuto della memoria dopo la programmazione fatta in fabbrica.\\
Le ROM risultano economicamente convenienti per volumi molto grandi.
Nel caso debba essere l‚Äôutente a programmare la ROM si ricorre alle cosiddette PROM(Programmable Read Only
Memory); la matrice ha inizialmente tutti i punti di contatto tra righe e colonne, attraverso un diodo e un fusibile.

\newpage
\begin{center}
    8 Novembre 2021
\end{center}

\subsection{Riassunto}
Consuetamente, la costruzione di una funzione logica ha sempre previsto una minimizzazione massimale del numero di componenti, attraverso le mappe di Karnaugh e il metodo tabella di Quine-Mc Cusky.\\
Tuttavia, molto spesso, non risulta essere conveniente operare in tal senso, ma √® spesso molto pi√π agevole impiegare dei circuiti precostuiti, ovvero dei moduli gi√† pronti, che permette anche di abbattere i costi.\\
Pertanto, molto spesso si ricorre all'impiego di \textbf{multiplexer}, che permette di avere \(2^n\) ingressi e \(n\) selettori e produce in uscita un solo livello logico.

\vspace{1em}
\noindent
\textbf{Osservazione}: I selettori molto spesso prendono il nome di \textbf{tip-switch} (denominazione da verificare).

\vspace{1em}
\noindent
L'impiego di un multiplexer per la realizzazione di un funzione logica √® molto pratico e agevole, e inoltre permette di avere una grande programmabilit√† e versatilit√†, cosa che non accade quando si definisce una semplificazione massima e si costruisce un circuito ad hoc per una specifica funzione logica.\\
Si osservi, inoltre, che un circuito di tale tipologia pu√≤ essere ulteriormente ottimizzata semplicemente evitando di considerare gli ingressi a \(0\) e prolungando solamente gli ingressi che vengono portati a \(1\), andando cos√¨ facendo a costituire una \textbf{matrice di contatti}.\\
Mappando, quindi, a livello circuitale, la funzione di ingresso si perde la programmabilit√† e la versatilit√† del circuito, procedendo, per√≤, alla programmazione \textit{in fabbrica} del circuito specificatamente per l'impiego che se ne richiede.\\
Per eseguire tali programmazioni √® sufficiente intervenire su delle apposite tracce gi√† presenti sul circuito e bruciare solamente i fusibili per i quali non si vuole il passaggio della corrente.

\vspace{1em}
\noindent
\textbf{Osservazione}: Quando si realizza logicamente una interconnessione fra le uscite delle porte AND e gli ingressi della porta OR si commette un errore concettuale, in quanto cos√¨ facendo, se le uscite di due AND in serie sono a \(0\) e \(1\) si viene a creare una differenza di potenziale elevata e viene a crearsi un cortocircuito.

\vspace{1em}
\noindent
Nella programmazione in sola lettura di un circuito con multiplexer √® fondamentale l'impiego dei \textbf{diodi}.\\
Quando un diodo viene polarizzato direttamente si comporta come se fosse un cortocircuito, e lascia passare la corrente. Un \(1\) dalla parte dell'anodo lo polarizza direttamente e permette di avere un \(1\) anche nel catodo.\\
Quando un diodo viene polarizzato inversamente si comporta come un circuito aperto, bloccando il passaggio della corrente. Uno \(0\) dalla parte dell'anodo lo polarizza inversamente e permette di bloccare il valore logico posto in corrispondenza del catodo.\\
Tale funzionamento √® cruciale per bloccare la propagazione di uno o pi√π \(1\) logici all'interno della rete logica oggetto di studio. L'utilizzo dei diodi, infatti, permette la propagazione solamente degli \(1\) delle porte interessate, ma non interferiscono con il funzionamento degli zeri prodotti da altre porte AND che, di fatto, rimangono isolate, impedendo ogni forma di cortocircuito e garantendo il funzionamento della rete logica stessa.

\vspace{1em}
\noindent
\textbf{Osservazione}: Un fusibile, dal punto di vista pratico, √® costituito da un sottile filo di rame. Essi sono programmati appositamente per essere bruciati ad uno specifico livello di corrente, dimodoch√© l'effetto Joule sia tale da fondere il rame.\\
Ci√≤ permette di programmare in fabbrica (o dall'utente) mandando in cortocircuiti i fusibili corrispondenti alla connessione. Naturalmente, questo non permette una riprogrammazione (al limite si pu√≤ riprogrammare attraverso la fusione di ulteriori fusibili).\\

\vspace{1em}
\noindent
Naturalmente, tale operazione ha un vantaggio molto elevato. Se da un lato non permette una riprogrammazione (che non costituisce una procedura consueta), dall'altro permette di eliminare i \(2^n\) ingressi del circuito con multiplexer, con un notevole risparmio di \textit{pin}.\\
Molto probabilmente, il costo di questa seconda opzione √® inferiore rispetto a quello di un circuito ad hoc (per il quale, molto probabilmente, si dovevano anche fronteggiare degli sprechi).\\
Ci√≤, di fatto, va a costituire una prima forma di memoria, ovvero una ROM, ovvero una Read-Only Memory, in cui sono presenti \(2^n\) indirizzi di memoria e in grado di contenere \(2^n\) valori numerici, codificati mediante un certo numero di bit.

\vspace{1em}
\noindent
\textbf{Funzionamento}: Mandando in ingresso, su \(n\) bit, l'indirizzo di memoria da interrogare, solamente una porta AND produce in uscita il valore 0. Laddove vi sono dei diodi, questi vengono polarizzati inversamente e quindi si comportano come un circuito aperto, quindi non lasciano passare la corrente e il potenziale della linea va a \(0\). Tale valore logico viene poi complementato e, alla fine, viene prodotto il valore logico \(1\).\\
Alla fine, avendo inserito i diodi correttamente, avendo interrogato la cella che presenta l'indirizzo specificato in ingresso, verr√† prodotto in uscita il valore contenuto nella cella interessata codificato in opportuni bit.

\subsection{Memorie E-PROM}
A partire dagli anni \('70\) sono state introdotte delle memorie E-PROM, ovvero \textit{Erasable Programmable ROM}, che possono essere riprogrammate attraverso l'uso di raggi ultravioletti propagati attraverso un cristallo di quarzo presente sulla memoria stessa.

\subsection{Moduli per la realizzazione dell‚Äôunita logico-aritmetica}
Uno degli elementi centrali nell‚Äôarchitettura di un calcolatore e l'\textit{Unit√† Logico Aritmetica}, meglio nota con l‚Äôacronimo \textit{ALU} - che sta per \textit{Arithmetic Logic Unit}; essa lavora a stretto contatto con i registri di memoria, guidata dall'azione dell'\textit{Unit√† di Controllo}.\\
Nella ALU si realizzano tipicamente operazione su numeri interi quali somma, sottrazione, incremento, decremento, scorrimento di bit, ma si attuano anche operazioni logiche sui dati, quali AND, OR, XOR o complementazione; le ALU pi√π recenti contengono anche moduli per eseguire direttamente prodotti e moltiplicazioni.

\vspace{1em}
\noindent
\subsubsection{Il semisommatore e il sommatore completo}
Il nucleo di partenza per costruire una ALU √® il modulo \textit{semisommatore} (o \textit{Half Adder}), che realizza la somma di due bit con riporto. Di seguito viene riprodotta la tabella aritmetica della somma bit per bit con riporto, che corrisponde alla tavola di verit√† di due funzioni Booleane, una che realizza la somma \(S_i\) e una che realizza il riporto \(R_i\), per ogni coppia \(A_i\), \(B_i\) dei bit d‚Äôingresso. Si riconosce immediatamente che la \(S_i\) corrisponde a uno XOR, mentre la \(R_i\) √® un AND; di conseguenza il modulo ha la realizzazione circuitale di figura 5.29b, mentre la
figura 5.29c rappresenta il suo simbolo circuitale.\\
Se ora vogliamo effettuare la somma completa tra due numeri interi \(\textbf{A} = \left[ A_{n - 1} \hspace{0.1em} A_{n - 2} \hspace{0.1em} ... \hspace{0.1em} A_1 \hspace{0.1em} A_0 \right]\) e \(\textbf{B} = \left[ B_{n - 1} \hspace{0.1em} B_{n - 2} \hspace{0.1em} ... \hspace{0.1em} B_1 \hspace{0.1em} B_0 \right]\), espressi in notazione posizionale con \(n\) bit, √® necessario costruire una rete che accetti in ingresso \(2n\) bit e generi la somma binaria dei due,\(\textbf{S} = \left[ S_{n - 1} \hspace{0.1em} S_{n - 2} \hspace{0.1em} ... \hspace{0.1em} S_1 \hspace{0.1em} S_0 \right]\), secondo il classico procedimento di somma con riporto evidenziato in figura 5.30a. Partendo da destra si inizia a sommare \(A_0\) con \(B_0\); detto \(R_0\) il riporto, questi dovr√† essere sommato con la somma di \(A_1\) e \(B_1\), che genera \(R_1\); questo va sommato con la somma di \(A_2\) e \(B_2\) e cos√¨ via. √à evidente che il riporto \(R_{-1}\) della colonna \(A_0 || B_0\) vale \(0\) e che se l‚Äôultimo riporto, Rn 1
dovesse valere 1, siamo di fronte a una situazione di overflow, che richiede il passaggio alla notazione a virgola
mobile. Per realizzare un tale circuito bisogna modificare il semisommatore, in modo da includere il contributo
Ri 1 del riporto del passo precedente. In questo modo si ottiene il sommatore completo (o full adder), la cui
tavola di verita  e riportata in figura 5.31a. La somma di   Ai, Bi e Ri 1 vale 1 solo quando c‚Äôe un numero dispari
di 1 nella somma, ed e quindi lo XOR dei tre bit;   Ri vale 1 quando Ai e Bi sono entrambi a 1 (qualunque sia il
valore di Ri 1), oppure quando Ri 1 ‚Äú 1 e Ai   Bi ‚Äú 1. Per ricavare in modo formale l‚Äôespressione risolutiva
scriviamo i minterm di entrambe le funzioni che si ricavano dalla tavola di verita di figura 5.31a e procediamo con

\subsubsection{Calcolo della differenza mediante sommatore}
Com'√® noto, i numeri negativi, in binario, vengono rappresentati con la notazione mediante complemento a \(2\). Ci√≤ significa che la differenza \(A - B\) si realizza come \(A + (- B)\), ove \(- B\) si ottiene complementando \(B\) e sommando \(1\). Si ha, dunque
\[A - B = A + (- B) = A + \overline{B} + 1\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che la rappresentazione in binario dei numeri negativi sfrutta un difetto di ogni rappresentazione con una memoria limitata, ovvero l'\textbf{overflow}. In generale, sarebbe necessario che fosse presente un circuito che appositamente rilevi la presenza di tale overflow e provveda alla modifica della rappresentazione del risultato.\\
Anche con una base consueta quale quella decimale √® possibile operare sfruttando l'overflow, infatti
\[
    \rowcolors{1}{white}{white}
    \begin{array}{rlc}
         3 & 7 & -\\
         1 & 5 & =\\
         2 & 2 &
    \end{array}
\]
che si pu√≤ tradurre anche come
\[
    \rowcolors{1}{white}{white}
    \begin{array}{crlc}
         & 3 & 7 & +\\
         & 8 & 5 & =\\
         1 & 2 & 2 & =\\
         & 2 & 2 &
    \end{array}
\]
Ove \(85\) non √® nient'altro che \(100 - 15\) che permette di sfruttare l'overflow per ottenere una corretta rappresentazione del risultato cercato.\\
La stessa cosa si pu√≤ ripetere anche per il sistema binario, ovvero, se si deve realizzare \(5 - 2\) con \(n = 4\) bit, si rappresenta \(2\) in complemento a \(2\), ovvero \(2^4 - 2 = 14 = (1110)_2\), da cui
\[
    \rowcolors{1}{white}{white}
    \begin{array}{cccccc}
         %& 0 & 1 & 0 & 1 & +\\
         %& 1 & 1 & 1 & 0 & =\\
         %1 & 0 & 0 & 1 & 1 & =
         %& & 0 & 0 & 1 & 1
    \end{array}
\]

\newpage
\begin{center}
    9 Novembre 2021
\end{center}

\subsection{Riassunto}
Impiegando un multiplexer √® possibile costruire qualunque funzione booleana. Inoltre, tale dispositivo permette una grandissima versatilit√†, in quanto cambiando i valori di ingresso √® possibile costruire tutte le funzioni booleane a \(n\) variabili, ovvero \(2^{2^n}\).\\
Inoltre, i multiplexer vengono realizzati su larga scala e quindi, alla fine, il costo di una rete logica di questo tipo √® inferiore rispetto ad una rete logica costituita ad hoc.\\
Naturalmente, poi, si osserva che gli ingressi a \(0\) non √® conveniente che siano considerati, in quanto sicuramente porteranno a \(0\) l'uscita. Quindi gli unici piedini di ingresso che devono essere prolungati sono gli \(1\), i quali vengono direttamente costruiti internamente al circuito.\\
Un'altra significativa ottimizzazione prevederebbe l'eliminazione di una porta OR con pi√π ingressi, ma impiegando una sola porta OR con un solo ingresso, dato dall'unione di tutte le uscite delle porte AND. Ma ci√≤ √® logicamente corretto, ma fisicamente erroneo, in quando se due uscite delle AND si trovano a potenziale diverso si viene a creare un cortocircuito, che pu√≤ essere risolto con la presenza di un diodo per ciascuna uscita delle porte AND, che permette di propagare la corrente in un solo senso.\\
Tale approccio consente una programmazione in fabbrica della rete circuitale, la quale presenta una matrice di contatti costituita da una rete di tracce che devono essere bruciate a seconda delle proprie esigenze.\\
Ci√≤ permette di eliminare i \(2^n\) piedini di ingresso, in quanto la rete non viene pi√π programmata dall'esterno, ma solamente dall'interno. Si √® di fatto costituita una memoria ROM, la quale pu√≤ essere interrogata semplicemente fornendo in ingresso l'indirizzo della cella di memoria di cui si vuole sapere il contenuto.

\vspace{1em}
\noindent
L'Unit√† Logico Aritmetica √® il cuore del funzionamento di un calcolatore, il quale consente di effettuare qualsiasi operazione aritmetica, permettendo anche di controllare la presenza di \textbf{overflow}, ovvero il fenomeno che si verifica quando un'operazione produce un valore che eccede la capacit√† di rappresentazione della struttura aritmetica, il valore risultante √® errato.\\
Naturalmente √® noto che la somma tra due valori binari si pu√≤ realizzare con uno XOR, mentre il riporto di pu√≤ realizzare con un semplice AND. Questo dispositivo costituisce un semisommatore o \textit{half-adder}, che posto in serie con un altro semisommatore permette di realizzare il sommatore completo o \textit{full-adder}.\\
Naturalmente, in questo caso, si rinuncia ad una minimizzazione del circuito, ma ad una ottimizzazione del circuito con i dispositivi gi√† noti.

\vspace{1em}
\noindent
Naturalmente, il sommatore consente di eseguire delle somme, ma per eseguire delle differenze √® fondamentale comprendere la modalit√† di rappresentazione binaria dei numeri negativi in complemento a \(2\), la quale consente di centrare in \(0\) l'intervallo \([0, 2^{n} - 1]\) costituito da tutti i valori rappresentabili con \(n\) bit, in modo tale da rappresentare anche i valori negativi.\\
Tale rappresentazione risulta essere geniale, in quanto consente di sfruttare un difetto della rappresentazione binaria, ovvero l'\textbf{overflow} per rappresentare anche i numeri negativi, ed eseguire, quindi, le differenze.\\
Ci√≤ consente di rappresentare correttamente tutti i valori da \([-2^{n - 1}, 2^{n - 1} - 1]\); se si eccede tale intervallo, naturalmente, si ottiene un errore.\\
Per rappresentare un numero binario in complemento a \(2\) sar√† necessario complementare il valore binario e poi sommarci \(1\). Questo, in quanto, l'operazione di complemento propriamente detta sarebbe
\[-x = 2^n - x\]
ma osservando che
\[x + \overline{x} = 2^n - 1 \rightarrow \overline{x} + 1= 2^n - x\]
per cui il numero negativo \(-x\) si ottiene complementando \(x\) e aggiungendovi \(1\).\\

\vspace{1em}
\noindent
Le tre porte di sinistra servono invece per dare un segnale di allarme quando si √® in presenza di overflow; infatti dalla tavola si pu√≤ osservare che tale condizione si realizza quando si verificano le seguenti condizioni:
\begin{itemize}
    \item quando si sommano due numeri negativi (cio√® con \(1\) nella prima posizione) e il risultato √®, invece, positivo (con \(0\) nella prima posizione);
    \item quando si sommano due numeri positivi (con \(0\) nella prima posizione) e il risultato √®, invece, negativo (con \(1\) nella prima posizione).
\end{itemize}
La prima delle due condizioni si ha con \(A_{n - 1} = 1, B_{n - 1} = 1, S_{n - 1} = 0\), e quando si realizza fornisce un uscita \(1\) nella porta AND di sinistra; la seconda condizione si ha con \(A_{n - 1} = 0, B_{n - 1} = 0, S_{n - 1} = 1\), e fornisce un uscita 1 nella porta AND di destra. La porta OR raccoglie dunque l‚Äôunione logica dei due eventi.\\
Il segnale di allarme viene usato per commutare nella rappresentazione a virgola mobile. In figura 5.34a viene illustrato il simbolo schematico della ALU descritta dalla rete 5.32. Con una piccola modifica della circuiteria √® possibile fare in modo da realizzare, oltre alla somma e alla differenza tra \(A\) e \(B\), anche l‚ÄôAND e l‚ÄôOR tra i due ed eventuali altre operazioni logiche; lo schema di figura 5.34b mostra una ALU completa, nella quale i comandi \(C_A\), \(C_B\), \(R_{-1}\) e tutti gli altri per attivare le varie operazioni logiche sono rappresentati con la notazione \(Com_1, Com_2, ..., Com_n\).

\newpage
\section{Circuiti sequenziali}
I circuiti considerati fino a questo punto sono i circuiti combinatori, nei quali in ogni istante la configurazione di una generica variabile di uscita \(y_i\) dipende unicamente dal valore assunto dalle variabili d‚Äôingresso \(x_1, x_2, ..., x_n\), secondo la funzione Booleana \(y_i = f_i(x_1, x_2, ..., x_n)\), con \(1 \leq i \leq m\).\\
Il modello generale di un circuito combinatorio e illustrato di seguito, in cui si suppone che che le variabili in ingresso vengono immediatamente propagate in uscita opportunamente processate. Si noti, infatti, che in esso non compare la variabile temporale, a sottolineare il fatto che i valori presi in considerazione per le \(n\) variabili di ingresso si riferiscono allo stesso istante e il comportamento della rete, se escludiamo i fenomeni transitori, e univocamente dedotto dalla tavola di verit√† che stabilisce il legame tra ciascuna \(y_i\) e le variabili d‚Äôingresso \(x_1, x_2, ..., x_n\).

% Contenitore per immagini
\begin{figure}[H]
    \centering
%        \includegraphics[scale=0.4]{img/circuiti_sequenziali/image1.png}
    \caption{Schema generale di un circuito di commutazione con \(n\) ingressi e \(m\) uscite}
    \label{fig:schema_circuito_commutazione}
\end{figure}

\noindent
Nel caso in cui in un sistema il valore delle uscite dipenda anche dalla storia passata della circuiteria che lo costituisce, ovvero dallo stato della rete, si parla di sistema o circuito sequenziale. Il sistema telefonico √® un tipico esempio di sistema sequenziale: se infatti si √® in procinto di comporre l‚Äôultima cifra di un numero telefonico, il comportamento del sistema dipender√† anche dalle cifre precedentemente selezionate; questa cifra √® l‚Äôingresso attuale del sistema e l‚Äôuscita sar√† il segnale che effettuer√† il collegamento. Ovviamente l‚Äôingresso attuale non √® il solo fattore che determina il collegamento, poich√© anche le cifre composte precedentemente sono ugualmente importanti. Anche un calcolatore elettronico e un esempio di circuito sequenziale, anzi, √® l‚Äôesempio per eccellenza; di solito in esso vengono usati in maniera sequenziale diversi sottoinsiemi che possono essere di volta in volta sequenziali o combinatori.\\
Da un punto di vista formale un circuito sequenziale e un \textbf{automa a stati finiti} \(M\), cio√® un sistema dinamico \textbf{discreto} (nella scansione del tempo e nella descrizione del suo stato) e \textbf{stazionario} (il sistema si comporta alla stessa maniera indipendentemente dall‚Äôistante di tempo in cui agisce). Esso √® caratterizzato da:
\begin{itemize}
    \item un insieme finito \(\mathbb{Q} = \{q_1, q_2, ...., q_S\}\) di stati interni;
    \item un insieme finito \(\mathbb{A} = \{a_1, a_2, ..., a_K\}\) di valori che possono essere assunti dalle variabili d‚Äôingresso \(\textbf{x} = \{x_1, x_2, ..., x_n\}\);
    \item un insieme finito \(\mathbb{B} = \{b_1, b_2, ..., b_D\}\) di valori che possono essere assunti dalle variabili di uscita \(\textbf{y} = \{y_1, y_2, ..., y_m\}\);
    \item un insieme di regole, detto \textit{mappa di transizione \(\tau\)}, che specifica lo stato \(q*\) raggiunto dalla macchina a partire dallo stato \(q\) per effetto dell‚Äôingresso \(\textbf{x}\);
    \item un insieme di regole, detto \textit{mappa delle uscite \(\mathbb{U}\)}, che specifica il valore \(\textbf{y*}\) assunto dalle variabili di uscita \(\{y_1, y_2, ..., y_m\}\) per effetto dell'ingresso \textbf{x} applicato allo stato q.
\end{itemize}

\vspace{1em}
\noindent
La macchina sequenziale e pertanto definita dai cinque insiemi citati:
\[M = \left(\mathbb{Q}, \mathbb{A}, \mathbb{B}, \tau, \mathbb{U} \right)\]
Tanto per fare un breve esempio si consideri la seguente tabella

\subsection{Moduli sequenziali asincroni}
Nei sistemi sequenziali introdotti in precedenza, l‚Äôinformazione sulla storia passata del circuito, ovvero il valore acquisito dalla variabile di stato Q, deve essere memorizzato su un qualche supporto. Si possono
avere diversi tipi di dispositivi di memorizzazione, ma uno dei pi√π usati √® il cosiddetto flip-flop, ovvero un circuito \textbf{bi-stabile}.\\
In figura seguente viene illustrato il flip-flop gi√† introdotto nella figura 2.26, nel quale l‚Äôuscita di un transistor in interdizione viene connessa con l‚Äôingresso di un transistor in conduzione. Sono transistor ad emettitore comune, in quanto l'emettitore viene posto a massa.\\
Il circuito che si ottiene e bistabile, nel senso che esso pu√≤ stare indifferentemente e stabilmente in uno o nell'altro dei due stati rappresentati in figura 6.3a e 6.3b. Il funzionamento e basato sul fatto che, quando il transistor di sinistra √® interdetto (non passa corrente nel circuito di collettore), allora la sua tensione di collettore e alta (\(v = 2,6 V\)); ci√≤ polarizza la base del transistor di destra, che entra in
piena conduzione, facendo collassare a un valore basso (v ‚Ä† 0, 4 V) la sua tensione di uscita (figura 6.3a), che
corrisponde a uno 0 logico. I ruoli dei due transistor si scambiano quanto la tensione di collettore del transistor di
destra viene portata (con un impulso) a un valore (v ¬∞ 2, 6 V) (figura 6.3b). Dal funzionamento del circuito risulta
evidente che esso costituisce un elemento di memoria di 1 bit; infatti si puo decidere che l‚Äôuscita del collettore
di uno dei due transistor rappresenti la variabile logica il cui valore vogliamo memorizzare; scegliendo p.es. il
transistor di destra, se vogliamo memorizzare 1 dobbiamo mandare lo stesso transistor in interdizione; per lo 0
dobbiamo mandarlo in conduzione (in una logica positiva).

\vspace{1em}
\noindent
\textbf{Osservazione}: Tale circuito, anche se perfettamente funzionante, in realt√† non viene impiegato, in quanto non √® determinabile a priori quale configurazione il sistema raggiunger√† quando viene data tensione al circuito, a causa di microscopiche differenze tra le resistenze di carico e dei transistor stessi.\\
Naturalmente il comportamento di ciascun transistor dipende anche dalle uscite dei due transistor, in quanto in uno dei due stati ciascun transistor si trova in uno stato di \textbf{minimo locale energetico} che, per√≤, pu√≤ essere condizionato dalla variazione di tensione dei collettori dei due transistor stessi.

\vspace{1em}
\subsection{Il Flip-Flop Set-Reset - FFSR}
Anche se perfettamente funzionante, questa realizzazione non viene usata nella pratica per memorizzare bit, poich√© si preferisce sempre ricorrere alle porte logiche, che costituiscono le unit√† elementari di qualunque circuito logico. Il vantaggio di tale approccio consiste nel fatto che, stando all‚Äôinterno di una certa famiglia logica, tutti i segnali di comando e i livelli di tensione sono uniformati per l‚Äôintero circuito; possiamo cos√¨ aggiungere singole unita funzionali senza preoccuparci di uniformare i livelli di tensione, poich√© sono gi√† standardizzati all‚Äôinterno della famiglia. Mostreremo allora le due realizzazioni principali del cosiddetto Flip-Flop Set-Reset (FFSR), basate rispettivamente sulle porte NOR e sulle porte NAND.

\vspace{1em}
\noindent
\subsubsection{Latch di NOR}
La figura 6.4 illustra un flip-flop realizzato con due porte NOR; in gergo viene anche chiamato \textbf{Latch di NOR}. La prima cosa che balza all‚Äôocchio √® il fatto che entrambe le uscite \(X\) e \(Y\) sono riportate all'ingresso; questo lascia presagire che il valore assunto dalle variabili di uscita dipenda anche dalle uscite stesse. Se si impostano le equazioni del sistema otteniamo che conferma la nostra previsione. Nonostante l‚Äôequazione (6.1) sia impeccabile, non ci rende conto chiaramente
del comportamento di questa semplice rete. La cosa migliore da fare e allora quella di fissare i valori di \(S, R, X\) e \(Y\) in tutti i modi possibili e vedere quali quaterne sono compatibili con i vincoli imposti dalle equazioni 6.1.\\
Nella figura 6.5a vengono riportate tutte le possibili combinazioni per \(R, S, X\) e \(Y\); quelle in rosso non soddisfano l‚Äôequazione 6.1, perche \(X \neq \overline{R} \cdot (S + X)\) oppure \(Y \neq \overline{S + X}\); queste configurazioni non sono stabili.\\
Nella successiva figura 6.5b si riportano invece i soli stati stabili, per semplicit√† di lettura. Si osservi che, a parte il caso in cui \(R = S = 1\), che escludiamo per i motivi che vedremo nel seguito, in tutte le altre combinazioni lecite si ha sempre \(X = \overline{Y}\) , cio√® \(X\) e \(Y\) sono l‚Äôuno complementare dell'altro.\\
Partiamo ora dalla condizione R ‚Äú S ‚Äú 0; dalla tabella 6.5b osserviamo che ci sono due stati stabili possibili, uno
con X ‚Äú 0, Y ‚Äú 1 e l‚Äôaltro con X ‚Äú 1, Y ‚Äú 0; supponiamo di essere nel secondo, cioe  X ‚Äú 1, Y ‚Äú 0, cos ƒ± come
evidenziato in figura 6.6a. Supponiamo ora di portare l‚Äôingresso R da 0 a 1 nell‚Äôistante t1; quando cio avviene,
l‚Äôuscita della porta 1 commuta a X ‚Äú 0 con un certo ritardo   , legato ai tempi di commutazione dei transistor della
porta. Il nuovo segnale X ‚Äú 0 alimenta l‚Äôingresso della porta 2, facendo commutare Y a 1 con un ritardo pari a 2  .
Se ora riportiamo R a 0 (si veda figura 6.6b), X e Y rimangono nella stessa configurazione acquisita, cioe  X ‚Äú 0
e Y ‚Äú 1, poiche essa   e stabile rispetto a   R ‚Äú S ‚Äú 0, a norma della tabella 6.5b. Riportando ora R nuovamente a
1, non cambia comunque nulla, perche con   X ‚Äú 0 e Y ‚Äú 1, R e S possono stare stabilmente in ciascuno dei due
stati R ‚Äú S ‚Äú 0 oppure R ‚Äú 1, S ‚Äú 0. Quello che e successo   e che inviando un impulso sull‚Äôingresso   R, che
viene chiamato impulso di Reset, l‚Äôingresso X va (o permane) a 0.

\newpage
\begin{center}
    10 Novembre 2021
\end{center}

\subsection{Riassunto}
La costruzione di un semisommatore √® molto semplice, in quanto prevede di costruire la tabella di verit√† della somma di due valori binari, che si traduce semplicemente in una porta XOR e del riporto della somma che √®, appunto, una porta AND.\\
Il sommatore completo, invece, √® dato da due half-adder in serie. Ci√≤ giustifica la presenza di tre input, anzich√© due, in quanto √® necessario tenere conto anche del riporto della somma precedente.\\
Tuttavia, tale approccio, pur essendo significativamente valido, non tiene conto dell'eventualit√† di un overflow, cos√¨ come non prevede la presenza del calcolo di differenze.\\
Per risolvere tale problema, √® necessario comprendere la rappresentazione a complemento a \(2\) dei numeri binari negativi, ovvero
\[-x = \overline{x} + 1\]
Attraverso tale approccio si √® in grado di eseguire la differenza, prevedendo la presenza, nel sommatore, di un pin che permette la complementazione di \(B\) e l'azzeramento di \(A\), anche se si sarebbe potuto procedere anche in modo opposto, ma comunque perfettamente analogo.\\
Il controllo dell'overflow, a cui si faceva riferimento in precedenza, √® sufficiente prevedere due casistiche, ovvero
\begin{itemize}
    \item la somma di due numeri negativi (con \(1\) come primo bit) che produce un valore positivo (con \(0\) come primo bit).

    \item la somma di due numeri positivi (con \(0\) come primo bit) che produce un valore negativo (con \(1\) come primo bit).
\end{itemize}
eventualit√† che si possono rilevare grazie a due porte AND, le cui uscite costituiranno gli ingressi di una porta OR che porta il segnale.\\
Di fatto, in questo modo, si √® costruita una unit√† logico aritmetica, che viene rappresentata specificatamente con il simbolo seguente

% Contenitore per immagini
\begin{figure}[H]
    \centering
%        \includegraphics[scale=0.4]{img/circuiti_combinatori/image22.png}
    \caption{ALU}
    \label{fig:alu}
\end{figure}

\noindent
Tuttavia, i circuiti combinatori non sono gli unici dispositivi che vengono considerati. Essi, infatti, producono un risultato in uscita che dipende esclusivamente dalla configurazione degli ingressi, mentre nulla influenza lo stato interno del circuito.\\
I circuiti sequenziali, invece, vengono influenzati dallo stato interno del sistema, che pu√≤ essere concepito come un automa a stati finiti, per cui l'ossatura strutturale dei circuiti sequenziali √® data dai circuiti sequenziali, in quanto sono fondamentali anche gli ingressi, ma prevedendo anche una componente di retroazione che ne influenza lo stato.\\
Il circuito sequenziale fondamentale √® il \textit{flip-flop}, che pu√≤ essere rappresentato dalla configurazione dei transistor seguenti, perfettamente bistabile, ovvero in grado di trovarsi equivalentemente e stabilmente su ciascuna delle \(2\) configurazioni possibili.

% Contenitore per immagini
\begin{figure}[H]
    \centering
    %\subfloat[\parbox{\linewidth}{Il transistor di sinistra del \textit{flip-flop} √® interdetto; ci√≤ porta conduzione il transistor di destra, che fornisce uscita logica \(0\)} ]{{\includegraphics[width=0.45 \textwidth]{img/circuiti_sequenziali/image3.png} }}%
    \qquad
    %\subfloat[\parbox{\linewidth}{ Il transistor di sinistra del \textit{flip-flop} √® in conduzione; ci√≤ porta in interdizione il transistor di destra, che fornisce uscita logica \(1\)} 2]{{\includegraphics[width=0.45 \textwidth]{img/circuiti_sequenziali/image4.png} }}%
    \label{fig:flip-flop}
\end{figure}

\noindent
Tale circuito, per quanto costituisca un vero e proprio dispositivo di memoria, non viene utilizzato, in quanto quando viene fornita tensione non √® noto su quale stato si andrebbe a posizionare. Inoltre, per cambiare stato, bisognerebbe forza la base di un transistor per comandare il collettore dell'altro transistor, il quale, tuttavia, √® collegata al collettore del transistor considerato in principio.\\
Per questo tale dispositivo costituisce unicamente un oscillatore \(RC\).

\vspace{1em}
\noindent
\textbf{Latch di NOR}\\\\
Il Latch di NOR √® un classico dispositivo a retroazione, in cui i valori delle uscite non possono essere determinate algebricamente, in quanto dipendono anche dalle uscite.\\
Una volta ottenute le equazioni delle uscite, che sono influenzate da loro stesse, bisogna costruire una tabella con \(2^4\) entrate e verificare per quali combinazioni di ingressi e uscite del Latch di NOR risultano essere compatibili con i vincoli imposti dal circuito stesso.\\
Pertanto, la tabella \(2^4\) si traduce in una tabella a \(5\) entrate, anche se l'ultima non viene prevista nel funzionamento del dispositivo, in quanto √® l'unica che non prevede che le uscite siano \(X = X\) e \(Y = \overline{X}\). Inoltre, fornendo il valore \(1\) logico su entrambi gli ingressi, il circuito ottenuto non √® noto su quale configurazione si andr√† a posizionare, a causa di piccole variazioni di costruzione dei dispositivi.\\
Studiando i diversi stati si ottiene il seguente schema, ottenuto analizzando la variazione di \(R\) da \(0\) a \(1\) e da \(1\) a \(0\).

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{PP}
    {
        % Contenitore per immagini
        \begin{figure}[H]
            \centering
                %\includegraphics[scale=0.4]{img/circuiti_sequenziali/image10.png}
            \caption{Funzionamento di \textit{flip-flop}}
            \label{fig:flip-flop}
        \end{figure}
    }
    &
    {

    }
    \end{tabularx}
    \caption{Reset del \textit{flip-flop}}
    \label{tab:reset}
\end{table}

\vspace{1em}
\noindent
\textbf{Osservazione}: Tuttavia, per comprendere il funzionamento del sistema, √® necessario comprendere anche il suo comportamento tendendo presente anche lo stato precedente del circuito, come illustrato nella seguente tabella:


Di seguito il funzionamento: Con il vincolo che uno dei due input \(R\) o \(S\) deve essere uguale a \(0\), ovvero \(R \cdot S\), fornendo un impulso di \textit{reset} \(X\) va a \(0\), mentre fornendo un impulso di set \(X\) va a \(1\). Attraverso la mappa di Karnaugh si ottiene la funzione
\[X = S + x \cdot \overline{R}\]
Si √® detto che non si tollerano due ingressi contemporaneamente a \(1\), in quanto
\begin{itemize}
    \item ambedue le uscite sarebbero a \(0\), violando la condizione base di funzionamento di un \textit{flip-flop}, secondo la quale le due uscite devono essere sempre complementari.

    \item Se ambedue gli ingressi tornassero a \(0\) al medesimo istante, lo stato in cui il \textit{flip-flop} si porterebbe non sarebbe prevedibile e al limite potrebbe realizzarsi una condizione di oscillazione.
\end{itemize}
Con il vincolo \(R \cdot S = 0\), il \textit{flip-flop RS} diventa un dispositivo di memorizzazione affidabile.

\subsection{Latch di NAND}
Analogamente a quanto visto per il \textbf{Latch di NOR}, si pu√≤ procedere per costruire un \textbf{Latch di NAND} che sar√† il \textbf{corrispettivo duale} di quanto visto in precedenza.\\
Infatti, la configurazione \(R\) e \(S\) uguale a \(0\) non √® ammissibile per il sistema, mentre tutti gli altri stati prevedono un comportamento esattamente identico. Pertanto

Funzionamento: Con il vincolo che \(R + S = 1\), con un impulso \(0\) su \(S\) porta l'uscita \(X\) a \(0\), mentre un impulso a \(0\) su R riporta l'uscita \(X\) a \(1\).

\vspace{1em}
\noindent
\textbf{Osservazione}: Naturalmente tali dispositivi funzionano in modo perfettamente identico, solamente che i segnali di controllo dovranno essere a \(1\) per il NOR, mentre a \(0\) in NAND. Entrambi, per√≤, funzionano in modo \textbf{asincrono}: √® noto che, nei calcolatori, vi √® un clock interno che controlla il funzionamento del sistema, per cui costituisce un sistema sincrono, pi√π facilmente controllabile, ove le variazioni del sistema possono avvenire solamente in specifici istanti di clock, cosa che non accade con i \textit{flip-flop}, ove le variazioni degli ingressi possono avvenire in qualsiasi istante. Ci√≤ costituirebbe un problema, in quanto le variazioni degli ingressi potrebbero verificarsi mentre il segnale non √® ancora stato propagato all'interno del circuito stesso.

\subsection{\textit{Flip-Flop} SR sincrono}
Si distinguono, in generale, due tipi di segnali
\begin{itemize}
    \item \textit{Impulso}: segnale che normalmente si mantiene ad un livello, usualmente \(0\), e va all'altro livello solamente per intervalli di tempo estremamente brevi;

    \item A \textit{livelli}: segnale che pu√≤ rimanere sia a \(0\) che a \(1\) per periodi di tempo indefiniti e comunque molto lunghi se paragonati alla durata di un impulso.
\end{itemize}
Si ottiene, di fatto, il seguente \textit{flip-flop SR sincrono}, ovvero un dispositivo che funziona come \textit{flip-flop SR} solamente in corrispondenza degli istanti di clock.

\subsection{\textit{Flip-Flop} JK}
Per arginare l'impossibilit√† di gestire gli ingressi di \(R\) e \(S\) entrambi a \(1\) √® stato ideato il \textit{Flip-Flop} JK, che prevede che
\begin{itemize}
    \item Quando (K = J = 1), se \(x = 0\), allora \(X = 1\).
    \item Quando \(K = J = 1\), se \(x = 1\), allora \(X = 0\)
\end{itemize}
Ovvero l'uscita deve essere complementata a seconda dello stato precedente. Naturalmente, in questo caso, \(S = J\), mentre \(R = K\). Si ottiene, quindi
\[X = \overline{x} \cdot X + x \cdot \overline{K}\]
Si ottiene, pertanto, che
\begin{itemize}
    \item Quando \(x = 1\), si abilita la sola porta AND del \textit{reset K}
    \item Quando \(x = 0\), si abilita la sola porta AND del \textit{set J}
    \item Se entrambi \(J\) e \(K\) sono a \(1\), \(x = 1\) forza un \textit{reset}, mentre \(x = 0\) forza un \textit{set}.
\end{itemize}

\subsection{Flip-Flop di tipo T}
Nel \textit{flip-flop} T, ove \(T\) sta per \textit{Toggle}, mentre il \textit{clock} √® il solo segnale d'ingresso. Invece, tale dispositivo, funziona in modo tale che, quando \(T = 1\), allora l'uscita cambia stato ad ogni istante di clock, mentre se \(T = 0\) ci√≤ non accade. Un possibile impiego di tale dispositivo permette di dimezzare la frequenza di clock del sistema stessa.

\subsection{\textit{Flip-Flop} di tipo D}
Nel \textit{flip-flop} D, ove \(D\) sta per delay, l'uscita dopo un impulso di \textit{clock} √® uguale al valore presente all'ingresso \(D\) all'istante di clock. Infatti si ottiene che
\[X = \overline{x}D + x \overline{D}x\]

\subsection{Registri e contatori}
I flip-flop costituiscono la circuiteria di base per la memorizzazione di singoli bit in formato elettronico. A partire da essi si possono costruire unita per la memorizzazione di blocchi di \(m\) bit denominati registri; la figura mostra un esempio in tal senso, nel quale si costruisce un registro di \(m\) celle di memoria a partire da \(m\) flip-flop di tipo \(D\).

% Contenitore per immagini
\begin{figure}[H]
    \centering
%        \includegraphics[scale=0.4]{img/circuiti_sequenziali/image10.png}
    \caption{Registro di memoria da \(m\)-bit}
    \label{fig:registro_di_memoria_da_m_bit}
\end{figure}

\noindent
Gli stessi \(m\) flip-flop di tipo \(D\) possono essere organizzati per realizzare i registri a scorrimento, che sono di fondamentale importanza per i flussi informativi interni ai calcolatori. Il circuito e rappresentato in figura e il suo funzionamento e intuitivo: a ogni istante di tempo il contenuto del registro j-esimo si sposta nel registro \((j - 1)\)-esimo e si rende disponibile per l‚Äôuscita, che rende possibile, sotto opportune condizioni e attraverso una retroazione, la generazione di sequenze pseudocasuali con un equo bilanciamento di zeri e di uni secondo la legge debole dei grandi numeri, ma vi sar√† anche una distribuzione quanto pi√π eterogenea degli zeri e degli uni relativamente alla lunghezza della sequenza considerata.\\
Viene illustrato di seguito:

% Contenitore per immagini
\begin{figure}[H]
    \centering
%        \includegraphics[scale=0.4]{img/circuiti_sequenziali/image11.png}
    \caption{Registro a scorrimento}
    \label{fig:registro_scorrimento}
\end{figure}

\subsection{Contatore}
Con \(m\) \textit{flip-flop} di tipo T √® possibile realizzare anche un contatore, che scandisce, una dopo l‚Äôaltra, tutte le 2m
configurazioni da 00...0 a 111...1. Per capirne il funzionamento facciamo riferimento al contatore a 2 bit di figura
6.18, partendo dalla configurazione 00. Il flip-flop di sinistra ha sempre J ‚Äú K ‚Äú 1, e in corrispondenza del primo


\newpage
\begin{center}
    15 Novembre 2021
\end{center}
\subsection{Riassunto}
I circuiti sequenziali si distinguono dai circuiti combinatori in quanto √® presente una retroazione tra ingresso e uscita, rappresentabile tramite il concetto di automa a stati finiti.\\
Con un circuito realizzato attraverso due transistors viene definito bistabile, ma non garantisce una affidabilit√†. Il suo principio, tuttavia, viene trasferito alle porte logiche, realizzando i latch di NOR, per il quale, esprimendo le uscite in funzione degli ingressi, si ottiene un cortocircuito logico. Realizzando le quaterne degli ingressi e delle uscite e ponendole in una tabella si rilevano \(11\) stati non stabili e non conformi ai vincoli circuitali. Solamente \(5\) sono gli stati stabili, anche se la configurazione con gli ingressi a \(1\), non da un punto di vista logico, ma dal punto di vista concettuale.\\
In questo caso, si hanno due ingressi \(R\) e \(S\): dando un impulso di \(R\) si porta la variabile di uscita \(X\) a \(0\), con un impulso \(S\) l'uscita \(X\) va a \(1\).\\
Analizzando anche, nella tabella di verit√†, lo stato precedente \(x\) si ottiene la funzione specifica,
con il vincolo che \(R \cdot S = 0\).\\
Pertanto, fintantoch√© viene alimentato, tale circuito mantiene la sua configurazione; √® un circuito bistabile in cui il cambio di variabile √® pi√π semplificato rispetto al circuito con due transistor.

\vspace{1em}
\noindent
Naturalmente, √® possibile anche realizzare un \textit{flip-flop} perfettamente equivalente, realizzato in logica duale, per cui il vincolo, in questo caso √® che
\[R + S = 1\]
Taluni dispositivi, per√≤, sono \textbf{asincroni}, ovvero in qualsiasi momento √® possibile interagire con il sistema per cambiarne lo stato. Tuttavia, i dispositivi digitali sono sincroni, ovvero cambiano stato esclusivamente in corrispondenza di un preciso istante di clock. Inoltre, √® doveroso tenere conto anche dei tempi di ritardo di propagazione del segnale nei circuiti, latenze determinate dalle capacit√† dei condensatori; anche quando ve ne sono, per√≤, sono sempre da tenere presente le cosiddette \textbf{capacit√† parassite}, ovvero le capacit√† che si vengono a creare quando delle tracce di rame a differente potenziale sono poste in prossimit√†, ma non si toccano. Tali capacit√† parassite sono ininfluente a basse frequenze, ma quando le frequenze aumentano si avr√† un'impedenza prossima allo \(0\), creando un cortocircuito, in quanto
\[Z = \frac{1}{I \cdot \omega \cdot C}\]
ove per \(Z\) √® da intendere l'impedenza. Ci√≤ potrebbe determinare anche dei fenomeni oscillatori. Ci√≤ per spiegare che quando si cambiano i valori di ingresso in una porta si otterr√† una variazione del valore di uscita dopo un certo \(\delta\); e se vi sono delle porte concatenate si dovranno sommare tutti i \(\delta\) delle porte.\\
Per tale ragione non si possono impiegare dei \textit{flip-flop} asincroni, in quanto si avrebbe un circuito estremamente instabile.

\vspace{1em}
\noindent
Per risolvere tale problema sar√† sufficiente introdurre due porte AND agli ingressi \(R\) e \(S\) che prendano in ingresso l'impulso di clock.\\
Un altro significativo \textit{flip-flop} √® il \(FFJK\), il quale permette di prendere in considerazione anche gli ingressi a \(0\) e a \(1\), per cui si prevede in ogni caso la commutazione dell'uscita (\(x = 1\) si forza un \textit{reset}, \(x = 0\) si forza un \textit{set}).\\
Collegando fra di loto i due ingressi si ottiene il \textit{flip-flop} T, per cui se \(T = 1\) si ha una continua commutazione dell'uscita, ad ogni istante di clock. Ci√≤ permette di dimezzare la frequenza del clock, e cos√¨ a cascata.\\
Il \textit{flip-flop} di tipo D, invece, permette di propagare in uscita il valore di \(D\) in ingresso.

\vspace{1em}
\noindent
\textbf{Registri}: I \textit{flip-flop} costituiscono la circuiteria di base per la memorizzazione di un singolo bit in formato elettronico e vengono realizzati attraverso i \textit{flip-flop} di tipo \(D\).\\
Vi sono anche i registri a scorrimento , costruiti concatenando \(n\) \textit{flip-flop} di tipo \(D\), dimodoch√® dopo \(n\) istanti si avr√† in uscita il primo bit inserito.\\
Naturalmente l'uscita del registro pu√≤ andare ad alimentare uno o pi√π registri in ingresso, costituendo i registri a scorrimento retroazionati, che se opportunamente configurati, si possono ottenere tutte le \(2^n - 1\) configurazioni possibili con \(n\) bit, meno la configurazione nulla, per motivazioni legate al comportamento algebrico del sistema.

\vspace{1em}
\noindent
Utilizzando i \textit{flip-flop} di tipo \(T\) si riesce ad ottenere anche un contatore. Se si hanno \(n\) \textit{flip-flop}, si riesce a contare da \(0\) fino a \(2^n - 1\), con una continua ripetizione del ciclo.
Quando si hanno \(3\) \textit{flip-flop}, si dovr√† usare una porta AND che prende in ingresso l'entrata \(X_0\) e l'uscita \(X_1\) e la cui uscita costituir√† l'ingresso del terzo \textit{flip-flop}.

\newpage
\section{Codifica}
La codifica dei segnali che servono per alimentare un computer √® fondamentale per la comprensione del funzionamento dei calcolatori. Ci√≤ √® la prima base per capire la connessione tra alto livello e basso livello di funzionamento di un computer.\\
Il calcolatore, infatti, √® costituito da supporti di natura diversa che operano sempre in logica binaria. Questo, per quello che si √® visto, deriva da una esigenza da un punto di vista pratico (per ragioni di dissipazione del sistema) e anche funzionale (in quanto la logica binaria √® retta dall'algebra booleana).\\
Inoltre, √® molto difficile che i dispositivi digitali si guastino, in quanto operano in una condizione ideale di dissipazione: quando si verifica un guasto, infatti, di solito √® di natura elettrica riguardante l'alimentazione.\\
La problematica di gestione della rappresentazione di tutte le possibili informazioni in ingresso in logica binaria non √® da sottovalutare. Infatti, le possibili informazioni in ingresso che devono essere processate da un elaboratore sono molteplici e svariate (caratteri alfanumerici, suoni, immagini, calcoli), e ciascuna deve essere opportunamente codificata attraverso una stringa di \textit{bit}.

\vspace{1em}
\subsubsection{Codifica dei caratteri}
Per poter codificare un carattere si potrebbe pensare di associare in modo univoco una stringa binaria a ogni lettera, dimodoch√© se vi sono \(k\) lettere, si dovranno impiegare \(2^{\log_2(k)}\) n-uple. Questo, naturalmente, nell'ipotesi in cui tutte le lettere siano codificate con lo stesso numero di bit; ma naturalmente si pu√≤ anche prevedere di comprimere i messaggi rappresentando le lettere pi√π frequenti con meno bit (come nel caso dell'alfabeto Morse, oppure come nei sistemi di compressione di file). In generale, vi sono quattro tipo di codifica delle stringhe:
\begin{itemize}
    \item Da blocco a blocco
    \item Da blocco a stringa di lunghezza variabile
    \item Da stringa di lunghezza variabile a blocco
    \item Da stringa di lunghezza variabile a stringa di lunghezza variabile
\end{itemize}
Se si hanno circa \(K = 111\) lettere (come in una tastiera), allora si dovranno usare
\[n \geq \log_2(k)\]
ovvero il pi√π piccolo naturale maggiore di \(\log_2(k)\), rappresentato come segue
\[n = \lceil \log_2(k) \rceil\]
che, nel caso analizzato, si traduce in
\[n = \lceil \log_2(111) \rceil = 7\]
Da questa evidenza √® nata la \textbf{tabella ASCII (American Standard Code for Information Interchanges)} che, negli anni \('60\), era sufficiente per rappresentare tutti i simboli che si impiegavano nelle tastiere dei primi computer che venivano introdotte.\\
Naturalmente, per√≤, la diffusione dei calcolatori nel mondo occidentale ha palesato la necessit√† di introdurre un nuovo standard
\[\text{ISO 8859-}n, 1 \leq n \leq 16\]
ove \(n\) rappresenta il numero di bit impiegati per la codifica dei caratteri alfanumerici. Si pervenne, ben presto, alla codifica dei caratteri attraverso lo standard \(UTF (Unicode Transformation Format)\), ben presto soppiantato dall'Unicode a \(16\) bit e poi anche da quello dell'Unicode a \(32\) bit.\\
In realt√†, vi sono anche delle sottocodifiche
\begin{itemize}
    \item UTF-8, a lunghezza variabile \(1-4\) byte
    \item UTF-16, a lunghezza variabile \(2-4\) byte
    \item UTF-32, a lunghezza costante di \(4\) byte
\end{itemize}

\vspace{1em}
\subsubsection{Codifica dei numeri}
Naturalmente i caratteri numerici possono essere impiegati sia in combinazione con i caratteri alfabetici, ma anche per eseguire dei calcoli. Naturalmente, si capisce immediatamente che i valori numerici, essendo infiniti, non potranno essere tutti rappresentati all'interno dei calcolatori, per cui se ne dar√† una rappresentazione approssimata.\\
√à noto che un valore numerico si rappresenta nella notazione posizionale come segue
\[(523)_{10} = 5 \cdot 10^2 + 2 \cdot 10^1 + 3 \cdot 10^0\]
Pi√π uin generale, si ha che
\[a_n \hspace{0.5em} a_{n - 1} \hspace{0.5em} ... \hspace{0.5em} a_1 \hspace{0.5em} a_0 = a_n \cdot b^n + a_{n - 1} \cdot b^{n - 1} + ... + a_1 \cdot b^1 + a_0 \cdot b^0\]

\vspace{1em}
\subsubsection{Conversione da base \(2\) a base \(10\)}
Per la conversione da binario a decimale √® sufficiente sommare tutte le potenze di \(2\) corrispondenti agli \(1\) logici per ottenere il valore numerico decimale cercato.

\vspace{1em}
\subsubsection{Conversione da base \(10\) a base \(2\)}
Per la conversione da decimale a binario √® sufficiente dividere il valore numerico decimale per \(2\) fino a che non si ottiene un resto \(\leq 1\) e considerare i resti di ciascuna divisione in ordine e per ottenere il valore binario sar√† sufficiente leggere tali resti dall'ultimo al primo.

\vspace{1em}
\subsection{Operazioni binarie}
Le operazioni tra valori binari (ma con qualsiasi base, in realt√†), palesano un evidente problema, quello dell'\textbf{overflow}. Tale inconveniente permette di rappresentare i numeri binari negativi in complemento a \(2\).\\
Se si operasse ponendo il bit pi√π significativo a \(1\) per rappresentare i numeri negativi e \(0\) per rappresentare i positivi, si incorrerebbe in un errore evidente nelle operazioni di calcolo.

\newpage
\begin{center}
    15 Novembre 2021
\end{center}
\subsection{Riassunto}: La codifica del mondo esterno all'interno del computer prevede una mappatura specifica per ciascuna delle specifiche informazioni  da elaborare.\\
In particolare, le modalit√† di rappresentazione dei caratteri alfabetici pu√≤ avvenire in \(4\) modalit√†, impiegando stringhe di lunghezza variabile o blocchi di lunghezza fissa. Naturalmente, per codificare \(k\) caratteri con \(n\) bit si devono impiegare
\[n = \lceil \log_2(k) \rceil\]
bit. A partire dalla tabella \textbf{ASCII} a \(7\) bit, si √® poi passati ad una codifica a \(8\) bit per poi introdurre il sistema \textbf{UNICODE}, ancora oggi impiegata.

\vspace{1em}
\noindent
Per quanto riguarda la rappresentazione dei caratteri numerici, si effettua attraverso la rappresentazione posizionale.\\
La conversione da base \(2\) a base \(10\) si ottiene in maniera immediata; mentre la conversione da base \(10\) a base \(2\) prevede semplicemente di eseguire reiteratamente la divisione per \(2\) del quoziente e tenere conto del resto.\\
La rappresentazione dei numeri binari negativi pu√≤ avvenire esclusivamente attraverso il complemento a \(2\). Il procedimento adottato nel caso binario √® il medesimo per qualsiasi base. Infatti, considerando la somma \(37 - 15\) si pu√≤ interpretare come \(37 + (100 - 15) - 100\), ovvero \(122 - 100 = 22\) che √® proprio il risultato cercato. Infatti, nell'ipotetica condizioni in cui si avessero avuto due sole posizioni per rappresentare i valori numerici, il valore \(100\) sarebbe stato automaticamente sottratto grazie al fenomeno dell'overflow.\\
In generale, per ottenere un numero in complemento a \(10\), avendo il vincolo di \(n\) celle di memoria si deve eseguire
\[comp_{10}(x) = 10^{n} - x\]
In questo modo si riesce a centrare l'intervallo \(\left[ 0 : 10^{n} - 1 \right]\) in zero. La stessa cosa vale esattamente anche nel caso binario, in cui
\[-x = \overline{x} + 1\]
questo in quanto √® noto che \(-x = 2^{n} - 1\), ma anche \(\overline{x} + x = 2^{n} - 1\), pertanto si ha che \(-x = \)\\
Un'altra rappresentazione possibile, ma oramai desueta, oltre al complemento a \(2\) si ha anche il complemento a \(1\), che prevede semplicemente di complementare la rappresentazione dei numeri positivi. Tuttavia, in questo caso, si ha una doppia rappresentazione del valore \(0\) e bisogna anche cambiare le operazioni di calcolo.\\

\vspace{1em}
\noindent
Tuttavia, anche se si √® stati in grado di rappresentare i numeri negativi, non √® possibile rappresentare tutti i numeri reali, in quanto non si hanno infiniti bit. Per arginare il problema si deve ricorrere ad un ulteriore sistema di rappresentazione, ovvero quello a \textbf{virgola mobile}.

\subsection{Rappresentazioni in \textit{floating-point}}
La rappresentazione a virgola mobile prevede di considerare una mantissa \(m\) e un esponente \(e\) che, nel caso della base decimale si ha
\[N = \pm \hspace{0.5em} m \cdot 10^{\pm e}\]
da cui si ottiene che, la rappresentazione in virgola mobile dei numeri reali √®
\[[\pm] \hspace{0.5em} [m] \hspace{0.5em} [\pm] \hspace{0.5em} [e]\]
Da cui si conviene che, assegnando \(1\) bit per il segno e i restanti alla mantissa \(m\) e all'esponente \(e\) si riesce ad avere un'ampia gamma e dinamica di rappresentazione dei numeri reali sulla retta reale, pur non riuscendo a saturare interamente la densit√† dei numeri reali.\\
Infatti, la rappresentazione esposta introduce un'approssimazione, in quanto la precisione di rappresentazione dipende strettamente dal numero di cifre significative, ovvero dal numero di bit sia della mantissa che dell'esponente.\\
Ufficialmente, la rappresentazione in virgola mobile √® stata standardizzata dalla \textbf{IEEE 754}, la quale prevede una precisa rappresentazione del valore numerico, distinto in base alla precisione, ovvero
\begin{itemize}
    \item \textit{Single-Precisione}, con \textbf{IEE 754-32} con \(23\) bit per la mantissa e \(8\) bit per l'esponente (rappresentato mediante eccesso a \(127\));
    \item \textit{Double-Precisione}, con \textbf{IEE 754-64} con \(52\) bit per la mantissa e \(11\) bit per l'esponente (rappresentato mediante eccesso a \(1023\)).
\end{itemize}

\vspace{1em}
\subsubsection{Segnali analogici}
Come √® possibile codificare un segnale analogico il quale ha infiniti valori e varia con continuit√† nel tempo. Per poter eseguire tale rappresentazione si ricorre al \textbf{campionamento} del segnale, la cui frequenza, naturalmente, deve essere la pi√π alta possibile. Naturalmente, la lettura del segnale avviene in maniera discreta e finita, in quanto non si dispone di strumenti atti ad una lettura con precisione infinita, ma anche se vi fosse, non si disporrebbe degli strumenti atti a rappresentare tale letture (se in \textit{floating-point}, per quanto appena visto, si avranno blocchetti di \(32\) o \(64\) bit).\\
Per poter ricostruire la forma d'onda di partenza con sufficiente precisione si deve avere una frequenza di campionamento sufficientemente elevata. La frequenza di campionamento, indicata con \(f_c\), √® legata strettamente alla banda (ovvero l'estensione in frequenza del segnale che si sta considerando, cos√¨ per un apparato ad alta fedelt√† si ha una banda che va da \(20 Hz\) a \(20 kHz\)) del segnale e, secondo il \textbf{teorema di Nyquist} si ha che se
\[f_c > 2B = f_N\]
si pu√≤ ricostruire il segnale senza ambiguit√†, ove \(f_N\) √® la \textbf{frequenza di Nyquist}.

\vspace{1em}
\noindent
\textbf{Osservazione}: Naturalmente, bisogna tenere presente anche gli errori di quantizzazione, ovvero l'errore di rappresentazione. Infatti, il valore del campione viene decodificato usando \(n\) bit; ci√≤ comporta un errore che diminuisce all'aumentare del numero di bit impiegati per la rappresentazione del valore campionato.\\
Il diagramma dell'errore √® un dente di sega con valore assoluto di \(1\), ma se viene centrato nella met√† del diagramma stesso si riesce a diminuire il valore assoluto a \(0.5\).

\vspace{1em}
\noindent
\textbf{Osservazione}: Da un punto di vista pratico, si ha che una \textbf{Conversione A/D} avviene dando in pasto un segnale analogico al \textbf{campionatore} il quale, successivamente, produce in uscita dei campioni che vengono dati in pasto al \textbf{quantizzatore} che produce in uscita i valori opportunamente rappresentati in binario.\\
Tali valori, opportunamente quantizzati, per essere convertiti in analogico, vengono dati in pasto a un \textbf{generatore d'impulsi} che deve essere poi seguito da un \textbf{filtro passa basso} che lascia passare solamente le frequenze pi√π basse. Questo, infatti, perch√© un impulso √® una variazione con una frequenza praticamente infinita del segnale considerato (infatti, √® come se si avesse una sinusoide con una elevata frequenza) per cui un filtro basso taglia i contributi alle elevate frequenze e si riesce a creare le connessioni per ricostruire la forma originale del segnale.\\
√à noto che i filtri passa alto e passa basso vengono realizzati con delle \textbf{celle R-C} che si comportano in modo opposto alle elevate e basse frequenze.\\
Naturalmente, tale processo palesa degli errori (errori di campionamento, di quantizzazione e del filtro passa basso).\\
Naturalmente i circuiti digitali non possono processare impulsi a frequenza arbitrariamente elevata, per cui gli impulsi campionati vengono interpretati sottoforma di \quotes{blocchetti} i quali mantengono lo stesso livello del segnale per il tempo di campionamento.

\vspace{1em}
\subsubsection{Immagini}
Per la digitalizzazione delle immagini con sostrato e modalit√† di tipo digitale √® stata la conseguente evoluzione della rappresentazione delle immagini con sostrato e modalit√† di tipo analogico.\\
Un tubo termoionico √® una sorta di tubo con dentro un'ampolla di vetro con catodo e anodo. Il filamento del catodo, costituito da ossidi, generalmente, quando viene alimentato con una certa tensione si scalda. Gli ossidi di Bario e Stronzio vengono sollecitati dall'agitazione termica, per cui si viene creare una nuvola elettronica attorno al catodo. Se l'anodo viene alimentato con una corrente positiva, allora gli elettroni vengono attirati dall'anodo e il flusso di elettroni viene ripristinata dalla batteria. Esattamente come per un diodo, si ha il flusso di elettroni solamente in senso.\\
Inoltre, se fra anodo e catodo si pone una griglia alimentato da una certa tensione negativa si viene a creare una barriera di potenziale che, a seconda della tensione di alimentazione pu√≤ essere pi√π o meno elevata che limita il flusso di elettroni. Si √® costruito, quindi, un \textbf{triodo}.\\
Ebbene, le videocamere analogiche operano con un tubo termoionico, nel quale, per√≤, vengono inserite anche delle bobine di deflessione per convogliare il fascio elettronico in un unico punto, costruendo, di fatto, un pennello elettronico.


\newpage
\begin{center}
    17 Novembre 2021
\end{center}

\subsection{Riassunto}
La rappresentazione dei numeri interi in binario si basa sulla tecnica del complemento a \(2\). I numeri reali, invece, non possono essere interamente rappresentati attraverso un calcolatore, per quanta memoria si possa impiegare. Allora si procede ad effettuare un troncamento del numero, il quale viene rappresentato con due componenti, la \textit{mantissa} e l'\textit{esponente}, ciascuno con opportuno segno. La rappresentazione a virgola mobile consente di avere un'ampia dinamica di rappresentazione, sia dei numeri grandi che di quelli piccoli.\\
√à implicito, tuttavia, che la rappresentazione in \textit{floating-point} porta con s√© un'approssimazione, tale per cui non vale pi√π la propriet√† associativa dell'addizione. Dal punto di vista della normalizzazione, si ha che lo standard \(IEEE 754\) a \(32\) bit (singola precisione) e \(64\) bit (doppia precisione).\\
Per quanto concerne la rappresentazione dei segnali analogici, ovvero segnali che variano con continuit√† nel tempo, si procede ad eseguire il campionamento, ovvero al prelievo ad intervalli regolari di campioni del segnale che, naturalmente, dovranno pur sempre essere rappresentati in modo discreto. Nyquist afferma che se la frequenza di campionamento √® almeno doppia della larghezza di banda allora si riesce a ricostruitre il segnale di partenza senza amboguit√†. Naturalmente in tal senso si dovr√† tenere presente anche dell'errore di quantizzazione, il quale viene progressivamente attenutato all'aumentare del numero di bit di rappresentazione.\\
Per la rigenerazione del segnale di partenza si impiega un generatore di impulsi e di un filtro passa basso; questo permetterebbe, dal punto di vista ideale, di ricostruire esattamente il segnale di partenza. Tuttavia, bisogna tenere presente sia dell'errore di campionamento, sia dell'errore di quantizzazione, sia dell'errore del generatore d'impulsi. Inoltre, la gestione degli impulsi a frequenza arbitrariamente elevata √® difficoltosa, si procede a mantenere il livello del segnale quantizzato per tutto l'intervallo di tempo del campionamento.\\

\vspace{1em}
\noindent
Per quanto riguarda le immagini riprodotte dal punto di vista analogico si ha un tubo a raggi catodici di emettitori di elettroni che vengono proiettati in un tubo termoionico, in cui il catodo viene alimentato con una tensione che produce una nuvola elettronica che vengono attirati verso l'anodo e vengono convogliati verso un punto attraverso delle tecniche di deflessione magnetica, attraverso, quindi, delle bobine.\\
Sullo strato esterno della telecamera analogica vengono poste delle sostanze fotoconduttive, ovvero modificano la loro luminosit√† a seconda della loro conducibilit√†. Ovvero la modulazione del pennello elettronico viene modulata dall'intensit√† di luminosit√† dell'immagine che si sta riprendendo.\\
Taluna √® una telecamera analogica, la quale rappresenta un dispositivo trasmettitore che, attraverso tecniche di modulazione di una portante (frequenza molto elevata), trasmette ad un dispositivo ricevente analogo, sempre operante a tubo catodico, in cui l'intensit√† del fascio viene modulata dall'intensit√† luminosa dell'immagine da riprodurre.\\
La tecnologia dei tubi \textbf{CRT} sono molto costosi, ingombranti e delicati (in quanto √® composto di vetro), per cui la tecnologia √® molto sofisticata, per cui cui non si riusciva ad abbattere i costi. Inoltre, essendo vuoti all'interno, esiste la possibilit√† che implodano e, inoltre, data l'elevata intensit√† del fascio elettronico, c'era la concreta possibilit√† di generare dei raggi X, molto pericolosi.

\vspace{1em}
\noindent
\textbf{Osservazione}: La combinazione dei tre colori base produce tutto lo spettro elettromagnetico del visibile. Per cui, per produrre il colore nell'immagine si dovranno avere avere tre fasci elettronici prodotti da \(3\) catodi; se ciascuno dei tre fasci va a colpire dei fosfori particolari che reagiscono alla sollecitazione dei tre fasci, per cui si ha l'effetto del colore sulla terna di fosfori che viene percepito dall'occhio umano.\\
Pertanto si hanno tre fasci (uno riservato al rosso, uno al blu e uno al verde) che vanno a colpire una cella (una terna di fosfori) che viene opportunamente sollecitata per produrre il colore desiderata.\\
Ad oggi, invece, si ricorre alla tecnologia dei cristalli liquidi. Infatti, se con il sistema analogico si aveva una continua rappresentazione dell'immagine nel tempo, dal punto di vista digitale si procede alla discretizzazione dell'immagine attraverso la tecnica della maggioranza (si dispone una griglia di pixel e se un pixel √® pi√π colorato che bianco, allora viene colorato.\\
Naturalmente √® ovvio che tanto pi√π √® fitta la griglia di pixel (ovvero tanto pi√π √® elevata la risoluzione dell'immagine, tanto maggiore sar√† la qualit√† finale dell'immagine discretizzata). Per la rappresentazione della scala di grigi si associa a ciascuna colorazione una opportuna codifica, mentre per la riproduzione dell'immagine si procede a riprodurre una differente gradazione luminosa.\\
Tanto maggiore sar√† la profondit√† di colore (ovvero i livelli di grigio) maggiore sar√† la colorazione e la qualit√† risultante dell'immagine riprodotta. La stessa cosa vale anche per i colori.\\
Per la creazione dei colori non si usa pi√π un pennello elettronico che colpisce un fosforo, ma vengono realizzati da dei dispositivi a semiconduttori, come i LED: in prima approssimazione, infatti, ciascuno dei tre colori primari viene rappresentato da un diodo LED emettitore di luce. Infatti, ciascun colore viene costruito dalla combinazione lineare dei tre colori primari, con una qualit√† di rappresentazione che dipende dal numero di bit associati a ciascun colore primario.\\
Le diverse tecnologie di rappresentazione che si sono susseguite hanno previsto, in principio \(8\) bit per pixel, associandone \(3\) al rosso e verde, mentre \(2\) al blu in quanto l'occhio umano √® meno sensibili a questo colore e pi√π sensibile rispetto al verde.\\
Il canale \(\alpha\) permette anche di modificare la rappresentazione attraverso la trasparenza delle immagini.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si capisce facilmente, per√≤, le immagini pesano molto a seconda del numero di bit scelti. Infatti, data una risoluzione di \(1280 \times 1024\) con \(32 bit/pixel\) si ha un peso di
\[1280 \cdot 1024 \cdot 32 = 5 MB\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Il numero di immagini che si possono creare con una griglia \(m \cdot n\) con solo bianco e nero si ottiene
\[2^{m \cdot n}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Il \textbf{bifenile} √® un \textbf{cristallo nematico} con una struttura elicoidale che se viene sollecitato da una luce polarizzata (ovvero una luce in cui √® stato isolato una delle due sue componenti, elettrica e magnetica) produce un colore.\\
Infatti, illuminando dal basso con una luce polarizzata un filtro polarizzatore e ponendo sopra un ulteriore filtro polarizzatore posto ortogonalmente al filtro sottostante e la luce pu√≤ uscire accompagnata: questo accade in condizione di riposo. Se al filtro viene sollecitato da un campo elettrico, allora la luce non viene pi√π accompagnata in uscita, ma viene sbarrata dal filtro polarizzatore e ci√≤ permette di creare l'immagine. Tuttavia, si necessita di una illuminazione esterna per riuscire a vedere l'immagine: sono i cosiddetti critalli liquidi passivi.\\
La tecnologia TFT, ovverosia Thin Film Transistor, si ha una illuminazione interna, sottostante, prodotta da un dispositivo a semiconduttore. Il controllo di ogni singolo pixel avviene su ogni riga e su ogni colonna e un segnale a \(20 V\) viene fatto passare per ciascuna riga. Taluno √® il segnale di attivazione che permette di attivare ciascun subpixel a seconda dello stato del gate di giascuno. Ogni singolo subpixel, infatti, contiene delle capacit√† che permettono di mantenere la corrente fino a quando non si costruisce una immagine completa. Tale tempistica √® necessaria per fare in modo che al turno successivo la tensione da \(20 V\) vada ad alimentare nuovamente i condensatori e cos√¨ via.\\
Tale tecnologia, tuttavia, continua ed essere molto costosa, in quanto gli schermi per i quali non risulta funzionante anche un solo pixel vengono scartati.

\subsection{Rappresentazione fisica dei bit}
I simboli binari hanno una loro rappresentazione fisica. Infatti, i due stati \(1/0\) devono essere equiprobabili ed interpretati come presenza/assenza di una certa grandezza fisica (come una tensione e una corrente).\\
Da un punto di vista meccanico, un bit √® rappresentato attraverso un interruttore (acceso/spento). In maniera pi√π sofisticata, un bit pu√≤ essere rappresentato anche attraverso un rel√®, che pu√≤ essere comandato a distanza. Infatti, un rel√® √® una bobina avvolta ad un nucleo ferromagnetico che quando viene sollecitata, va ad azionare o a chiudere un interruttore fisico.\\
Ad oggi i rel√® vengono utilizzati quando si necessita di azionare un grosso carico senza impiegare un interruttore standard. Infatti, quando si deve azionare un grosso carico con una molla dalla resistivit√† pi√π piccola possibile per abbassare quanto pi√π la dissipazione di corrente. Pertanto l'interruttore normale viene impiegato solamente per lasciar passare la corrente e azionare il rel√®.\\
Dal punto di vista magnetico, il bit pu√≤ essere rappresentato attraverso l'anello di ferrite, molto fragile ma capace di memorizzare un bit attraverso un mutamento dell'orientamento del campo magnetico. Si tratta, comunque, di una tecnologia poco efficiente perch√© si hanno pochi bit per \(cm^2\).
Gli Hard-Disk vengono realizzati in policarbonato su cui viene posto del materiale ferromagnetico che viene polarizzato attraverso una testina; pertanto la memorizzazione dei bit viene associata non alla tipologia di polarizzazione (nord/sud), ma al mutamento della polarizzazione dallo stato precedente a quello successivo.\\
Il bit elettrico viene rappresentato da un condensatore che, molto intuitivamente, rappresento
\begin{itemize}
    \item Il bit logico \(1\) se il condensatore √® carico.
    \item Il bit logico \(0\) se il condensatore √® scarico.
\end{itemize}
Infatti, i condensatori presentano una resistenza di dissipazione, causa del fatto che il condensatore si scarica dopo un certo tempo (la resistenza dovrebbe essere infinita per avere un tempo di scaricamento infinito). Naturalmente, quindi, per mantenere la memorizzazione del bit sul condensatore si ha che questo deve essere sempre alimentato per mantenere il suo stato.\\
Ancora un altro modo per rappresentare un bit elettronicamente √® il transistor; infatti, quando il transistor √® in interdizione rappresenta lo stato logico \(1\), lo stato logico \(0\) se in saturazione. Questo dispositivo, come il condensatore e il \textit{flip-flop}, devono essere sempre realizzati.\\
√à stato anche possibile realizzare dei CD di memorizzazione sui quali viene posto una lamina di alluminio che, all'atto di masterizzazione, vengono bruciate con un laser alcune tracce dimodoch√® queste diventino poco riflettente. Quando il CD viene letto il bit \(1\) solamente sui fronti in cui la riflessione aumenta e diminuisce, lettura eseguita attraverso una tecnologia molto complessa.\\
Tale tecnologia si √® poi evoluta passando da \(CD\) a \(DVD\) a \(HD \textbf{ } DVD\) e \(Blue \textbf{ } Ray\).

\subsubsection{Bit nelle memoria RAM}
Il bit nelle RAM statiche (SRAM) vengono realizzati con una tecnologia √® molto complessa, in cui sono contenuti \(6\) transistor che vanno a creare un \textit{flip-flop} e che garantisce tempi di risposti ridotti. Mentre la memoria RAM dinamica memorizza i propri bit attraverso un condensatore e i tempi di risposta sono molto ridotti

\subsubsection{Seriale e Parallelo}
La trasmissione dei bit pu√≤ avvenire un modo seriale, impiegando una sola linea, ma in maniera molto lenta, mentre in modo parallelo si usano pi√π linee di trasmissione, ma con tempi di trasmissione molto ridotti.

\newpage
\begin{center}
    22 Novembre 2021
\end{center}
\subsection{Riassunto}
La codifica delle immagini, ad oggi, √® totalmente digitale, mentre in passato si eseguivano delle scansioni esclusivamente analogiche. Per la realizzazione dei colori ci si basa sulla terna dei colori primari \textbf{RGB}, per cui, nei tubi catodici il colore viene riprodotto andando a sollecitare attraverso dei fasci elettronici ciascuna delle celle contenente un colore primario che, viste da lontano, riproducevano correttamente l'immagine colorata.\\
Dal punto di vista digitale, l'immagine viene scansionata attraverso una rete \(m \times n\) di pixel, ciascuno dei quali pu√≤ essere colorato (prima attraverso una scala di grigio, poi attraverso una opportuna codifica dei diversi colori dell'iride). Naturalmente, tanto pi√π sono i bit per la descrizione di un pixel, tanto pi√π raffinata sar√† la riproduzione dell'immagine. Si capisce immediatamente, naturalmente, che le immagini sono molto pesanti in termini di memoria, tanto pi√π pesanti a seconda del tipo di standard impiegati.\\
Gli schermi, ad oggi, sono realizzate attraverso la tecnologia a cristalli liquidi sfruttando delle particolari propriet√† di alcuni composti organici, quali il \textbf{bifenile}, ottenendo una matrice a cristalli liquidi passiva, oppure attiva.\\
La rappresentazione meccanica di un bit pu√≤ essere ricondotta ad un interruttore, mentre dal punto di vista elettromeccanico si possono impiegare i rel√®. I bit, negli anni \('60\), venivano memorizzato in degli anelli di ferrite, le quali potevano essere polarizzate in modo diretto o inverso, ma con un rapporto di memorizzazione e dimensione assolutamente ridicola.\\
Gli Hard-Disk, invece, sono ancora oggi utilizzati e funzionando attraverso una variazione di intensit√† ferromagnetica. Le capacit√†, inoltre, possono rappresentare un bit, associando lo stato carico come stato alto, mentre se il condensatore √® scarico, si ha lo \(0\) (questa tipologia di memoria √® naturalmente volatile, in quanto il circuito deve essere sempre alimentata).\\
Il transistor, in modo perfettamente analogo, consente di memorizzare i bit associando un valore alla condizione di saturazione e interdizione. Anche i \textit{flip-flop} possono memorizzare dei bit, dando un colpo di set si porta l'uscita a \(1\), mentre si ottiene lo stato logico \(0\) dando un colpo di reset.\\
I dispositivi CD sono stati introdotti relativamente di recente, e attraverso una testina laser √® possibile leggere il disco, riuscendo a distinguere i bit \(1\) e \(0\) attraverso la differenza tra zone bruciate e zone luminose del disco di policarbonato su cui sono stati eseguite delle tracce attraverso un fascio laser.\\
Le memorie RAM possono essere statiche (costose e molto efficienti) o dinamiche (poco costose, ma molto lente, specialmente nei temi di risposta). I bit, su una linea, possono essere trasmessi in serie, impiegando una sola linea, ma uno alla volta, oppure in parallelo, impiegando pi√π linee di trasmissione, ma i bit arrivano a destinazione tutti insieme.\\
Per la trasmissione dei segnali su una linea, i segnali analogici possono essere trasmessi codificando un valore con l'ampiezza del segnale, trasmesso ad intervalli regolari, oppure attraverso un segnale continuo, mentre attraverso un segnale digitale si codificano attraverso i comuni bit.

\newpage
\section{Rivoluzione microelettronica}
La tecnologia odierna, cos√¨ rivoluzionaria, √® stata ottenuta attraverso un'evoluzione lunga e progressiva di tecnologie precedenti.\\
La prima fase della rivoluzione microelettronica riguarda l'introduzione di un primo componente attivo (che viene usata per amplificare il segnale, a differenza dei componenti passivi, come le resistenze), ovvero il \textbf{diodo di Fleming} (\(1904\)): un tubo termoionico √® costituito da un anodo e un catodo, il quale, quando viene alimentato, produce una nuvola elettronica che viene attirata dall'anodo quando questo viene alimentato e assume potenziale positivo. Naturalmente, tale circuito, chiuso da una batteria, √® un dispositivo unidirezionale, in quanto gli elettroni transitano dal catodo all'anodo, il quale pu√≤ essere impiegato per \textbf{raddrizzare la corrente} alternata, facendola divenire corrente continua.\\
Il \textbf{diodo di Fleming}, tuttavia, non √® ancora un dispositivo attivo, ma lo sarebbe diventato due anni dopo, nel \((1906\)), con l'introduzione del \textbf{triodo di de Forest}, il quale era un dispositivo che aggiungeva al diodo di Fleming una griglia (una spirale, concretamente) che si trova tra il catodo e l'anodo: in questo modo, gli elettroni che transitano dl catodo all'anodo devono prima passare attraverso la griglia, la quale pu√≤ essere polarizzata opportunamente per amplificare o attenuare un segnale. Il triodo pu√≤ anche operare in una condizione di saturazione o interdizione.\\
In principio, un triodo, ovvero un tubo termoionico, veniva associato ad un singolo bit, ma il dispositivo aveva una dimensione di circa \(7-8\) centimetri.\\
Successivamente, negli anni \('80\), i dispositivi venivano realizzato non pi√π in vetro, ma attraverso la bachelite (il primo isolante realizzato in maniera sintetica). Inoltre, bisogna ricordare che i tubi non avevano vita eterna, per cui nel tempo perdevano le loro propriet√† e i filamenti interni si consumavano, per cui dovevano essere sostituiti.\\
Nel tempo, per√≤, si √® cercato di miniaturizzare tali dispositivi, ma anche tale processo venne limitato a causa delle \textbf{scariche disruttive}, ovvero delle scariche che si vengono a determinare quando due elettrodi vengono posti troppo vicini fra di loro. Di fatto, se non fossero stati introdotti i transistor non si avrebbe avuto la possibilit√† di evolvere tecnologico.

\subsection{Seconda fase: Transistor}
L'introduzione dei \textbf{transistor} avvenne nel (\(1948\)), costituito dapprima attraverso un cristallo di \textbf{germanio}, che si trova sullo stesso gruppo del silicio nella tavola periodica degli elementi di Mendelehev. Naturalmente le dimensioni erano molto ridotte, ma ancora considerevoli a causa della struttura circostante il cristallo di germanio necessaria per la trasmissione del segnale. In ogni caso, per√≤, la dissipazione e la tensione sono molto ridotte e la durata √® eterna, dell'ordine di \(100.000\) ore.\\
A partire dagli anni \('70\) i transistor vengono realizzati con dei contenitori (\textit{case}) di metallo e con un cristallo di silicio.

\subsection{Circuiti integrati}
Con un cristallo di silicio √® possibile realizzare un transistor, mentre introducendo dei cristalli di dimensioni pi√π elevate √® possibile creare pi√π transistor in un solo chip e interconnessi fra di loro danno vita ad un circuito integrato, le cui dimensioni, dalla fine degli anni \('70\) e l'inizio degli anni \('80\) sono stati realizzati con dimensioni sempre pi√π piccole.

\vspace{1em}
\noindent
\textbf{Osservazione}: La crescita dell'integrazione, ovvero della concentrazione di transistor in un singolo chip, √® di tipo esponenziale, con un raddoppio di circa \(18\) e \(24\) mesi, nota come \textbf{legge di Moore}. Ad oggi, invece, la curva incomincia ad appiattirsi, in quanto si √® arrivati ad un punto in cui le tracce del chip sono dell'ordine degli atomi. E l'appiattimento della curva √® un'eventualit√† assolutamente inevitabile, che caratterizza tutti i processi in natura.\\
La legge di Moore ha influenzato significativamente il mercato tecnologico, permettendo di abbattere i costi e di migliorare in maniera importante la qualit√† del prodotto, ottimizzando persino il consumo di potenza.\\
Ci√≤ ha delle ripercussione anche dal punto di vista software. Infatti, \textit{il software √® come un gas}, in quanto segue le \(3\) leggi della termodinamica
\begin{itemize}
    \item Il software diventa sempre pi√π complesso all'aumentare delle prestazioni del supporto tecnologico
    \item Il software limita la propria complessit√† secondo la legge di Moore, a causa della limitazione della tecnologica hardware a disposizione
    \item Quando la tecnologia hardware non √® pi√π in grado di stare al passo con l'esigenza software dell'utente, vengono introdotti dei nuovi dispositivi hardware, sempre pi√π prestazionali.
\end{itemize}

\subsection{Concetto di informazione}
√à noto che i \textbf{bit} costituiscono la \textbf{minima quantit√† di informazione associata a due stati equiprobabili}.\\
L'\textbf{informatica} riguarda la \textbf{gestione e l'elaborazione automatica dell'informazione}. Ma √® importante chiedersi che cosa sia l'\textbf{informazione}: l'informazione nasce a seguito di una variazione (una differenza) di una certa grandezza fisica, la quale si pu√≤ sviluppare tanto in modo analogico, quanto in modo digitale. Tale differenza si propaga attraverso dei canali di comunicazione attraverso i quali √® possibile prelevare un'informazione dalla relativa sorgente.\\
La variazione pu√≤ essere trasmessa sia oltrepassando la \textbf{barriera spaziale}, oppure attraverso una \textbf{barriera temporale}. Banalmente, un supporto di trasmissione dell'informazione √® la \textbf{memoria}.\\
√à fondamentale, inoltre, comprendere anche il concetto di \textbf{stratificazione gerarchica delle differenze}, in quanto le differenze possono essere rilevate anche su delle differenze (si pensi a dei dati che sono frutto di rilevazioni di differenze e poi agli attributi dei dati, che sono nuovamente delle differenze, ma rilevate su delle nuove differenze).\\
Inoltre, quando una sorgente di informazione genera un flusso informazionale, vi sono diversi canali di informazione che vengono sollecitati, i quali portano con s√© informazioni di natura diversa, che possono essere rilevati dagli utenti, i quali sono in grado di recepire tali informazioni, ma hanno anche la possibilit√† di scartare certe informazioni.\\
L'informazione, pertanto, si pu√≤ rilevare su diversi piani, ovvero
\begin{itemize}
    \item Un'informazione che si pu√≤ considerare
    \item Un'informazione che si vuole considerare
    \item Un'informazione latente, ovvero disponibile, ma non immediatamente fruibile
\end{itemize}
L'informazione, poi, √® alla base del cosiddetto \textbf{processo di comunicazione}, il quale si dirama in pi√π passi
\begin{enumerate}
    \item \textbf{Rilevamento - Livello sintattico}, ovvero una certa grandezza fisica viene rilevata attraverso uno strumento.

    \item \textbf{Comprensione - Livello semantico}, la quale richiede che vi sia uno strumento cognitivo superiore, quale il cervello umano, che sia in grado di processare l'informazione attraverso i propri processi cognitivi, mediante l'esperienza e la capacit√† acquisite.

    \item \textbf{Impiego - Livello pragmatico}, ovvero reagire all'informazione o fruire dell'informazione per compiere un'azione conseguente o sviluppare un pensiero successivo connesso all'informazione rilevata e compresa.
\end{enumerate}

\newpage
\begin{center}
    23 Novembre 2021
\end{center}
\subsection{Riassunto}
La rivoluzione microelettronica si articola in \(3\) fasi. La prima riguarda la costruzione dei tubi termoionici, ovvero dei dispositivi pesanti, ingombranti, fragili, poco duraturi e con una potenza dissipata assai inferiore.\\
La seconda fase riguarda i transistor, dispositivi assai pi√π efficienti, in tutti i sensi, rispetto ai tubi termoionici, per poi giungere alla terza fase, riguardante i circuiti integrati, che rappresentano la concentrazione massima possibile dei transistor in un circuito integrato, che segue una legge nota come legge di Moore, di carattere esponenziale.\\
Tale legge √® stata valida fino ad oggi, quando si √® arrivati ad una miniaturizzazione tale da scontrarsi con dei limiti quantistici. Infatti, √® molto interessante capire come il software si comporti come un vero e proprio gas, cercando sempre di richiedere maggiori prestazioni alle macchine che lo supportano.\\

\vspace{1em}
\noindent
Il bit dell'informazione √® l'unit√† minima di informazione in grado di contenere i dettagli di due stati egualmente probabili.\\
Un sistema basato sulle interazioni informazionali √® di natura molto pi√π complessa rispetto ad un qualsiasi sistema fisico o biologico. L'informazione, inoltre, nasce quando si assiste ad una differenza di una certa grandezza fisica: senza differenze non si ha informazione, la quale pu√≤ essere trasmessa attraverso lo spazio o il tempo.\\
Tuttavia, √® anche fondamentale rilevare che oltre alle differenze di primo livello, meramente superficiali, possono essere rilevate anche differenze di pi√π livelli, ovvero delle differenze sulle differenze.\\
Inoltre le informazioni possono essere destinate a pi√π utenti che avranno la possibilit√† di valutarle oppure no. Inoltre il processo di comunicazione si diparte in tre rami
\begin{enumerate}
    \item Rilevamento, a livello sintattico
    \item Comprensione, a livello semantico, la quale pu√≤ avvenire solamente con l'esperienza
    \item Impiego, a livello pragmatico, che si pone a livello dell'utente e riguarda l'utilizzo dell'informazione per i propri fini
\end{enumerate}
Nella tecnologia di elaborazione dell'informazione, anche mediante i calcolatori, ci si √® sempre fermati al livello sintattico, al fine di garantire una comunicazione intelligibile.\\
Solamente di recente si √® cercato di sfondare la barriera semantica, anche se √® molto complesso, cercando di rielaborare in tal senso le informazioni, in quanto per fare ci√≤ si necessita di un cervello, di una infrastruttura logica che √® capace di simulare la volont√† e la direzione del pensiero umano.\\
Grazie all'enorme patrimonio esperienziale e informazionale contenuto nel Web, ovvero alla stratificazione sintattica di frasi e stringhe strutturate logicamente e aventi senso compiuto, √® possibile iniziare ad avere una prima risibile forma di interazione con un sistema esperto, nel senso prettamente pratico del tempo.

\vspace{1em}
\subsection{Ridondanza}
La \textbf{ridondanza} √® un eccesso d'informazione rispetto a quella strettamente necessaria per ricostruire il tutto, e risulta fondamentale per fare previsioni sui dati mancanti con una probabilit√† di successo superiore alla distribuzione uniforme.\\
L'informazione trasmessa, infatti, √® costituito da un'informazione essenziale, non compressibile ed essenziale, e da tutto ci√≤ che non √® essenziale, appunto, la \textbf{ridondanza}.\\
Anche la ridondanza, come l'informazione, pu√≤ essere di tipo \textbf{sintattico} e \textbf{semantico}, la prima riguardante i dati, mentre il secondo riguardante il significato.\\
Per impiegare la ridondanza semantica al fine di completare un'informazione essenziale √® fondamentale valutare la frequenza relativa delle lettere dell'alfabeto della lingua impiegata per la scrittura dell'informazione.\\
Pertanto, per ricostruire l'integrit√† dell'informazione essenziale, oltre alle frequenze relative delle singole lettere, sar√† necessario anche impiegare la frequenza relativa delle coppie di lettere, in modo tale da valutare di volta in volta le lettere che seguono quelle precedenti.\\
Riuscendo a procedere in questo modo si riesce a costruire sintatticamente l'informazione essenziale e, anche se l'informazione non ha senso compiuto, ovvero √® scorretta semanticamente, ma assomiglia ad un'informazione della lingua di trasmissione, in quanto costruita proprio sulla base delle frequenze relative delle lettere delle parole della lingua di riferimento.\\
Quindi l'informazione non coincide con il supporto (infatti √® possibile cambiare infinite volte il supporto di trasmissione di trasmissione, ma l'informazione rimane inalterata, al pi√π cambier√† la persistenza dell'informazione stessa).\\
Inoltre, l'informazione non segue le leggi di conservazione della fisica, in quanto distribuendola essa non diminuisce. Pertanto non √® una grandezza fisica e dipende dal contesto, in quanto la stessa informazione sintattica pu√≤ assumere dei significati differenti, dal punto di vista semantico, a seconda del contesto, ovvero a seconda dell'esperienza dell'osservatore che interpreta l'informazione sintattica fornita.\\
√à fondamentale anche capire che l'assenza di informazione √® essa stessa un'informazione.

\newpage
\section{Storia dell'informatica}
L'informatica deriva dal francese \textit{Information Automatiqu√©}. L'informatica non √® riducibile al calcolatore, in quanto √® nata quando il computer ancora non c'era, nel \(1936\).\\
Di fatto, l'informatica non dipende dalla tecnologia di supporto e non √® vincolata all'esistenza stessa di un calcolatore.\\
Nel \(1936\), infatti, sono sfociate due desideri millenari dell'essere umano
\begin{itemize}
    \item Il sogno millenario di una macchina per eseguire i calcoli in modo automatico
    \item Il progetto Hilbertiano (dal tedesco David Hilbert, un celeberrimo matematico dei primi anni del \('900\)) di \textit{meccanizzazione della matematica} che consentisse di ottenere tutti i teoremi a partire degli assiomi e dalle regole di inferenza note (ovvero le regole con le quali si passa da affermazioni vere ad altre affermazioni vere, come la dimostrazione per assurdo).
\end{itemize}
In questo anno si assiste alla costruzione del primo calcolatore da parte di \textit{Conrad Zuse}, un calcolatore meccanico rudimentale, ma straordinario dal punto di vista concettuale e la pubblicazione dei \(3\) articoli relativi al primo modello di computazione da parte di \textit{Alan Turing}.\\
\textit{Kurt Godel} ha dimostrato che la matematica ha dei limiti intrinseci, ovvero che tutto ci√≤ che √® vero non √® dimostrabile, realizzando anche un secondo modello oltre a quello di \textit{Alan Turing}, avviando una rivoluzione matematica paragonabile a quella di Einstein per la fisica.\\
\textit{Alan Turing} pubblic√≤, nel \(1936\) tre articoli che erano una dissertazione meramente matematica e logica, e nulla aveva a che fare con il concetto di informatica, che al tempo nemmeno esisteva.\\
\textit{Charles Babbage} fu il primo a concepire il concetto di computer moderno, anche se nel primo \('800\) non riusc√¨ a realizzare un calcolatore vero e proprio, in quanto la tecnologia del tempo non era sufficientemente sofisticata per gli scopi di Babbage.\\
Nel \(1643\) venne costruite la Pascalina che risuciva, attraverso processi meccanici, riusciva ad eseguire le somme e le sottrazioni.\\
Nel \(1674\) venne concepita una nuova macchina, le \textit{ruote di Leibniz}, che permetteva di eseguire moltiplicazioni e divisioni, con un hardware completamente diverso rispetto alla Pascalina.\\
Successivamente venne realizzata la \textit{macchina analitica}, che permetteva di riprogrammare la medesima macchina per eseguire pi√π operazioni diverse, a differenza delle macchine cablate precedenti.\\
\textit{Ada Byron}, figlia di Lord Byron, fu la prima programmatrice della storia, in quanto fu la prima a comprendere le potenzialit√† dell'invenzione di \textit{Babbage}.\\
Verso la met√† dell'\('800\) \textit{George Boole} concep√¨ l'algebra booleana, senza impiegarla concretamente. Cento anni dopo \textit{Shannon} riusc√¨ ad impiegare proficuamente l'algebra booleana per progettare e controllare le reti di interruttori nei circuiti elettronici.\\
Verso l'inizio del \('900\) erano gi√† largamente diffuse delle macchine meccaniche capaci di eseguire dei calcoli, in uso nei grandi magazzini.\\
Nel \(1936\) venne realizzato il primo computer meccanico, la \textit{Z1}, realizzato da \textit{Zuse}, che poi venne distrutta nei bombardamenti, poi realizzando la \textit{Z2} e infine la \textit{Z3}.\\
Pertanto, si possono individuare tre livelli di astrazione del concetto di calcolatore
\begin{itemize}
    \item Pi√π macchine per assolvere a diversi scopi
    \item Una stessa macchina, ma con pi√π software
    \item Una stessa macchina e un solo software per riuscire a risolvere problemi diversi, secondo il calcolatore universale e gli \textit{interprete} di Alan Turing.
\end{itemize}
\textit{John von Neumann} concep√¨ la moderna architettura dei calcolatori moderni, con una memoria e un'unit√† di calcolo che permette di processare programmi memorizzati in memoria.\\
Tutti i modelli che si sono susseguiti nella storia sono tutti in grado di processare le medesime funzioni di calcolo, per cui tutti sono fra di loro equivalenti, ma espressione di diversi meccanismi per sfruttare la potenza di calcolo degli elaboratori.\\
Inoltre, √® fondamentale osservare che fino agli anni \('60\) i modelli di computazione proposti non si basavano sulla tecnologia dei calcolatori, ma erano modelli astratti: questo non sorprende, in quanto quando vennero concepiti i computer non esistevano ancora.\\
Alla base del processo computazionale vi √®, per√≤, il concetto di \textbf{algoritmo}, ovvero in elenco di istruzioni che devono essere attuate in modo diretto, non possono essere subruotine complesse.\\
Il numero di istruzioni che descrivono la procedura deve essere finito.\\
Il numero di passi per ottenere i risultati deve essere finito.

\newpage
\begin{center}
    24 Novembre 2021
\end{center}
\subsection{Riassunto}
Le varie generazioni di computer si sono susseguite su due binari, quello degli ingegneri, che volevano creare una macchina per elaborare i calcoli in maniera automatica, e dei matematici, i quali volevano meccanizzare la matematica, e con essa ottenere tutti i teoremi a partire dagli assiomi e le regole di inferenza.\\
Nel primo caso vennero realizzate delle prime macchine rudimentali, come la pascalina, per poi sfociare nella straordinaria invenzione della Z1.\\
Nel 1936 contemporaneamente si realizza il primo computer e vengono pubblicati i primi contributi teorici relativi alla struttura di un modello di computazione, ma solamente dal punto di vista astratto, come da parte di Turing.\\
Tuttavia, il problema che si ravvis√≤ negli anni fu che i diversi modelli di computazione erano completamente distaccati e slegati dalle caratteristiche tecniche, architetturali e strutturali dei calcolatori veri e propri, proprio perch√© al tempo non esistevano.\\
Ci√≤ che per√≤ si cap√¨, √® che tutti i modelli, per quanto indipendenti fra loro e logicamente distinti, puntano allo stesso insieme di funzioni computabili, ovvero l'insieme di problemi di risolubili.\\
Ci√≤, per√≤, √® relativamente limitante, in quanto le funzioni computabili sono molto poche, in quanto hanno un ordine naturale, per cui il rapporto tra le funzioni computabili e quelle che teoricamente si potrebbero concepire √® pari al rapporto tra i numeri naturali e quelli reali.\\
Nel \(1936\) venne concepito il modello \textbf{RAM} (anche chiamato \textbf{Unlimited} ...) che permette di creare una connessione logica tra il linguaggio macchina e quello di alto livello: alla base del linguaggio RAM si pone la procedura effettiva, chiamata algoritmo, il quale deve presentare delle caratteristiche imprescindibile
\begin{enumerate}
    \item Ogni istruzione elementare si deve attuare in modo \quotes{diretto}
    \item Il \textbf{numero di istruzioni} che descrivono la procedura deve essere \textbf{finito}
    \item Il \textbf{numero di passi} per ottenere i risultati deve essere \textbf{finito}: l'algoritmo, infatti, deve produrre una risposta in un tempo finito, anche se √® possibile che i programmi concreti possano incorrere in delle computazioni infinite: in questo si ha la distinzione tra \textbf{programma} e \textbf{algoritmo}.
\end{enumerate}

\vspace{1em}
\subsection{Nozione di algoritmo}
Un algoritmo presenta le seguenti caratteristiche
\begin{enumerate}
    \item Esso √® composto da istruzioni \(I_1, ..., I_s\) di lunghezza finita
    \item Deve essere presente un \textbf{agente di calcolo} (ovvero una circuiteria a cui viene demandato il compito di eseguire i calcoli)
    \item Deve essere presente, e a disposizione della memoria.
    \item La circuiteria \(\mathcal{A}\) interagisce con \(\mathcal{P}\) in \textbf{modalit√† discreta} e non certamente in modalit√† analogica.
    \item La circuiteria \(\mathcal{A}\) interagisce con \(\mathcal{P}\) in \textbf{modalit√† deterministica}, ovvero la macchina si comporter√† sempre allo stesso modo partendo dallo stesso stato iniziale e producendo il medesimo stato d'uscita.
\end{enumerate}
Inoltre √® opportuno osservare che il calcolatore non presenta una limitazione sulla dimensione dei dati d'ingresso, cos√¨ come non √® necessario fissare la dimensione dell'insieme \(\mathcal{I} = \{I_1, I_2, ... I_k\}\) di istruzioni. Naturalmente non ha senso imporre una limitazione sulla dimensione della memoria (infatti nel modello RAM si richiede che la memoria sia infinita, ma questo √® impossibile).\\
Ci√≤ che √® necessario limitare √® la capacit√† di computazione di \(\mathcal{A}\), in quanto le istruzioni richiedono di eseguire delle operazioni elementari.\\
Non ha senso imporre un limite sulla lunghezza della computazione, ma ha senso affermare che la lunghezza della computazione sia finita. Tuttavia, nel modello computazionale, sono ammesse computazioni con un numero infinito di passi (computazioni non terminanti): sono i cosiddetti loop innescati dai bachi, ovvero i \textit{bug}, i quali non sono mai eliminabili completamente (in quanto le possibilit√† di incorrere in un \textit{bug} sono infinite, e vi sono dei teoremi che permettono di dimostrare che non √® possibile costruire un programma di test che possa individuare tutti i \textit{bug}).\\
Si potrebbe dimostrare che se si imponesse un limite al numero di passi non si sarebbe in grado di costruire dei programmi in grado di esprimere nella sua interezza le capacit√† computazionali dei computer.\\
Pertanto, accettando la possibilit√† di avere delle \textbf{computazioni non terminanti} si riesce ad ottenere un programma reale. Dal punto di vista teorico si ha un algoritmo; aggiungendo a tale concetto la possibilit√† che ci possano essere delle computazioni non terminanti, ossia dei \textit{bug}, si ottengono dagli algoritmi i programmi.

\vspace{1em}
\subsection{Modello RAM}
Il modello RAM presenta un nastro di memoria, costituita da delle celle nelle quali √® possibile inserire un qualsiasi numero reale, illimitato superiormente, ovverosia avente la potenzialit√† dell'infinito. Inoltre √® presente, naturalmente, anche il programma \(\mathcal{P}\) che √® costituita da una serie di istruzioni, le quali si possono riassumere in \(4\) tipologie, le prime \(3\) di natura aritmetica, l'ultima di natura logica (responsabile della capacit√† di computazione del calcolatore)
\begin{enumerate}
    \item \textbf{Azzeramento} \(Z(n)\), ovvero \(r_n := 0\);
    \item \textbf{Incremento} \(S(n)\), ovvero \(r_n := r_n + 1\);
    \item \textbf{Assegnazione} \(T(m, n)\), ovvero \(r_m = r_n\);
    \item \textbf{Salto condizionato} \(C(m, n, q)\), per cui se \(r_n = r_m\) si va all'istruzione \(I_q\).
\end{enumerate}

\vspace{1em}
\subsection{Computazione}
Per eseguire la computazione RAM bisogna fornire un \textit{nastro}, caricato con una \textit{configurazione iniziale} costituita da una sequenza \(a_1, a_2,a_3, ..., a_n\) di numeri reali; se \(\mathcal{P} = I_1, I_2, ..., I_s\) √® il programma associato alla macchina, la computazione inizia eseguendo l'istruzione \(I_1\). Dopo averla eseguita, la macchina RAM dovr√† eseguire la \textit{prossima istruzione} \(I_{\textit{NEXT}}\) finch√© si raggiunge uno STOP (se mai si raggiunge).

\vspace{1em}
\subsubsection{Prossima istruzione}
Naturalmente l'istruzione successiva \(I_{\textit{NEXT}}\) sar√† quella numericamente successiva \(I_{\textit{NEXT}} = I_{k + 1}\) se l'istruzione precedente \(I_k\) √® di tipo aritmetico, altrimenti sar√† l'istruzione specificata dall'istruzione logica eseguita, ovvero \(I_q\), naturalmente se la condizione indicata viene soddisfatta.

\vspace{1em}
\subsubsection{STOP della computazione}
La computazione si ferma per due possibili motivi
\begin{itemize}
    \item √à stata eseguita \(I_k = I_s\) aritmetica, oppure \(I_k = I_s = C(m, n, q)\), con \(r_m \neq r_n\), ovvero √® stata eseguita l'ultima istruzione del programma.
    \item √à stata eseguita \(I_k = C(m, n, q)\), con \(r_m = r_n\) e \(q > s\), ovvero √® stata ottenuta la soluzione richiesta e si esegue una uscita anticipata dal programma e, quindi, si esegue un'istruzione successiva a quella finale, non presente nel programma.
\end{itemize}

\vspace{1em}
\subsubsection{Configurazione iniziale}
√à la configurazione dalla quale si parte per effettuare la computazione. Se \(a_1, a_2, ..., a_n\) sono i dati di ingresso, per convenzione essi vengono posti all'inizio del nastro (nelle prime \(n\) celle), lasciando a \(0\) tutte le altre (infinite) celle di memoria.

\vspace{1em}
\subsubsection{Configurazione finale}
√à la configurazione che si ottiene alla fine della computazione. Per convenzione il valore \(b\) calcolato dalla computazione √® il contenuto della prima cella. Ci√≤ accade ovviamente nel solo caso in cui la computazione termini.

\vspace{1em}
\subsubsection{Convergenza}
Indicando con la notazione \(\mathcal{P} (a_1, a_2, ..., a_n)\) la computazione del programma \(\mathcal{P}\) a partire dalla configurazione iniziale \(a_1, a_2, ..., a_n\), se tale computazione termina si afferma che c'√® stata \textbf{convergenza}, e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \downarrow\). Se \(b\) √® il contenuto della prima cella alla fine della computazione si dice che la computazione √® andata a convergenza su \(b\) e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \downarrow b\). Se la computazione non termina si dice che si √® avuta una \textbf{divergenza} e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \uparrow\).

\vspace{1em}
\subsubsection{Calcolo di una funzione tramite un programma}
Si afferma che il programma \(\mathcal{P}\) RAM-calcola (in quanto il modello adottato √® il modello RAM, altrimenti si sarebbe detto Turing-calcola, Charles-calcola) la funzione \(f\) se, \(\forall a_1, a_2, ..., a_n, b\)
\[\mathcal{P}(a_1, a_2, ..., a_n) \downarrow b \hspace{1em} \leftrightarrow \hspace{1em}
    \left\{
        \rowcolors{1}{white}{white}
        \begin{array}{l}
             a_1, a_2, ..., a_n \in \text{Dom}(f)\\
             b = f(a_1, a_2, ..., a_n)
        \end{array}
    \right.
\]

\vspace{1em}
\subsubsection{Funzione calcolabile}
Una funzione \(f\) si dice \textbf{calcolabile} se esiste un programma \(\mathcal{P}\) che la RAM-calcola.

\vspace{1em}
\noindent
\textbf{Osservazione}: Pertanto, il numero delle funzioni calcolabili si traduce effettivamente nel numero di problemi risolubili, in quanto risolvere un problema si traduce nel trovare una funzione che se calcolata permette di ottenere la soluzione richiesta del problema.

\vspace{1em}
\subsubsection{Linguaggio delle funzioni}
Per esprimere il funzionamento e l'attivit√† di un calcolatore si ricorre al linguaggio delle funzioni.

\vspace{1em}
\noindent
\textbf{Esempio}: Si scriva un programma che calcola la funzione \(f(x) = 0, \forall x\), impiegando le \(3\) funzioni aritmetiche note e l'unica funzione logica disponibile.\\
Si consideri, allora, un nastro un cui nella prima cella √® presente il valore \(x\).

\newpage
\begin{center}
    26 Novembre 2021
\end{center}
\subsection{Riassunto}
Il percorso storico dei primi modelli di computazione si √® diramato in due direzioni: da un lato per la meccanizzazione della matematica, dall'altro per la meccanizzazione dei calcoli in modo automatico.\\
Ci√≤ port√≤ alla realizzazione del primo calcolatore da parte di \textit{Conrad Zuse} nel \(1936\) e, sempre nello stesso anno, si diffusero ben \(4\) differenti modelli di computazione, formulati da parti di logici e matematici: essi si fondano su concetti e processi logici completamente diversi, ma √® interessante osservare come tutti puntino al medesimo insieme di funzioni calcolabili, e quindi di problemi risolubili.\\
L'ultimo modello di computazione \(\textbf{modello RAM}\) venne introdotto in modo tale da ritagliare le modalit√† computazionali oggetto di interesse sulla struttura fisica e strutturale di un calcolatore. Ci√≤ permette di capire la limitatezza del calcolo computazionale, il quale non pu√≤ risolvere tutti i problemi pensabili: infatti, l'insieme delle funzioni computabili ha la cardinalit√† dei numeri naturali, quindi √® \textbf{numerabile}, mentre l'insieme dei problemi da risolvere ha l'ordine dei numeri reali, quindi non √® numerabile, e lo scarto √® infinito.\\
Alla base del calcolo computazionale vi √® la cosiddetta \textbf{procedura effettiva} o \textbf{algoritmo}, il quale deve presentare delle caratteristiche imprescindibili
\begin{itemize}
    \item Ogni istruzione deve essere direttamente attuabile
    \item Il numero delle istruzioni deve essere finito
    \item Il numero dei passi deve essere finito
\end{itemize}

\vspace{1em}
\noindent
Il modello RAM √® un modello molto semplice, il quale prevede di disporre di una \textbf{memoria infinita} (per questo √® un modello astratto, senza una controparte concreta); vi sono delle celle di memoria che contengono dei numeri naturali (di qualunque grandezza, per cui ogni cella pu√≤ contenere un insieme di informazioni non limitabili superiormente) che vengono impiegate nella computazione, basata su quattro possibili istruzioni:
\begin{enumerate}
    \item \textit{Z(n)}: azzeramento della cella n-esima
    \item \textit{S(n)}: incremento della cella n-esima
    \item \textit{T(m, n)}: trasferimento del contenuto della cella n-esima nella cella m-esima
    \item \textit{C(m, n, q)}: salto condizionato, per cui se il contenuto della cella n-esima √® uguale al contenuto della cella m-esima, si esegue l'istruzione q-esima.
\end{enumerate}
Per eseguire la computazione RAM bisogna fornire un \textit{nastro}, caricato con una \textit{configurazione iniziale} costituita da una sequenza \(a_1, a_2,a_3, ..., a_n\) di numeri reali; se \(\mathcal{P} = I_1, I_2, ..., I_s\) √® il programma associato alla macchina, la computazione inizia eseguendo l'istruzione \(I_1\). Dopo averla eseguita, la macchina RAM dovr√† eseguire la \textit{prossima istruzione} \(I_{\textit{NEXT}}\) finch√© si raggiunge uno STOP (se mai si raggiunge).\\
Naturalmente l'istruzione successiva \(I_{\textit{NEXT}}\) sar√† quella numericamente successiva \(I_{\textit{NEXT}} = I_{k + 1}\) se l'istruzione precedente \(I_k\) √® di tipo aritmetico, altrimenti sar√† l'istruzione specificata dall'istruzione logica eseguita, ovvero \(I_q\), naturalmente se la condizione indicata viene soddisfatta.\\
La computazione si ferma per due possibili motivi
\begin{itemize}
    \item √à stata eseguita \(I_k = I_s\) aritmetica, oppure \(I_k = I_s = C(m, n, q)\), con \(r_m \neq r_n\), ovvero √® stata eseguita l'ultima istruzione del programma.
    \item √à stata eseguita \(I_k = C(m, n, q)\), con \(r_m = r_n\) e \(q > s\), ovvero √® stata ottenuta la soluzione richiesta e si esegue una uscita anticipata dal programma e, quindi, si esegue un'istruzione successiva a quella finale, non presente nel programma.
\end{itemize}
La configurazione iniziale √® la configurazione dalla quale si parte per effettuare la computazione. Se \(a_1, a_2, ..., a_n\) sono i dati di ingresso, per convenzione essi vengono posti all'inizio del nastro (nelle prime \(n\) celle), lasciando a \(0\) tutte le altre (infinite) celle di memoria.\\
La configurazione finale √® la configurazione che si ottiene alla fine della computazione. Per convenzione il valore \(b\) calcolato dalla computazione √® il contenuto della prima cella. Ci√≤ accade ovviamente nel solo caso in cui la computazione termini.\\
Indicando con la notazione \(\mathcal{P} (a_1, a_2, ..., a_n)\) la computazione del programma \(\mathcal{P}\) a partire dalla configurazione iniziale \(a_1, a_2, ..., a_n\), se tale computazione termina si afferma che c'√® stata \textbf{convergenza}, e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \downarrow\). Se \(b\) √® il contenuto della prima cella alla fine della computazione si dice che la computazione √® andata a convergenza su \(b\) e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \downarrow b\). Se la computazione non termina si dice che si √® avuta una \textbf{divergenza} e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \uparrow\).\\
Si afferma che il programma \(\mathcal{P}\) RAM-calcola (in quanto il modello adottato √® il modello RAM, altrimenti si sarebbe detto Turing-calcola, Charles-calcola) la funzione \(f\) se, \(\forall a_1, a_2, ..., a_n, b\)
\[\mathcal{P}(a_1, a_2, ..., a_n) \downarrow b \hspace{1em} \leftrightarrow \hspace{1em}
    \left\{
        \rowcolors{1}{white}{white}
        \begin{array}{l}
             a_1, a_2, ..., a_n \in \text{Dom}(f)\\
             b = f(a_1, a_2, ..., a_n)
        \end{array}
    \right.
\]
Una funzione \(f\) si dice \textbf{calcolabile} se esiste un programma \(\mathcal{P}\) che la RAM-calcola.\\
Una computazione potrebbe anche essere non terminante, come nel caso di una funzione con ciclo infinito: allora si dir√† in quel caso che la n-upla \(a_1, a_2, ..., a_n\) non appartiene al dominio della funzione, ovvero la funzione non √® definita per l'n-upla \(a_1, a_2, ..., a_n\).

\vspace{1em}
\noindent
\textbf{Osservazione}: Se all'interno di un programma vengono inserite delle istruzioni superflue che non alterano il funzionamento di un programma, si ottiene un programma strutturalmente e logicamente diverso, ma che produce il medesimo risultato, calcolando la stessa funzione.

\vspace{1em}
\noindent
\textbf{Esempio}: Per sommare fra di loro due numeri \(x\) e \(y\) senza saperne il valore, si dovr√† controllare in prima analisi se il contenuto della seconda cella √® uguale a quello della terza, ovvero \(y = 0\).\\
Se cos√¨ non √® si procede ad incrementare la prima e la terza cella e si esegue un salto incondizionato alla prima istruzione di controllo: se la seconda e la terza cella sono uguali allora si termina il programma, altrimenti si continua il ciclo:
\begin{enumerate}
    \item \(C(2, 3, 99)\)
    \item \(S(1)\)
    \item \(S(3)\)
    \item \(C(1, 1, 1)\)
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esercizio}: Per eseguire la sottrazione tra due numeri si proceda a capire come si esegue la cosiddetta \textbf{somma naturale}, ovvero
\[f(x) = x \overset{\cdot}{-} 1 = \left\{
    \rowcolors{1}{white}{white}
    \begin{array}{ccc}
         x - 1 & \text{se} & x > 0\\
         0 & \text{se} & x = 0
    \end{array}
\right.\]
Per cui si procede come segue
\begin{enumerate}
    \item \(C(1, 4, 99)\)
    \item \(S(3)\)
    \item \(C(1, 3, 7)\)
    \item \(S(2)\)
    \item \(S(3)\)
    \item \(C(1, 1, 3)\)
    \item \(T(2. 1)\)
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esercizio}: Se si vuole eseguire la differenza tra due valori numerici sar√† sufficiente eseguire il programma seguente
\begin{enumerate}
    \item \(C(1, 2,5)\)
    \item \(S(2)\)
    \item \(S(3)\)
    \item \(C(1, 1, 1)\)
    \item \(T(3, 1)\)
\end{enumerate}
Nel caso in cui \(x < y\) la differenza non pu√≤ essere effettuata, allora si deve fare in modo che il programma cicli in maniera indefinita.

\vspace{1em}
\subsection{Programmazione imperativa}
Ogni istruzione corrisponde a un \quotes{comando} che viene impartito alla macchina, e che prevede l'esecuzione di un certo lavoro.\\
Si si fa riferimento al paradigma pi√π usato di \textbf{programmazione imperativa}, denominato \textit{programmazione strutturata}, √® possibile affermare che un programma √® solitamente costruito nel seguente modo:
\begin{itemize}
    \item \textbf{una parte dichiarativa}, in cui si dichiarano tutte le variabili del programma e il loro tipo (come, ad esempio, variabile intera, variabile carattere, etc.)
    \item \textbf{una parte che descrive l'algoritmo} risolutiva utilizzato, basato sulle istruzioni del linguaggio che, a loro volto, si suddividono in
    \begin{itemize}
        \item istruzioni di lettura e scrittura (scrittura a video, scrittura su disco, lettura da tastiera, ...)
        \item istruzioni di assegnamento (del valore a una variabile)
        \item istruzioni logiche di controllo del programma
    \end{itemize}
\end{itemize}

\vspace{1em}
\noindent
\subsubsection{Istruzioni logiche di controllo}
Esistono essenzialmente tre tipi di strutture logiche di controllo del programma
\begin{enumerate}
    \item Sequenza
    \item Selezione
    \item Iterazione
\end{enumerate}

\vspace{1em}
\subsubsection{Selezione}
Per eseguire un \textbf{if} \(C\) \textbf{then} \(I_{\text{SI}}\) \textbf{else} \(I_{\text{NO}}\) √® sufficiente eseguire due salti condizionati, come mostrato di seguito
\begin{enumerate}
    \item \(I_\text{\textit{prec}}\)
    \item \(C(m, n, 5)\)
    \item \(I_{\textit{NO}}\)
    \item \(C(1, 1, 6)\)
    \item \(I_{\textit{SI}}\)
    \item \(I_{\textit{succ}}\)
\end{enumerate}

\vspace{1em}
\subsubsection{Iterazione while - do}
Per eseguire un \textbf{while} \(C\) \textbf{do} \(I\) si procede come segue
\begin{enumerate}
    \item \(I_{\textit{prec}}\)
    \item \(C(m, n, 4)\)
    \item \(C(1, 1, 6)\)
    \item \(I\)
    \item \(C(1, 1, 2)\)
    \item \(I_{\textit{succ}}\)
\end{enumerate}

\vspace{1em}
\subsubsection{Iterazione repeat - unti}
Per eseguire un \textbf{repeat} \(I\) \textbf{until} \(C\) si procede come segue
\begin{enumerate}
    \item \(I_{\textit{prec}}\)
    \item \(I\)
    \item \(C(m, n, 5)\)
    \item \(C(1, 1, 2)\)
    \item \(I_{\textit{succ}}\)
\end{enumerate}

\subsection{Tesi di Church-Turing}
Tutto ci√≤ che pu√≤ essere fatto col calcolatore tradizionale pu√≤ essere realizzato anche col \quotes{calcolatore} astratto del modello RAM (o qualunque altro modello di calcolo equivalente) e viceversa.\\
O meglio, si pu√≤ fare di pi√π con il modello RAM che con un modello concreto, in quanto si ha una quantit√† di memoria infinita nel primo, mentre √® finita nel secondo.\\
Per questa ragione, si ha che il modello del calcolatore √® \textbf{Turing-completo}, in quanto rispetta il modello computazionale di Turing.

\newpage
\section{Architettura dei calcolatori}
√à nota la struttura fisica di un sommatore, in grado di eseguire somme e sottrazioni e capace anche di individuare l'overflow.\\
Dopodich√© sono stati progettati i differenti \textit{flip-flop} che si pongono alla base dei registri normali, sequenziali e dei contatori.

\vspace{1em}
\subsection{Componenti essenziali di un calcolatore}
Le componenti essenziali di un calcolatore sono \(3\), cos√¨ come stabilito da Von-Neuman:
\begin{enumerate}
    \item una \textit{memoria indirizzabile}, che possa contenere il programma e i dati
    \item un'\textit{unit√† logico-aritmetica}, che possa lavorare sui dati della memoria, ovvero l'agente di calcolo
    \item un \textit{program counter}, cio√® un registro che indica l'indirizzo di memoria dell'istruzione che deve essere eseguita
\end{enumerate}

\vspace{1em}
\noindent
\subsection{Ciclo \textit{fetch-decode-execute}}
Le istruzione di un calcolatore vengono eseguite secondo un ciclo che prevede di eseguire tre istruzioni, secondo un ciclo nella forma \textbf{repeat} \(I\) \textbf{until} \(C\), ovvero
\begin{enumerate}
    \item \(PC \leftarrow 0\);
    \item \textbf{repeat}
    \begin{enumerate}
        \item istruzione $\leftarrow$ memoria \([PC]\)
        \item decode(istruzione)
        \item fetch(operandi)
        \item execute
        \item \(PC \leftarrow PC + 1\)
    \end{enumerate}
    \item \textbf{until} istruzione  = STOP
\end{enumerate}

\newpage
\begin{center}
    30 Novembre 2021
\end{center}
\subsection{Riassunto}
L'architettura dei calcolatori √® basata sull'infrastruttura logica fornita da Jhon Von Neumann. In particolare, all'interno del calcolatore dovr√† essere inserito un programma che dovr√† essere compilato dal calcolatore e tradotto in linguaggio macchia per poi essere eseguito.\\
Il funzionamento del computer si pu√≤ riassumere con il ciclo \textit{fetch-decode-execute} di seguito presentato
\begin{enumerate}
    \item \(PC \leftarrow 0\);
    \item \textbf{repeat}
    \begin{enumerate}
        \item istruzione $\leftarrow$ memoria \([PC]\)
        \item decode(istruzione)
        \item fetch(operandi)
        \item execute
        \item \(PC \leftarrow PC + 1\)
    \end{enumerate}
    \item \textbf{until} istruzione  = STOP
\end{enumerate}
Tale ciclo si arresta quando si raggiunge lo STOP della computazione. L'architettura dei calcolatori che consente di svolgere tali operazioni √® cos√¨ formata
\begin{enumerate}
    \item L'ALU, ovvero l'unit√† logico aritmetica in cui √® presente il sommatore gi√† studiato.
    \item I registri, che sono le unit√† di memoria pi√π vicine all'ALU
    \item La memoria RAM, ovvero la memoria volatile sulla quale viene caricato il programma da eseguire.
    \item Il Program Counter, il quale √® un registro di memoria che indica l'indirizzo della cella di memoria che contiene l'istruzione che deve essere eseguite.
    \item Il RI, ovvero il registro che contiene l'istruzione da eseguire.
    \item L'ACC, ovvero l'accumulatore dei risultati delle operazioni.
\end{enumerate}

\vspace{1em}
\subsection{Struttura di base del calcolatore}
Alla base dell'infrastruttura del calcolatore si pongono i seguenti quattro elementi
\begin{itemize}
    \item Processore
    \item Memoria primaria o principale (RAM)
    \item Memoria secondaria o di massa (HDD)
    \item Periferiche di I/O
\end{itemize}

\vspace{1em}
\subsubsection{Processore}
All'interno della CPU sono presenti due componenti fondamentali UC (Unit√† di Controllo) e ALU (Arithmetic Logic Unit), alla quale viene associato un Processore Matematico, impiegato per svolgere le operazioni a virgola mobile. Inoltre sono presenti i seguenti registri
\begin{itemize}
    \item PC - Program Counter
    \item RS - Registro di Stato (per gestire, per esempio, gli overflow)
    \item RI - Registro delle Istruzioni
    \item Registri Generali
    \item Registri di gestione RAM, per la gestione della lettura/scrittura
    \begin{itemize}
        \item RIM - Registro Indirizzi di Memoria
        \item RDM - Registro Dati di Memoria
        \item RC - Registro di Controllo
    \end{itemize}
\end{itemize}

\vspace{1em}
\noindent
\textbf{Osservazione}: Se il registro RIM √® a \(32\) bit, significa che possono essere indirizzati fino a \(2^32 = 4GB\) celle di memoria. Il RC, ovvero il registro di controllo della memoria RAM indica se deve essere eseguita un'operazione di lettura, oppure di scrittura. all'interno del registro dati di memoria (RDM) viene inserito il dato che deve essere letto o scritto da/nell'indirizzo di memoria specificato nel RIM.\\
Si capisce, per√≤, che il punto in cui devono essere eseguite le operazioni (ALU) √® fisicamente distante dal punto in cui si acquisiscono, o inseriscono le informazioni (ovvero la RAM): ci√≤ comporta un rallentamento e una limitazione della capacit√† di calcolo, per non parlare del bassissimo efficientamento energetico che contraddistingue tale sistema.

\vspace{1em}
\subsection{Istruzioni in linguaggio ASSEMBLY}
Le istruzioni di basso livello in linguaggio ASSEMBLY sono di quattro tipi
\begin{itemize}
    \item Istruzioni di I/O
    \begin{itemize}
        \item \textbf{READ INP 1322}: Legge da tastiera e mette il dato nella cella 1322 della memoria RAM
        \item \textbf{WRITE OUT 1902}: Scrive a video il contenuto della cella 1902 della memoria RAM
    \end{itemize}
    \item Istruzioni logico/aritmetiche
    \begin{itemize}
        \item \textbf{ADD R1 R2}
        \item \textbf{MUL R1 R2}
    \end{itemize}
    \item Istruzioni di accesso alla memoria
    \begin{itemize}
        \item \textbf{LOAD 1672 R2}
        \item \textbf{STORE R1 1559}
    \end{itemize}
    \item Istruzioni di salto
    \begin{itemize}
        \item \textbf{BRLT}
        \item \textbf{JUMP}
    \end{itemize}
\end{itemize}

\vspace{1em}
\noindent
\textbf{Osservazione}: Le operazioni che devono essere eseguite per effettuare un'operazione:
\begin{enumerate}
    \item L'indirizzo di memoria specificato nel PC deve essere copiato nel registro RIM
    \item Nel registro RC viene specificata l'operazione da eseguire: lettura
    \item Una volta letto il contenuto della cella di memoria specificata, l'istruzione viene inserita all'interno del RDM
    \item Il contenuto del registro RDM viene trasferito nel registro RI in modo tale che possa essere eseguito dal processore
    \item Nel caso di una lettura, bisogna ripetere le operazioni di lettura dalla memoria RAM e inserire il contenuto letto nel primo registro disponibile
    \item Una volta eseguita l'operazione viene incrementato il PC
    \item Si ripetono le operazioni precedenti con iterazioni
\end{enumerate}
Tali istruzioni possono essere riassunte in 5 macroistruzioni
\begin{enumerate}
    \item IF - Instruction Fetch
    \item ID - Instruction Decode
    \item EX - Execture
    \item MEM - Memorization
    \item WB - Write BACK
\end{enumerate}
Ad oggi queste operazioni non vengono pi√π eseguire in serie, ma in parallelo (\textit{pipeline}), con il significativo vantaggio che ad ogni ciclo di clock viene eseguita una operazioni.\\
Le istruzioni che vengono specificate in linguaggio ASSEMBLY sono, per quanto di basso livello, comunque orientate all'utente e, per poter essere eseguite dalla macchina devono essere tradotte in linguaggio macchina. Il processo di traduzione avviene in due passaggi
\begin{enumerate}
    \item Dopo aver scritto il programma in linguaggio ad alto livello, questo viene \textbf{compilato} in linguaggio ASSEMBLY
    \item Il programma scritto in \textbf{ASSEMBLY} viene assemblato dall'\textbf{assemblatore}, il quale converte tale programma in linguaggio macchina (ISA), ovvero come sequenza di \(0\) e \(1\).
\end{enumerate}
In realt√†, per√≤, sono presenti pi√π di due livelli di traduzione dei programmi, come riportato di seguito
\begin{itemize}
    \item Livello -1 - Elettronico, a livello circuitale: transistor, mosfet
    \item Livello 0 - Logico, di prte logiche
    \item Livello 1 - Microarchitettura, come ALU e registri
    \item Livello 2 - ISA (\textit{Instruction Set Architecture})
    \item Livello 3 - Sistema Operativo
    \item Livello 4 - Assemblatore
    \item Livello 5 - Linguaggi applicativi
\end{itemize}
In questo modo la progettazione del livello i-esimo deve valutare solamente cosa c'√® al livello \(i - 1\) e \(i + 1\).

\vspace{1em}
\subsection{Gerarchia di memoria}
A mano a mano che ci si allontana dalla unit√† logico aritmetica si incontrano memorie pi√π capienti, meno costose, e pi√π lente, come HD e SSD, mentre risalendo la gerarchia si incontrano la RAM, la memoria CACHE e e i registri.

\vspace{1em}
\subsubsection{Registri CPU}
I registri della CPU sono contraddistinti da
\begin{itemize}
    \item Altissima velocit√† di accesso
    \item Bassissima capacit√†
    \item Altissima velocit√† di trasferimento dati
    \item Integrati nell'infrastruttura
\end{itemize}

\vspace{1em}
\subsubsection{RAM}
Le memorie RAM (Random Access Memory), pur sempre volatili, sono di due tipi
\begin{itemize}
    \item DRAM, poco costosa, poco efficiente e lenta
    \item SRAM, costosa, efficiente e molto veloce
\end{itemize}
Le RAM hanno un accesso a tempo costante, sono relativamente veloci e poco capienti, se comparate alle memorie secondarie.

\vspace{1em}
\subsubsection{Memoria Cache}
La memoria Cache √® in stretto contatto con il processore (√® realizzata nel chip) e permette di evitare l'accesso alla RAM. Il tempo di accesso √® molto ridotto, √® basata sulla tecnologia SRAM e ha una dimensione assai inferiore alla RAM.\\
Anche all'interno dei moderni processori le memorie cache vengono gerarchizzate, in modo tale da ridurre il pi√π possibile il ritardo di lettura/scrittura e gestire le interazioni fra i diversi core.

\vspace{1em}
\subsubsection{Memoria secondaria}
Le memorie secondarie sono due tipologie
\begin{itemize}
    \item Hard Disk
    \begin{itemize}
        \item con alta capacit√† di memorizzazione
        \item a basso costo
        \item ad alto tempo di accesso
        \item con memoria permanente (non volatile)
        \item basata sulla tecnologia elettromeccanica (sul disco di policarbonato viene letto e scritto grazie ad una testina meccanica): per questo la tecnologia √® molto arretrata, a causa dell'inerzia tra i dispositivi meccanici e a causa della presenza dei motori ad alto consumo.
        \item √® possibile anche creare dei banchi di HD in modo tale da aumentare la capacit√†
    \end{itemize}

    \item Solid State Disk (SSD), ovvero la prima memoria elettronica \textbf{non volatile}, che permette di memorizzare le informazioni imprigionando gli elettroni in una zona di potenziale dalla quale √® difficile scappare. Gli SSD
    \begin{itemize}
        \item hanno alta capacit√† di memorizzazione
        \item hanno alto costo, seppur in diminuzione, ma di sicuro maggiore agli HD
        \item hanno elevata velocit√† di lettura e basso tempo di risposta e di accesso
    \end{itemize}
\end{itemize}
Naturalmente, a queste memorie di massa interne, si possono sommare delle memorie di massa esterne che, pur essendo molto capienti, hanno tempi di accesso, lettura e scrittura molto elevati.

\end{document}
