\documentclass[a4paper]{extarticle}
\usepackage[utf8]{inputenc}
\usepackage[italian]{babel}
\selectlanguage{italian}
\usepackage[table]{xcolor}
\usepackage{xcolor}
\usepackage{circuitikz}
\usetikzlibrary{positioning, circuits.logic.US}
\usetikzlibrary {shapes.gates.logic.US, shapes.gates.logic.IEC, calc}
\tikzset {branch/.style={fill, shape = circle, minimum size = 3pt, inner sep = 0pt}}
\usetikzlibrary{matrix,calc}
\usepackage{multirow}
\usepackage{float}
\usepackage{geometry}
\usepackage{tabularx}
\usepackage{pgf-pie}
\usepackage{tikz}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color, soul}
\usepackage{fancyhdr}
\usepackage{graphicx}
\usepackage{subfig}
\graphicspath{ {./img/} }
\newtheorem{theorem}{Teorema}[section]
\newtheorem{corollary}{Corollario}[theorem]
\newtheorem{lemma}[theorem]{Lemma}

% Specifiche
\geometry{
 a4paper,
 top=20mm,
 left=30mm,
 right=30mm,
 bottom=30mm
}

\pagestyle{fancy}
\fancyhf{}
\fancyhead[LO]{\nouppercase{\leftmark}}
\fancyfoot[CE, CO]{\thepage}
\addtolength{\headheight}{1em}
\addtolength{\footskip}{-0.5em}

\newcommand{\quotes}[1]{``#1''}
\renewcommand\tabularxcolumn[1]{>{\vspace{\fill}}m{#1}<{\vspace{\fill}}}
\renewcommand\arraystretch{}
\newcolumntype{P}{>{\centering\arraybackslash}X}

\title{\textbf{Università di Trieste\\ \vspace{1em}
Laurea in ingegneria elettronica e informatica}}
\author{Enrico Piccin - Corso di Fondamenti di informatica - Prof. Francesco Fabris}
\date{Anno Accademico 2021/2022 - 27 Settembre 2021}

%isolated term
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - node
%#3 - filling color
\newcommand{\implicantsol}[3][0]{
    \draw[rounded corners=3pt, fill=#3, opacity=0.3] ($(#2.north west)+(135:#1)$) rectangle ($(#2.south east)+(-45:#1)$);
    }


%internal group
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - top left node
%#3 - bottom right node
%#4 - filling color
\newcommand{\implicant}[4][0]{
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(#2.north west)+(135:#1)$) rectangle ($(#3.south east)+(-45:#1)$);
    }

%group lateral borders
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - top left node
%#3 - bottom right node
%#4 - filling color
\newcommand{\implicantcostats}[4][0]{
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(rf.east |- #2.north)+(90:#1)$)-| ($(#2.east)+(0:#1)$) |- ($(rf.east |- #3.south)+(-90:#1)$);
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(cf.west |- #2.north)+(90:#1)$) -| ($(#3.west)+(180:#1)$) |- ($(cf.west |- #3.south)+(-90:#1)$);
}

%group top-bottom borders
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - top left node
%#3 - bottom right node
%#4 - filling color
\newcommand{\implicantdaltbaix}[4][0]{
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(cf.south -| #2.west)+(180:#1)$) |- ($(#2.south)+(-90:#1)$) -| ($(cf.south -| #3.east)+(0:#1)$);
    \draw[rounded corners=3pt, fill=#4, opacity=0.3] ($(rf.north -| #2.west)+(180:#1)$) |- ($(#3.north)+(90:#1)$) -| ($(rf.north -| #3.east)+(0:#1)$);
}

%group corners
%#1 - Optional. Space between node and grouping line. Default=0
%#2 - filling color
\newcommand{\implicantcantons}[2][0]{
    \draw[rounded corners=3pt, opacity=.3] ($(rf.east |- 0.south)+(-90:#1)$) -| ($(0.east |- cf.south)+(0:#1)$);
    \draw[rounded corners=3pt, opacity=.3] ($(rf.east |- 8.north)+(90:#1)$) -| ($(8.east |- rf.north)+(0:#1)$);
    \draw[rounded corners=3pt, opacity=.3] ($(cf.west |- 2.south)+(-90:#1)$) -| ($(2.west |- cf.south)+(180:#1)$);
    \draw[rounded corners=3pt, opacity=.3] ($(cf.west |- 10.north)+(90:#1)$) -| ($(10.west |- rf.north)+(180:#1)$);
    \fill[rounded corners=3pt, fill=#2, opacity=.3] ($(rf.east |- 0.south)+(-90:#1)$) -|  ($(0.east |- cf.south)+(0:#1)$) [sharp corners] ($(rf.east |- 0.south)+(-90:#1)$) |-  ($(0.east |- cf.south)+(0:#1)$) ;
    \fill[rounded corners=3pt, fill=#2, opacity=.3] ($(rf.east |- 8.north)+(90:#1)$) -| ($(8.east |- rf.north)+(0:#1)$) [sharp corners] ($(rf.east |- 8.north)+(90:#1)$) |- ($(8.east |- rf.north)+(0:#1)$) ;
    \fill[rounded corners=3pt, fill=#2, opacity=.3] ($(cf.west |- 2.south)+(-90:#1)$) -| ($(2.west |- cf.south)+(180:#1)$) [sharp corners]($(cf.west |- 2.south)+(-90:#1)$) |- ($(2.west |- cf.south)+(180:#1)$) ;
    \fill[rounded corners=3pt, fill=#2, opacity=.3] ($(cf.west |- 10.north)+(90:#1)$) -| ($(10.west |- rf.north)+(180:#1)$) [sharp corners] ($(cf.west |- 10.north)+(90:#1)$) |- ($(10.west |- rf.north)+(180:#1)$) ;
}

%Empty Karnaugh map 4x4
\newenvironment{Karnaugh}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (4,4);
\draw (0,4) -- node [pos=0.7,above right,anchor=south west] {$xy$} node [pos=0.7,below left,anchor=north east] {$zw$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=8.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                       \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $00$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $01$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(r11)| $11$             \& |(12)| \phantom{0} \& |(13)| \phantom{0} \& |(15)| \phantom{0} \& |(14)| \phantom{0} \&                     \\
|(r10)| $10$             \& |(8)|  \phantom{0} \& |(9)|  \phantom{0} \& |(11)| \phantom{0} \& |(10)| \phantom{0} \&                     \\
|(rf) | \phantom{00}   \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 2x4
\newenvironment{Karnaughvuit}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (4,2);
\draw (0,2) -- node [pos=0.7,above right,anchor=south west] {$xy$} node [pos=0.7,below left,anchor=north east] {$z$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=4.center,
        ampersand replacement=\&] at (0.5,0.5)
{
                      \& |(c00)| $00$         \& |(c01)| $01$         \& |(c11)| $11$         \& |(c10)| $10$         \& |(cf)| \phantom{00} \\
|(r00)| $0$             \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \& |(3)|  \phantom{0} \& |(2)|  \phantom{0} \&                     \\
|(r01)| $1$             \& |(4)|  \phantom{0} \& |(5)|  \phantom{0} \& |(7)|  \phantom{0} \& |(6)|  \phantom{0} \&                     \\
|(rf) | \phantom{00}  \&                    \&                    \&                    \&                    \&                     \\
};
}%
{
\end{tikzpicture}
}

%Empty Karnaugh map 2x2
\newenvironment{Karnaughquatre}%
{
\begin{tikzpicture}[baseline=(current bounding box.north),scale=0.8]
\draw (0,0) grid (2,2);
\draw (0,2) -- node [pos=0.7,above right,anchor=south west] {$x$} node [pos=0.7,below left,anchor=north east] {$y$} ++(135:1);
%
\matrix (mapa) [matrix of nodes,
        column sep={0.8cm,between origins},
        row sep={0.8cm,between origins},
        every node/.style={minimum size=0.3mm},
        anchor=2.center,
        ampersand replacement=\&] at (0.5,0.5)
{
          \& |(c00)| $0$          \& |(c01)| $1$  \\
|(r00)| $0$ \& |(0)|  \phantom{0} \& |(1)|  \phantom{0} \\
|(r01)| $1$ \& |(2)|  \phantom{0} \& |(3)|  \phantom{0} \\
};
}%
{
\end{tikzpicture}
}

%Defines 8 or 16 values (0,1,X)
\newcommand{\contingut}[1]{%
\foreach \x [count=\xi from 0]  in {#1}
     \path (\xi) node {$\x$};
}

%Places 1 in listed positions
\newcommand{\minterms}[1]{%
    \foreach \x in {#1}
        \path (\x) node {1};
}

%Places 0 in listed positions
\newcommand{\maxterms}[1]{%
    \foreach \x in {#1}
        \path (\x) node {0};
}

%Places X in listed positions
\newcommand{\indeterminats}[1]{%
    \foreach \x in {#1}
        \path (\x) node {X};
}

\begin{document}

\vspace{-10mm}
\maketitle

\tableofcontents
\newpage

\section{Analogico e digitale}

\subsection{Analogico}
Un \textbf{segnale analogico} è un segnale (tipicamente di natura elettrica) che segue in modo analogo l'andamento di una grandezza di riferimento (una grandezza fisica).\\ Pertanto varia in modo continuo (con continuità) nel tempo (senza interrruzioni) e ha caratteristiche analoghe alla grandezza di riferimento.\\
Per trasformare un segnale analogico in uno digitale è necessario impiegare un \textbf{trasduttore}, come per convertire un segnale di variazione (come la temperatura) in un segnale elettrico.

\subsection{Digitale}
Un \textbf{segnale digitale} (o \textbf{discreto}) viene espresso attraverso una sequenza di \textbf{simboli} di un \textbf{alfabeto finito}.\\
Un modo per rappresentare un segnale digitale composto da \(0\) e \(1\) è quello di associare un valore di tensione al valore \(1\) e uno al valore \(0\), assicurandosi che siano ben distinti e identificabili.\\
L'\textbf{ordine di un alfabeto} costituisce il numero di simboli che si possono impiegare per rappresentare un segnale digitale.

\vspace{1em}
\noindent
\textbf{Osservazione}: Negli ultimi 30-40 anni si è assistito a un passaggio
graduale dai sistemi analogici ai sistemi digitali. È possibile, infatti, codificare un segnale analogico mediante un segnale digitale, attraverso la tecnica del campionamento.

\subsection{Teorema del campionamento}
Per trasformare un segnale analogico in uno digitale è necessario campionare il segnale, ovvero rilevare il valore del segnale analogico ad intervalli di tempo regolari. La frequenza con cui avvengono i campionamenti prende il nome di \textbf{frequenza di campionamento}. Tanto più alta sarà la frequenza di campionamento tanto maggiore sarà la precisione di rappresentazione digitale del segnale analogico corrispondente.\\
Dopo aver ottenuto la successione di valori di campionamento è possibile ricostruire il segnale analogico per mezzo di quello digitale.\\
Se la \textbf{frequenza di campionamento} è stata sufficientemente alta, ovvero
\[f_c > 2 \cdot B\]
\textbf{maggiore del doppio della larghezza di banda del segnale analogico originario}, allora è possibile ricostruire il segnale senza ambiguità.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che la \textbf{larghezza di banda} di un segnale è l'\textbf{insieme delle frequenze} di cui è composto il segnale. Non solo, ma il segnale analogico che si otterrà attraverso la trasformazione inversa (digitale - analogico), a seguito di un precedente campionamento, sarà indistinguibile dal segnale analogico di partenza se la frequenza adottata corrisponde a quella di Nyquist.

\vspace{1em}
\noindent
\textbf{Osservazione}: Per la rappresentazione di un segnale \textbf{ad alta fedeltà} è necessario avere una larghezza di banda maggiore, dai \(20\)Hz ai \(22\)KHz. Mentre per una normale conversazione telefonica è necessaria una larghezza di banda dai \(300\)Hz ai \(3400\)Hz.\\
L'elettronica che gestisce i segnali digitali è molto più conveniente rispetto a quella impiegata per gestire i segnali analogici.

\subsection{Rumore}
Nei sistemi reali, al segnale analogico si sovrappone sempre un segnale di \textbf{rumore} (ovvero tutto ciò che \textbf{non è segnale}). Nel caso dei circuiti elettronici chiusi, secondo la legge di \textbf{Lenz}, ogni variazione di campo elettromagnetico è rumore per il segnale elettrico del circuito stesso.\\
Il più comune dei rumori è quello \textbf{termico}: l'agitazione delle particelle atomiche dovuta al calore induce del rumore.\\
I rumori elettromagnetici possono essere risolti ponendo il circuito interessato all'interno di uno schermo chiuso conduttore, ovvero la \textbf{gabbia di Faraday}: è quello che accade negli ospedali all'interno delle stanze di misurazione molto precisa, come la T.A.C..\\
Il rumore termico, invece, è molto difficile da arginare, in quanto non si ha sempre la disponibilità (fatta eccezione per casi particolari) di lavorare a \(-273,15 ^\circ\)C, ovvero in corrispondenza dello \textbf{\(0\) assoluto}.\\
Tuttavia, quando un segnale analogico viene \textbf{inquinato} dal rumore, è impossibile eliminare a questo stadio tale inquinamento; infatti, l'inquinamento da rumore è un fenomeno che presenta un carattere di \textbf{irreversibilità} nei segnali analogici.\\
L'unico modo per poter arginare il problema dell'inquinamento da rumore è quello di aumentare il \textbf{rapporto segnale-disturbo}. Pertanto, si dovrà lavorare con segnale più consistenti, anche se questo determina sempre un aumento della complessità (e del costo) della circuiteria a disposizione.

\subsubsection{Rumore nei segnali digitali}
Se si usano i segnali digitali, il segnale può essere ricostruito in modo perfetto, anche se è stato inquinato dal rumore (a meno che il segnale di rumore non sia troppo forte).\\
Infatti, nel mondo digitale, l'inquinamento da rumore non è irreversibile. Nel caso di una onda quadra inquinata da rumore, per esempio, calcolando la media delle variazioni del segnale determinate dal rumore, se essa è superiore o inferiore ad un certo valore si può discernere se codificare il segnale come \(0\), oppure \(1\).\\
La percezione del rumore, quindi, nei segnali digitali è diversa rispetto a quella dei segnali analogici. Infatti, a differenza dei \textbf{segnali analogici}, in cui \textbf{il rumore si sovrapponeva costantemente a tutto il segnale}, alterandolo in maniera irreversibile, \textbf{nei sistemi digitali è sempre possibile ricostruire il segnale originario}, con l'aggiunta di una probabilità più o meno elevata di incorrere in un errore di codifica (risolvibile con algoritmi correttori): taluno costituisce un primo grande vantaggio dei sistemi digitali.

\subsection{L'importanza dell'alfabeto binario}
Tutti gli alfabeti con cui operano i sistemi digitali hanno \textbf{ordine 2}. Questo per due motivi:
\begin{enumerate}
    \item Da un punto di vista concettuale, esiste l'\textbf{algebra booleana} estremamente efficiente e performante.
    \item Da un punto di vista tecnico-pratico, se si dovesse operare con alfabeti con ordine maggiore di \(2\), aumenterebbe rovinosamente la \textbf{temperatura di esercizio} dei sistemi digitali. Infatti, nei circuiti elettronici sono presenti elementi attivi e passivi.\\
    Gli elementi passivi (che seguono le consuete regole dell'elettronica) sono
    \begin{itemize}
        \item \textbf{resistenze}
        \item \textbf{induttanze}
        \item \textbf{capacità}
    \end{itemize}
    Mentre gli elementi attivi sono i \textbf{transistors}, i quali vengono integrati in piccolissime piastrine di silicio. Le loro caratteristiche sono completamente diverse rispetto a quelle degli elementi passivi. La ragione dell'ordine binario degli alfabeti di codifica dei sistemi digitali è da ricercarsi nel funzionamento del transistor.

    \def\CalcC#1{
    \coordinate (base) at (#1.B);
    \coordinate (collector) at (#1.C);
    \coordinate (emitter) at (#1.E);
    \draw (barycentric cs:base=0.32,collector=0.5,emitter=0.5) circle [radius=14pt];
    }

    % Contenitore per immagini
    \begin{figure}[H]
        \centering
            \begin{circuitikz}
                \draw (0,0) node[npn] (name) {}
                (name.base) node[anchor=east] {B}
                (name.collector) node[anchor=south] {C}
                (name.emitter) node[anchor=north] {E};
                \CalcC{name}
            \end{circuitikz}
        \caption{Transistor}
        \label{fig:transistor}
    \end{figure}


    Questo componente elettronico attivo è un dispositivo che comanda un flusso di corrente tra \textbf{collettore} ed \textbf{emettitore} attraverso un elettrodo che prende il nome di \textbf{base}. Se la corrente di base è pressoché nulla, allora si ha una \textbf{interdizione} (non passa corrente), mentre se la corrente di base è significativamente maggiore di \(0\), allora si ha \textbf{conduzione piena (o saturazione)}.\\
    Pertanto, un transistor, in un dato istante, si può trovare solamente in uno di due stati:
    \begin{itemize}
        \item Se la corrente è massima e la tensione è nulla (\textbf{saturazione}) si ottiene il valore logico \(0\).

        % Contenitore per immagini
        \noindent
        \begin{figure}[H]
            \centering
                \begin{circuitikz}
                    \draw[line width=0.6pt,black,-stealth](-1.5,1.2)--(-1.5,-1.2) node[anchor=north west]{};
                    \filldraw[black] (-2.4,0.2) circle (0pt) node[anchor=north] {$I = max$};

                    \draw[line width=0.6pt,black,-stealth](1,-1.2)--(1,1.2) node[anchor=north west]{};
                    \filldraw[black] (1.8,0.2) circle (0pt) node[anchor=north] {$V = 0$};

                    \draw (0,0) node[npn] (name) {}
                    (name.base) node[anchor=east] {B}
                    (name.collector) node[anchor=south] {C}
                    (name.emitter) node[anchor=north] {E};
                    \CalcC{name}
                \end{circuitikz}
            \caption{Transistor in saturazione}
            \label{fig:transistor}
        \end{figure}

        \item Se la corrente è nulla e la tensione è massima (\textbf{interdizione})  si ottiene il valore logico \(1\).

        % Contenitore per immagini
        \noindent
        \begin{figure}[H]
            \centering
                \hspace{2.3em}
                \begin{circuitikz}
                    \draw[line width=0.6pt,black,-stealth](-1.5,1.2)--(-1.5,-1.2) node[anchor=north west]{};
                    \filldraw[black] (-2.2,0.2) circle (0pt) node[anchor=north] {$I = 0$};

                    \draw[line width=0.6pt,black,-stealth](1,-1.2)--(1,1.2) node[anchor=north west]{};
                    \filldraw[black] (2,0.2) circle (0pt) node[anchor=north] {$V = max$};

                    \draw (0,0) node[npn] (name) {}
                    (name.base) node[anchor=east] {B}
                    (name.collector) node[anchor=south] {C}
                    (name.emitter) node[anchor=north] {E};
                    \CalcC{name}
                \end{circuitikz}
            \caption{Transistor in saturazione}
            \label{fig:transistor}
        \end{figure}

    \end{itemize}
    La temperatura di esercizio viene determinata dalla seguente formula:
    \[P = V \cdot I\]
    per cui se il transistor è in saturazione, la corrente è massima e la tensione è nulla, quindi la potenza è nulla. Mentre se il transistor è in interdizione, la corrente è nulla e la tensione è massima, quindi la potenza è ancora una volta nulla.\\
    Per cui la potenza dissipata dai transistors è sempre nulla in questi due stati, ma assume un valore non nullo nel passaggio dall'uno all'altro stato.\\
    A queste potenze deve aggiungersi anche la dissipazione di calore delle resistenze, che può essere variabile.\\
    Se si aggiungesse un terzo stato logico, ad esso bisognerebbe attribuire un valore di tensione e uno di corrente, necessariamente diversi da \(0\), per cui anche la potenza dissipata sarà diversa da \(0\) e questo aumenterebbe la temperatura di esercizio.\\
    Ciò accadrebbe per ogni stato logico diverso dai due del sistema binario che si aggiungerebbe se si avesse un alfabeto di codifica di ordine \(> 2\). E la dissipazione, per quanto piccola, deve essere moltiplicata per il numero di transistors che si trovano in questo ipotetico stato che, in un moderno chip, sono \textbf{miliardi}: pertanto la dissipazione di calore non sarebbe trascurabile.
\end{enumerate}

\subsection{Vantaggi sistemi digitali}
Come si è potuto appurare, vi sono molti vantaggi nell'adottare sistemi digitali in luogo di quelli analogici:
\begin{enumerate}
    \item Minor sollecitazione al rumore
    \item Maggior affidabilità (arginando la \textbf{deriva termica})
    \item Presenza dell'algebra booleana
    \item Minori dissipazioni di potenza
\end{enumerate}
I dispositivi analogici, invece, lavorano con la dissipazione di potenza, sempre ed in ogni stato; questo costituisce un problema, in quanto dissipazione di potenza significa scaldare per \textbf{effetto Joule}. Se la temperatura si innalza eccessivamente (\textbf{deriva termica}) il componente (transistor) si brucia.\\
Ciò non accade (o accade molto raramente) nella circuiteria digitale, in quanto i dispositivi attivi dei circuiti non dissipano potenza a riposo.

\newpage
\begin{center}
    5 Ottobre 2021
\end{center}

\subsection{Riassunto}
Ci sono due diversi sistemi in utilizzo al giorno d'oggi, analogico e digitale, anche se negli ultimi \(40\) anni si è progressivamente passati dai sistemi analogici a quelli digitali.\\
È possibile passare da un segnale analogico ad uno digitale attraverso la tecnica del campionamento. Il teorema di campionamento afferma che se la frequenza di campionamento è almeno doppia della larghezza di banda del segnale da campionare, allora il segnale digitale risultante sarà indistinguibile da quello originario.\\
Il segnale di rumore, inoltre, è sempre presente nei sistemi reali, e si sovrappone in maniera inevitabile al segnale di partenza, inquinandolo; per cercare di far fronte a tale problema bisogna aumentare il rapporto \textbf{segnale-rumore}.\\
Nei sistemi digitali, invece, il segnale di rumore non altera il valore del segnale di partenza, ma può indurre a degli errori di ricostruzione (che possono essere risolti con dei sistemi di correzione degli errori).\\
I motivi per cui i sistemi digitali sono basati su una logica binaria sono svariati:
\begin{enumerate}
    \item La presenza e l'efficienza dell'algebra booleana;
    \item Migliore affidabilità, in quanto meno soggetti alla deriva termica, in quanto presentano una dissipazione nulla a riposo;
    \item Meno soggetti al segnale di rumore e maggiore facilità di ricostruzione del segnale;
    \item Nei sistemi elettronici sono presenti dispositivi passivi e attivi, ovvero i transistors, i quali non dissipano potenza a riposo, proprio perché a riposo si possono trovare in due soli stati, in cui la corrente è massima e la tensione è nulla, oppure la corrente è nulla e la tensione è massima.\\
    Se si avesse un terzo stato logico, infatti, il transistor che si trovasse su quello stato dissiperebbe potenza a riposo, per cui ammettendo che anche solo \(\frac{1}{3}\) dei transistor totali si trovi su questo stato, la dissipazione di calore sarebbe considerevole e non trascurabile: pertanto, si necessiterebbe di sistemi di raffreddamento molto costosi per un corretto funzionamento del sistema.\\
    Nei circuiti analogici (come gli amplificatori) i transistors devono essere polarizzati e quindi presentano una corrente di base tale da dissipare potenza anche a riposo e questo determina un aumento della temperatura di esercizio.\\
    Nei transistors, infatti, è presente una corrente di base chiamata \textbf{corrente di deriva termica \(I_{C_{v_{0}}}\)} che tende ad aumentare esponenzialmente all'aumentare della temperatura di esercizio; aumentando la corrente, aumenta la dissapazione e ciò alla \textbf{deriva termica}, e quindi alla rottura del transistors.
\end{enumerate}

\newpage
\section{Algebra booleana}
Tutta la tecnologia elettronica fa uso dell'algebra booleana che, grazie agli studi di Shannon, è stato dimostrato essere fondamentale nella progettazione digitale.\\
L'ideazione dell'algebra booleana è da attribuire a \textbf{George Boole}, ovvero un logico, mentre essa verrà proficuamente impiegata, come anticipato, da \textbf{Claude Elwood Shannon} per la prima volta come strumento per la progettazione logica di circuiti composti da \textbf{relé}, ovvero un interruttore comandato da correnti.\\
Shannon, infatti, si accorse che l'algebra booleana poteva essere utilizzata per la gestione di una rete complessa di interrutori, tale da rendere tale operazione molto più semplificata.

\subsection{Costanti booleane}
Le due costanti booleane sono \textbf{vero} e \textbf{falso}, corrispondenti ai due soli valori logici contemplati nei sistemi binari (\(0\), ovvero il valore basso di tensione, in generale) e (\(1\), ovvero il valore alto di tensione, in generale).

\subsection{Calcolo funzionale di verità}
Per la risoluzione di un problema logico è necessario tenere conto di una serie di condizioni che devono essere verificate affinché possa essere prodotto un risultato logico (o pratico); in un problema concreto, si potrebbe pensare di disporre di una serie di sensori atti ciascuno a rilevare il valore logico di una certa proposizione.\\
L'algebra booleana viene usata, invece, per manipolare delle equazioni logiche composte da valori anch'essi di natura logica.\\
Il modo per rappresentare il valore logico di tali proposizioni è costituito dalle \textbf{variabili binarie booleane}; il metodo che permette di manipolare tali variabili e di assegnare ad esse un valore di verità è conosciuto come \textbf{calcolo funzionale di verità}.\\
Per ogni affermazione assertiva quale
\[\text{\quotes{La cintura di sicurezza è allacciata}} \rightarrow B_{L}\]
si attribuisce il valore della proposizione ad una variabile booleana.\\
Per poter tenere conto della composizione di funzioni di verità si usano dei \textbf{connettivi logici}, come l'\textbf{and} (\(\cap\)) che produce un valore positivo se e solo se entrambe le proposizioni elementari sono vere:
\[A \cap B\]
Un altro connettivo logico è l'\textbf{or} (\(\cup\)) che produce un valore positivo se almeno una delle due proposizioni elementari è vera:
\[A \cup B\]
Il modo per ottenere il risultato logico di una funzione composta di verità è rappresentato dalle tabelle di verità.

\subsection{Tavole di verità}
Di seguito la tavola di verità dei principali connettivi:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{>{\hsize=0.01\textwidth}PP|PPPPPP}
         $ $ & $ $ & $\text{AND}$ & $\text{OR}$ & $\text{XOR}$ & $\text{XNOR}$ & $\text{NOR}$ & $\text{NAND}$\\
         $A$ & $B$ & $A \cap B$ & $A \cup B$ & $A \oplus B$ & $A \equiv B$ & $A \downarrow B$ & $A \vert B$\\
         \hline
         $F$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$\\
         $F$ & $V$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$\\
         $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$\\
         $V$ & $V$ & $V$ & $V$ & $F$ & $V$ & $F$ & $F$\\
    \end{tabularx}
    \caption{Tavola di verità dei principali connettivi}
    \label{tab:tavola_verità_connettivi}
\end{table}

\vspace{1em}
\noindent
I primi quattro connettivi logici sono molto comuni, mentre gli ultimi due sono fondamentali, perché sono in grado di ricostruire ciascuna delle \(2^4 = 16\) possibili combinazioni di \(V\) e \(F\).\\
Si tenga presente che ciascun connettivo logico presenta un suo corrispettivo, chiamato \textbf{porta logica}. Pertanto, con le porte logiche \textbf{NOR} e \textbf{NAND} (le cui funzioni booleane associate sono le ultime due della Tabella \ref{tab:tavola_verità_connettivi}) è possibile costruire qualunque funzione logica.\\
L'equazione logica si ottiene combinando fra di loro tutte le variabili logiche prese in considerazione attraverso i connettivi logici, pertanto:
\[C \equiv A \cap G \cap \left[\left(S_L \cap \overline{B_L}\right) \cup \left(S_R \cap \overline{B_R} \right) \right]\]
Per costruire tutte le possibili combinazioni di \(V\) e \(F\) su \(4\) posti basta eseguire un semplice calcolo
\[2^4 = 16\]
Infatti, in generale, se si dispone di \(n\) bit il numero delle possibili \(n\)-ple binarie è pari a \[2^n\]

\subsection{Connettivi binari}
Nella Tabella \ref{tab:tavola_verità_connettivi} sono stati individuati sei connettivi logici, AND, OR, XOR e XNOR, NOR e NAND, che sono i più interessanti. Poiché per ciascuna coppia di valori delle variabili ci sono due possibilità, come si è detto vi sono \(4\) righe, e quindi \(2^4 = 16\) connettivi logici, come illustrato di seguito:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{>{\hsize=0.01\textwidth}PP|PPPPPPPP>{\hsize=0.035\textwidth}PPPPPPPP}
         $ $ & $ $ & $0$ & $1$ & $2$ & $3$ & $4$ & $5$ & $6$ & $7$ & $8$ & $9$ & $10$ & $11$ & $12$ & $13$ & $14$ & $15$\\
         \hline
         $ $ & $ $ & $ $ & $\hspace{-0.7em} \text{AND}$ & $ $ & $ $ & $ $ & $ $ & $\hspace{-0.75em} \text{XOR}$ & $\hspace{-0.45em}  \text{OR}$ & $\hspace{-0.5em} \text{NOR}$ & $\hspace{-1em} \text{XNOR}$ & $ $ & $ $ & $ $ & $ $ & $\hspace{-0.75em} \text{NAND}$ & $ $\\
         $A$ & $B$ & $ $ & $\cap$ & $ $ & $ $ & $ $ & $ $ & $\oplus$ & $\cup$ & $\downarrow$ & $\equiv$ & $ $ & $\subset$ & $ $ & $\supset$ & $\hspace{0.4em} \vert$ & $ $\\
         \hline
         $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$\\
         $F$ & $V$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$\\
         $V$ & $F$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$\\
         $V$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$\\
    \end{tabularx}
    \caption{Tavola di verità dei $16$ connettivi binari}
    \label{tab:tavola_verità_connettivi_binari}
\end{table}

\noindent
Due ulteriori connettivi logici sono quelli di implicazione \(A \subset B\) e \(A \supset B\) (ovvero B implica A e A implica B).\\
Si noti che
\[A \equiv B \leftrightarrow A \supset B \text{ e } A \subset B\]
ovvero
\[(A \equiv B) \equiv (A \supset B) \cap (A \subset B)\]
e si può verificare attraverso le tabelle di verità.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{2}
    \begin{tabularx}{\textwidth}{cc||P|P|P|c}
         $A$ & $B$ & $A \supset B$ & $A \subset B$ & $(A \supset B) \cap (A \subset B)$ & $A \equiv B $\\
         \hline
         $F$ & $F$ & $V$ & $V$ & $V$ & $V$\\
         $F$ & $V$ & $V$ & $F$ & $F$ & $F$\\
         $V$ & $F$ & $F$ & $V$ & $F$ & $F$\\
         $V$ & $V$ & $V$ & $V$ & $V$ & $V$\\
    \end{tabularx}
    \caption{Tabella di verità dell'implicazione}
    \label{tab:tabella_verità_implicazione}
\end{table}

\subsection{Insiemi minimi di connettivi}
Come si è visto nella Tabella \ref{tab:tabella_verità_implicazione}, alcuni connettivi binari possono essere espressi sulla base di altri connettivi; in questo caso la XNOR viene espressa in funzione di \(\supset\), \(\subset\) e \(\cap\).\\
Si presenta quindi spontanea la domanda di quali siano i connettivi idonei a esprimere tutti gli altri, e quale sia l’insieme minimo tra essi che permette di esprimere tutte le \(16\) combinazioni della Tabella \ref{tab:tavola_verità_connettivi_binari}.\\
Si consideri, ad esempio, l’insieme dei connettivi che contiene solo \(\cup\) e \(\cap\), ovvero OR e AND. I casi in cui sia A che B sono falsi sono chiaramente situazioni critiche; infatti dalla Tabella \ref{tab:tavola_verità_connettivi} si osserva che sia \(A \cup B\) che \(A \cap B\) sono ambedue falsi; quindi, sulla base di questi due soli connettivi, non e possibile esprimere connettivi che assumono valore vero quando A e B sono falsi.\\
Per poter esprimere anche questi casi, e necessario arricchire l’insieme introducendo anche il connettivo NOT. Ecco allora che l’insieme dei connettivi AND, OR, NOT e un insieme sufficiente per ricostruire tutti gli altri connettivi, come si può verificare dalla tavola di verità in Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT}.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{8pt}
    \renewcommand{\arraystretch}{2}
    \begin{tabularx}{\textwidth}{|c|l|>{\hsize=0.066\textwidth}P||c|l|>{\hsize=0.066\textwidth}P|}
    \hline
         $FFVV$ & $A$ & $ $ & $FFVV$ & $A$ & $ $\\
         $FVFV$ & $B$ & $ $ & $FVFV$ & $B$ & $ $\\
         \hline
         \hline
         $FFFF$ & $f_{0} \equiv A \cap \overline{A}$ & $ $ & $VFFF$ & $f_{8} \equiv \overline{A \cup B}$ &\text{NOR}$ $\\
         $FFFV$ & $f_{1} \equiv A \cap B $ & $\text{AND}$ & $VFFV $ & $f_{9} \equiv (A \cup \overline{B}) \cap (\overline{A} \cup B)$ & $\text{XNOR}$\\
         $FFVF$ & $f_{2} \equiv A \cap \overline{B} $ & $ $ & $VFVF $ & $\hspace{1.2em} \equiv (\overline{A} \cap \overline{B}) \cup (A \cap B)$ & $ $\\
         $FFVV$ & $f_{3} \equiv A $ & $ $ & $VFVV$ & $ f_{10} \equiv \overline{B}$ & $ $\\
         $FVFF$ & $f_{4} \equiv \overline{A} \cap B $ & $ $ & $VVFF $ & $f_{11} \equiv A \cup \overline{B}$ & $\subset$\\
         $FVFV$ & $f_{5} \equiv B $ & $ $ & $VVFV$ & $f_{12} \equiv \overline{A}$ & $ $\\
         $FVVF$ & $f_{6} \equiv (A \cap \overline{B}) \cup (\overline{A} \cap B)$ & $\text{XOR}$ & $VVVF$ & $f_{13} \equiv \overline{A} \cup B$ & $\supset$\\
         $ $ & $\hspace{1.2em} \equiv (\overline{A} \cup \overline{B}) \cap (A \cup B) $ & $ $ & $VVVF$ & $f_{14} \equiv \overline{A \cap B} $ & $\text{NAND}$\\
         $FVVV$ & $f_{7} \equiv A \cup B $ & $\text{OR}$ & $VVVV$ & $f_{15} \equiv A \cup \overline{A} $ & $ $\\
         \hline
    \end{tabularx}
    \caption{I \(16\) connettivi binari espressi mediante AND, OR, NOT}
    \label{tab:connettivi_espressi_con_AND_OR_NOT}
\end{table}

\noindent
\textbf{Osservazione}: \textbf{Ogni connettivo binario} si può esprimere, pertanto, tramite combinazione di altri connettivi binari.\\
Infatti, come si è detto, i connettivi \textbf{NAND} e \textbf{NOR} sono \textbf{connettivi universali} e quindi sono in grado di rappresentare tutti gli altri connettivi binari.\\
Si noti, infatti, come utilizzando \textbf{AND}, \textbf{OR} e \textbf{NOT} si possono costruire tutte e \(16\) le possibili funzioni logiche.

\vspace{1em}
\noindent
Quasi tutti i connettivi da \(f_0, ..., f_{15}\) possono essere costruiti usando solo il connettivo \(\cup\) oppure solo il connettivo \(\cap\) (con l’eventuale negazione). L’unica eccezione è costituita dai connettivi \(f_6\) ed \(f_9\), che necessitano l’impiego contemporaneo di \(\cup\) e \(\cap\).\\
L’espressione risolutiva per la \(f_9\) si può ricavare tenendo conto dell'equivalenza messa in evidenza nella Tabella \ref{tab:tabella_verità_implicazione} e del fatto che \(A \supset B \equiv \overline{A} \cup B\) e \(A \subset B \equiv A \cup \overline{B}\), e dunque la \(f_9 \equiv (A \cup \overline{B}) \cap (\overline{A} \cup B)\), mentre la \(f_6\) è la sua negazione.\\
È interessante notare, inoltre, che ci sono due modi per realizzare \(f_6\) e \(f_9\), combinando assieme \(\cup\) e \(\cap\), ma a ben guardare un po’ tutti i connettivi possono essere espressi in modi alternativi: per esempio \(f_0 \equiv A \cap \overline{A}\) ma anche \(f_0 \equiv \overline{A \cup \overline{A}}\), e così via.\\
Tutto ciò deriva dalla circostanza che l’insieme dei connettivi AND, OR, NOT non costituisce l'insieme minimo di connettivi atti ad ottenere tutti gli altri tramite combinazione dei propri elementi; il connettivo AND può, infatti, essere espresso in funzione del connettivo OR (e viceversa); a tal riguardo vale l’importante \textbf{Teorema di De Morgan} (§ \ref{sec:teorema_de_morgan}).

\subsection{Teorema di De Morgan}
\label{sec:teorema_de_morgan}
Si espone di seguito il teorema di \textbf{De Morgan}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{TEOREMA DI DE MORGAN}}\\
    \parbox{\linewidth}{Si verifica che
    \[\overline{A \cup B} = \overline{A} \cap \overline{B}\]
    così come
    \[\overline{A \cap B} = \overline{A} \cup \overline{B}\]
    \vspace{-3mm}}\\
    \hline
\end{tabularx}
\vspace{1em}

\noindent
Si può dimostrare tale teorema attraverso il \textbf{metodo dell'induzione perfetta}, quindi compilando una tabella di verità per verificare l'effettiva veridicità dell'enunciato.

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{lr}
        {
            \noindent
            \hspace{-2.2em}
            \setlength{\tabcolsep}{6pt}
            \begin{tabularx}{0.48 \textwidth}{cc||c|c|c||P|P||}
                 $A$ & $B$ & $\overline{A}$ & $\overline{B}$ & $\overline{A} \cap \overline{B}$ & $A \cup B$ & $\overline{A \cup B}$\\
                 \hline
                 $F$ & $F$ & $V$ & $V$ & $V$ & $F$ & $V$\\
                 $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $F$\\
                 $V$ & $F$ & $F$ & $V$ & $F$ & $V$ & $F$\\
                 $V$ & $V$ & $F$ & $F$ & $F$ & $V$ & $F$\\
            \end{tabularx}
        }
        &
        {
            \noindent
            \hspace{-2.6em}
            \setlength{\tabcolsep}{6pt}
            \begin{tabularx}{0.48 \textwidth}{cc||c|c|c||P|P||}
                 $A$ & $B$ & $\overline{A}$ & $\overline{B}$ & $\overline{A} \cup \overline{B}$ & $A \cap B$ & $\overline{A \cap B}$\\
                 \hline
                 $F$ & $F$ & $V$ & $V$ & $V$ & $F$ & $V$\\
                 $F$ & $V$ & $V$ & $F$ & $V$ & $F$ & $V$\\
                 $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $V$\\
                 $V$ & $V$ & $F$ & $F$ & $F$ & $V$ & $F$\\
            \end{tabularx}
        }
    \end{tabularx}
    \caption{Dimostrazione del teorema di De Morgan con tabelle di verità}
    \label{tab:dimostrazione_teorema_de_morgan}
\end{table}

\vspace{1em}
\noindent
Il teorema di \textbf{De Morgan} si può generalizzare al caso di più di due variabili. Si verifica, infatti, che la negazione di un connettivo di più variabili si ottiene negando ogni variabile e scambiando tra di loro i due operatori \(\cup\) e \(\cap\).\\
In termini formali si ha
\[\overline{F}(x_1, x_2, ..., x_n)[\cup, \cap]) = F(\overline{x_1}, \overline{x_2}, ..., \overline{x_n})[\cap, \cup]\]
I connettivi che legano le variabili non negate si esprimono allora come
\[A \cap B \equiv \overline{\overline{A} \cup \overline{B}} \hspace{0.5em} \text{ e } \hspace{0.5em} A \cup B \equiv \overline{\overline{A} \cap \overline{B}}\]
Poiché l’AND può essere espresso in funzione di OR e NOT, quest’ultimo insieme è da solo sufficiente per coprire tutti i connettivi formulati in Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT} che sono riportati nella prima colonna della Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT_OR_NOT_AND_NOT}. Per farlo bisogna sostituire tutti i simboli \(\cap\) con l'espressione \(A \cap B \equiv \overline{\overline{A} \cup \overline{B}}\); così facendo si ottiene la prima colonna della Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT_OR_NOT_AND_NOT}.\\
Lo stesso ragionamento può essere fatto per l’OR, che può essere espresso in funzione di AND e NOT; per farlo bisogna sostituire tutti i simboli \(\cup\) con l'espressione \(A \cup B \equiv \overline{\overline{A} \cap \overline{B}}\); così facendo si ottiene la seconda colonna della Tabella \ref{tab:connettivi_espressi_con_AND_OR_NOT_OR_NOT_AND_NOT}.

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{|P||l|l|l|}
         \hline
         $ $ & \begin{center} AND, OR, NOT \end{center} & \begin{center} OR, NOT \end{center} & \begin{center} AND, NOT \end{center}\\
         \hline
         \hline
         $ $ & $f_0 \equiv A \cap \overline{A}$ & $\overline{\overline{A} \cup A}$ & $A \cap \overline{A}$\\
         AND & $f_1 \equiv A \cap B$ & $\overline{\overline{A} \cup \overline{B}}$ & $A \cap \overline{B}$\\
         $ $ & $f_2 \equiv A \cap \overline{B}$ & $\overline{\overline{A} \cup B}$ & $A \cap \overline{B}$\\
         $ $ & $f_3 \equiv A$ & $A$ & $A$\\
         $ $ & $f_4 \equiv \overline{A} \cap B$ & $\overline{A \cup \overline{B}}$ & $\overline{A} \cap B$\\
         $ $ & $f_5 \equiv B$ & $B$ & $B$\\
         XOR & $f_6 \equiv (A \cap \overline{B}) \cup (\overline{A} \cap B)$ & $\overline{(\overline{A} \cup B)} \cup \overline{(A \cup \overline{B})}$ & $\overline{\overline{(A \cap \overline{B})} \cap \overline{(\overline{A} \cap B)}}$\\
         OR & $f_7 \equiv A \cup B$ & $A \cup B$ & $\overline{\overline{A} \cap \overline{B}}$\\
         NOR & $f_8 \equiv \overline{A \cup B}$ & $\overline{A \cup B}$ & $\overline{A} \cap \overline{B}$\\
         XNOR & $f_9 \equiv (A \cup \overline{B}) \cap (\overline{A} \cup B)$ & $\overline{\overline{(A \cup \overline{B})} \cup \overline{(\overline{A} \cup B)}}$ & $\overline{(\overline{A} \cap B)} \cap \overline{(A \cap \overline{B})}$\\
         $ $ & $f_{10} \equiv \overline{B}$ & $\overline{B}$ & $\overline{B}$\\
         $\subset$ & $f_{11} \equiv A \cup \overline{B}$ & $A \cup \overline{B}$ & $\overline{\overline{A} \cap B}$\\
         $ $ & $f_{12} \equiv \overline{A}$ & $\overline{A}$ & $\overline{A}$\\
         $\supset$ & $f_{13} \equiv \overline{A} \cup B$ & $\overline{A} \cup B$ & $\overline{A \cap \overline{B}}$\\
         NAND & $f_{14} \equiv \overline{A \cap B}$ & $\overline{A} \cup \overline{B}$ & $\overline{A \cap B}$\\
         $ $ & $f_{15} \equiv A \cup \overline{A}$ & $A \cup \overline{B}$ & $\overline{\overline{A} \cap A}$\\
         \hline
    \end{tabularx}
    \caption{I 16 connettivi binari espressi rispettivamente mediante AND, OR, NOT, mediante OR, NOT e mediante AND, NOT}
    \label{tab:connettivi_espressi_con_AND_OR_NOT_OR_NOT_AND_NOT}
\end{table}

\noindent
\textbf{Osservazione}: Quindi non solo è possibile esprimere le \(16\) possibili funzioni logiche attraverso le tre sole funzioni logiche \textbf{AND}, \textbf{OR} e \textbf{NOT}, ma addirittura è possibile farlo solo con \textbf{AND} e \textbf{NOT} o solo con \textbf{OR} e \textbf{NOT}, grazie al teorema di \textbf{De Morgan}.

\newpage
\begin{center}
    6 Ottobre 2021
\end{center}

\subsection{Riassunto}
L'algebra booleana è atta a gestire le combinazioni dei due valori logici VERO e FALSO, mentre i sensori sono gli strumenti pratici che vengono utilizzati per ottenere la validazione di certe condizioni logiche al fine di estrapolarne il corrispettivo valore logico.\\
La combinazione di tali condizioni avviene attraverso i connettivi logici:
\begin{itemize}
    \item AND: Produce il valore VERO se entrambe le condizioni sono vere.
    \item OR: Produce il valore VERO se almeno una delle due condizioni è vera.
    \item XOR: che produce il valore VERO se le due condizioni hanno un diverso valore logico.
\end{itemize}
Naturalmente oltre a queste funzioni vi sono le corrispettive negazioni NAND, NOR e XNOR. Poiché per ciascuna coppia di valori delle variabili è possibile associare solamente due valori, ovvero VERO e FALSO, si possono avere fino a \(2^{4} = 16\) possibili combinazioni; da ciò si evince che, oltre ai connettivi logici principali, ve ne sono anche degli altri che possono essere ottenuti attraverso la combinazioni dei connettivi binari noti, per i quali, al fine di verificare la corretta creazione di una nuova funzione di verità è possibile utilizzare il metodo dell'induzione perfetta.\\
Per poter capire come è possibile creare le \(16\) funzioni logiche non è possibile procedere attraverso la combinazione delle sole funzioni AND e OR, ma deve essere utilizzato anche il NOT. Non solo, ma attraverso il teorema di \textbf{De Morgan} è possibile anche impiegare solamente AND e NOT, oppure OR e NOT per la creazione di tutte le \(16\) possibili funzioni logiche.\\
Ancora una volta, la correttezza di quanto affermato da \textbf{De Morgan} può essere verificata attraverso il metodo dell'\textbf{induzione perfetta}, come si è visto in Tabella \ref{tab:dimostrazione_teorema_de_morgan}.

\subsection{Insieme minimo}
Si osservi che l’insieme minimo che consente di rappresentare tutti i connettivi può essere ulteriormente ridotto al solo connettivo NOR, oppure al solo connettivo NAND. Per farlo è sufficiente esprimere AND, OR e NOT in funzione del solo NOR oppure del solo NAND. Per questo motivo i connettivi NOR e NAND sono chiamati \textbf{connettivi universali}, in quanto da soli sono in grado di creare tutti i \(16\) connettivi logici, come si vede di seguito per la porta NOR:

\begin{itemize}
    \item \(\overline{A} \equiv \overline{A \cup A} \equiv A \downarrow A\)
    \item \(A \cup B \equiv \overline{\overline{A \cup B}} \equiv \overline{A \downarrow B} \equiv (A \downarrow B) \downarrow (A \downarrow B)\)
    \item \(A \cap B \equiv \overline{\overline{A \cap B}} \equiv \overline{\overline{A} \cup \overline{B}} \equiv \overline{A} \downarrow \overline{B} \equiv (A \downarrow A) \downarrow (B \downarrow B)\)
\end{itemize}
E la stessa cosa accade anche per la porta NAND:
\begin{itemize}
    \item \(\overline{A} \equiv \overline{A \cap A} \equiv A | A\)
    \item \(A \cup B \equiv \overline{\overline{A \cup B}} \equiv \overline{\overline{A} \cap \overline{B}} \equiv \overline{A} | \overline{B} \equiv (A | A) | (B | B)\)
    \item \(A \cap B \equiv \overline{\overline{A \cap B}} \equiv \overline{A \vert B} \equiv (A | B) | (A | B)\)
\end{itemize}

\noindent
Tale risultato è straordinario e può avere dei risvolti molti vantaggiosi, specialmente di natura economica, in quanto è possibile impiegare solamente una porta per realizzare un'intera rete logica.

\subsection{Impostazione assiomatica dell'algebra booleana}
Il calcolo booleano costruito in precedenza in forma puramente euristica deve essere rielaborato in forma più rigorosa in modo tale da manipolare complicate espressioni logiche in maniera semiautomatica e più semplificata.\\
Per la costruzione di uno strumento operativo che abbia una infrastruttura logica solida e affidabile è necessario formulare una teoria, di tipo algebrico, che sia ben costituita dal punto di vista formale, ovvero una teoria assiomatica che si articola in una sequenza di assiomi fondamentali.\\
In generale, è possibile affermare che gli \textbf{assiomi} siano delle \textbf{verità primitive, non contestabili, non dimostrabili e date una volta per tutte}.\\
A partire dalle verità primitive si possono costruire (attraverso la tecnica di inferenza o il principio di induzione) delle nuove verità, ovvero i teoremi, e la combinazione di tali strumenti costituisce una \textbf{teoria}.\\
Di seguito si espone la definizione di \textbf{Algebra Booleana}:

% Tabella per le definizione di concetti, etc...
\vspace{1em}
\rowcolors{1}{black!5}{black!5}
\setlength{\tabcolsep}{14pt}
\renewcommand{\arraystretch}{2}
\noindent
\begin{tabularx}{\textwidth}{@{}|P|@{}}
    \hline
    {\textbf{ALGEBRA BOOLEANA}}\\
    \parbox{\linewidth}{Un'Algebra Booleana è un insieme \(\mathcal{B}\) caratterizzato dagli assiomi (univocamente determinati) che vengono esposti di seguito.
    \vspace{3mm}}\\
    \hline
\end{tabularx}

\subsubsection{Assioma 0 (A0) - Leggi di composizione}
Vi sono due leggi di composizione interna di-arie, denominate rispettivamente AND e OR, e una legge di composizione interna unaria, denominata NOT; tali leggi (od \quotes{operatori Booleani}) sono definite come segue:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{l|l|c|P}
         \textbf{Operatore} & \textbf{Nome} & \textbf{Simboli usati} & \textbf{che soddisfa}\\
         \hline
         AND(x, y) & congiunzione & \(x \wedge y\) \hspace{0.5em} o \hspace{0.5em} \(x \cdot y\) & \parbox{\linewidth}{\(x \cdot y = 1\) se \(x = 1, y = 1\)\\ \(x \cdot y = 0\) altrimenti}\\
         OR(x, y) & disgiunzione & \hspace{0.2em} \(x \vee y\) \hspace{0.5 em} o \hspace{0.5em} \(x + y\) & \parbox{\linewidth}{\(x + y = 0\) se \(x = 0, y = 0\)\\ \(x + y = 1\) altrimenti}\\
         NOT(x) & negazione & \(\neg x\) \hspace{1em} o \hspace{1em} \(\overline{x}\) & \parbox{\linewidth}{\(\overline{x} = 0\) se \(x = 1\) \\ \(\overline{x} = 1\) se \(x = 0\)}\\
    \end{tabularx}
    \caption{Leggi di composizione interna dell'Algebra Booleana}
    \label{tab:leggi_composizione_interna}
\end{table}

\noindent
Inoltre, per gli elementi dell'insieme \(\mathcal{B}\) valgono i seguenti assiomi:

\subsubsection{Assioma 1 (A1) - Esistenza}
Esistono due elementi \(x, y \in \mathcal{B}\) tali che \(x \neq y\).

\subsubsection{Assioma 2 (A2) - Chiusura}
Se \(x, y \in \mathcal{B}\) allora \hspace{1em} \(x \cdot y \in \mathcal{B}\), \hspace{1em} \(x + y \in \mathcal{B}\), \hspace{1em} \(\overline{x} \in \mathcal{B}\), \hspace{1em} \(\overline{y} \in \mathcal{B}\).

\subsubsection{Assioma 3 (A3) - Elemento neutro}
Esiste un elemento neutro per la disgiunzione, indicato con \(0\), tale che
\[x + 0 = x\]
Esiste un elemento neutro per la congiunzione, indicato con \(1\), tale che
\[x \cdot 1 = x\]

\subsubsection{Assioma 4 (A4) - Commutatività}
\(\forall x, y \in \mathcal{B}\) valgono le seguenti relazioni:
\[x + y = y + x\]
\[x \cdot y = y \cdot x\]

\subsubsection{Assioma 5 (A5) - Associatività}
\(\forall x, y \in \mathcal{B}\) valgono le seguenti relazioni:
\[x + (y + z) = (x + y) + z\]
\[x \cdot (y \cdot z) = (x \cdot y) \cdot z\]

\subsubsection{Assioma 6 (A6) - Distributività}
\(\forall x, y \in \mathcal{B}\) valgono le seguenti relazioni:
\[x + (y \cdot z) = (x+ z) \cdot (x + z)\]
\[x \cdot (y + x) = (x \cdot y) + (x \cdot z)\]

\subsubsection{Assioma 7 (A7) - Complementarietà}
\(\forall x \in \mathcal{B}\) vale:
\[x \cdot \overline{x} = 0\]
\[x + \overline{x} = 1\]

\vspace{1em}
\noindent
Il più semplice insieme \(\mathcal{B}\) che soddisfa i postulati di cui sopra è rappresentato dalla cosiddetta \textbf{Algebra Booleana a due elementi}, o \textbf{Algebra Binaria}, basata sugli elementi \(0\) e \(1\) e caratterizzata dalle seguenti tre leggi di composizione

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{PPP}
        {
            \setlength{\tabcolsep}{12pt}
            \renewcommand{\arraystretch}{1.7}
            \begin{tabularx}{0.22 \textwidth}{c|cc}
                \(\cdot\) & \(0\) & \(1\)\\
                \hline
                \(0\) & \(0\) & \(0\)\\
                \(1\) & \(0\) & \(1\)\\
            \end{tabularx}
        }
        &
        {
            \setlength{\tabcolsep}{12pt}
            \renewcommand{\arraystretch}{1.7}
            \begin{tabularx}{0.22 \textwidth}{c|cc}
                \(+\) & \(0\) & \(1\)\\
                \hline
                \(0\) & \(0\) & \(1\)\\
                \(1\) & \(1\) & \(1\)\\
            \end{tabularx}
        }
        &
        {
            \setlength{\tabcolsep}{12pt}
            \renewcommand{\arraystretch}{1.7}
            \begin{tabularx}{0.22 \textwidth}{c|cc}
                \(A\) & \(0\) & \(1\)\\
                \hline
                \(\overline{A}\) & \(1\) & \(0\)

            \end{tabularx}
        }\\
        AND & OR & NOT
    \end{tabularx}
    \caption{Le \(3\) leggi di composizione fondamentali}
    \label{tab:tre_leggi_composizione}
\end{table}

\noindent
L’Algebra Booleana a due elementi e quella impiegata per la progettazione delle reti logiche; i suoi due elementi \(1\) e \(0\) corrispondono alle costanti logiche VERO e FALSO (V e F) prima introdotte, e le tre leggi di composizione interna sono rispettivamente AND, OR e NOT e corrispondono ai connettivi precedentemente introdotti nelle tavole di verità. In questo contesto la simbologia che si usa è però diversa; in particolare si osservi che i simboli \(+\) e \(\cdot\) nulla hanno a che vedere con gli stessi simboli usati nel contesto dell’aritmetica.\\
Un altro importante esempio di Algebra Booleana e quello derivante dalla teoria degli insiemi; si consideri un insieme \(S\) e il corrispondente insieme delle parti \(\mathcal{P}(S)\), costituito dall’insieme di tutti i sottoinsiemi costruiti con elementi di \(S\). Allora \(\mathcal{P}(S)\) è un'Algebra Booleana, nella quale sono definite tre leggi di composizione interna date dall’intersezione \(\cap\), dall’unione \(\cup\) e dalla complementazione tra insiemi \(\overline{A}\). L’elemento neutro per la disgiunzione, o \(0\) dell’insieme, è costituito dall’insieme vuoto, mentre l’elemento neutro per la congiunzione, o \(1\) dell’insieme, è l’insieme \(S\) stesso.\\
Disponendo degli operatori Booleani e agendo sugli elementi di \(\mathcal{B}\), si potrebbero ricavare infinite relazioni notevoli, dette \textbf{leggi Booleane} o \textbf{teoremi}, alcune delle quali sono già state viste precedentemente con le tavole di verità; un esempio potrebbe essere il Teorema di De Morgan (§ \ref{sec:teorema_de_morgan}). Una legge Booleana è dunque un’identità tra due termini Booleani, costruiti su un insieme di variabili e sulle costanti \(0\) e \(1\) a partire dagli operatori \(\wedge\), \(\vee\), \(\neg\). Per verificare una legge è sufficiente procedere con la cosiddetta \textbf{induzione perfetta}, che consiste nella sostituzione di tutti i possibili valori per le variabili, verificando che l’uguaglianza sia sempre soddisfatta.\\
Le leggi Booleane sono ovviamente infinite, ma poiché l’Algebra Booleana è un insieme \textbf{finitamente assiomatizzabile}, è possibile descrivere compiutamente l’Algebra Booleana usando solamente un insieme finito di leggi base, che sono gli assiomi precedentemente descritti. Ciò significa che partendo dagli assiomi si possono poi ricavare tutte le leggi (o teoremi) dell’Algebra Booleana, combinando gli assiomi e i teoremi che ne derivano in tutti i modi possibili.\\
Gli assiomi non sono soggetti a verifica, nel senso che sono \textbf{verità primitive} che costituiscono il punto di partenza di una teoria matematica. Essi devono inoltre essere \textbf{non contradditori} tra loro e possibilmente \textbf{indipendenti}.\
Quest’ultima caratteristica è in qualche modo legata al problema di determinare se, assegnato un insieme di assiomi, esso sia il minimo possibile o se ne esista uno più piccolo.\\
Per esempio, si può osservare che l’operatore disgiunzione \(\cdot\), usato come operatore base nel quadro assiomatico appena analizzato, può essere definito in funzione degli altri due operatori \(+\) e \(\neg\), come già verificato nel teorema di De Morgan (§ \ref{sec:teorema_de_morgan}). Ecco allora che si potrebbe rimuovere tale operatore, pervenendo a un quadro assiomatico più sintetico. Tale problema fu affrontato da Edward V. Huntington, che nel 1933 riuscì a formulare un insieme minimo di assiomi tra loro indipendenti, che partono dai soli operatori \(+\) e \(\neg\) e che prevedono, oltre alla commutatività e all’associatività, anche la cosiddetta equazione di Huntington:
\[\overline{(\overline{x} + y)} + \overline{(\overline{x} + \overline{y})} = x\]

\subsection{Teoremi principali dell'Algebra Booleana}
A partire dagli assiomi sopra esposti, si potrebbero ricavare tutti i possibili teoremi dell’Algebra Booleana; tra questi ve ne sono alcuni molto semplici e utili nella manipolazione delle formule, di seguito elencati, che sono validi sia in forma base che in forma duale:

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{l|P|P}
        Teorema & \textbf{Base (a)} & \textbf{Duale (d)} \\
        \hline
        \textbf{T1 - Idempotenza} & \(x + x = x\) & \(x \cdot x = x\)\\
        \textbf{T2 - Nullifico} &\(x + 1 = 1\) & \(x \cdot 0 = 0\)\\
        \textbf{T3 - Doppia negazione} & \(\overline{\overline{x}} = x\) & $ $\\
        \textbf{T4 - Assorbimento 1} & \(x + x \cdot y = x\) & \(x \cdot (x + y) = x\)\\
        \textbf{T5 - Assorbimento 2} & \(x + \overline{x} \cdot y = x + y\) & \(x \cdot (\overline{x} + y) = x \cdot y\)\\
        \textbf{T6 - Assorbimento 3} & \(x \cdot y + \overline{x} \cdot z + y \cdot z = x \cdot y + \overline{x} \cdot z\) & \((x + y) \cdot (\overline{x} + z) \cdot (y + z) = (x + y) \cdot (\overline{x} + z)\)\\
        \textbf{T7 - De Morgan} & \(\overline{x + y} = \overline{x} \cdot \overline{y}\) & \(\overline{x \cdot y} = \overline{x} + \overline{y}\)\\
        \textbf{T8} & \(x \cdot ( x + y + z) = x\) & \(x + (x \cdot y \cdot z) = x\)\\
        \textbf{T9} & \((x + y) \cdot (\overline{x} + y) = y\) & \((x \cdot y) + (\overline{x} \cdot y) = y\)\\
        \textbf{T10} & \((x + y) \cdot (\overline{x} + z) = x \cdot z + \overline{x} \cdot y\) & \((x \cdot y) + (\overline{x} \cdot z) = (x + z) \cdot (\overline{x} + y)\)\\
    \end{tabularx}
    \caption{Teoremi principali dell'Algebra Booleana}
    \label{tab:teoremi_principali}
\end{table}

\vspace{1em}
\noindent
La dimostrazione di uno qualunque di questi teoremi può essere fatta per induzione perfetta, che che è la via più lunga e tediosa, oppure sfruttando gli assiomi e/o i teoremi già dimostrati.\\ Si considerino alcune dimostrazioni dei teoremi più importanti, giacché i primi (da T1 a T3) sono banali, poiché è sufficiente operare una verifica diretta tramite \textbf{induzione perfetta}.\\
Si analizzi, invece, la dimostrazione di T4, T5 e T6, ponendo tra parentesi, subito dopo il segno di uguaglianza, l’assioma o il teorema usato. Per la dimostrazione di tali teoremi, è possibile naturalmente ricorrere al metodo dell'\textbf{induzione perfetta}, ma quando i casi si complicano è necessario ricorrere a dei teoremi precedentemente dimostrati:\\

\rowcolors{1}{white}{white}
\noindent
\renewcommand{\arraystretch}{1.5}
\begin{tabularx}{\textwidth}{>{\hsize=0.2\textwidth}P>{\hsize=0.001\textwidth}ll}
    \textbf{Teorema} & $ $ & \textbf{Dimostrazione} \\
    \hline
    \multirow{2}{10em}{T4 - Assorbimento 1} & Base & $x + xy \overset{(A3)}{=} x \cdot 1 + xy \overset{(A6)}{=} x \cdot (1 + y) \overset{(T2)}{=} x$\\
    & Duale & $x (x + y) \overset{(A6)}{=} xx + xy \overset{(T1)}{=} x + xy \overset{(T4.b)}{=} x$\\
    \hline
    \multirow{2}{10em}{T5 - Assorbimento 2} & Base & \parbox{\linewidth}{$x + \overline{x}y \overset{(T2)}{=} x (1 + y) + \overline{x}y \overset{(A6)}{=} x + xy + \overline{x}y \overset{(A6)}{=}$ \\ $x + (x + \overline{x})y \overset{(A7)}{=} x + y$}\\
    & Duale & $x(\overline{x} + y) \overset{(A6)}{=} x \overline{x} + xy \overset{(A7)}{=} xy$\\
    \hline
    \multirow{2}{10em}{T6 - Assorbimento 3} & Base & \parbox{\linewidth}{$xy + \overline{x}z + yz \overset{(A7)}{=} xy + \overline{x}z + yz(x + \overline{x}) \overset{(A6)}{=} xy + \overline{x}z + $ \\ $ xyz + \overline{x}yz \overset{(A6)}{=} xy(z + 1) + \overline{x}z(y + 1) \overset{(T2)}{=} xy + \overline{x}z$}\\
    & Duale & \parbox{\linewidth}{$(x + y)(\overline{x} + z)(y + z) \overset{(A7)}{=} (x + y)(\overline{x} + z)(y + z + x \overline{x}) \overset{(A6)}{=}$ \\ $(x + y)(\overline{x} + z)(y + z + x)(y + z + \overline{x}) \overset{(A4)}{=}$ \\ $(x + y)(x + y + z)(\overline{x} + z)(\overline{x} + z + y) \overset{(T4)}{=} (x + y)(\overline{x} + z)$}\\
\end{tabularx}

\vspace{1em}
\noindent
\textbf{Osservazione}: Il teorema dell'idempotenza viene utilizzato frequentemente, non tanto nel senso da sinistra verso destra, ma più che altro per clonare una variabile ed ottenerne una identica.

\vspace{1em}
\noindent
\textbf{Dimostrazione del teorema di De Morgan}:
La verifica del \textbf{T7 - Teorema di De Morgan} basata l’induzione perfetta, e già stata effettuata nella dimostrazione nella Tabella \ref{tab:dimostrazione_teorema_de_morgan}, ma si coglie l'occasione per rinnovare l'importanza fondamentale di questo teorema, per le applicazioni e per la semplificazione delle espressioni complesse.

\subsection{Logica duale}
Se si osserva l’elenco dei teoremi di Tabella \ref{tab:teoremi_principali}, è possibile notare che le proposizioni della colonna di destra possono essere ottenute dalla colonna centrale semplicemente scambiando \quotes{\(0\)} con \quotes{\(1\)} e \quotes{\(+\)} con \quotes{\(\cdot\)} e viceversa.
Questa è una manifestazione del cosiddetto \textbf{Principio di dualità}.\\
Per comprenderlo si considerino le seguenti tabelle di verità, limitatamente ai valori di AND e OR, e si operi una sostituzione \quotes{\(0\)} con \quotes{\(1\)} e \quotes{\(+\)} con \quotes{\(\cdot\)}. Si ottiene

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{PP}
        {
            \begin{tabularx}{0.45 \textwidth}{cc|cc}
                 \(x\) & \(y\) & \(x + y\) & \(x \cdot y\)\\
                 \hline
                 \(0\) & \(0\) & \(0\) & \(0\)\\
                 \(0\) & \(1\) & \(1\) & \(0\)\\
                 \(1\) & \(0\) & \(1\) & \(0\)\\
                 \(1\) & \(1\) & \(1\) & \(1\)\\
            \end{tabularx}
        }
        &
        {
            \begin{tabularx}{0.45 \textwidth}{cc|cc}
                 \(x\) & \(y\) & \(x \cdot y\) & \(x + y\)\\
                 \hline
                 \(1\) & \(1\) & \(1\) & \(1\)\\
                 \(1\) & \(0\) & \(0\) & \(1\)\\
                 \(0\) & \(1\) & \(0\) & \(1\)\\
                 \(0\) & \(0\) & \(0\) & \(0\)\\
            \end{tabularx}
        }
    \end{tabularx}
    \caption{Principio di dualità}
    \label{tab:principio_dualita}
\end{table}

\noindent
Si può osservare che la tavola di verità a che ne deriva conserva la propria validità, sia pur con una permutazione delle righe, del tutto ininfluente. Il principio di dualità consente allora di trasformare in modo duale le espressioni Booleane, realizzando nuove espressioni che continuano a valere. Si osservi tuttavia che i valori delle espressioni così ottenute sono in generale diversi da quelle di partenza.\\
Si consideri, a tal proposito, il teorema T10: l’espressione Booleana \((x + y) \cdot (\overline{x} + z)\) ha come duale la \(x \cdot y + \overline{x} \cdot z\).

\begin{table}[H]
    \centering
    \rowcolors{1}{white}{white}
    \begin{tabularx}{\textwidth}{lr}
        {
            \setlength{\tabcolsep}{8pt}
            \begin{tabularx}{0.5 \textwidth}{ccc|c|c}
                 \(1\) & \(2\) & \(3\) & \(4\) & \(5\)\\
                 \hline
                 \(x\) & \(y\) & \(z\) & \((x + y) \cdot (\overline{x} + z)\) & \(x \cdot y + \overline{x} \cdot z\)\\
                 \hline
                 \(0\) & \(0\) & \(0\) & \(0\) & \(0\)\\
                 \(0\) & \(0\) & \(1\) & \(0\) & \(1\)\\
                 \(0\) & \(1\) & \(0\) & \(1\) & \(0\)\\
                 \(0\) & \(1\) & \(1\) & \(1\) & \(1\)\\
                 \(1\) & \(0\) & \(0\) & \(0\) & \(0\)\\
                 \(1\) & \(0\) & \(1\) & \(1\) & \(0\)\\
                 \(1\) & \(1\) & \(0\) & \(0\) & \(1\)\\
                 \(1\) & \(1\) & \(1\) & \(1\) & \(1\)\\
            \end{tabularx}
        }
        &
        {
            \setlength{\tabcolsep}{8pt}
            \begin{tabularx}{0.3 \textwidth}{ccc|c}
                 \(6\) & \(7\) & \(8\) & \(9\)\\
                 \hline
                 \(x\) & \(y\) & \(z\) & \(x \cdot y + \overline{x} \cdot z\)\\
                 \hline
                 \(0\) & \(0\) & \(0\) & \(0\)\\
                 \(0\) & \(0\) & \(1\) & \(1\)\\
                 \(0\) & \(1\) & \(0\) & \(0\)\\
                 \(0\) & \(1\) & \(1\) & \(1\)\\
                 \(1\) & \(0\) & \(0\) & \(0\)\\
                 \(1\) & \(0\) & \(1\) & \(0\)\\
                 \(1\) & \(1\) & \(0\) & \(1\)\\
                 \(1\) & \(1\) & \(1\) & \(1\)\\
            \end{tabularx}
        }
    \end{tabularx}
    \caption{Principio di dualità applicato all'espressione Booleana \((x + y) \cdot (\overline{x} + z)\)}
    \label{tab:principio_dualita_espressione_booleana}
\end{table}

\noindent
Nella Tabella \ref{tab:principio_dualita_espressione_booleana} sono riportati, in colonna \(4\) e \(5\), i valori di queste due espressioni duali, e come si vede sono diversi. Per verificare la validità del principio di dualità è necessario operare una sostituzione di \quotes{\(0\)} con \quotes{\(1\)} e di \quotes{\(+\)} con \quotes{\(\cdot\)} nelle colonne \(1, 2, 3\) e nella colonna \(4\), che riporta i valori dell’espressione; così facendo si ottengono rispettivamente le colonne \(6, 7, 8\) e \(9\).\\
Si può verificare che a ciascuna terna delle colonne duali \(6, 7, 8\) corrisponde un valore duale di colonna \(9\) che è esattamente il valore attribuito dall’espressione di colonna \(5\) alla stessa terna letta nelle colonne primitive \(2, 3, 4\). Per esempio, a \(011\) delle colonne \(6, 7, 8\) corrisponde \(1\) in colonna \(9\); questo è lo stesso valore attribuito dalla colonna \(5\) alla terna \(011\) delle colonne primitive \(1, 2, 3\).

\vspace{1em}
\noindent
\textbf{Osservazione}: La logica duale è estremamente importante e vantaggiosa, in quanto se in una espressione è presente il \quotes{\(+\)} ed ad esso si sostituisce il \quotes{\(\cdot\)}, si ottiene una espressione ancora vera.\\
Tutto ciò trova spiegazione nel fatto che il principio di dualità è un fondamento base della manipolazione booleana, che permette di trasformare proposizioni vere in altre proposizioni vere, pur tenendo presente che le espressioni che si ottengono attraverso lo strumento della dualità sono pur sempre delle espressioni diverse da quelle di partenza.

\subsection{Variabili, funzioni Booleane e porte logiche}
Data una funzione di verità, è possibile associare alla combinazione di \(n\) variabili logiche uno e un solo valore logico. Se dunque \(x_1, x_2, ..., x_n\) sono \(n\) variabili Booleane (o binarie) che possono assumere l’uno o l’altro dei due valori possibili \(0\) e \(1\), si indica con
\[f(x_1, x_2, ..., x_n)\]
una \textbf{generica funzione Booleana} del tipo:
\[f : 2^n \rightarrow 2\]
che a ogni valore della n-upla \(x_1, x_2, ..., x_n\) associa un valore dell’insieme \(\{0, 1\}\). La tabella di verità di una simile funzione è rappresentata nella tabella che segue:

\begin{table}[H]
    \centering
    \begin{tabularx}{\textwidth}{ccccc|P}
         \(x_1\) & \(x_2\) & \(...\) & \(x_{n - 1}\) & \(x_n\) & \(f(x_1, x_2, ..., x_n)\)\\
         \hline
         \(0\) & \(0\) & \(...\) & \(0\) & \(0\) & \(f(0, 0, ..., 0, 0)\)\\
         \(0\) & \(0\) & \(...\) & \(0\) & \(1\) & \(f(0, 0, ..., 0, 1)\)\\
         \(...\) & \(...\) & \(...\) & \(...\) & \(...\) & \(...\)\\
         \(1\) & \(1\) & \(...\) & \(1\) & \(0\) & \(f(1, 1, ..., 1, 0)\)\\
         \(1\) & \(1\) & \(...\) & \(1\) & \(1\) & \(f(1, 1, ..., 1, 1)\)\\
    \end{tabularx}
    \caption{Tabella di verità di una generica funzione Booleana n-aria}
    \label{tab:tabella_verita_funzione_naria}
\end{table}

\noindent
Si osservi che il numero di n-uple binarie dell’insieme \(2^n\) cresce in modo esponenziale. In generale, poiché l’insieme \(2^n\) contiene \(2^n\) n-uple binarie, e a ciascuna di esse si associa un valore della funzione (che può essere o \(0\) o \(1\)), il numero totale di funzioni Booleane n-arie che si possono realizzare risulta essere:
\[2^{2^{n}}\]
Risulta fondamentale, più specificatamente, studiare in particolare le funzioni Booleane per \(n = 1\) (a una variabile, o \textbf{unarie}) e \(n = 2\) (a due variabili, o \textbf{di-arie}).

\subsubsection{Funzioni a una variabile (unarie)}
Le funzioni ad una variabile (in cui \(n = 1\)) che si possono costruire sono in tutto
\[2^{2^1} = 2^2 = 4\]
e sono funzioni del tipo \(y = f(x)\).

\begin{table}[H]
    \centering
    \noindent
    \setlength{\tabcolsep}{1.8pt}
    \begin{tabularx}{\textwidth}{>{\hsize=0.28\textwidth}PPPPP}
         {
            \setlength{\tabcolsep}{7pt}
            \begin{tabular}{c|cccc}
                 $ $ & $f_0$ & $f_1$ & $f_2$ & $f_3$\\
                 \hline
                 $x$ & $0$ & $x$ & $\overline{x}$ & $1$\\
                 \hline
                 $0$ & $0$ & $0$ & $1$ & $1$\\
                 $1$ & $0$ & $1$ & $0$ & $1$\\
            \end{tabular}
         }
         &
         {
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{c|c}
                 $ $ & \textbf{Nulla}\\
                 \hline
                 $x$ & $z$\\
                 \hline
                 $0$ & $0$\\
                 $1$ & $0$
            \end{tabular}
         }
         &
         {
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{c|c}
                 $ $ & \textbf{Unitaria}\\
                 \hline
                 $x$ & $z$\\
                 \hline
                 $0$ & $1$\\
                 $1$ & $1$
            \end{tabular}
         }
         &
         {
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{c|c}
                 $ $ & \textbf{Buffer}\\
                 \hline
                 $x$ & $z$\\
                 \hline
                 $0$ & $0$\\
                 $1$ & $1$
            \end{tabular}
         }
         &
         {
            \setlength{\tabcolsep}{5pt}
            \begin{tabular}{c|c}
                 $ $ & \textbf{NOT}\\
                 \hline
                 $x$ & $z$\\
                 \hline
                 $0$ & $1$\\
                 $1$ & $0$
            \end{tabular}
         }
    \end{tabularx}
    \caption{Tutte le possibili \(2^{2^1} = 4\) funzioni Booleane a \(1\) variabile}
    \label{tab:funzioni_una_variabile}
\end{table}

\noindent
\begin{enumerate}
    \item La prima funzione fornisce sempre \(0\) in uscita, qualunque sia l’ingresso; è dunque la \textbf{funzione nulla}, che si nota con \(\textbf{0}\).

    \item Un discorso analogo vale per la seconda funzione, che fornisce sempre \(1\) in uscita, qualunque sia l'ingresso; è dunque la \textbf{funzione unitaria}, che si denota con \(\textbf{1}\).

    \item La terza funzione replica il valore di \(x\) in uscita, cioè \(y = x\) e si tratta dunque della \textbf{funzione identità}. Poiché la logica Booleana è connessa, come già anticipato, all’ambito circuitale, per la rappresentazione della funzione identità si usa il termine \textbf{Buffer}, e le si attribuisce lo schema circuitale dato da un triangolo:

        % Contenitore per immagini
            \begin{figure}[H]
                \centering
                    \begin{tikzpicture}
                        \node (A) at (0,0) {$x$};
                        \node (Y) at (2,0) {$y$};
                        \node[buffer gate US, draw, logic gate inputs=n] at (1,0) (TS) {};
                        \draw (A) -- (TS.input);
                        \draw (TS.output) -- (Y);
                    \end{tikzpicture}
                \caption{Buffer}
                \label{fig:buffer}
            \end{figure}

    \noindent
    Esso corrisponde a un dispositivo che fornisce sull’uscita a destra esattamente ciò che si presenta in ingresso a sinistra.

    \item La quarta funzione è la più importante dal punto di vista della logica Booleana, poiché è uno dei connettivi base già analizzati, cioè il NOT. Esso fornisce in uscita la negazione di quanto sta all’ingresso; si può dunque scrivere \(y = \overline{x}\).\\
    Per la sua rappresentazione circuitale si usa il triangolo di prima concatenato con un piccolo circoletto, che in tutta la circuiteria logica ha sempre il significato di una \textbf{negazione} o \textbf{complementazione}:

        % Contenitore per immagini
        \begin{figure}[H]
        \centering
            \begin{tikzpicture}
                \node (A) at (0,0) {$x$};
                \node (Y) at (2.2,0) {$y$};
                \node[not gate US, draw, logic gate inputs=n] at (1,0) (TS) {};
                \draw (A) -- (TS.input);
                \draw (TS.output) -- (Y);
            \end{tikzpicture}
        \caption{Negazione (o complementazione)}
        \label{fig:negazione_o_complementazione}
        \end{figure}
\end{enumerate}

\subsubsection{Funzioni a due variabili}
Le funzioni a due variabili (in cui \(n = 2\)) che si possono costruire sono
\[2^{2^2} = 2^4 = 16\]
Sono funzioni Booleane di-arie del tipo \(z = f(x, y)\) e sono così importanti da meritare una descrizione anche circuitale.\\
Di seguito vengono riportate usando il linguaggio dell'Algebra Booleana:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{PP|P>{\hsize=0.015\textwidth}PPPPPPP>{\hsize=0.03\textwidth}P>{\hsize=0.03\textwidth}PPPPPPPPPPP>{\hsize=0.03\textwidth}PP}
         $ $ & $ $ & $f_0$ & $f_1$ & $f_2$ & $f_3$ & $f_4$ & $f_5$ & $f_6$ & $f_7$ & $f_8$ & $f_9$ & $f_{10}$ & $f_{11}$ & $f_{12}$ & $f_{13}$ & $f_{14}$ & $f_{15}$\\
         \hline
         $ $ & $ $ & $ $ & $\hspace{-0.75em} \text{AND}$ & $ $ & $ $ & $ $ & $ $ & $\hspace{-0.95em} \text{XOR}$ & $\hspace{-0.45em}  \text{OR}$ & $\hspace{-0.5em} \text{NOR}$ & $\hspace{-1em} \text{XNOR} \hspace{1em}$ & $ $ & $ $ & $ $ & $ $ & \multicolumn{2}{P}{$\hspace{-3.5em} \text{NAND}$}\\
         $A$ & $B$ & $\textbf{0}$ & $\cdot$ & $ $ & $ $ & $ $ & $ $ & $\oplus$ & $+$ & $\downarrow$ & $\odot$ & $ $ & $ $ & $ $ & $ $ & $\hspace{0.4em} \vert$ & $\textbf{1}$\\
         \hline
         $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$ & $V$\\
         $F$ & $V$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$ & $F$ & $F$ & $F$ & $F$ & $V$ & $V$ & $V$ & $V$\\
         $V$ & $F$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$ & $F$ & $F$ & $V$ & $V$\\
         $V$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$ & $F$ & $V$\\
    \end{tabularx}
    \caption{Tutte le possibili \(2^{2^2} = 16\) funzioni Booleane a due variabili}
    \label{tab:16_funzioni_due_variabili}
\end{table}

\noindent
Tra tutte queste funzioni è noto che alcune sono particolarmente significative, precisamente le sei già evidenziate in Tabella \ref{tab:16_funzioni_due_variabili}, che sono rispettivamente AND, OR, XOR, NAND, NOR e XNOR; nella tabella seguente esse sono espresse, assieme alle rimanenti, mediante i simboli \(\cdot, +, \oplus, \vert, \downarrow\) e \(\odot\) che si usano tradizionalmente nell’ambito dell’Algebra Booleana; si noti che \(+, \cdot\) e \(\odot\) stanno rispettivamente per \(\cup, \cap\) e \(\equiv\), visti nella precedente Tabella \ref{tab:tavola_verità_connettivi_binari} parlando di connettivi.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{|l|P||l|P|}
    \hline
        \(f_0 = \textbf{0} \hspace{5em}\) & $ $ & \(f_8 = x \downarrow y \hspace{5em}\) & NOR\\
        \(f_1 = x \cdot y \hspace{5em}\) & AND & \(f_9 = x \odot y \hspace{5em}\) & XNOR\\
        \(f_2 = x \cdot \overline{y} \hspace{5em}\) & $ $ & \(f_{10} = \overline{y} \hspace{5em}\) & $ $\\
        \(f_3 = x \hspace{5em}\) & $ $ & \(f_{11} = x + \overline{y} \hspace{5em}\) & $ $\\
        \(f_4 = \overline{x} \cdot y \hspace{5em}\) & $ $ & \(f_{12} = \overline{x} \hspace{5em}\) & $ $\\
        \(f_5 = y \hspace{5em}\) & $ $ & \(f_{13} = \overline{x} + y \hspace{5em}\) & $ $\\
        \(f_6 = x \oplus y \hspace{5em}\) & XOR & \(f_{14} = x | y \hspace{5em}\) & NAND\\
        \(f_7 = x + y \hspace{5em}\) & OR & \(f_{15} = \textbf{1}\) & $ $\\
        \hline
    \end{tabularx}
    \caption{Le \(16\) funzione Booleane espresse mediante \(\cdot, +, \oplus, \odot, \downarrow, \vert\) e complementazione}
    \label{tab:16_funzioni_booleane_con_connettivi_proincipali}
\end{table}

\noindent
Come anticipato, data l’estrema importanza, in ambito circuitale, delle funzioni AND, OR, XOR, NAND, NOR e XNOR, dette anche operatori Booleani, vengono analizzate singolarmente di seguito:

\begin{itemize}
    \item \textbf{Porta AND}\\
    È detta anche \textbf{prodotto logico}. La porta AND restituisce \(0\) in uscita se anche uno solo dei due valori d’ingresso è pari a \(0\); restituisce \(1\) solo quando entrambi gli ingressi sono a \(1\). Il simbolo circuitale è:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
        \begin{tikzpicture}
            \node [and gate US, draw, logic gate inputs =nn] (and){};
            \draw (and.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
            \draw (and.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
            \draw (and.output) -- node[at end,right]{$x \cdot y$} ++(right:4mm);
        \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \cdot y\)\\
             \hline
             $0$\\
             $0$\\
             $0$\\
             $1$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}
    \noindent

    \item \textbf{Porta OR}\\
    È detta anche \textbf{somma logica}. La porta OR restituisce \(1\) in uscita se almeno uno dei due valori d’ingresso è pari a \(1\); restituisce \(0\) solo quando entrambi gli ingressi sono a \(0\). Il simbolo circuitale è:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
    \begin{tikzpicture}
        \node [or gate US, draw, logic gate inputs =nn] (or){};
        \draw (or.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
        \draw (or.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
        \draw (or.output) -- node[at end,right]{$x + y$} ++(right:4mm);
    \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x + y\)\\
             \hline
             $0$\\
             $1$\\
             $1$\\
             $1$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}
    \noindent

    \item \textbf{Porta XOR}\\
    È l’OR esclusivo. La porta XOR restituisce \(1\) in uscita se o uno o l’altro dei due valori d’ingresso è pari a \(1\), ma non entrambi; restituisce \(0\) quando entrambi gli ingressi sono a \(0\) o a \(1\). Il simbolo circuitale è

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
      \begin{tikzpicture}
          \node [xor gate US, draw, logic gate inputs =nn] (xor){};
          \draw (xor.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
          \draw (xor.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
          \draw (xor.output) -- node[at end,right]{$x \oplus y$} ++(right:4mm);
      \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \oplus y\)\\
             \hline
             $0$\\
             $1$\\
             $1$\\
             $0$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}
    \noindent
\end{itemize}

\newpage
\begin{center}
    11 Ottobre 2021
\end{center}

\subsection{Riassunto}
L'algebra booleana è l'apparato teorico che costituisce le fondamenta della logica binaria. Attraverso il teorema di De Morgan, in particolare, l'insieme minimo dei connettivi in grado di esprimere le \(16\) espressioni booleane può essere ristretto a AND, NOT oppure a OR, NOT.\\
Non solo, ma impiegando i connettivi universali NOR e NAND è possibile impiegare un solo connettivo per costruire ogni funzione logica.\\
Gli assiomi che si pongono alla base dell'algebra booleana sono verità assolute, incontestabili e non dimostrabili e costituiscono le fondamenta della teoria assiomatica quale quella booleana. L'algebra booleana, tuttavia, non è solo quella delle porte logiche, ma anche quella delle operazioni insiemistiche, secondo \textbf{Kantor}; esse, infatti, rispettano tutti i dettami dell'algebra booleana.\\
A partire dagli assiomi fondamentali si possono, poi, formulare dei teoremi che permettono la semplificazione di espressioni logiche, tramite il \textbf{principio di inferenza}. Il \textbf{principio di dualità}, invece, permette di trasformare una proposizione vera con la congiunzione in un'altra proposizione vera con la disgiunzione. Naturalmente, si ottiene una seconda espressione sempre vera, ma che risulta comunque differente rispetto alla funzione di partenza.\\
Le funzioni booleane vanno da \(2^n \rightarrow 2\), ovvero ad ogni n-upla viene associato uno dei \(2\) possibili valori (VERO o FALSO).\\
Con \(n = 1\), si possono avere solamente \(2^2 = 4\) funzioni unarie del tipo \(y = f(x)\), mentre con \(n = 2\) ci sono \(2^{2^2} = 16\) funzioni booleane di-arie del tipo \(z = f(x, y)\). Tali funzioni sono le \(16\) funzioni logiche precedentemente esposte, ma che presentano dei simboli circuitali differenti rispetto ai connettivi analizzati.\\
Pertanto, dopo aver discusso ampiamente le due porte principali dell'Algebra Booleana (AND e OR), è doveroso rivolgere un'importante attenzione alle porte solo in apparenza secondarie, di seguito esposte:

\begin{itemize}
    \item \textbf{Porta XOR}\\
    È l’OR esclusivo. La porta XOR restituisce \(1\) in uscita se uno o l’altro dei due valori d’ingresso è pari a \(1\), ma non entrambi; restituisce \(0\) quando entrambi gli ingressi sono a \(0\) o a \(1\). Il simbolo circuitale è

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
      \begin{tikzpicture}
          \node [xor gate US, draw, logic gate inputs =nn] (xor){};
          \draw (xor.input 1) -- node[at end, above left]{$x$} ++(left:4mm);
          \draw (xor.input 2) -- node[at end, below left]{$y$} ++(left:4mm);
          \draw (xor.output) -- node[at end,right]{$x \oplus y$} ++(right:4mm);
      \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \oplus y\)\\
             \hline
             $0$\\
             $1$\\
             $1$\\
             $0$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}
    \noindent

    \noindent
    Si osservi che una porta XOR è in grado di realizzare la somma binaria modulo \(2\) e che costituisce un \textbf{rilevatore di differenza} tra i due valori d'ingresso.\\
    Inoltre, si osserva che:
    \[x \oplus y = x \overline{y} + \overline{x} y\]
    che corrisponde a un OR di due AND. Mediante manipolazione algebrica si ottiene anche la seguente espressione:
    \[x \oplus y = x \overline{y} + \overline{x} y = x \overline{y} + \overline{x} y + x \overline{x} + y \overline{y} = (x + y) \cdot (\overline{x} + \overline{y})\]
    che corrisponde a un AND di due OR. Si possono pertanto realizzare due circuiti del tutto equivalenti, visibili in Figura \ref{fig:XOR_espressa_AND_OR}:

    % Contenitore per immagini
            \begin{figure}[H]
                \centering
                \begin{tikzpicture}
                    \coordinate (start) at (-1.5,0);
                    \node [and gate US, draw, logic gate inputs=ni] (and1){};
                    \node [and gate US, draw, below=of and1, yshift=5.5mm, logic gate inputs=in] (and2){};
                    \node [or gate US, draw, right=of and1, xshift=-3mm, yshift=-5mm, logic gate inputs=nn] (or){};

                    \draw (and1.input 1) -- node[at end, left]{$x$} (and1.input 1 -| start);
                    \draw (and2.input 2) -- node[at end, left]{$y$} (and2.input 2 -| start);
                    \draw (and1.input 1) ++(-0.8,0) node [branch]{} |- (and2.input 1);
                    \draw (and2.input 2) ++(-0.5,0) node [branch]{} |- (and1.input 2);
                    \draw (and1.output) -- ([xshift=0.3cm] and1.output) |- (or.input 1);
                    \draw (and2.output) -- ([xshift=0.3cm] and2.output) |- (or.input 2);
                    \draw (or.output) -- ([xshift=0.5cm] or.output) node [right] {{$x\overline{y} + \overline{x}y$}};
                \end{tikzpicture}
                \hspace{3em}
                \begin{tikzpicture}
                  \coordinate (start) at (-1.5,0);
                  \node [or gate US, draw, logic gate inputs=ii] (or1){};
                  \node [or gate US, draw, below=of or1, yshift=5.5mm, logic gate inputs=nn] (or2){};
                  \node [and gate US, draw, right=of and1, xshift=-3mm, yshift=-5mm, logic gate inputs=nn] (and){};

                  \draw (or1.input 1) -- node[at end, left]{$x$} (or1.input 1 -| start);
                  \draw (or2.input 2) -- node[at end, left]{$y$} (or2.input 2 -| start);
                  \draw (or1.input 1) ++(-0.8,0) node [branch]{} |- (or2.input 1);
                  \draw (or2.input 2) ++(-0.5,0) node [branch]{} |- (or1.input 2);
                  \draw (or1.output) -- ([xshift=0.3cm] or1.output) |- (and.input 1);
                  \draw (or2.output) -- ([xshift=0.3cm] or2.output) |- (and.input 2);
                  \draw (and.output) -- ([xshift=0.5cm] and.output) node [right] {{$(x + y) \cdot (\overline{x} + \overline{y})$}};
                \end{tikzpicture}
                \caption{La funzione XOR realizzata mediante porte AND e OR}
                \label{fig:XOR_espressa_AND_OR}
            \end{figure}

    \item \textbf{Porta XNOR}\\
    È la negazione della porta XOR. La porta XNOR restituisce \(1\) in uscita solo quando entrambe le variabili d'ingresso hanno lo stesso valore, o entrambe a \(0\) oppure entrambe a \(1\). Il simbolo circuitale si ottiene concatenando la porta XOR con la porta NOT:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
        \begin{tikzpicture}
            \node (A) at (0,0.5) {$x$};
            \node (B) at (0,-0.7) {$y$};
            \node [xnor gate US , draw , logic gate inputs =nn] at ($(xnor.input 1 -| xnor.input 2)+(.5,-0.08)$) (xnor){};
            \draw (A) |- node  {}(xnor.input 1);
            \draw (B) |- node  {}(xnor.input 2);
            \draw (xnor.output) -- ([xshift=0.5cm] xnor.output) node [right] {{$x \odot y$}};
        \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \odot y\)\\
             \hline
             $1$\\
             $0$\\
             $0$\\
             $1$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}

    \noindent
    Si osservi che una porta XNOR costituisce un \textbf{rilevatore di identità} tra i due valori d'ingresso. Per trovare una rappresentazione circuitale mediante porte AND e OR bisogna partire dal fatto che si tratta di uno XOR negato, traendone le conseguenze sempre usando il Teorema di De Morgan (§ \ref{sec:teorema_de_morgan}):
    \[x \odot y = \overline{x \oplus y} = \overline{\overline{x}y + x \overline{y}} = \overline{(\overline{x}y)} \cdot \overline{(x\overline{y})} = (x + \overline{y}) \cdot (\overline{x} + y) = x\overline{x} + xy + \overline{x}\overline{y} + \overline{y}y = xy + \overline{x}\overline{y}\]
    Nella prima parte dello svolgimento si ottiene \((x + \overline{y}) \cdot (\overline{x} + y)\), e quindi l’AND di due OR, mentre nella seconda parte si ottiene \(xy + \overline{x} \overline{y}\) le quali portano alla realizzazione circuitale seguente

    % Contenitore per immagini
            \begin{figure}[H]
                \centering
                \begin{tikzpicture}
                    \node (A) at (-0.5,0.3) {$x$};
                    \node (B) at (0,0.3) {$y$};
                    \node [and gate US, draw, logic gate inputs=ii, anchor=input 1] at ($(and1.input 1 |- and1.input 2)+(.1,-0.08)$) (and1){};
                    \node [and gate US, draw, logic gate inputs=nn, anchor=input 2] at ($(and2.input 1 |- and2.input 2)+(.38,-0.58)$) (and2){};
                    \node [or gate US, draw, logic gate inputs=nn, anchor=input 1] at ($(or.input 1 |- or.input 2)+(.35,-0.25)$) (or){};
                    \draw (A) |- node {}(and1.input 1);
                    \draw (B) |- node {}(and2.input 2);
                    \draw (A) |- node [branch] {}(and2.input 1);
                    \draw (B) |- node [branch] {}(and1.input 2);

                    \draw (and1.output) -- ([xshift=0.3cm] and1.output) |- (or.input 1);
                    \draw (and2.output) -- ([xshift=0.3cm] and2.output) |- (or.input 2);
                    \draw (or.output)   -- ([xshift=0.3cm] or.output) node [right] {{$xy + \overline{x}\overline{y}$}};

                    \node () at (1.65,0.1) {$\overline{x}\overline{y}$};
                    \node () at (1.65,-1.95) {$xy$};
                \end{tikzpicture}
                \hspace{1em}
                \begin{tikzpicture}
                    \node (A) at (-0.5,0.3) {$x$};
                    \node (B) at (0,0.3) {$y$};
                    \node [or gate US, draw, logic gate inputs=ni, anchor=input 1] at ($(or1.input 1 |- or1.input 2)+(.1,-0.08)$) (or1){};
                    \node [or gate US, draw, logic gate inputs=in, anchor=input 2] at ($(or2.input 1 |- or2.input 2)+(-.05,-0.58)$) (or2){};
                    \node [and gate US, draw, logic gate inputs=nn, anchor=input 1] at ($(and.input 1 |- and.input 2)+(.35,-0.25)$) (and){};
                    \draw (A) |- node {}(or1.input 1);
                    \draw (B) |- node {}(or2.input 2);
                    \draw (A) |- node [branch] {}(or2.input 1);
                    \draw (B) |- node [branch] {}(or1.input 2);

                    \draw (or1.output) -- ([xshift=0.3cm] or1.output) |- (and.input 1);
                    \draw (or2.output) -- ([xshift=0.3cm] or2.output) |- (and.input 2);
                    \draw (and.output)   -- ([xshift=0.3cm] and.output) node [right] {$(x + \overline{y}) \cdot (\overline{x} + y)$};

                    \node () at (1.65,0.1) {$x + \overline{y}$};
                    \node () at (1.65,-1.95) {$\overline{x} + y$};
                \end{tikzpicture}
                \caption{La funzione XNOR realizzata mediante porte AND e OR}
                \label{fig:XNOR_espressa_AND_OR}
            \end{figure}

    \noindent
    Dal punto di vista ingegneristico, non vi è una sostanziale differenza tra le due, dal momento che il numero di operazioni binarie e di negazioni sono esattamente identici.

    \item \textbf{Porta NAND}\\
    È la negazione della porta AND, rappresentata dal seguente simbolo circuitale:

    \vspace{1em}
    \rowcolors{1}{white}{white}
    \noindent
    \begin{tabularx}{\textwidth}{PPP}
    {
        \begin{tabular}{c|c}
             \(x\) & \(y\)\\
             \hline
             $0$ & $0$\\
             $0$ & $1$\\
             $1$ & $0$\\
             $1$ & $1$
        \end{tabular}
    }
    &
    {
      \begin{tikzpicture}
          \node (A) at (0,0.8) {$x$};
          \node (B) at (0,-0.5) {$y$};
          \node (Y) at (2.2,0.18) {$x \vert y$};
          \node [nand gate US , draw , logic gate inputs =nn] at ($(nand.input 1 -| nand.input 2)+(.5,0)$) (nand){};
          \draw (A) |- node  {}(nand.input 1);
          \draw (B) |- node  {}(nand.input 2);
          \draw (Y) -- node  {}(nand.output);
      \end{tikzpicture}
    }
    &
    {
        \begin{tabular}{c}
             \(x \vert y\)\\
             \hline
             $1$\\
             $1$\\
             $1$\\
             $0$
        \end{tabular}
    }\\
    \end{tabularx}
    \vspace{1em}

    \noindent
    Com'è noto, la porta NAND è un \textbf{operatore universale}, nel senso che da sola consente di costruire una qualunque tra le \(16\) possibili funzioni. Per declinare le relazioni succitate nei termini del linguaggio dell'Algebra Booleana è sufficiente usare gli assiomi e i teoremi visti in precedenza:
    \begin{align*}
        \overline{x} = \overline{x \cdot x} = x | x\\
        x + y = \overline{\overline{x} \cdot \overline{y}} = \overline{x} | \overline{y}\\
        x \cdot y = \overline{\overline{x \cdot y}} = \overline{x | y}
     \end{align*}

     \item \textbf{Porta NOR}\\
    È la negazione della porta OR, rappresentata dal seguente simbolo circuitale:

    \noindent
    Com'è noto, anche la porta OR è un \textbf{operatore universale}, nel senso che da sola consente di costruire una qualunque tra le \(16\) possibili funzioni. Per declinare le relazioni succitate nei termini del linguaggio dell'Algebra Booleana è sufficiente usare gli assiomi e i teoremi visti in precedenza:
    \begin{align*}
        \overline{x} = \overline{x + x} = x \downarrow x\\
        x + y = \overline{\overline{x + y}} = \overline{x \downarrow y}\\
        x \cdot y = \overline{\overline{x} + \overline{y}} = \overline{x} \downarrow \overline{y}
     \end{align*}
\end{itemize}
E questo è un risultato molto importante dal punto di vista tecnico industriale, dal momento che potrebbero comportare significativi vantaggi dal punto di vista economico-produttivo.

\subsubsection{Funzioni a tre variabili}
Finora sono state trattate solamente porte associate a funzioni a due variabili. La generalizzazione a \(n\) variabili ha pieno senso solo per le porte AND e OR; si tratterà per esteso il caso con \(n = 3\), poiché gli altri sono la banale generalizzazione di questo. Le tavole di verità delle funzioni AND e OR a \(3\) variabili sono riportate nella successiva Tabella ; la funzione AND vale \(1\) solo quando tutte le variabili in ingresso hanno valore \(1\); la funzione OR vale \(0\) solo quando tutte le variabili in ingresso hanno valore \(0\).

\subsection{Realizzazione circuitale delle porte logiche}
Le funzioni logiche di base, a \(1\) e \(2\) variabili, possono essere facilmente realizzate impiegando i transistor.\\
Tuttavia, in fase di realizzazione è necessario tenere conto di alcuni fondamentali obiettivi:
\begin{enumerate}
    \item Minimizzazione della potenza dissipata. Infatti, la deriva termica dei transistor rappresenta un esito deleterio per il dispositivo, in quanto verso i \(200 ^{°}C\) il cristallino di silicio si fonde e il transistor si brucia.

    \item Minimizzazione dei tempi di risposta. Infatti, la variazione di tensione dei transistor determina la generazione di un impulso che deve transitare per il circuito e deve essere validato dalle porte logiche, anche in cascata. Non è ammissibile che vi siano tempi di risposta differenti in quanto la validazione delle variabili logiche ne potrebbe risentire.

    \item Minimizzazione dei costi

    \item Aumento progressivo della densità di integrazione sui relativi circuiti integrati.
\end{enumerate}

\noindent
Nel tempo si sono succedute numerose \textbf{famiglie logiche}, che a seconda del periodo in cui sono state introdotte e dello sviluppo tecnologico corrente hanno privilegiato l’uso di uno o dell’altro dei vari dispositivi a semiconduttore per la realizzazione delle funzioni di base, quali diodi, transistor, CMOS, ecc...\\
Anche se in pratica sono molte di piu, le principali famiglie logiche sono le seguenti (in ordine cronologico):

\begin{itemize}
    \item Resistor-Transistor Logic (RTL) e una classe di porte logiche costruite usando resistenze nella rete d’ingresso e transistori bipolari a giunzione (BJT) come dispositivi di commutazione. La RTL e stata la prima classe di circuito logico digitale basata sull’impiego dei transistor. Le prime porte RTL furono costruite con elementi discreti, ma nel 1961 divenne la prima famiglia logica a esser realizzata su un circuito integrato monolitico. Circuiti integrati RTL sono stati utilizzati nel computer Apollo Guidance, il cui progetto risale al 1961 con un primo volo fatto nel 1966.

    \item Diode-Transistor Logic (DTL) e la classe di di porte logiche che precede la grande famiglia TTL. Si chiama così perché la funzione logica viene eseguita da una rete di diodi, mentre la funzione di inversione-amplificazione viene eseguita da un transistore.

    \item Transistor-Transistor Logic (TTL) e senza dubbio la classe pi ` u nota e famosa, poiché e ha avuto un larghissimo impiego. Fa uso di transistori bipolari a giunzione (BJT) e resistenze. Si chiama logica transistor-transistor perché il transistor svolge sia la funzione logica che la funzione di inversione-amplificazione. I circuiti integrati basati sulla famiglia TTL sono stati ampiamente usati in applicazioni quali computer, controlli industriali, apparecchiature di prova, strumentazione elettronica, elettronica di consumo, sintetizzatori e molto altro. Dopo la loro introduzione come circuito integrato a opera di Sylvania nel 1963, i circuiti integrati TTL sono stati prodotti da diverse aziende di semiconduttori. La serie 7400 (chiamato anche 74xx) della Texas Instruments e diventata particolarmente popolare. I produttori di porte basati sulla tecnologia TTL hanno offerto una vasta gamma di porte logiche, flip-flop, contatori, multiplexer e altri circuiti.

    \item Complementary Metal-Oxide-Semiconductor (CMOS) e la tecnologia pi ` u recente per la costruzione di porte logiche inserite in circuiti integrati. La tecnologia CMOS e usata in microprocessori, microcontrollori, nella RAM statica e in molti altri circuiti logici digitali. E’ la tecnologia piu raffinata, che consente un abbattimento dei consumi e dei tempi di risposta, congiuntamente alla possibilita di realizzare un’altissima densita di integrazione.\\
    I transistor CMOS sono chiamati transistor MOS-FET a effetti di campo ..., richiedono molta meno potenza e non dissipano potenza in ingresso, sono molto più piccoli e garantiscono un minore tempo di risposta e sono diversi dai transistor a giunzione (VJT).
\end{itemize}

\noindent
Si consideri la realizzazione tramite transistor delle principali porte logiche.

\begin{itemize}
    \item \textbf{Porta NOT}\\
    \[circuito\]
    Nella porta NOT bisogna realizzare un’inversione del valore logico. Questa funzione si realizza mediante un singolo transistor, nel quale la variabile d’ingresso va ad alimentare la base, mentre quella di uscita si ricava sul collettore del transistor. Se si associ la costante 1 a un livello alto di tensione, p.es. la VCC di figura 4.18a, e la costante 0 a un livello basso, cioè la tensione di massa pari a 0V , il funzionamento dell’invertitore e il seguente: quando la variabile ` x assume valore logico 1, e cioe viene portata a tensione ` VCC , il transistor si polarizza direttamente ed entra in piena conduzione. Tale condizione corrisponde alla saturazione vista in figura 3.252; la tensione VCE crolla idealmente a 0 V , portando la variabile y in uscita nello stato logico 03. Quando viceversa la variabile x assume valore logico 0, e cioe viene portata a tensione ` 0 V (connessione a massa), il transistor blocca la conduzione e la IC diventa (praticamente) nulla. Tale condizione corrisponde all’interdizione vista in figura 3.25; la tensione VCE diventa pari alla VCC , portando a 1 logico il valore dell’uscita.
    Infatti, con corrente in ingresso, il transistor va in saturazione, per cui la tensione è nulla.\\
    Se la corrente in ingresso è nulla, il transistor va in interdizione, per cui la tensione è massima.\\
    La resistenza in ingresso deve essere ovviamene commisurata per non bruciare il circuito, così come è fondamentale il ruolo della \textbf{resistenza di carico} che permette di separare la tensione di alimentazione e avere una corrente variabile.\\
    La tensione di saturazione \(V_{SAT}\) non è mai nulla, nella realtà, ma se la corrente in ingresso è significativamente maggiore di \(0\), allora in uscita si avrà il valore logico \(0\), a causa di un \textbf{cortocircuito} che si viene a determinare.\\
    Se, invece, la corrente in ingresso è nulla, allora il transistor va in \textbf{interdizione}, per cui la corrente in uscita viene \textbf{interdetta}, pertanto la tensione in uscita sarà pari a quella di alimentazione. Pertanto, l'uscita corrisponde al valore ALTO.\\
    In questo modo si sta usando il transistor in modo digitale, come se fosse un vero interruttore, in quanto si opera ai suoi valori estremi, \(0\) e \(1\).\\
    Un transistor che opera, invece, in modo analogico, viene usato come amplificatore, e può assumere anche valori intermedi.\\
    Se si utilizzasse un transistor CMOS, il funzionamento sarebbe esattamente analogico, solo che viene comandato in tensione, con significativi vantaggi in termini di \textbf{dissipazione di potenza}. Inoltre, i CMOS possono essere anche realizzati in modo molto più microscopico.

    \item \textbf{Porta AND}
    Nella porta AND bisogna fare in modo che se anche uno solo degli ingressi e a ` 0, l’uscita resti a 0. Il circuito di figura 4.18b realizza questa condizione. Poiche l’uscita a  ́ 1 significa livello alto di tensione, per realizzarla bisogna che entrambi i due transistor associati ai due ingressi, che sono posti in serie, siano in piena conduzione. Per realizzare cio` e necessario portare le variabili ` x e y d’ingresso a VCC . Se anche uno solo dei due ingressi rimane a livello basso, uno dei due transistor va in interdizione e la tensione di uscita resta a livello basso, il che corrisponde a 0 logico.
    Se in ingresso \(x\) e \(y\) sono a valore logico \(1\), allora entrambi i transistor vanno in saturazione, pertanto diventano dei cortocircuiti, e lasciano passare la tensione di alimentazione, quindi l'uscita avrà valore \(1\).\\
    Se almeno uno dei due transistor va in interdizione, allora si forma un circuito aperto e quindi l'uscita ha valore \(0\).

    \item Nella porta OR bisogna fare in modo che se anche uno solo degli ingressi e a ` 1, l’uscita resti a 1. Il circuito di figura 4.18c realizza questa condizione. Poiche l’uscita a  ́ 1 significa livello alto di tensione, per realizzarla basta che anche uno solo dei due transistor associati ai due ingressi, che sono posti in parallelo, sia in piena conduzione. Per realizzare cio` e sufficiente portare o l’ingresso ` x o l’ingresso y al valore VCC . Solo se entrambi gli ingressi rimangono a livello basso i transistor sono in interdizione e la tensione di uscita resta a livello basso, il che corrisponde a 0 logico.\\
    Effettivamente, essendo i due transistor posti in \textbf{parallelo} a differenza della porta AND, è sufficiente che almeno uno dei due vada in saturazione perché l'uscita sia a \(1\).\\
    Inoltre, solamente quando entrambi i transistor sono interdetti, ovvero sono a valore \(0\), allora anche in uscita sarà valore \(1\).

    \item \textbf{Porta NOR}\\
    Anche in questo caso si parte della porta negata, che e la OR, spostando la resistenza ` R2 di carico dall’emettitore di T2  ́ T1 al collettore di T2   T1 (si veda la figura 4.19b). In questo modo, quando entrambi i transistor sono in interdizione grazie al fatto che entrambi gli ingressi sono a 0, l’uscita va a 1; e questa rimane l’unica condizione per la quale si ha uscita alta. Infatti se anche uno solo degli ingressi va a 1, uno dei due transistor va in saturazione e l’uscita collassa a 0.
\end{itemize}

\subsection{Forme canoniche: \textit{minterm}}
L'obiettivo di questa sezione si traduce nel formulare una struttura logica tale da poter semplificare nei minimi termini una funzione logica, riducendo il numero di connettivi (e porte) logiche per la realizzazione la rete logica, con significativi vantaggi in termini di latenza e tempi di risposta.\\
Le modalità per raggiungere tali fini sono \(3\): la prima di tipo squisitamente algebrico e dal risultato dubbio (o incerto), in quanto vi possono essere diverse linee di semplificazione che producono espressioni booleane diverse, ma perfettamente equivalenti dal punto di vista algebrico. Dopodiché vi è la \textbf{mappa di Karnaugh} e il \textbf{metodo tabella di Quine-McCluskey}.

\vspace{1em}
\noindent
Sia assegnata una qualunque funzione Booleana espressa mediante tavola di verità. Si considei, in particolare, la seguente funzione:


\newpage
\begin{center}
    12 Ottobre 2021
\end{center}

\subsection{Riassunto}
Una funzione a \(3\) variabili è una funzione che va dall'insieme \(2^3\) a \(2\), pertanto il numero di funzioni che si possono costruire con \(n\) variabili cresce molto velocemente, in quanto è dato da:
\[2^{2^n}\]
Considerando le funzioni più semplici, ad una sola variabile, si considerano \(4\) sole possibile funzioni, quella \textbf{nulla}, quella \textbf{identica}, la funzione \textbf{buffer} che trasmette a distanza il valore della variabile \(x\), mentre la funzione \textbf{complementare} trasmette a distanza il valore complementare della variabile \(x\).\\
Le funzioni a due variabili sono \(2^{2^2} = 16\) e sono le più comuni e importanti, tali da giustificarne una dignità circuitale.\\
In particolare si considerano le porte AND e OR, a cui si aggiungono:
\begin{itemize}
    \item XOR, la quale può essere espressa come:
    \[x \oplus y = (A \cap \overline{B}) \cup (\overline{A} \cap B)\]
    che, in termini di logica binaria si esprime anche come
    \[x \oplus y = x\overline{y} + \overline{x}y \]
    ma anche
    \[x \oplus y = x\overline{y} + \overline{x}y = x\overline{y} + \overline{x}y + x\overline{x} + y \overline{y} = (x + y) + (\overline{x} + \overline{y})\]
    che, dal punto di vista logico, circuitale ed economico sono perfettamente equivalenti.

    \item XNOR, ovvero la negazione della porta XOR, la quale può essere espressa come:
    \[x \odot y = \overline{x \oplus y} = \overline{\overline{x}y + x \overline{y}} = \overline{(\overline{x}y)}\]
    ... continua...

    \item NAND

    \item NOR

    che sono definiti connettivi universali, in quanto da sole sono in grado di costruire tutte e \(16\) le possibili funzioni logiche a \(2\) variabili.
\end{itemize}

\vspace{1em}
\noindent
\textbf{Osservazione}: Il principio di funzionamento della porta NOT prevede l'utilizzo di un solo transistor, il quale viene polarizzato con una corrente (opportunamente commisurata alle caratteristiche tecniche del transistor stesso), pertanto va in \textbf{saturazione} e la tensione in uscita collassa al valore \(0\).\\
Se il transitors non viene polarizzato, allora il transistor va in \textbf{interdizione} e la tensione sul collettore si trova allo stesso valore della tensione di alimentazione (\(V_{CC}\)), per cui la tensione di uscita ha valore \(1\).

\vspace{1em}
\noindent
\textbf{Osservazione}: Il principio di funzionamento della porta AND si prevede l'utilizzo di due transistors a giunzione, o anche di tipo MOS, o MOS FET, con un princpio di funzionamento analogo.

\vspace{1em}
\noindent
\textbf{Osservazione}: Il principio di funzionamento della porta OR si prevede l'utlizzo di due transistors posti in parallelo, pertanto solamente quando ambedue i transistors sono in saturazione allora la tensione in uscita avrà valore alto.\\
Altrimenti, se almeno uno dei due è in \textbf{interdizione}, allora la tensione in uscita sarà a valore alto.

\subsection{Forme canoniche: \textit{minterm}}
L'obiettivo di questa sezione è quello di poter manipolare e gestire qualunque tipo di funzione logica, con qualunque numero di variabili.\\
Si consideri, per semplciità, la seguente funzione
\[f = (x + z) \cdot (\overline{x} + z)\]
che assumerà il valore in uscita \(1\) solamente in corrispondenza di specifiche terne di valori delle variabili in ingresso, ovvero \(010\), \(011\), \(101\) e \(111\) che prendono il nome di \textbf{termini minimi}.\\
Per poterli comporre in una funzione, bisogna sommarli logicamente, in modo tale che la funzione risultante produca il valore logico \(1\) solamente in una di tali \(4\) possibili casi. Infatti:
\[f = \overline{x}y\overline{z} + \overline{x}yz + x\overline{y}z + xyz\]
ovvero si è costruita la \textbf{somma dei termini minimi}, ovvero una \textbf{somma logica dei \textit{minterm}}, che è in grado di rappresentare una qualunque funzione logica.\\
In altre parole:
\[f(x_1, x_2, ..., x_n) = \underset{i = 0}{\overset{2^n - 1}{\sum}} \mu_i m_i = \underset{i: \mu_i = 1}{\sum} m_i\]
dove \(\mu_i\) è il valore assunto dalla funzione in corrispondenza del termine minimo \(m_i\) e \(0 \leq i \leq 2^n -1\).\\
Nel caso analizzato, si ha \(m_2 = \overline{x}y\overline{z}, m_3 = \overline{x}yz, m_5 = x\overline{y}z, m_7 = xyz, \mu_2 = \mu_3 = \mu_5 = \mu_7 = 1, \mu_0 = \mu_1 = \mu_4 = \mu6 = 0\). La formula (4.16) rappresenta la funzione nei termini della cosiddetta prima forma canonica (o somma di prodotti). Se nella tavola di verità della funzione si pone in evidenza la codifica dei termini minimi si ottiene:

\[Tabella di verita\]

Dal punto di vista circuitale, la somma di \textit{minterm} si rappresenta come segue:

\subsection{Forme canoniche: \textit{maxterm}}
Un discorso del tutto analogo si può formulare procedendo per dualità, e realizzando un \textbf{prodotto di somme}. Ciò richiede di analizzare i termini per i quali la funzione vale 0; dalla figura 4.20a si osserva che ciò accade in corrispondenza delle terne \(000, 001, 100\) e \(110\), cioè \(0, 1, 4\) e \(6\) con la codifica impiegata in precedenza.\\
L’idea e quella di esprimere il valore della funzione come prodotto di somme che sono sempre a 1, tranne che per una singola configurazione che le manda a 0; una funzione che vale sempre 1, tranne che per una singola configurazione per la quale vale 0 si chiama \textbf{termine massimo} (o \textbf{\textit{maxterm}}), e viene indicata con \(M_1\). In figura 4.22 viene rappresentato \(M_1\); il modo più semplice per esprimere un termine massimo è quello di ricorrere alla somma logica di variabili dirette e negate, le prime in corrispondenza delle variabili che in ingresso valgono 0, le seconde in corrispondenza delle variabili che in ingresso valgono 1. Nel caso di figura 4.22 si tratta della funzione \(x + y + \overline{z}\)

\[Tabella di verita\]

Tenendo conto di tutto ciò si perviene alla \textit{seconda forma canonica} (o prodotti di somme), nella quale la generica funzione si rappresenta come
\[f(x_1, x_2, ..., x_n) = \prod_{i = 0}^{2^n - 1} (\mu_i + M_i) = \prod_{i : \mu_i = 0} M_i\]
Dove \(0 \leq i \leq 2^n - 1\), \(\mu_i\) è il valore della funzione in corrispondenza del termine massimo \(M_i\), il quale si codifica secondo la procedura prima descritta: nel caso analizzato si ha \(M_0 = x + y + z, M_1 = x + y + \overline{z}, M_4 = \overline{x} + y + z, M_6 = \overline{x} + \overline{y} + z\) e così via.
Dal punto di vista circuitale, il prodotto dei \textit{maxterm} si rappresenta come segue:

\vspace{1em}
\noindent
\textbf{Osservazione}: Si verifichi che:
\[\overline{x}y\overline{z} + \overline{x}yz + x\overline{y}z + xyz = (x + y + z) \cdot (x + y + \overline{z}) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{y} + z)\]
Infatti:
\[\overline{x}y\overline{z} + \overline{x}yz + x\overline{y}z + xyz \overset{(A6)}{=} \overline{x}y(\overline{z} + z) + xz(\overline{y} + y) \overset{(A7)}{=} \overline{x}y \cdot 1 + xz \cdot 1 \overset{(A3)}{=} \overline{x}y + xz\]
Se, invece, si considera il prodotto di somme si ottiene:
\[(x + y + z) \cdot (x + y + \overline{z}) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{y} + z) \overset{(T9)}{=} (x + y) \cdot (\overline{x} + z) \overset{(T10)}{=} \overline{x}z + xz\]
In questo caso si è ottenuta la medesima espressione, anche dal punto di vista formale, ma potrebbe accadere che, con funzioni più complesse e, con un maggior numero di variabili si ottenga un risultato logicamente equivalente, ma formalmente differente. A tal proposito, sempre sfruttando i teoremi precedentemente esplicati, si dovrà dimostrare che sono equivalenti anche formalmente.\\
A seguito della semplificazione la complessità del circuito associato alla funzione si riduce drasticamente, come si può notare dalla figura 4.25; servono in tutto \(3\) porte a \(2\) ingressi al posto di \(11\) porte a \(2\) ingressi.\\
La semplificazione certamente apporta vantaggi enormi alla rete logica ottenuta, in quanto si riduce la dissipazione (che comunque non sarà mai nulla) e anche una minore probabilità di guasto. Naturalmente, maggiore è il numero di porte, maggiori saranno le transizioni a cui la rete logica sarà soggetta. Ad ogni transizione corrisponde una commutazione di stato del transistor, e quindi per una frazione di secondo si avrà sia tensione che corrente e quindi si rilevano dei picchi di dissipazione deleteri per le componenti circuitali.\\
Le formule (4.17) e (4.19), che portano entrambe alla forma semplificata \(\overline{x}y + xz\) per la funzione appena analizzata, aprono il problema della ricerca della forma algebrica minima, che consenta, cioè, di realizzare la funzione usando il minimo numero possibile di porte logiche.\\
Tanto per inquadrare la questione, si tenga conto che la (4.17) richiederebbe quattro porte AND con tre ingressi e una porta OR a quattro ingressi, più tutti i NOT che servono alla complementazione delle varie variabili; nel caso della (4.19) servono invece quattro porte OR con tre ingressi e una porta AND a quattro ingressi; se invece usiamo la funzione semplificata bastano due AND e un OR a due ingressi.\\ Affronteremo nel seguito il problema della minimazione delle espressioni. Si osservi inoltre che e sempre possibile passare dal prodotto di somme (4.21) alla somma di prodotti (4.20) e viceversa, sfruttando il Teorema di De Morgan a partire dalla doppia negazione T3
\[\overline{\overline{(x + y + z) \cdot (x + y + \overline{z}) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{y} + z)}} \overset{(T7)}{=} \overline{\overline{(x + y + z)} + \overline{(x + y + \overline{z})} + \overline{(\overline{x} + y + z)} + \overline{(\overline{x} + \overline{y} + z)}}\]
\[\overset{(T7)}{=} \overline{\overline{x} \overline{y} \overline{z} + \overline{x} \overline{y} z + x \overline{y} \overline{z} + x y \overline{z}}\]
La semplificazione si può a questo punto concludere nel modo seguente
\[\overline{\overline{x} \overline{y} \overline{z} + \overline{x} \overline{y} z + x \overline{y} \overline{z} + x y \overline{z}} \overset{(A6)}{=} \overline{\overline{x} \overline{y}(z + \overline{z}) + x \overline{z}(y + \overline{y})} \overset{(A7)}{=} \overline{\overline{x} \overline{y} + x \overline{z}} \overset{(T7)}{=} \overline{\overline{x} \overline{y}} \cdot \overline{x \overline{z}} \overset{(T7)}{=} (x + y) \cdot (\overline{x} + z) \overset{(T10)}{=} \overline{x}y + xz\]

\subsection{Interpretazione circuitale}
Come già accennato in precedenza, la prima applicazione circuitale dell’Algebra Booleana si deve a Shannon, che la usò nella progettazione di circuiti complessi per la commutazione a contatti. Questo tipo di applicazione e ancora largamente usata, anche se i contatti dei rel ` e sono oggi sostituiti da dispositivi a stato solido (SCR, TRIAC). Tuttavia l’importanza dell’Algebra Booleana e legata soprattutto all’impiego nell’ambito dei circuiti logici, il cui peso e oggidì preponderante.\\
Nello stesso periodo di Shannon, Bush stava progettando un calcolatore analogico che viene utilizzata per la risoluzione di equazioni differenziali mediante la progettazione di circuiti di resistenze retti proprio dall'equazione differenziale di interesse. L'evoluzione del circuito, poi, permetterà di rilevare tutte le soluzioni dell'equazione analizzata.
Nell'interpretazione di Shannon le costanti logiche \(0\) e \(1\) indicano rispettivamente un circuito aperto o uno chiuso (mediante, per esempio, un interruttore), mentre le variabili indicano il contatto di un interrutore o di un relè.\\
Con i simboli \(x\) e \(\overline{x}\) si indicano due contati azionati contemporaneamente, me sempre tali che quando uno è aperto, l'altro è chiuso e viceversa.\\
Se si pongono degli interruttori in parallelo, si ottiene un circuito che simula una porta logica OR, mentre se gli interrutori vengono posti in serie si ottiene un circuito perfettamemte equivalente ad una porta logica AND.\\
La stessa cosa accade con un circuito deviatore che permette di ottenere la negazione di una variabile.\\
In questo modo è possibile esprimere una funzione logica complicata che sia attraverso la realizzazione di un circuito equivalente, e viceversa.

\newpage
\begin{center}
    13 Ottobre 2021
\end{center}

\subsection{Riassunto}
È stata precedentemente introdotta una duplice modalità per manipolare le espressioni logiche, ovvero la \textbf{prodotto dei termini massimi} (o \textit{maxterm}, che valgono sempre \(1\), tranne che per una sola combinazione per cui valgono \(0\)) e \textbf{somma dei termini minimi} (o \textit{minterm}, che valgono sempre \(0\) tranne che per una sola combinazione per la quale valgono \(1\)).\\
Naturalmente, le espressioni sono \textbf{mutuamente escludenti}, per cui è chiaro che in ambedue i casi è ovvio che in ingresso si presenti solamente uno solo dei \textit{minterm} (o \textit{maxterm}) individuati.\\
Il discernimento tra una o l'altra configurazione è assolutamente ininfluente: certo è che, se la funzione logica da semplificare assume maggiori \(1\) rispetto allo \(0\), allora sarà più conveniente procedere alla trasformazione della funzione in \textbf{prodotti di somme}, o di \textit{maxterm}.\\
Naturalmente, però, se, come si è detto, i due procedimenti conducono al medesimo risultato, pertanto sarà sempre possibile ricondurre una somma di \textit{minterm} ad un prodotto di \textit{maxterm}. È chiaro che è possibile che vi siano più forme minime equivalenti, che differiscono solamente dal punto di vista formale.\\
Un procedimento atto a passare dal prodotto di somme alla somma di prodotti e viceversa, sfruttando il Teorema di De Morgan \ref{sec:teorema_de_morgan} a partire dalla doppia negazione.

\vspace{1em}
\noindent
\textbf{Osservazione}: L'interpretazione circuitale dell'algebra booleana si deve a Claude Shannon, il quale osservò, molto semplicemente che:

\begin{itemize}
    \item Interruttori posti in serie simulano il funzionamento di una porta AND
    \item Interruttori posti in parallelo simulano il funzionamento di una porta OR
    \item Un deviatore permette di simulare il funzionamento di una porta NOT
\end{itemize}

\vspace{1em}
\noindent
\textbf{Esempio}: Tale osservazione può avere dei risvolti particolarmente interessanti dal punto di vista pratico.\\
Si consideri, come esempio concreto, il problema seguente: in un appartamento c’e un corridoio; quando si entra si vuole accendere la luce dall’interruttore \(x\) prossimo all’ingresso, che si supponga sia a destra nel disegno di figura 4.31). Uscendo si vuole spegnere la luce dall’interruttore \(y\) prossimo all’uscita sulla sinistra.\\
Dal momento che si hanno due variabili binarie \(x\) e \(y\), è possibile costruire una tavola di verità che permetta di rappresentare tutti i possibili stati della luce (accesa o spenta) in funzione del valore delle variabili in ingresso.\\
Pertanto:

\begin{table}[H]
    \centering
    \begin{tabular}{cc|c}
         \(x\) & \(y\) & \(L\)\\
         \hline
         \(0\) & \(0\) & \(0\)\\
         \(0\) & \(1\) & \(1\)\\
         \(1\) & \(0\) & \(1\)\\
         \(1\) & \(1\) & \(0\)\\
    \end{tabular}
    \caption{Circuito di comando di una luce da due punti e relativa tavola di verità}
    \label{tab:circuito_luce_due_punti_tavola_verita}
\end{table}

\vspace{1em}
\noindent
Si proceda, ora, alla traduzione di tale funzione logica in forma canonica. Pertanto, tale funzione espressa come \textbf{somma di \textit{mintern}}:
\[\overline{x}y + x\\overline{y}\]
che, dal punto di vista circuitale, corrisponde ad un circuito in parallelo con due deviatori, dimodoché sia soddisfatta la funzione logica di partenza.\\
Mentre come \textbf{prodotto di \textit{maxterm}}:
\[(\overline{x} + \overline{y}) \cdot (x + y)\]
che, dal punto di vista circuitale, corrisponde ad un circuito in serie, in cui sono sempre presenti due deviatori. Tuttavia, tale soluzione non è conveniente, in
quanto si necessita di un un cavo in più per la connessione trai due deviatori.

\vspace{1em}
\noindent
\textbf{Osservazione}: Naturalmente, in questo caso si palesa la necessità di prevedere l'adeguamento degli interruttori in funzione della tipologia di carico da azionare.\\
Infatti, quando le lamine dei conduttori vengono poste a contatto, per quanto possa essere irrilevante, si ha una resistenza  di contatto che comporta la dissipazione di potenza. Ma non solo, quando le lamine vengono avvicinate per la chiusura del contatto, si ha una \textbf{carica disruttiva} che comporta la generazione di una scarica elettrica che, con successivi e multipli utilizzi, determina un danneggiamento dell'interruttore. Per questo si necessita l'applicazione di un interruttore che esercita una maggiore pressione fra le lamine, ma questo comporta un maggior costo.\\
In questo secondo caso, si necessita la presenza di un \textit{transistor} e di un relè, in modo tale che la \textbf{circuiteria di potenza} (ovvero il grosso interruttore e la lampada) sia separata dalla \textbf{circuiteria di controllo logico}, che viene realizzata con delle porte logiche.\\
Questo, chiaramente, comporta un maggior costo, ma con due grandi vantaggi. Il primo rappresentato dal fatto che si ha una netta separazione tra i due circuiti, mentre il secondo è rappresentato dalla sicurezza, in quanto si ha una barriera tra il circuito ad elevata tensione e quello che opera ai livelli di tensione propri delle porte logiche. Pertanto, nel malaugurato caso in cui vi sia una perdita dell'interruttore, l'utente è separato e protetto da eventuali scariche di alta tensione.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri, ora, il caso in cui al posto di avere due soli interruttori per comandare un carico.\\
In questo secondo caso, si avranno tre variabili binarie \(x, y\) e \(z\) per le quali si costruisce la seguente tabella di verità:

\begin{table}[H]
    \centering
    \begin{tabular}{ccc|c}
         \(x\) & \(y\) & \(L\)\\
         \hline
         \(0\) & \(0\) & \(0\) & \(0\)\\
         \(0\) & \(0\) & \(1\) & \(1\)\\
         \(0\) & \(1\) & \(0\) & \(1\)\\
         \(0\) & \(1\) & \(1\) & \(0\)\\
         \(1\) & \(0\) & \(0\) & \(1\)\\
         \(1\) & \(0\) & \(1\) & \(0\)\\
         \(1\) & \(1\) & \(0\) & \(0\)\\
         \(1\) & \(1\) & \(1\) & \(1\)\\
    \end{tabular}
    \caption{Circuito di comando di una luce da tre punti e relativa tavola di verità}
    \label{tab:circuito_luce_tre_punti_tavola_verita}
\end{table}

\vspace{1em}
\noindent
La sintesi del circuito mediante termini minimi fornisce
\[\overline{x} \overline{y} z + \overline{x} y \overline{z} + x \overline{y} \overline{z} + xyz\]
Prima di procedere alla realizzazione circuitale, è però opportuno semplificare il più possibile l'espressione, ottenendo
\[\overline{x} (\overline{y}z + y \overline{z}) + x (\overline{y} \overline{z} + yz)\]
Il circuito che si ricava è rappresentato nella figura seguente:

Si noti che i circuiti ottenuti presentano un numero di invertitori maggiore del numero di interruttori richiesti dal problema.\\
Si necessita, allora, l'impiego di un dispositivo noto con il nome di \textbf{invertitore}, ovvero un \textbf{doppio deviatore} che si può trovare solamente in due possibili stati \(=\), oppure \(\times\).

\vspace{1em}
\noindent
Si provi, ora, a realizzare la rete logica mediante i termini massimi, per cui si ottiene
\[(x + y + z) \cdot (x + y + \overline{z}) \cdot (\overline{x} + y + \overline{z}) \cdot (\overline{x} + \overline{y} + z) = [x + (y +z) \cdot (\overline{y} + \overline{z})] \cdot [(\overline{x} + (y + \overline{z}) \cdot (\overline{y} + z)]\]
che con la semplificazione porta al circuito della figura seguente:


Anche in questo caso la soluzione basata sui termini massimi è meno vantaggiosa, poiché richiede \(5\) deviatori invece di \(4\), ma tale circuito è del tutto analogo a quello precedente, ma differente dal punto di vista topologico.\\
Al di là della straordinaria importanza applicativa del metodo formale basato sull’Algebra Booleana, importante riflettere, soprattutto alla luce di quest’ultimo esempio, che molto spesso in ambito ingegneristico la teoria offre diverse soluzioni tra loro equivalenti; sta poi al progettista scegliere la migliore, tenuto conto della razionalità e semplicità delle soluzioni prospettate, dei costi, del numero di componenti impiegati ecc.

\subsection{Semplificazione delle espressioni Booleane}
Si e già visto, dagli esempi che precedono, che le forme canoniche non esauriscono le espressioni analitiche di una funzione; anzi, come per qualsiasi relazione algebrica, anche quelle logiche possono essere trasformate in un certo numero di espressioni formalmente diverse, ma equivalenti dal punto di vista matematico.\\
Ad esempio:
\[f = \overline{x} \overline{y} \overline{z} + \overline{x} \overline{y} z + \overline{x}yz + xyz = \overline{x} \overline{z} (\overline{z} + z) + yz (\overline{x} + x) = \overline{x} \overline{y} + yz\]
Si diranno equivalenti due funzioni che abbiano la stessa tavola di verità, forma semplificata di una funzione ogni sua espressione non canonica, forma minima quella in cui ogni variabile, diretta o negata che sia, compare il minor numero di volte.\\
Le tecniche di semplificazione sono due:
\begin{enumerate}
    \item Mappe di Karnaugh
    \item Metodo tabellare di Quine - Mc Cluskey
\end{enumerate}

\subsubsection{Mappe di Karnaugh}
Il metodo proposto da Karnaugh e un metodo grafico di semplificazione che permette di ottenere molto semplicemente la forma minima di una funzione espressa come somma di prodotti (\textit{minterm}), facendo ricorso a particolari mappe di rappresentazione. Quale limitazione si ha che, sebbene il metodo sia concettualmente applicabile a funzioni di qualsiasi numero di variabili, esso diviene difficoltoso già per \(5, 6\) variabili.\\
Le mappe di Karnaugh, che possono essere considerate un ulteriore metodo di rappresentazione di una funzione logica, consistono in matrici di \(m\) righe e \(k\) colonne, in cui \(m = 2^i\) e \(k = 2^j\) per qualche \(i, j\), col vincolo che
\[2^i \cdot 2^j = 2^n\]
ovvero pari al numero di elementi della matrice, in cui \(n\) è il numero delle variabili. Di conseguenza, le mappe di Karnaugh presentano \(4\) celle nel caso di funzioni di due variabili, \(8\) per quelle di tre variabili, \(16\) per quelle di quattro e così via.\\
Ogni elemento della matrice rappresenta un termine minimo, che entra in un’espressione \textit{minterm} di somma di prodotti.\\
Infatti, il concetto alla base delle mappe di Karnaugh prevede di disporre i termini minimi nello spazio in modo tale che i termini minimi da semplificare si trovino vicini fra di loro.\\
In particolare, le mappe devono essere costruita in modo tale che nel passaggio da una cella all'altra ci sia sempre e solo un'unica variabile che viene a modificarsi. Ciò implica che la tabella è chiusa in se stessa tanto in senso orizzontale, quanto in senso verticale.\\
Per questo motivo, infatti, nella disposizione dei numeri binari sulle righe e sulle colonne si utilizza la sequenza \(00, 01, 11, 10\) dimodoché nel passaggio da una colonna\\riga all'altra vi sia il cambio di una sola variabile.

\newpage
\begin{center}
    18 Ottobre 2021
\end{center}
\subsection{Riassunto}
Le forme canoniche sono di due tipi: \textit{minterm} e \textit{maxterm}. In particolare considerando la funzione che vale sempre \(1\) tranne per un solo caso in cui vale \(0\) prende il nome di \textit{maxterm}, mentre la funzione che vale sempre \(0\) e vale \(1\) solamente per un solo caso, ovvero quello oggetto di studio prende il nome di \textit{minterm}. Talune forme sono esattamente equivalenti per l'espressione di una funzione logica: \textbf{prodotto di \textit{maxterm}} oppure \textbf{somma di \textit{minterm}}.\\
Dal punto di vista pratico, come si è detto, sono perfettamente equivalentiu: certo è che, se una funzione presenta più \(0\) che \(1\), sarà più conveniente ricorrere al \textbf{prodotto di \textit{maxterm}} anziché una \textbf{somma di \textit{minterm}}.\\
Attraverso l'applicazione dei teoremi fondanti dell'algebra booleana, così come attraverso i teoremi di De Morgan, è possibile passare da una forma all'altra in modo molto equivalente, giungendo ad una semplificazione decisamente vantaggiosa, sia in termini circuitali che in termini logici.\\
L'interpretazione circuitale dell'Algebra Booleana si deve a Shannon, che la scelse come tema del suo master. La chiave centrale di tale interpretazione sono gli interruttori che rappresentano le variabili booleana e che possono essere poste in serie per simulare il funzionamento di una porta AND; se sono poste in parallelo simulano il funzionamento di una porta OR.\\
La commutazione di ciascun interruttore rappresentante una variabile determina una particolare configurazione del circuito da cui è possibile estrarre la corrispondente funzione logica.\\
L'utilizzo dell'Algebra Booleana e delle tavole di verità è fondamentale nella progettazione di un circuito e per la determinazione della soluzione più conveniente e pratica dal punto di vista circuitale.\\
Dal punto di vista tecnico, inoltre, si è osservato che il carico che è necessario comandare comporterebbe la necessità di dimensionare tutti gli interruttori esposti all'elevata tensione del carico, con un elevato costo per ciascun interruttore. Attraverso l'utilizzo di un relè e di un transistor, si ha una separazione netta tra la parte del circuito ad elevata tensione e quella di controllo, per cui gli interruttori con cui interagisce l'utente lavorano alla tensione delle porte logiche, ovvero pochi volt, eliminando il rischio delle perdite di elevate tensioni.\\
Inoltre, gli interruttori che operano ad elevata tensione sono molto costosi e pesanti e presentano una molla di richiamo che sarebbe stato difficile azionare, anche dal punto di vista meccanico. Implementando, invece, interruttori che operano sui \(5 V\) si agevola anche l'azione di accensione e spegnimento da parte dell'utente.\\
L'accessione di un punto luce da più di \(2\) interruttori, invece richiederebbe l'uso di un dispositivo denominato \textbf{invertitore}, che può essere installato in quantità molteplice per assolvere i compito richiesto.
Le semplificazioni booleane effettuate ricorrendo ai teoremi dell'Algebra Booleana o ai teoremi di De Morgan sono molto complesse e dal basso tasso di successo.\\
Le mappe di Karnaugh, invece, sono delle mappe \textbf{bidimensionali} (che, comunque, ne limita le applicazioni) che presentano un numero di righe e di colonne che deve essere sempre \(2^i \times 2^j = 2^n\), ove \(n\) è il numero delle variabili di cui si sta analizzando l'equazione logica. Inoltre, le n-uple di variabili devono essere disposte in modo tale che tra due n-uple successive vi sia la variazione di una sola variabile.\\
Si presti particolare attenzione che la mappa deve essere considerata \textbf{chiusa} sia in senso orizzontale che in senso verticale, pertanto la combinazione \(00, 01, 11, 10\) rispetta la regola precedentemente esposta, in quanto la dupla \(10\) è considerata adiacente a \(00\), ma comunque tra le due si ha il cambiamento di una sola variabile.\\
Nella Figura \ref{fig:mappa_karnaugh_16_8_2} sono riprodotte le strutture delle mappe per \(2\), \(3\) e \(4\) variabili.

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaughquatre}
        \contingut{\overline{x} \overline{y}, x \overline{y}, \overline{x}y, xy}
    \end{Karnaughquatre}
    %
    \begin{Karnaughvuit}
        \contingut{\overline{x}\overline{y}\overline{z}, \overline{x}y\overline{z}, x\overline{y}\overline{z}, xy\overline{z}, \overline{x}\overline{y}z, \overline{x}yz, x\overline{y}z, xyz}
    \end{Karnaughvuit}
    %
    \begin{Karnaugh}

    \end{Karnaugh}
        %
    \caption{Mappe di Karnaugh a \(16\), \(8\) e \(2\)}
    \label{fig:mappa_karnaugh_16_8_2}
\end{figure}

\noindent
Grazie al fatto che le mappe sono costruite in modo tale che due celle contigue differiscono solamente per una sola variabile è possibile costruire il \textbf{prodotto di \textit{maxterm}} e la \textbf{somma di \textit{minterm}} osservando dove la funzione vale \(0\) o \(1\) rispettivamente. Costruendo i \textbf{sottocubi} come multipli di \(2\) è possibile costruire il \textbf{determinante} semplicemente osservando sulle righe e sulle colonne interessate le variabili che rimangono costanti.\\
In particolare:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,0,0,1,0,1,0}
        \implicant{0}{4}{red}
        \implicantcostats{4}{6}{blue}
    \end{Karnaughvuit}
    \caption{Mappa di Karnaugh a \(8\)}
    \label{fig:mappa_karnaugh_8}
\end{figure}

\noindent
Pertanto costruendo i due implicanti corrispondenti a due \textit{minterm} si ha:
\[\overline{xy} + z\overline{y}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Quando si costruiscono i \textbf{sottocubi} bisogna fare attenzione a non includere dei termini già considerati, per cui si costruirebbero degli \textbf{implicanti \textit{non primi}}.\\
In particolare, vige la regola dei \textbf{sottocubi massimali} e della \textbf{copertura minima}.

\vspace{1em}
\noindent
\textbf{Osservazione}: Naturalmente, attraverso la costruzione degli implicanti è possibile ottenere, in conclusione, delle semplificazioni corrette, ma formalmente diverse, ma deve essere sempre possibile passare dall'una all'altra.

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri la seguente mappa di Karnaugh:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{1,0,0,0,0,0,0,0,0,1,0,0,1,1,0,0}
        \implicant{0}{0}{red}
        \implicant{12}{13}{blue}
        \implicant{13}{9}{yellow}
    \end{Karnaugh}
    \caption{Mappa di Karnaugh a \(16\)}
    \label{fig:mappa_karnaugh_16_1}
\end{figure}

\vspace{1em}
\noindent
\textbf{Esempio}: Si consideri la seguente mappa di Karnaugh:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{1,0,1,0,1,1,1,0,1,0,1,0,1,1,1,0}
        \implicantcostats{0}{10}{green}
    \end{Karnaugh}
    \caption{Mappa di Karnaugh a \(16\)}
    \label{fig:mappa_karnaugh_16_2}
\end{figure}

\subsubsection{Mappa di Karnaugh sui termini massimi}
Le mappe di Karnaugh possono essere usate anche per costruire la funzione semplificata secondo la II forma canonica basata sul prodotto di somme. In tal caso i sottocubi e la relativa copertura minima vanno costruiti sugli \(0\).\\
Si consideri la seguente mappa di Karnaugh:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,0,1,1,1,0}
    \end{Karnaughvuit}
    \caption{Mappa di Karnaugh a \(8\)}
    \label{fig:mappa_karnaugh_8_1}
\end{figure}

\subsubsection{Mappe di Karnaugh a \(5\) o più variabili}
Per la realizzazione delle mappe di Karnaugh con più di \(4\) variabili è impossibile costruire un'unica mappa, ma è sufficiente, nel caso di \(5\) variabili, sdoppiare la mappa in due sottomappe da \(4\):

\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{0,0,1,0,0,0,1,0,0,0,1,0,0,0,1,0}
    \end{Karnaugh}
    \begin{Karnaugh}
        \contingut{0,1,1,0,0,0,1,0,0,0,1,0,1,1,1,1}
    \end{Karnaugh}
    \caption{Mappa di Karnaugh a \(32\)}
    \label{fig:mappa_karnaugh_32}
\end{figure}

\noindent
Se si avessero \(6\) variabili, si necessiterebbe la costruzione di \(4\) mappe di Karnaugh a \(16\) e così via.

\subsection{Condizioni non specificate}
Nella sintesi di una funzione logica di \(n\) variabili si può presentare il caso in cui per \(k\) configurazioni delle variabili di ingresso la funzione vale \(1\), per \(m\) configurazioni vale \(0\), ma \(k + m = 2^n\). Le restanti \(2^n - (m + k)\) configurazioni vengono dette \textbf{condizioni non specificate} (o anche d.c.c., acronimo di \textit{don’t care condition}).\\
In pratica questa situazione si verifica ogni qualvolta in un circuito certe configurazioni di ingresso sono fisicamente impossibili, o rendono privo di significato il valore dell’uscita. Da un punto di vista strettamente analitico ciò accade quando una funzione \(F\) è funzione delle variabili \(\phi_1, \phi_2, \phi_3, ..., \phi_m\), ognuna delle quali è a sua volta funzione delle variabili \(x_1, x_2, ..., x_n\), cioé
\[... continua ...\]
Si nota che le terne di possibili valori \(\phi_1, \phi_2, \phi_3\) sono \(000, 001, 010, 100, 101\), mentre le configurazioni rimanenti \(011, 110, 111\) non compaiono. Ne consegue che la tavola di verità della \(F\) conterrà condizioni non specificate in corrispondenza di queste configurazioni d’ingresso.\\
Sulla tavola di verita le condizioni non specificate vengono indicate con un trattino, nella forma canonica racco- `
gliendo in parentesi i termini minimi corrispondenti, sulle mappe di Karnaugh contrassegnando con il simbolo ˆ
la casella corrispondente a ciascuna condizione non specificata.
Le condizioni non specificate possono venir sfruttate nelle semplificazioni, in modo da pervenire ad espressioni
minime piu semplici. Se si opera con le mappe di Karnaugh, le semplificazioni vanno ancora fatte in modo da `
coprire tutte le caselle contrassegnate con un 1, ma se serve si possono aggregare anche le caselle associate a
condizioni non specificate, che possiamo contrassegnare con ˆ ; in pratica si tratta di utilizzare le condizioni non
specificate per allargare al massimo i sottocubi di copertura della funzione, assegnando a ciascuna di loro il valore
1 o 0 a seconda che torni o meno utile per ottenere sottocubi piu ampi. Nell’esempio di sopra si ottiene

\newpage
\begin{center}
    11 Ottobre 2021
\end{center}
\subsection{Riassunto}
La semplificazione delle espressioni booleane può avvenire in tre modi egualmente validi:
\begin{enumerate}
    \item Teoremi dell'Algebra Booleana
    \item Mappa di Karnaugh
    \item Metodo tabellare Quine-McCluskey
\end{enumerate}
Le mappe di Karnaugh sono delle \textbf{tabelle piane} che presentano un numero di celle pari a \(2^n\), ove \(n\) è il numero di variabili oggetto di studio. Le righe e le colonne devono essere formate nel seguente modo
\[2^i \cdot 2^j = 2^n\]
La realizzazione prevede di disporre le variabili sulle righe e sulle colonne in modo tale che tra una cella all'altra, tanto in senso orizzontale quanto in quello verticale, vi sia una sola variazione di una variabile, nel senso della sua complementarietà.\\
L'individuazione dei blocchi di \textit{minterm} deve avvenire rispettando due importanti condizioni: \textbf{sottocubi massimali} e della \textbf{copertura minima}.\\
Per determinare, poi, a quale \textbf{implicante} corrisponde al sottocubo evidenziato è sufficiente rilevare quelle variabili che nel sottocubo rimangono costanti sia in orizzontale che in verticale, nel senso della loro complementarietà.\\
Si ricordi, ancora, che le mappe di Karnaugh devono essere considerate chiuse in senso circolare (\textbf{adiacenza per circolarità}), per cui è necessario disporre le variabili come \(00, 01, 11, 10\) per cui tra \(00 - 01\), \(01 - 11\), \(11 - 10\) e \(10 - 00\) vi è la variazione di una sola variabile.\\
Naturalmente, con questa modalità è possibile anche individuare \textbf{sottocubi \textit{non primi}}, ovvero sottocubi che includono minterm già inglobati in altri sottocubi. Certo è che la somma di minterm risultante sarà comunque correttamente espressa, solamente sarà presente una ridondanza superflua, che può essere semplificata tramite i teoremi dell'Algebra Booleana. Naturalmente, però, è sufficiente evitare di considerare sottocubi non primi per ottenere, alla fine, la formula minima di espressione della funzione booleana.\\
Naturalmente, in forza del \textbf{principio di dualità}, così com'è possibile ottenere una somma di \textit{minterm} tramite le mappe di Karnaugh, sarà anche possibile ottenere un prodotto di \textit{maxterm}, che può rivelarsi più conveniente qualora nella tabella siano maggiormente presenti gli \(0\) piuttosto che gli \(1\).\\
Naturalmente, è possibile procedere all'applicazione delle mappe di Karnaugh anche a \(5\), \(6\) variabili, con un sensibile aumento della complicazione della procedura di semplificazione. In questi casi, sarà maggiormente conveniente operare tramite il metodo tabella di Quine-McCluskey (anche più facilmente programmabile).\\
È possibile, inoltre, che la funzione analizzata non possa presentare determinate combinazioni di variabili in ingresso, le quali sarebbero prive di significato. Allora, nella procedura di semplificazione tramite mappa di Karnaugh, laddove figurano le combinazioni di variabili in ingresso si pone una \(X\) che può tramutarsi in \(1\) o \(0\) al fine di \textbf{massimizzare i sottocubi} e garantire una \textbf{copertura minima}.

\vspace{1em}
\noindent
\textbf{Esercizio}: Si costruisca una funzione \(f\) a \(n = 3\) variabili:

\begin{table}[H]
    \centering
    \begin{tabular}{ccc|c}
         $x$ & $y$ & $z$ & $f(x, y, z)$\\
         \hline
         $0$ & $0$ & $0$ & $1$\\
         $0$ & $0$ & $1$ & $1$\\
         $0$ & $1$ & $0$ & $0$\\
         $0$ & $1$ & $1$ & $1$\\
         $1$ & $0$ & $0$ & $1$\\
         $1$ & $0$ & $1$ & $0$\\
         $1$ & $1$ & $0$ & $1$\\
         $1$ & $1$ & $1$ & $1$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_1}
\end{table}

\vspace{1em}
\noindent
Considerando la \textbf{somma di \textit{minterm}} si ottiene
\[f = \overline{x}\overline{y}\overline{z} + \overline{x}\overline{y}z + \overline{x}yz + x\overline{y}\overline{z} + xy\overline{z} + xyz\]
Che si può semplificare come segue, sfruttando i \textbf{teoremi di assorbimento} e dell'\textbf{idempotenza}:
\[f = \overline{x}\overline{y} \cdot (\overline{z} + z) + yz \cdot (\overline{x} + x) + \overline{y} \overline{z} \cdot (\overline{x} + x) + xy \cdot (\overline{z} + z)\]
ottenendo
\[f = \overline{x}\overline{y} + yz + \overline{y}\overline{z} + xy = \overline{y} \cdot (\overline{x} + \overline{z}) + y \cdot (x + z)\]

\vspace{1em}
\noindent
Considerando il \textbf{prodotto di \textit{maxterm}} si ottiene
\[f = (\overline{x} + y + \overline{z}) \cdot (x + \overline{y} + z)\]
ovvero
\[f = \overline{x}x + \overline{x}y + \overline{x}z + xy + \overline{y}y + xz + \overline{x}\overline{z} + y\overline{z} + z\overline{z}\]
da cui si ottiene
\[f = xy + x\overline{z} + \overline{x}\overline{y} + \overline{y}\overline{z} + \overline{x}z + yz\]
Ma per il \textbf{teorema dell'assorbimento 3}, \(x\overline{y} + \overline{x}\overline{z} + \overline{y}\overline{z} = x\overline{y} + \overline{x}\overline{z}\) così come \(xy + \overline{x}z + yz = xy + \overline{x}z\), pertanto si ottiene:
\[f = x\overline{z} + \overline{x}\overline{y} + xy + \overline{x}z\]

\vspace{1em}
\noindent
Si realizzi, allora, la mappa di Karnaugh corrispondente, scegliendo i \textit{minterm}
\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,1,1,1,0,1}
        \implicant{4}{5}{red}
        \implicantcostats{0}{2}{yellow}
        \implicant{3}{7}{blue}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_1}
\end{figure}

\vspace{1em}
\noindent
Da cui si ottiene
\[f = \overline{y}z + \overline{x}z + xy\]
la quale è differente dalla espressione ottenuta all'inizio. Per cui, costruendo un'ulteriore mappa di Karnaugh si individuano tutti i termini presenti nell'espressione di partenza, ovvero
\[f = \overline{x}\overline{y} + yz + \overline{y}\overline{z} + xy\]

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,1,1,1,0,1}
        \implicant{3}{2}{red}
        \implicant{3}{7}{blue}
        \implicant{0}{4}{yellow}
        \implicant{4}{5}{green}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_1}
\end{figure}

\noindent
Pertanto, come si nota, sono stati scelti dei sottocubi \textit{non primi}, pertanto vi sono \(4\) termini al posto di \(3\), come formula minima.\\
Pertanto si deve cercare di eliminare i due sottocubi non primi \(xy\) e \(\overline{x}z\) che deve divenire \(yz\), ovvero
\[xy + \overline{x}z = yz\]

\vspace{1em}
\noindent
Si consideri una nuova funzione a \(n = 3\) variabili
\begin{table}[H]
    \centering
    \begin{tabular}{ccc|c}
         $x$ & $y$ & $z$ & $f(x, y, z)$\\
         \hline
         $0$ & $0$ & $0$ & $1$\\
         $0$ & $0$ & $1$ & $0$\\
         $0$ & $1$ & $0$ & $1$\\
         $0$ & $1$ & $1$ & $0$\\
         $1$ & $0$ & $0$ & $1$\\
         $1$ & $0$ & $1$ & $0$\\
         $1$ & $1$ & $0$ & $0$\\
         $1$ & $1$ & $1$ & $0$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_2}
\end{table}

\noindent
Considerando la \textbf{somma di \textit{minterm}} si ottiene
\[f = \overline{x}\overline{y}\overline{z} + \overline{x}y\overline{z} + x\overline{y}\overline{x}\]
che per l'idempotenza di supo scrivere come:
\[f = \overline{x}\overline{y}\overline{z} + \overline{x}y\overline{z} + x\overline{y}\overline{x} + \overline{x} \overline{y} \overline{z}\]
Per cui, per il teorema dell'assorbimento si ha
\[f = \overline{x}\overline{z} \cdot (\overline{y} + y) + \overline{y}\overline{z} \cdot (x + \overline{x}) = \overline{x} \overline{z} + \overline{y}\overline{z}\]

\vspace{1em}
\noindent
Considerando il \textbf{prodotto di \textit{maxterm}} si ottiene
\[f = (y + \overline{z}) \cdot (\overline{y} + \overline{z}) \cdot (\overline{x} + \overline{y}) = (y \overline{y} + y \overline{z} + \overline{y}\overline{z} + \overline{z} \overline{z}) \cdot (\overline{x} + \overline{y}) = \overline{z} \cdot (\overline{x} + \overline{y}) = \overline{x} \overline{z} + \overline{y} \overline{z}\]

\vspace{1em}
\noindent
Che sulla mappa di Karnaugh figura come segue:

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,1,1,0,0,0,0,0}
        \implicant{0}{1}{red}
        \implicantcostats{1}{2}{green}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_3}
\end{figure}

\vspace{1em}
\noindent
\textbf{Esercizio}: Si consideri la seguente funzione logica:

\vspace{1em}
\noindent
Si consideri una nuova funzione a \(n = 3\) variabili
\begin{table}[H]
    \centering
    \begin{tabular}{ccc|c}
         $x$ & $y$ & $z$ & $f(x, y, z)$\\
         \hline
         $0$ & $0$ & $0$ & $1$\\
         $0$ & $0$ & $1$ & $1$\\
         $0$ & $1$ & $0$ & $0$\\
         $0$ & $1$ & $1$ & $1$\\
         $1$ & $0$ & $0$ & $0$\\
         $1$ & $0$ & $1$ & $0$\\
         $1$ & $1$ & $0$ & $1$\\
         $1$ & $1$ & $1$ & $0$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_3}
\end{table}

\noindent
Considerando la \textbf{somma di \textit{minterm}} si ottiene
\[f = \overline{x}\overline{y}\overline{z} + \overline{x}\overline{y}z + \overline{x}yz + xy\overline{z}\]
Procedendo alla semplificazione si ottiene
\[f = \overline{x}\overline{y}(\overline{z} + z) + \overline{x}yz + xy\overline{z}\]
e procedendo per \textbf{idempotenza}, si ottiene
\[f = \overline{x}\overline{y}(\overline{z} + z) + \overline{x}\overline{y}z + \overline{x}yz + xy\overline{z} = \overline{x}\overline{y}(\overline{z} + z) + \overline{x}z (\overline{y} + y) + xy\overline{z}\]
che equivale a
\[f = \overline{x}\overline{y} + \overline{x}z + xy\overline{z}\]

\vspace{1em}
\noindent
Considerando il \textbf{prodotto di \textit{maxterm}} si ottiene:
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y + z) \cdot (\overline{x} + y + \overline{z}) \cdot (\overline{x} + \overline{y} + \overline{z})\]
che per il teorema \textbf{T9} si ottiene
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y + z) \cdot (\overline{x} + \overline{z})\]
Procedendo per \textbf{idempotenza} si procede alla duplicazione di \(\overline{x} + y + \overline{z}\) per cui si ottiene:
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y + z) \cdot (\overline{x} + y + \overline{z}) \cdot (\overline{x} + \overline{z})\]
da cui, sempre per il teorema \textbf{T9},  si ottiene
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y) \cdot (\overline{x} + \overline{z})\]
Ancora una volta si è ottenuto un risultato di \textbf{prodotto di \textit{maxterm}} differente dalla \textbf{somma di \textit{minterm}}, per cui, sviluppando i prodotti si ha:
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y) \cdot (\overline{x} + \overline{z}) = (x + \overline{y} + z) \cdot (\overline{x} + \overline{x} \overline{z} + \overline{x}y + y \overline{x}\]
che per il teorema dell'assorbimento \(3\) si ottiene:
\[f = (x + \overline{y} + z) \cdot (\overline{x} + y \overline{z})\]
che, sviluppando il prodotto è uguale a
\[f = (x \overline{x} ... continua ...\]
Di fatto, come si osserva, si è ottenuto il medesimo risultato di partenza.

\vspace{1em}
\noindent
La realizzazione della mappa di Karnaugh si ottiene

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,0,1,1,1,0,0}
        \implicant{3}{3}{red}
        \implicant{4}{5}{blue}
        \implicant{0}{4}{green}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_4}
\end{figure}

\noindent
Che ancora una volta produce il risultato cercato:
\[\overline{x} \overline{y} + \overline{x} z + xy\overline{z}\]

\vspace{1em}
\noindent
Si consideri una nuova funzione a \(n = 3\) variabili
\begin{table}[H]
    \centering
    \begin{tabular}{ccc|c}
         $x$ & $y$ & $z$ & $f(x, y, z)$\\
         \hline
         $0$ & $0$ & $0$ & $1$\\
         $0$ & $0$ & $1$ & $0$\\
         $0$ & $1$ & $0$ & $1$\\
         $0$ & $1$ & $1$ & $1$\\
         $1$ & $0$ & $0$ & $0$\\
         $1$ & $0$ & $1$ & $1$\\
         $1$ & $1$ & $0$ & $1$\\
         $1$ & $1$ & $1$ & $0$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_4}
\end{table}

Considerando la \textbf{somma di \textit{minterm}} si ottiene
\[f = \overline{x} \overline{y} \overline{z} + \overline{x} y \overline{z} + \overline{x} y z + x \overline{y} \overline{z} + xy \overline{z}\]
Procedendo alla semplificazione si ottiene
\[f = \overline{x} (\overline{z} + yz) + x \overline{y} + x\overline{y}z + xy \overline{z} = \overline{x} (\overline{z} + y) + x \overline{y} + x\overline{y}z + xy \overline{z}\]
ovvero
\[f = \overline{x}\overline{z} + \overline{x}y + x \overline{y} + x\overline{y}z + xy \overline{z}\]
Ancora una volta è possibile raccogliere il primo e l'ultimo addendo
\[f = \overline{z} \cdot (\overline{x} + xy) + \overline{x}y + x \overline{y} + x\overline{y}z\]
ovvero
\[f = \overline{x}\overline{z} + \overline{z}y + \overline{x}y + x \overline{y} + x\overline{y}z\]
da cui
\[f = \overline{x}\overline{z} + \overline{x}y + y \overline{z} + x\overline{y}z\]

\vspace{1em}
Considerando, ora, il \textbf{prodotto di \textit{maxterm}} si ottiene
\[f = (\overline{x} + \overline{y} + z) \cdot (x + \overline{y} + \overline{z}) \cdot (x + y + z)\]
Non potendo semplificare, si procede allo sviluppo dei prodotti:
\[f = (x \overline{x} + xy + xz + \overline{x}y + y + yz + \overline{x}\overline{z} + y \overline{z} + z \overline{z}) \cdot (\overline{x} + \overline{y} + \overline{z})\]
da cui si ottiene
\[f = (y \cdot (x + \overline{x} + 1 + z + \overline{z}) + xz + \overline{x} \overline{z}) \cdot (\overline{x} + \overline{y} + \overline{z})\]
ovvero
\[f = (y + xz + \overline{x} \overline{z}) \cdot (\overline{x} + \overline{y} + \overline{z})\]
Ancora una volta si sviluppano i prodotti:
\[f = \overline{x}y + y\overline{y} + y \overline{z} + x \overline{x} z + x \overline{y} z + x z \overline{z} + \overline{x} \overline{z} + \overline{x} \overline{y} \overline{z} + \overline{x} \overline{z}\]
da cui
\[f = \overline{x}y + y \overline{z} + x \overline{y} z + \overline{x} \overline{z} + \overline{x} \overline{y} \overline{z} + \overline{x} \overline{z}\]
che, per il teorema dell'assorbimento si semplifica come:
\[f = \overline{x}\overline{z} + \overline{x}y + y \overline{z} + x\overline{y}z\]


e procedendo per \textbf{idempotenza}, si ottiene
\[f = \overline{x}\overline{y}(\overline{z} + z) + \overline{x}\overline{y}z + \overline{x}yz + xy\overline{z} = \overline{x}\overline{y}(\overline{z} + z) + \overline{x}z (\overline{y} + y) + xy\overline{z}\]
che equivale a
\[f = \overline{x}\overline{z} + \overline{x}y + y \overline{z} + x\overline{y}z\]

\vspace{1em}
\noindent
La realizzazione della mappa di Karnaugh si ottiene

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,1,0,1,0,1,1,0}
        \implicant{0}{1}{red}
        \implicant{1}{3}{green}
        \implicant{1}{5}{blue}
        \implicant{6}{6}{yellow}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_5}
\end{figure}

Da cui si può osservare:
\[f = \overline{x}\overline{z} + \overline{x}y + y\overline{z} + x\overline{y}z\]

\newpage
\begin{center}
    20 Ottobre 2021
\end{center}
\subsection{Metodo tabellare Quine - Mc Cluskey}
Il metodo di Quine - Mc Cluskey è un procedimento tabellare che consente di ottenere la forma minima come somma di prodotti per qualsiasi funzione logica. Esso si basa sulla relazione:
\[f x + f \overline{x} = f\]
già usata in precedenza per le mappe di Karnaugh; solo che ora essa viene applicata in modo sistematico a tutti i termini minimi della funzione.\\
Per capirne la logica si consideri la seguente funzione logica:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{5pt}
    \begin{tabularx}{\textwidth}{ccc}
    {
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|ccc|cc}
             & & $x$ & $y$ & $z$ & $f$\\
             \hline
             $0$ & $\overline{x}\overline{y}\overline{z}$ & $0$ & $0$ & $0$ & $0$\\
             $1$ & $\overline{x}\overline{y}z$ & $0$ & $0$ & $1$ & $0$\\
             $2$ & $\overline{x}y\overline{z}$ & $0$ & $1$ & $0$ & $1$ & \color{red}$\bm{*}\\
             $3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$ & \color{red}$\bm{*}\\
             $4$ & $x\overline{y}\overline{z}$ & $1$ & $0$ & $0$ & $0$\\
             $5$ & $x\overline{y}z$ & $1$ & $0$ & $1$ & $1$ & \color{blue}$\bm{*}\\
             $6$ & $xy\overline{z}$ & $1$ & $1$ & $0$ & $0$\\
             $7$ & $xyz$ & $1$ & $1$ & $1$ & $1$ & \color{blue}$\bm{*}\\
        \end{tabular}
    }
    &
    {
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|c|ccc|cc}
             \textbf{Livello} & & & $x$ & $y$ & $z$ & $f$\\
             \hline
             $0$ & $0$ & $\overline{x}\overline{y}\overline{z}$ & $0$ & $0$ & $0$ & $0$\\
             \hline
              & $1$ & $\overline{x}\overline{y}z$ & $0$ & $0$ & $1$ & $0$\\
              \(1\) & $2$ & $\overline{x}y\overline{z}$ & $0$ & $1$ & $0$ & $1$ & \textcolor{red}{*}\\
              & $4$ & $x\overline{y}\overline{z}$ & $1$ & $0$ & $0$ & $0$\\
             \hline
              &
             $3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$ & \textcolor{red}{*}\\
             \(2\) & $5$ & $x\overline{y}z$ & $1$ & $0$ & $1$ & $1$ & \textcolor{blue}{*}\\
             & $6$ & $xy\overline{z}$ & $1$ & $1$ & $0$ & $0$\\
             \hline
             $3$ & $7$ & $xyz$ & $1$ & $1$ & $1$ & $1$ & \textcolor{blue}{*}\\
        \end{tabular}
    }
    &
    {
        \setlength{\tabcolsep}{3.5pt}
        \begin{tabular}{c|c|c|ccc|cc}
             \textbf{Livello} & & & $x$ & $y$ & $z$ & $f$\\
             \hline
             $1$ & $2$ & $\overline{x}y\overline{z}$ & $0$ & $1$ & $0$ & $1$ & \textcolor{red}{*}\\
             \hline
             \parbox{3em}{\multirow{2}{3em}{\centering \(2\)}} &
             $3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$ & \textcolor{red}{*}\\
             & $5$ & $x\overline{y}z$ & $1$ & $0$ & $1$ & $1$ & \textcolor{blue}{*}\\
             \hline
             $3$ & $7$ & $xyz$ & $1$ & $1$ & $1$ & $1$ & \textcolor{blue}{*}\\
        \end{tabular}
    }
    \end{tabularx}


    \caption{Trasformazione della tavola di verità della funzione logica \(f\) per ottenere la tabella di Quine-Mc Cuskey}
    \label{tab:tavola_verita_Quine_Mc_Cuskey}
\end{table}

\noindent
La cui semplificazione per via algebrica porta a:
\[\overline{x}y\overline{z} + \overline{x}yz + x\overline{y}z + xyz = \overline{x}y(\overline{z} + z) + xz(\overline{y} + y) = \overline{x}y + xz\]
È ben evidente che la struttura della semplificazione \(\overline{x}y\overline{z} + \overline{x}yz = \overline{x}y(\overline{z} + z)\), che riguarda i termini minimi contrassegnati con \textcolor{red}{*} in tabella, e del tipo \(f\overline{z} + fz = f\) e riguarda due termini minimi che differiscono per la sola variabile \(z\), che si trova diretta in uno dei due termini e negata nell'altro. La stessa cosa si può dire per i due termini minimi contrassegnati con \textcolor{blue}{*}.\\
Si procede, quindi, all'ordinamento delle righe della tabella in modo da mettere su livelli adiacenti le n-uple che differiscono per una sola variabile.\\
Una possibilità e quella di procedere per peso crescente delle n-uple binarie associate ai termini minimi (dove per peso di un'n-upla è da intendersi il numero di 1 in essa presenti) in modo che a ciascun peso corrisponda un livello; così facendo si ottiene la seconda tabella riportata.\\
Se ora si eliminano le righe che corrispondono a termini minimi per i quali la funzione vale 0 (che non rientrano nella somma di prodotti) si ottiene la terza tabella di figura, che corrisponde alla tabella di Quine-Mc Cuskey.\\
A questo punto si può procedere con le semplificazioni, che generano una seconda tabella. Poiché \(\overline{x} y \overline{z}\) si semplifica con \(\overline{x}yz\) per ottenere
\(\overline{x}y\), su questa tabella vengono contrassegnate con una lineetta la variabile \(z\) che è stata oggetto di semplificazione; vengono, inoltre, contrassegnati a lato i termini minimi che sono coinvolti nella semplificazione, cioè \(2 - 3\); viceversa la coppia \(2 - 5\) non porta ad alcuna semplificazione. Esaurito il confronto tra i livelli \(1\) e \(2\), è possibile ora controllare le semplificazioni tra i livelli \(2\) e \(3\); in questo caso si trovano semplificazioni per entrambe le coppie, cioè \(3 - 7\) e \(5 - 7\).\\
La tabella che si ottiene è la seguente:

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{c|c|ccc|cc}
         & $ $ & $x$ & $y$ & $z$ & $ $ & \\
         \hline
         & $2 - 3$ & $0$ & $1$ & $-$ & $A$ & \\
         \hline
         & $3 - 7$ & $-$ & $1$ & $1$ & $B$ & \\
         & $5 - 7$ & $1$ & $-$ & $1$ & $C$ & \\
    \end{tabular}
    \caption{Tabella di semplificazione}
    \label{tab:semplificazione_quine_mc_cuskey}
\end{table}

\noindent
Poiché non è possibile fare altre semplificazioni ci si ferma, contrassegnando con delle lettere progressive gli implicanti che non si possono più semplificare.\\
L’espressione finale deriva dalla somma degli implicanti coinvolti, \(f = A + B + C = \overline{x}y + yz + xz\).\\
Si osservi tuttavia che l’espressione che otteniamo non e in forma minima, poiché come noto il termine \(yz\) si può eliminare per il terzo teorema dell'assorbimento.\\
Infatti, ciò si può facilmente osservare anche attraverso la realizzazione della mappa di Karnaugh della funzione considerata

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{0,1,0,0,0,1,1,1}
        \implicant{1}{5}{red}
        \implicant{7}{6}{green}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_6}
\end{figure}

\noindent
Per individuare il minimo numero di implicanti che implicano tutti i termini minimi è necessario costruire il \textbf{reticolo del metodo}, disponendo sulle righe gli implicanti, sulle colonne i termini minimi, e ponendo un segno (p.es. un pallino) in corrispondenza dei termini minimi che formano ciascun implicante.\\
Infatti si osserva che:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \draw[-] (0,1)--(6.5,1) node[left]{};
        \draw[-] (1,0)--(1,6) node[above]{};
        \draw[-] (0,3)--(6.5,3) node[right]{};
        \draw[-] (2.5,0)--(2.5,6) node[above]{};
        \draw[-] (0,5)--(6.5,5) node[right]{};
        \draw[-] (4,0)--(4,6) node[above]{};
        \draw[-] (5.5,0)--(5.5,6) node[above]{};



        \draw[line width=2pt,black,-stealth](0,0)--(3,3) node[anchor=north west]{};
        \filldraw[black] (0,0) circle (2pt) node[anchor=south] {};
        \filldraw[black] (3,3) circle (2pt) node[anchor=south] {$a + i \cdot b$};
\end{tikzpicture}
    \caption{Modulo di un numero complesso}
    \label{fig:modulo_numero_complesso}
\end{figure}

\vspace{1em}
\noindent
La mappa di Karnaugh corrispondente è

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,1,0,0,1,1,0,1}
        \implicant{0}{5}{red}
        \implicant{5}{7}{green}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_6}
\end{figure}

... continua ...
\noindent
Tali realizzazioni si comprendono non appena si valuta attentamente la mappa di Karnaugh associata alla funzione a \( n = 4\) variabili:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{0,1,0,1,1,0,1,1,0,1,1,1,1,1,1,1}
        \implicantcostats{4}{14}{red}
        \implicant{13}{11}{blue}
        \implicant{13}{10}{yellow}
        \implicant{7}{10}{green}
        \implicantdaltbaix{1}{11}{violet}
        \implicant{7}{14}{orange}
    \end{Karnaugh}
    \caption{Mappa di Karnaugh a \(16\)}
    \label{fig:mappa_karnaugh_16_2}
\end{figure}

\newpage
\section{Circuiti combinatori}

\subsection{Introduzione}
Nella realtà pratica, l'Algebra Booleana non sempre viene impiegata per raggiungere la \textbf{forma minima} di una funzione logica, in quanto se così si procedesse non si potrebbe sfruttare il \textbf{fattore di scala}.\\
Infatti, quando si deve realizzare una rete logica, molto spesso è più conveniente impiegare dei \textbf{moduli precostituiti}, anche ridondanti, piuttosto che richiedere la realizzazione di un modulo \textit{custom}, costruito appositamente per lo scopo.\\
In questi termini si parla di \textbf{circuiti combinatori}. Si chiamano combinatori quei circuiti dotati di uno o più ingressi e uno o più uscite, il cui funzionamento è descritto da una funzione logica; in questi circuiti gli ingressi e le uscite possono assumere solo uno di due valori binari previsti (0 e 1); inoltre in ogni istante l’uscita è funzione deterministica unicamente degli ingressi. La figura seguente illustra la struttura generale di un circuito combinatorio con \(n\) ingressi e \(m\) uscite, il cui funzionamento è descritto dalla funzione \(F : 2^n \rightarrow 2^m\), che è una funzione Booleana da \(2^n\) a \(2^m\) realizzata mediante \(m\) funzioni Booleane \(f_i : 2^n \rightarrow 2\):
\[y_1 = f_1 (x_1, x_2, ..., x_n)\]
\[y_2 = f_2 (x_1, x_2, ..., x_n)\]
\[...\]
\[y_m = f_m (x_1, x_2, ..., x_n)\]

\subsubsection{Itinerari e livelli}
Ogni rete logica e formata da un certo numero di porte (AND, OR, ecc.) tra loro variamente interconnesse, da un certo numero di ingressi, contraddistinti in figura seguente con i simboli \(A_i\), e da un certo numero di uscite, contraddistinte nella medesima figura con i simboli \(B_k\).\\
Si dice itinerario tra due elementi \(X\) e \(Y\) qualsiasi

\newpage
\begin{center}
    25 Ottobre 2021
\end{center}

\subsection{Riassunto}
Il metodo di semplificazione di Quine Mc Cluskey si basa su una semplice proprietà:
\[f \cdot x + f \cdot \overline{x} = f\]
Una volta che è nota la tabella di verità della funzione logica oggetto di interesse si rilevano tutte le combinazioni delle variabili in ingresso che producono il valore logico \(1\) e si classificano tali combinazioni sulla base del peso, (ovvero \quotes{quanti \(1\) sono presenti in ciascuna combinazione delle variabili in ingresso}).\\
Classificate le combinazioni in ingresso si confrontano tutte le combinazioni di ciascun peso con quelle di tutti gli altri pesi al fine di verificare se vi sono delle coppie di variabili che si conservano e che, quindi, si possono semplificare, in modo tale da raggiungere la forma minima, maggiormente semplificata.\\
Quando non si può più procedere ad un'ulteriore semplificazione si è, di fatto, ottenuto l'insieme di tutti gli \textbf{implicanti} che non significa che costituiscono la forma minima, ma possono essere ancora ridondanti.\\
Infatti, gli implicanti ottenuti tramite la tabella di Quine Mc Cluskey devono essere analizzati ulteriormente tramite il cosiddetto \textbf{reticolo}, al fine di determinare la \textbf{copertura essenziale e minima}, e mai sovrabbondante.\\
Infatti, realizzando successivamente la mappa di Karnaugh ci si rende conto, effettivamente, della presenza di sottocubi non primi che vengono comunque ottenuti anche attraverso il metodo di Quine Mc Cluskey e che può essere arginato attraverso il reticolo, così come nella mappa di Karnaugh si osservava che alcuni \textit{minterm} erano già stati \quotes{coperti} da altri sottocubi precedentemente individuati.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si presti particolare attenzione che, nella fase di confronto e di semplificazione, ogni qualvolta si semplificano dei \textit{minterm}, questi vengono \quotes{spuntati}, per tenere conto che sono stati considerati.\\
Se, infatti, un \textit{minterm} non viene considerato in fase di semplificazione allora bisognerà tenerne conto, in quanto diventerà un \textbf{implicante} nella fase finale di semplificazione (per quanto possa essere modesto, in quanto implicherà solamente se stesso).

\vspace{1em}
\noindent
\textbf{Esercizio}: Si consideri la seguente funzione logica:

\vspace{1em}
\noindent
Si consideri una nuova funzione a \(n = 3\) variabili
\begin{table}[H]
    \centering
    \begin{tabular}{ccc|c}
         $x$ & $y$ & $z$ & $f(x, y, z)$\\
         \hline
         $0$ & $0$ & $0$ & $1$\\
         $0$ & $0$ & $1$ & $1$\\
         $0$ & $1$ & $0$ & $0$\\
         $0$ & $1$ & $1$ & $1$\\
         $1$ & $0$ & $0$ & $1$\\
         $1$ & $0$ & $1$ & $0$\\
         $1$ & $1$ & $0$ & $1$\\
         $1$ & $1$ & $1$ & $1$\\
    \end{tabular}
    \caption{Funzione a \(n = 3\) variabili}
    \label{tab:funzione_3_variabili_3}
\end{table}

\vspace{1em}
\noindent
La realizzazione della mappa di Karnaugh si ottiene

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,1,1,1,0,1}
        \implicant{3}{2}{red}
        \implicant{5}{7}{blue}
        \implicant{0}{4}{green}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_4}
\end{figure}

\noindent
Oppure, equivalentemente

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{1,0,1,1,1,1,0,1}
        \implicantcostats{0}{2}{red}
        \implicant{4}{5}{blue}
        \implicant{3}{7}{green}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_4}
\end{figure}

\noindent
Procedendo, invece, tramite il metodo tabella di Quine Mc Clusky si ottiene

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{c|c|c|ccc|cc}
         \textbf{Livello} & & & $x$ & $y$ & $z$ & $f$\\
         \hline
         $0$ & $0$ & $\overline{x}\overline{y}\overline{z}$ & $0$ & $0$ & $0$ & $1$\\
         \hline
         \parbox{3em}{\multirow{2}{3em}{\centering \(1\)}} & $1$ & $\overline{x}\overline{y}z$ & $0$ & $0$ & $1$ & $1$\\
          & $4$ & $x\overline{y}\overline{z}$ & $1$ & $0$ & $0$ & $1$\\
         \hline
         \parbox{3em}{\multirow{2}{3em}{\centering \(2\)}} &
         $3$ & $\overline{x}yz$ & $0$ & $1$ & $1$ & $1$\\
         & $6$ & $xy\overline{z}$ & $1$ & $1$ & $0$ & $1$\\
         \hline
         $3$ & $7$ & $xyz$ & $1$ & $1$ & $1$ & $1$\\
    \end{tabular}
    \caption{Tabella di Quine Mc Cuskley}
    \label{tab:tabella_quine_mc_cluskey}
\end{table}

\vspace{1em}
\noindent
Da cui si ottiene

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{5pt}
    \begin{tabular}{c|c|ccc|cc}
         & $ $ & $x$ & $y$ & $z$ & $ $ & \\
         \hline
         & $0 - 1$ & $0$ & $0$ & $-$ & $A$ & \\
         & $0 - 4$ & $-$ & $0$ & $0$ & $B$ & \\
         \hline
         & $1 - 3$ & $0$ & $-$ & $1$ & $C$ & \\
         & $4 - 6$ & $1$ & $-$ & $0$ & $D$ & \\
         \hline
         & $3 - 7$ & $-$ & $1$ & $1$ & $E$ & \\
         & $6 - 7$ & $1$ & $1$ & $-$ & $F$ & \\
    \end{tabular}
    \caption{Tabella di semplificazione}
    \label{tab:semplificazione_quine_mc_cuskey}
\end{table}

\vspace{1em}
\noindent
La realizzazione del reticolo conduce al seguente risultato

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{tikzpicture}
        \draw[-] (0,1)--(9.5,1) node[left]{};
        \draw[-] (1,0)--(1, 12) node[above]{};
        \draw[-] (0,3)--(9.5,3) node[right]{};
        \draw[-] (2.5,0)--(2.5,12) node[above]{};
        \draw[-] (0,5)--(9.5,5) node[right]{};
        \draw[-] (4,0)--(4,12) node[above]{};
        \draw[-] (5.5,0)--(5.5,12) node[above]{};
        \draw[-] (0,7)--(9.5,7) node[right]{};
        \draw[-] (7,0)--(7,12) node[above]{};
        \draw[-] (8.5,0)--(8.5,12) node[above]{};
        \draw[-] (0,9)--(10,9) node[right]{};
        \draw[-] (0,11)--(9.5,11) node[right]{};

        \filldraw[black] (-1,0.8) circle (0pt) node[anchor=south] {$F$};
        \filldraw[black] (-1,2.8) circle (0pt) node[anchor=south] {$E$};
        \filldraw[black] (-1,4.8) circle (0pt) node[anchor=south] {$D$};
        \filldraw[black] (-1,6.8) circle (0pt) node[anchor=south] {$C$};
        \filldraw[black] (-1,8.8) circle (0pt) node[anchor=south] {$B$};
        \filldraw[black] (-1,10.8) circle (0pt) node[anchor=south] {$A$};

        \filldraw[black] (1,-1) circle (0pt) node[anchor=south] {$0$};
        \filldraw[black] (2.5,-1) circle (0pt) node[anchor=south] {$1$};
        \filldraw[black] (4,-1) circle (0pt) node[anchor=south] {$3$};
        \filldraw[black] (5.5,-1) circle (0pt) node[anchor=south] {$4$};
        \filldraw[black] (7,-1) circle (0pt) node[anchor=south] {$6$};
        \filldraw[black] (8.5,-1) circle (0pt) node[anchor=south] {$7$};

        \filldraw[black] (1,11) circle (3pt) node[anchor=south] {};
        \filldraw[black] (2.5,11) circle (3pt) node[anchor=south] {};

        \filldraw[black] (1,9) circle (3pt) node[anchor=south] {};
        \filldraw[black] (5.5,9) circle (3pt) node[anchor=south] {};

        \filldraw[black] (2.5,7) circle (3pt) node[anchor=south] {};
        \filldraw[black] (4,7) circle (3pt) node[anchor=south] {};
\end{tikzpicture}
    \caption{Modulo di un numero complesso}
    \label{fig:modulo_numero_complesso}
\end{figure}

\vspace{1em}
\noindent
Da cui, tramite la creazione de reticolo, si possono ottenere le due possibili funzioni
\[f_1 = x \overline{z} + \overline{x} \overline{y} + yz\]
\[f_2 = x y + \overline{y} \overline{z} + \overline{x} z\]
ovvero
\[0 - 1 + 4 - 6 + 3 - 7\]
e
\[0 - 4 + 1 - 3 + 6 - 7\]

\vspace{1em}
\noindent
I circuiti combinatori devono essere studiati attraverso due procedure
\begin{itemize}
    \item L'\textbf{analisi logica}, al fine di determinarne il funzionamento e i componenti;
    \item La \textbf{sintesi logica}, al fine di ottimizzarne il funzionamento o semplicemente modificarlo.
\end{itemize}

\vspace{1em}
\noindent
Ogni rete logica e formata da un certo numero di porte (AND, OR, ecc.) tra loro variamente interconnesse, da un certo numero di ingressi, contraddistinti con i simboli \(A_i\), e da un certo numero di uscite, contraddistinte con i simboli \(B_k\).\\
Si dice \textbf{itinerario} tra due elementi X e Y qualsiasi il percorso che colleghi \(X\) con \(Y\).\\
Si dice invece \textbf{livello di un elemento \(X\) rispetto all’uscita \(B_j\)} e a un determinato
itinerario \(I\), il numero di elementi, \(X\) compreso, disposti lungo l’itinerario a partire dall’uscita \(B_j\).\\
Si dice \textbf{livello di una variabile rispetto all’uscita \(B_j\) e all’itinerario \(I\)} il numero di elementi compresi tra il rispettivo ingresso e l’uscita \(B_j\) lungo l’itinerario \(I\).\\

\vspace{1em}
\noindent
\textbf{Osservazione}: La presenza di più livelli all'interno di un circuito è molto critica, in quanto più livelli introducono più latenze che potrebbero determinare una scorretta analisi degli ingressi logici, in quanto le porte logiche presenti in un circuito introducono un tempo di propagazione che non necessariamente è trascurabile.\\
Tali ritardi prendo il nome di \textbf{alee}, ovvero dei ritardi che non sono ammissibili, in quanto le variabili di uscita devono essere processati senza eterogeneità di ritardi in ingresso.

\subsection{Analisi dei circuiti combinatori}
L’analisi di un circuito combinatorio tende a ottenere una rappresentazione della funzione d’uscita \(y\) o nella sua forma analitica, oppure sotto forma di tavola di verità. Poiché la rappresentazione circuitale è simbolica, l’analisi non e legata a considerazioni di logica positiva o negativa.\\
Per effettuare l’analisi, nel caso di circuiti AND-OR-NOT, e sufficiente partire dagli elementi su cui entrano le variabili e procedere verso il terminale di uscita secondo tutti i possibili itinerari, usando la funzione di uscita di ciascun elemento come variabile di ingresso dell’elemento successivo.\\
L’analisi dei circuiti basati su porte NAND e NOR è notevolmente più complessa, a causa della non associatività degli operatori.

\subsection{Sintesi dei circuiti combinatori}
Eseguire la sintesi di un circuito combinatorio consiste, come già accennato, nel progettare un circuito a \(n\) ingressi che soddisfi una determinata funzione di uscita \(y\) di progetto. La funzione \(y\) che il circuito deve soddisfare può essere assegnata in diverse forme.\\
precisamente:

\begin{itemize}
    \item con la \textbf{descrizione a parole} del funzionamento del circuito. È questa la forma di assegnazione più comune, ma anche la più imprecisa. È necessario porre un’estrema attenzione alla corretta interpretazione di eventuali condizioni implicite e all’esistenza di vincoli di qualsiasi natura. Dalla descrizione verbale è necessario passare poi alla tavola di verità, assegnando il valore della funzione per ognuna delle \(2^n\) configurazioni degli ingressi;

    \item con una vera e propria \textbf{tavola di verità}, che è in definitiva l’effettivo punto di partenza della sintesi cui tutti gli altri tipi di assegnazione devono essere ricondotti;

    \item con un’\textbf{espressione analitica}, che è il modo più conciso, anche se non univoco, di descrivere il funzionamento di un circuito;

    \item con uno \textbf{schema logico}, che è una procedura generalmente usata quando un determinato circuito logico debba essere riprogettato con componenti diversi. In tal caso, con le regole dell’analisi si ricava un’espressione analitica della funzione y.
\end{itemize}

\noindent
Qualunque sia il metodo di assegnazione, la sintesi procede partendo dalla tavola di verità o da un’espressione analitica; applicando i metodi di semplificazione delle funzioni logiche si perviene alla forma più conveniente per gli scopi che ci si propone.\\
Si noti che non sempre la forma più conveniente corrisponde alla forma minima della funzione. Ad esempio non e sempre opportuno realizzare circuitalmente la forma minima algebrica, in quanto vi possono essere dei vincoli sul numero massimo di livelli. Infatti, se e ben vero quanto esposto precedentemente, e cioè che nei circuiti combinatori l’uscita è, istante per istante, funzione unicamente degli ingressi, non significa che la variazione degli ingressi sia avvertita immediatamente in uscita; tale affermazione sta piuttosto a significare che ogni configurazione di ingresso dà luogo a una determinata uscita e che eventuali transitori di commutazione possono ritardare, ma non modificare questa uscita.\\
Poiché il tempo di commutazione \(\Delta\) di qualsiasi porta logica, per quanto piccolo, non è mai nullo, il tempo di risposta di un circuito a \(n\) livelli, al variare della configurazione d’ingresso, è \(n \cdot \Delta\).\\
In definitiva, il ritardo totale tra ingresso e uscita è proporzionale al numero di livelli e potendo la forma minima di una funzione contenere un numero di livelli molto elevato, la sua diretta realizzazione circuitale potrebbe dar luogo a ritardi intollerabili.\\
La forma in cui si ha il minimo ritardo è quella a due livelli, che d’altra parte è quella che si ottiene con i metodi di semplificazione che sono stati esposti in precedenza.\\
Inoltre si osservi che, molto spesso, anche dal punto di vista economico, è più conveniente introdurre nel circuito delle componenti ridondanti piuttosto che personalizzate al fine di ottimizzare anche i costi di produzione della propria rete logica. La convenienza di eventuali fattorizzazioni va valutata caso per caso. Si può dunque concludere che la sintesi di un circuito combinatorio procede attraverso i seguenti passi:

\begin{enumerate}
    \item Descrizione del funzionamento del circuito
    \item Determinazione della tavola di verità
    \item Sintesi della funzione Booleana
    \item Semplificazione della funzione logica relativa
    \item Determinazione della forma minima più conveniente
    \item Disegno del circuito
\end{enumerate}

Si osservi che il passo \(5\) non può essere attuato secondo un procedimento sistematico, e l’effettiva forma minima più conveniente andrà valutata di volta in volta, eventualmente facendo uso di tecniche basate sul concetto di decomponibilità.

\vspace{1em}
\noindent
\textbf{Esempio}: Si voglia realizzare un circuito a tre ingressi e quattro uscite; sugli ingressi si può presentare un numero binario compreso tra 0 e 5. All’uscita di tale circuito si deve ottenere il prodotto per \(3\) del numero in ingresso.\\
Il massimo numero di uscita rappresentabile con \(4\) bit è \(15\) e sarà necessario sintetizzare quattro funzioni logiche.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{8pt}
    \begin{tabular}{l||ccc|cccc}
         & & \textbf{\(x\)} & & & \textbf{\(y\)} &\\
         \hline
         \(3 \cdot \textbf{x} = \textbf{y}\) & \(x_2\) & \(x_1\) & \(x_0\) & \(y_3\) & \(y_2\) & \(y_1\) & \(y_0\)\\
         \hline
    \end{tabular}
    \caption{Caption}
    \label{tab:my_label}
\end{table}

\vspace{1em}
\noindent
Se il circuito viene impiegato rispettando le specifiche di progetto, allora il circuito funzionerà come previsto. Altrimenti il circuito risponde erroneamente, rispondendo in modo irregolare e scorretto.

\vspace{2em}
\noindent
\textbf{Esempio}: Si voglia sintetizzare un circuito con la stessa funzione Booleana di quello illustrato in figura 5.9a,
ma possibilmente più economico.\\
Si ottiene
\[y_1 = \overline{\overline{x_1} + \overline{x_3} + x_4} + ... \]

\newpage
\begin{center}
    26 Ottobre 2021
\end{center}

\subsection{Riassunto}
I circuiti combinatori sono dei dispositivi che permettono di realizzare delle funzioni booleane della forma
\[F : 2^n \rightarrow n\]
Le modalità per realizzare tali funzioni sono di due tipi:
\begin{itemize}
    \item \textbf{Logica positiva}: Al valore \(1\) logico viene associato il valore di tensione alto, a \(0\) il valore di tensione basso.

    \item \textbf{Logica negativa}: Al valore \(1\) logico viene associato il valore di tensione basso, a \(0\) il valore di tensione alto.
\end{itemize}

\noindent
I circuiti che vengono realizzati possono presentare più livelli di itinerario che può comportare una latenza, ovvero un ritardo di propagazione al variare delle variabili in ingresso.\\
Pertanto, è possibile che ad una porta giunga il valore della variabile \(y_1\) istantaneamente, mentre il valore della variabile \(y_2\) giunge con un ritardo di \(2\Delta\), ove \(\Delta\) è il tempo di assestamento di una porta logica, variabile a seconda della tecnologica impiegata.\\
Se tali variazioni sono infinitesime, possono essere trascurati, ma se non sono trascurabili determinano una instabilità della rete, a causa di continue ed irregolari oscillazioni di valori delle medesime variabili.\\
Tale fenomeno prende il nome di \textbf{Alea} ed è cruciale nella creazione delle porte logiche.\\
Lo studio e la manipolazione dei circuiti logici prevede due operazioni
\begin{itemize}
    \item Lo \textbf{studio della rete logica}: ovvero determinare ed estrapolare la funzione logica a partire dalla rete logica realizzata.

    \item La \textbf{sintesi della rete logica}: Semplificare un circuito o riprogettarlo con delle nuove porte, oppure con un diverso numero di livelli a seguito della constatazione della presenza di ritardi e conseguente instabilità del circuito.
\end{itemize}

\noindent
Eseguire la sintesi di un circuito combinatorio consiste, come già accennato, nel progettare un circuito a \(n\) ingressi che soddisfi una determinata funzione di uscita \(y\) di progetto. La funzione \(y\) che il circuito deve soddisfare può essere assegnata in diverse forme.\\
Più precisamente:

\begin{itemize}
    \item con la \textbf{descrizione a parole} del funzionamento del circuito. È questa la forma di assegnazione più comune, ma anche la più imprecisa. È necessario porre un’estrema attenzione alla corretta interpretazione di eventuali condizioni implicite e all’esistenza di vincoli di qualsiasi natura. Dalla descrizione verbale è necessario passare poi alla tavola di verità, assegnando il valore della funzione per ognuna delle \(2^n\) configurazioni degli ingressi;

    \item con una vera e propria \textbf{tavola di verità}, che è in definitiva l’effettivo punto di partenza della sintesi cui tutti gli altri tipi di assegnazione devono essere ricondotti;

    \item con un’\textbf{espressione analitica}, che è il modo più conciso, anche se non univoco, di descrivere il funzionamento di un circuito;

    \item con uno \textbf{schema logico}, che è una procedura generalmente usata quando un determinato circuito logico debba essere riprogettato con componenti diversi. In tal caso, con le regole dell’analisi si ricava un’espressione analitica della funzione y.
\end{itemize}

\noindent
Indipendentemente dalla modalità di assegnazione della funzione logica, si deve sempre giungere ad una tabella di verità, da cui si può ricavare la mappa di Karnaugh.\\
Dopodiché si dovrà verificare caso per caso se sia effettivamente più conveniente creare un circuito attraverso la semplificazione massimale, in quanto molto spesso il costo di un circuito \quotes{customizzato} è più elevato rispetto a moduli standard e precostituiti.

\vspace{1em}
\noindent
\textbf{Esempio}: Si voglia realizzare un circuito a tre ingressi e quattro uscite; sugli ingressi si può presentare un numero binario compreso tra 0 e 5. All’uscita di tale circuito si deve ottenere il prodotto per \(3\) del numero in ingresso.\\
Il massimo numero di uscita rappresentabile con \(4\) bit è \(15\) e sarà necessario sintetizzare quattro funzioni logiche.

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{8pt}
    \begin{tabular}{l||ccc|cccc}
         & & \textbf{\(x\)} & & & \textbf{\(y\)} &\\
         \hline
         \(3 \cdot \textbf{x} = \textbf{y}\) & \(x_2\) & \(x_1\) & \(x_0\) & \(y_3\) & \(y_2\) & \(y_1\) & \(y_0\)\\
         \hline
    \end{tabular}
    \caption{Caption}
    \label{tab:my_label}
\end{table}

\noindent
In cui, naturalmente, le combinazioni in ingresso che non possono essere considerate dalla rete logica costituita, in quanto produrrebbero in uscita un valore non rappresentabile con soli \(4\) bit, costituiranno delle \textbf{condizioni non specificate}, ovvero delle \textit{don't care conditions} e che verranno impiegate proficuamente nella creazione dei sottocubi nella mappa di Karnaugh.\\

\vspace{1em}
\noindent
\textbf{Esempio}: Si voglia costruire un circuito che esegue la moltiplicazione tra due numeri espressi in notazione posizionale in base \(2\).\\
Siano \(\textbf{x} = x_1 \cdot x_2\) i bit del moltiplicando e \(\textbf{y} = y_1 \cdot y_2\) i bit del moltiplicatore; ciascun fattore varia dunque nell’intervallo \([0, 3]\) mentre il prodotto e compreso nell’intervallo \([0, 9]\).\\
Il progetto richiede la costruzione della tavola di verità per tutte le possibili \(2^2 \cdot 2^2 = 16\) combinazioni, tenendo conto
che per rappresentare il valore del prodotto serviranno \([\log_2 (9)] = 4\) bit. Se, per esempio, si ha \(\textbf{x} = 10\), ovvero \(2\) in decimale e \(\textbf{y} = 11\), ovvero \(3\) in decimale, a questa configurazione d’ingresso deve corrispondere \(\textbf{z} = 0110\), ovvero \(6\) in decimale, considerato che \(2 \cdot 3 = 6\).\\
Operando in questo modo si ottiene la tavola di verità seguente nella quale ogni colonna i-esima rappresenta i valori assunti dalla funzione \(z\) in corrispondenza delle varie quaterne d’ingresso.\\
Si devono, allora, valutare quattro funzioni Booleane del tipo \(2^2 \rightarrow 2\). Poiché ci sono pochi \(1\) e molti \(0\), conviene usare la I forma canonica, basata sui termini minimi.

\subsection{Moduli combinatori}
L’algebra Booleana permette di analizzare e progettare qualunque tipo di rete combinatoria, di qualunque complessità. In precedenza abbiamo mostrato anche le tecniche per semplificare le reti ottenute direttamente dalle espressioni delle forme canoniche, basate sulla somma di prodotti o sui prodotti di somme. Sebbene in linea di principio quei metodi possono essere utilizzati per reti combinatorie di qualunque estensione, nella pratica si preferisce affrontare il progetto di una rete complessa secondo una tecnica di scomposizione della rete in blocchi funzionali, detti moduli combinatori. In questo modo si rinuncia alla soluzione teoricamente ottima, a favore di una maggiore comprensibilità, gestibilità e soprattutto modularità del progetto. Ciò porta anche a un effettivo risparmio economico, poiché i moduli combinatori, se prodotti in larga scala, hanno prezzi via via sempre più bassi; dunque non sempre un numero minore di porte implica un risparmio economico.\\
Già a partire dagli anni \(’70\) vennero prodotti moduli integrati, che svolgendo precise funzionalità di carattere combinatorio trovarono impiego nello sviluppo di progetti complessi. Nella parte che segue vengono esaminati alcuni moduli combinatori di uso corrente.

\subsubsection{Decodificatori}
I \textbf{decodificatori} convertono un numero espresso in notazione posizionale in base \(2\) in un numero intero in base \(10\). Un decodificatore accetta in ingresso \(n\) bit e presenta in uscita \(m = 2^n\) linee, numerate da \(0\) a \(2^{n - 1}\), in modo tale che va a \(1\) la sola linea \(y_j\) che corrisponde all’intero \(j\) codificato in notazione posizionale dagli \(n\) bit d’ingresso. Se dunque si indicano con \(y_0, y_1, ..., y_m\) le uscite del decodificatore, la generica uscita \(y_j\) ottenuta come AND delle \(n\) variabili che compongono il \textit{minterm} \(j\).\\
Nelle figure 5.14a e 5.14b vengono riportati, rispettivamente, la tavola di verità e il circuito di un decodificatore a \(2\) bit; analogamente, nelle figure 5.15a e 5.15b si presentano la tavola di verità e il circuito di un decodificatore a \(3\) bit.\\
In figura 5.14c viene invece rappresentato il simbolo circuitale per un generico decodificatore a \(n\) bit.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si noti che questo processo non deve creare confusione. Infatti, essendo i calcolatori binari, si sarebbe portati a rappresentare ogni valore, in ingresso come in uscita, sfruttando la logica binaria. Ma allora, se si hanno \(n\) bit in ingresso, che possono produrre \(2^n\) combinazioni di valori, che corrispondono a \(2^n\) numeri decimali. Allora, sarà sufficiente attivare solamente l'uscita corrispondente e si è ottenuto il valore da decodificare.

\subsubsection{Codificatore}
I codificatori convertono un numero intero in base \(10\) in un numero espresso in notazione posizionale in base \(2\).\\
Un codificatore svolge dunque la funzione inversa di un decodificatore, nel senso che esso prevede \(m = 2^n\) ingressi e \(n\) uscite. Le uniche configurazioni ammesse per gli ingressi sono quelle in cui c’e esattamente un solo \(1\) in corrispondenza della linea \(x_j\); dunque \(x_j = 1\) e \(x_i = 0\) per ogni \(i \neq j\).\\
Indicando con \(x_0, x_1, ..., x_{m - 1}\) gli ingressi, la corrispondente configurazione di uscita sulle variabili \(y_{n - }, y_{n - 2}, ..., y_0\) e tale che esse codificano \(j\) notazione posizionale in base \(2\).\\
Nelle figure 5.16a e 5.16b vengono riportate, rispettivamente, la tavola di verità e le due mappe di Karnaugh associate alle variabili \(y_1\) e \(y_0\). Si noti che nella tabella di verità sono state riportate le sole configurazioni di ingresso definite; le altre danno luogo a \textbf{condizioni non specificate}, che consentono un amplissimo margine di libertà nella realizzazione effettiva del circuito. Ciò è evidente dalle mappe di Karnaugh di figura 5.16b, che consentono almeno \(2\) soluzioni; la prima implica l’uso di due porte OR e la seconda due porte AND e due NOT. Nella figura 5.17a e 5.17b vengono riprodotti, rispettivamente, il circuito del codificatore a \(2\) bit associato alla soluzione con le porte OR e il simbolo circuitale di un generico codificatore a n bit. Analogamente, nelle figure 5.18a e 5.18b si presentano la tavola di verità e il circuito di un codificatore a \(3\) bit.

\subsubsection{Selettori}
Un \textbf{selettore d’ingresso (o Multiplexer o Mux)} è un modulo che permette di selezionare uno tra \(2^n\) ingressi e presentarlo sull’unica uscita. La selezione si effettua attraverso \(n\) linee di comando.\\
Nella figura 5.19a viene fornita la tavola di verità del Multiplexer a \(2\) vie (\(2:1\) Mux), che si ricava tenendo conto che per \(s_0 = 0\) viene riportato in uscita il contenuto di \(x_0\), mentre per \(s_0 = 1\) si porta in uscita il contenuto di \(x_1\); la semplificazione tramite minterm di figura 5.19b porta alla soluzione circuitale di figura 5.19c.\\
Nelle figure 5.20a, 5.20b sono invece rappresentati i Multiplexer a \(4\) e \(8\) vie, mentre la figura 5.20c illustra il simbolo circuitale
di un generico Multiplexer a \(n\) vie.\\
La mappa di Karnaugh corrispondente sarà

\begin{figure}[H]
    \centering
    \begin{Karnaughvuit}
        \contingut{0,0,1,1,0,1,0,1}
        \implicant{3}{2}{red}
        \implicant{5}{7}{blue}
    \end{Karnaughvuit}
    \label{fig:mappa_karnaugh_8_5}
\end{figure}

\noindent
Che permette di individuare i due determinanti, ovvero
\[y = yz + x\overline{z}\]
ove \(s\) è il selettore preso in esame, che si comporta come previsto:
\begin{itemize}
    \item Se \(s = 0 \rightarrow y = x_0\)
    \item Se \(s = 1 \rightarrow y = x_1\)
\end{itemize}

\subsubsection{Selettore d'uscita}
Un selettore d’uscita (o Demultiplexer o Demux) e al contrario un dispositivo che permette di dirottare l’unico ingresso su una delle possibili \(2n\) uscite.\\
La figura 5.21 mostra un Demultiplexer a \(2\) vie (\(1:2\) Demux), uno a \(4\) vie (\(1:4\) Demux) e uno a \(8\) vie (\(1:8\) Demux), oltre al simbolo grafico di un generico selettore d’uscita a \(2^n\) vie.\\
Si noti che nel caso di selettore di uscita l’ingresso viene presentato sulla via selezionata, mentre tutti gli altri ingressi sono a \(0\).\\
In entrambi i selettori (d’ingresso e d’uscita) l’n-upla binaria della linea \(Sel\) seleziona quale, tra le \(2^n\) linee, è interessata alla connessione con l’uscita (l’ingresso).

\newpage
\begin{center}
    27 Ottobre 2021
\end{center}
Si consideri un \textbf{display \(7\) segmenti} e si realizzi un sistema per rappresentare dei numeri attraverso proprio \(7\) diodi emettitori di luce, contrassegnati dalle lettere da \textbf{a} a \textbf{g},\\
Si ottiene

\begin{table}[H]
    \centering
    \begin{tabular}{cccc|ccccccc}
         $x$ & $y$ & $z$ & $w$ & a & b & c & d & e & f & g\\
         \hline
         $0$ & $0$ & $0$ & $0$ & $0$ & $1$ & $1$ & $0$ & $1$ & $1$ & $1$\\
         $0$ & $0$ & $0$ & $1$ & $0$ & $0$ & $1$ & $0$ & $0$ & $0$ & $1$ \\
         $0$ & $0$ & $1$ & $0$ & $1$ & $0$ & $1$ & $1$ & $1$ & $1$ & $0$ \\
         $0$ & $0$ & $1$ & $1$ & $1$ & $0$ & $1$ & $1$ & $0$ & $1$ & $1$ \\
         \hline
         $0$ & $1$ & $0$ & $0$ & $0$ & $1$ & $1$ & $1$ & $0$ & $0$ & $1$ \\
         $0$ & $1$ & $0$ & $1$\\
         $0$ & $1$ & $1$ & $0$\\
         $0$ & $1$ & $1$ & $1$\\
         \hline
         $1$ & $0$ & $0$ & $0$\\
         $1$ & $0$ & $0$ & $1$\\
         $1$ & $0$ & $1$ & $0$\\
         $1$ & $0$ & $1$ & $1$\\
         \hline
         $1$ & $1$ & $0$ & $0$\\
         $1$ & $1$ & $0$ & $1$\\
         $1$ & $1$ & $1$ & $0$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ \\
         $1$ & $1$ & $1$ & $1$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ & $-$ \\
    \end{tabular}
    \caption{Tabella di verità display \(7\) segmenti}
    \label{tab:tabella_verita_display_7_segmenti}
\end{table}

\noindent
Si realizzino, ora, le mappe di Karnaugh corrispondenti per ciascuna delle \(7\) funzioni di uscita, al fine di semplificare la funzione logica associata.\\
Si parta dalla funzione logica \(a\), ovvero:

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \begin{Karnaugh}
        \contingut{1,0,1,X,0,1,1,X,1,1,X,X,1,1,X,X}
        \implicantcostats{0}{2}{red}
        \implicant{3}{10}{green}
        \implicant{12}{10}{blue}
        \implicant{5}{11}{violet}
    \end{Karnaugh}
    \caption{Mappa di Karnaugh a \(16\)}
    \label{fig:mappa_karnaugh_16_3}
\end{figure}

\noindent
Tale sistema poteva essere effettivamente realizzato anche sfruttando i \textbf{codificatori}. Infatti, com'è noto, un codificatore presenta i ingresso una sola linea a \(1\) corrispondente al numero naturale compreso tra \([0, 9]\) che si vuole rappresentare. Il codificatore provvederà a rappresentare il numero in ingresso in base decimale nella base binaria. E le \(4\) uscite del codificatore rappresenteranno i \(4\) ingressi della rete logica che si è proprio realizzata in questo esercizio che, a sua volta, piloterà il display \(7\) segmenti.\\
Ciò agevolerà l'operazione di input che non sarà più composta da \(4\) linee, ma da una sola, quella del codificatore, che a sua volta provvederà a convertire il numero richiesto in binario.

\subsection{Riassunto}
I moduli combinatori sono stati introdotti per razionalizzare la realizzazione dei circuiti logici. I più importanti circuiti combinatori sono i seguenti:
\begin{itemize}
    \item \textbf{Decodificatori}, che presentano \(n\) bit in ingresso e \(2^n\) bit in uscita, permettendo la rappresentazione di numeri in base \(10\) di numeri espressi in forma binaria. Naturalmente verrà attivata solamente \(1\) delle \(2^n\) possibili uscite del decodificatore per indicare il valore decimale corrispondente.

    \item \textbf{Codificatori}, che presentano \(2^n\) bit in ingresso e \(n\) bit in uscita, in cui solamente una linea in ingresso verrà portata ad \(1\) per indicare il valore da codificare, mentre saranno \(n\) le uscite che produrranno il valore decimale codificato in binario.\\
    Naturalmente, in questo caso, se vi sono \(2^n\) ingressi si potranno rappresentare solamente \(n\) valori binari, pertanto \(2^{n} - n\) ingressi saranno inutilizzati e costituiranno delle condizione non specificate.

    \item \textbf{Multiplexer}, che presenta \(2^n\) ingressi e \(n\) selettori per selezionare, ovvero dirottare, uno dei \(2^n\) ingressi in un'unica uscita.

    \item \textbf{Demultiplexer}, che che presentano un solo ingresso, \(2^n\) uscite e \(n\) selettori.
\end{itemize}

\subsection{Costruzione modulare di una funzione Booleana}
Un impiego particolarmente interessante dei selettori d’ingresso, o multiplexer: la costruzione di qualunque funzione Booleana di \(n\) variabili attraverso un selettore d’ingresso a \(2^n\) vie.\\
Una qualunque funzione di \(n\) variabili, com'è noto, può essere ricondotta a una somma di \textit{minterm}.\\
Allora, se si considera una funzione Booleana \(f : n \rightarrow 2^n\) con \(n = 3\) e \(2^n = 8\) uscite, sarà sufficiente porre in ingresso al multiplexer a \(8\) vie le \(8\) costanti dei valori della funzione, mentre gli \(n = 3\) selettori comanderanno quale degli \(8\) ingressi dovrà essere dirottato in uscita.\\
Tuttavia, si capisce bene che un multiplexer a \(2^n\) vie presenta \(2^n\) porte AND e \(1\) porta OR di uscita, che sono sicuramente maggiori delle porte che si impiegherebbe per realizzare la medesima funzione logica riducendola in forma minima.\\
Ma allo stesso tempo si osservano i significativi vantaggi:
\begin{enumerate}
    \item Anche se il circuito è molto complesso, garantisce una straordinaria versatilità
    \item Un multiplexer è un dispositivo molto comune e prodotto \textbf{in larga scala}, quindi il suo costo sarà inferiore rispetto a quello di un circuito personalizzato e costruito appositamente per il proprio scopo.\\
    Si consideri, inoltre, che se non si volesse realizzare un circuito con esclusivamente le porte ottenute tramite semplificazione si dovrebbe ripiegare su circuiti integrati con un numero di porte AND e OR che, in ogni caso, sono ormai standardizzati. Pertanto, nella realizzazione del circuito con questa modalità, si avrebbe un risparmio solamente apparente.
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Osservazione}: C’e tuttavia un metodo più economico per costruire, in modo modulare, una qualunque funzione Booleana di \(n\) variabili. Facendo sempre riferimento alla I forma canonica, la sua realizzazione richiede un numero di porte AND a \(n\) ingressi pari al numero di minterm (cioè \(2^n\)) e una porta OR con un numero di ingressi pari al numero di porte AND (cioè sempre \(2^n\)).\\
Si tratta allora di ”prolungare” le uscite delle porte AND agli ingressi della porta OR per i soli minterm che entrano nella funzione.\\
La figura 5.24a mostra un circuito di questo genere, chiamato matrice di contatti, nel quale
si evidenzia la presenza di un contatto per i soli minterm che servono per realizzare la funzione z “ x1 x2 ` x1 x2;
nella pratica circuitale la configurazione diventa quella di figura 5.24b. Se ora vogliamo usare questa tecnica per
costruire la funzione (5.4) otteniamo il circuito di figura 5.25a. La sua struttura e estremamente vantaggiosa se `
viene realizzata direttamente dal costruttore di integrati, che privilegia un’alta uniformita nella struttura circuitale. `
Il confronto con la soluzione a selettori di figura 5.23 e chiarificatore: in quel caso, per realizzare una qualunque `
funzione di tre variabili occorre un integrato che abbia almeno 3 ` 8 ` 1 “ 12 piedini (a parte l’alimentazione
e la massa). Con la soluzione ora illustrata il numero di piedini sarebbe pari a soli 3 ` 1 “ 4. La struttura di
figura 5.25a fa uso di diodi per realizzare le connessioni della matrice; inoltre essa puo essere estesa in modo tale `
da fornire non una, ma piu funzioni di uscita, passando p.es. a una rete con ` n ingressi e k uscite. Una simile rete
fornisce, per ogni configurazione degli n ingressi, una configurazione sulle k uscite e viene a costituire quella che
si chiama una memoria ROM, acronimo di Read Only Memory (memoria di sola lettura); la memoria in questione
ha M “ 2n celle da k bit ciascuna, che vengono indirizzate dalle n linee di indirizzamento. Tenendo conto della
realizzazione circuitale effettiva illustrata in figura 5.24b, riportiamo in figura 5.25b la struttura di una memoria
ROM con 23 celle di memoria da 4 bit ciascuna.
Nella parte destra della figura 5.25b viene riportato l’indirizzo di ciascuna cella e, tra parentesi, il suo contenuto.
Per capirne il funzionamento supponiamo che si voglia leggere il contenuto della memoria all’indirizzo 3; cio`
significa che deve essere x2x1x0 “ 011. In tal caso ci sara una sola porta NAND che ha un’uscita bassa, la porta `
della riga 3, mentre tutte le altre porte NAND avranno uscita alta. I catodi dei diodi relativi alle due colonne z3 e \(z_0\) vanno allora a massa, inducendo una polarizzazione diretta per i corrispondenti diodi; sui rispettivi anodi si ha
allora una tensione virtualmente nulla (in pratica ci sara solo la ` VAK di saturazione, pari 0, 3 ̃0, 6 V ). Le linee z3
e z0 sono allora basse, e a seguito della complementazione finale diventano alte. Gli altri diodi sulle colonne z3
e z0 risultano invece interdetti, le linee rimangono allo stato alto (`VCC ) e quindi c’e` 0 in uscita, a seguito della
complementazione finale. Dunque z3 “ 1 e z0 “ 1, mentre le altre due linee z2 e z1 si trovano a zero, e dunque
z “ 1001.

\subsubsection{Diodi}
L'idea alla base dell'ottimizzazione appena analizzata è costituita dai diodi. I diodi, in teoria, sono di due tipologie:
\begin{enumerate}
    \item \textbf{Diodo a vuoto}, basata sulle ormai inutilizzate valvole termoioniche
    \item \textbf{Diodo a giunzione}, che può essere a giunzione \(PNP\) oppure \(NPN\) a seconda del drogaggio a cui è sottoposto.
\end{enumerate}

\vspace{1em}
\noindent
I diodi sono dei dispositivi che permettono di essere attraversati dalla corrente in un solo verso. Quando il diodo viene attraversato dalla corrente con \textbf{polarizzazione diretta} si ha un cortocircuito, quindi il diodo va in \textbf{interdizione}.\\
Se il diodo viene attraversato dalla corrente con \textbf{polarizzazione inversa} si ha un circuito aperto, quindi il diodo va in \textbf{saturazione}.\\
In figura 5.26 viene dato lo schema a blocchi di una memoria ROM; di fatto si tratta di un decodificatore seguito da una \textbf{matrice di contatti}. Il numero binario corrispondente alla combinazione degli \(n\) ingressi rappresenta l’indirizzo della corrispondente cella.\\
Si noti che fissare i contatti della matrice equivale a programmare il comportamento della rete. Nelle ROM propriamente dette, la matrice non ha inizialmente alcun punto di contatto tra righe e colonne. È il costruttore che esegue le connessioni in base alla matrice di bit desiderata dal committente. Per le memorie ROM, che sono appunto di sola lettura, non è possibile variare il contenuto della memoria dopo la programmazione fatta in fabbrica.\\
Le ROM risultano economicamente convenienti per volumi molto grandi.
Nel caso debba essere l’utente a programmare la ROM si ricorre alle cosiddette PROM(Programmable Read Only
Memory); la matrice ha inizialmente tutti i punti di contatto tra righe e colonne, attraverso un diodo e un fusibile.

\newpage
\begin{center}
    8 Novembre 2021
\end{center}

\subsection{Riassunto}
Consuetamente, la costruzione di una funzione logica ha sempre previsto una minimizzazione massimale del numero di componenti, attraverso le mappe di Karnaugh e il metodo tabella di Quine-Mc Cusky.\\
Tuttavia, molto spesso, non risulta essere conveniente operare in tal senso, ma è spesso molto più agevole impiegare dei circuiti precostuiti, ovvero dei moduli già pronti, che permette anche di abbattere i costi.\\
Pertanto, molto spesso si ricorre all'impiego di \textbf{multiplexer}, che permette di avere \(2^n\) ingressi e \(n\) selettori e produce in uscita un solo livello logico.

\vspace{1em}
\noindent
\textbf{Osservazione}: I selettori molto spesso prendono il nome di \textbf{tip-switch} (denominazione da verificare).

\vspace{1em}
\noindent
L'impiego di un multiplexer per la realizzazione di un funzione logica è molto pratico e agevole, e inoltre permette di avere una grande programmabilità e versatilità, cosa che non accade quando si definisce una semplificazione massima e si costruisce un circuito ad hoc per una specifica funzione logica.\\
Si osservi, inoltre, che un circuito di tale tipologia può essere ulteriormente ottimizzata semplicemente evitando di considerare gli ingressi a \(0\) e prolungando solamente gli ingressi che vengono portati a \(1\), andando così facendo a costituire una \textbf{matrice di contatti}.\\
Mappando, quindi, a livello circuitale, la funzione di ingresso si perde la programmabilità e la versatilità del circuito, procedendo, però, alla programmazione \textit{in fabbrica} del circuito specificatamente per l'impiego che se ne richiede.\\
Per eseguire tali programmazioni è sufficiente intervenire su delle apposite tracce già presenti sul circuito e bruciare solamente i fusibili per i quali non si vuole il passaggio della corrente.

\vspace{1em}
\noindent
\textbf{Osservazione}: Quando si realizza logicamente una interconnessione fra le uscite delle porte AND e gli ingressi della porta OR si commette un errore concettuale, in quanto così facendo, se le uscite di due AND in serie sono a \(0\) e \(1\) si viene a creare una differenza di potenziale elevata e viene a crearsi un cortocircuito.

\vspace{1em}
\noindent
Nella programmazione in sola lettura di un circuito con multiplexer è fondamentale l'impiego dei \textbf{diodi}.\\
Quando un diodo viene polarizzato direttamente si comporta come se fosse un cortocircuito, e lascia passare la corrente. Un \(1\) dalla parte dell'anodo lo polarizza direttamente e permette di avere un \(1\) anche nel catodo.\\
Quando un diodo viene polarizzato inversamente si comporta come un circuito aperto, bloccando il passaggio della corrente. Uno \(0\) dalla parte dell'anodo lo polarizza inversamente e permette di bloccare il valore logico posto in corrispondenza del catodo.\\
Tale funzionamento è cruciale per bloccare la propagazione di uno o più \(1\) logici all'interno della rete logica oggetto di studio. L'utilizzo dei diodi, infatti, permette la propagazione solamente degli \(1\) delle porte interessate, ma non interferiscono con il funzionamento degli zeri prodotti da altre porte AND che, di fatto, rimangono isolate, impedendo ogni forma di cortocircuito e garantendo il funzionamento della rete logica stessa.

\vspace{1em}
\noindent
\textbf{Osservazione}: Un fusibile, dal punto di vista pratico, è costituito da un sottile filo di rame. Essi sono programmati appositamente per essere bruciati ad uno specifico livello di corrente, dimodoché l'effetto Joule sia tale da fondere il rame.\\
Ciò permette di programmare in fabbrica (o dall'utente) mandando in cortocircuiti i fusibili corrispondenti alla connessione. Naturalmente, questo non permette una riprogrammazione (al limite si può riprogrammare attraverso la fusione di ulteriori fusibili).\\

\vspace{1em}
\noindent
Naturalmente, tale operazione ha un vantaggio molto elevato. Se da un lato non permette una riprogrammazione (che non costituisce una procedura consueta), dall'altro permette di eliminare i \(2^n\) ingressi del circuito con multiplexer, con un notevole risparmio di \textit{pin}.\\
Molto probabilmente, il costo di questa seconda opzione è inferiore rispetto a quello di un circuito ad hoc (per il quale, molto probabilmente, si dovevano anche fronteggiare degli sprechi).\\
Ciò, di fatto, va a costituire una prima forma di memoria, ovvero una ROM, ovvero una Read-Only Memory, in cui sono presenti \(2^n\) indirizzi di memoria e in grado di contenere \(2^n\) valori numerici, codificati mediante un certo numero di bit.

\vspace{1em}
\noindent
\textbf{Funzionamento}: Mandando in ingresso, su \(n\) bit, l'indirizzo di memoria da interrogare, solamente una porta AND produce in uscita il valore 0. Laddove vi sono dei diodi, questi vengono polarizzati inversamente e quindi si comportano come un circuito aperto, quindi non lasciano passare la corrente e il potenziale della linea va a \(0\). Tale valore logico viene poi complementato e, alla fine, viene prodotto il valore logico \(1\).\\
Alla fine, avendo inserito i diodi correttamente, avendo interrogato la cella che presenta l'indirizzo specificato in ingresso, verrà prodotto in uscita il valore contenuto nella cella interessata codificato in opportuni bit.

\subsection{Memorie E-PROM}
A partire dagli anni \('70\) sono state introdotte delle memorie E-PROM, ovvero \textit{Erasable Programmable ROM}, che possono essere riprogrammate attraverso l'uso di raggi ultravioletti propagati attraverso un cristallo di quarzo presente sulla memoria stessa.

\subsection{Moduli per la realizzazione dell’unita logico-aritmetica}
Uno degli elementi centrali nell’architettura di un calcolatore e l'\textit{Unità Logico Aritmetica}, meglio nota con l’acronimo \textit{ALU} - che sta per \textit{Arithmetic Logic Unit}; essa lavora a stretto contatto con i registri di memoria, guidata dall'azione dell'\textit{Unità di Controllo}.\\
Nella ALU si realizzano tipicamente operazione su numeri interi quali somma, sottrazione, incremento, decremento, scorrimento di bit, ma si attuano anche operazioni logiche sui dati, quali AND, OR, XOR o complementazione; le ALU più recenti contengono anche moduli per eseguire direttamente prodotti e moltiplicazioni.

\vspace{1em}
\noindent
\subsubsection{Il semisommatore e il sommatore completo}
Il nucleo di partenza per costruire una ALU è il modulo \textit{semisommatore} (o \textit{Half Adder}), che realizza la somma di due bit con riporto. Di seguito viene riprodotta la tabella aritmetica della somma bit per bit con riporto, che corrisponde alla tavola di verità di due funzioni Booleane, una che realizza la somma \(S_i\) e una che realizza il riporto \(R_i\), per ogni coppia \(A_i\), \(B_i\) dei bit d’ingresso. Si riconosce immediatamente che la \(S_i\) corrisponde a uno XOR, mentre la \(R_i\) è un AND; di conseguenza il modulo ha la realizzazione circuitale di figura 5.29b, mentre la
figura 5.29c rappresenta il suo simbolo circuitale.\\
Se ora vogliamo effettuare la somma completa tra due numeri interi \(\textbf{A} = \left[ A_{n - 1} \hspace{0.1em} A_{n - 2} \hspace{0.1em} ... \hspace{0.1em} A_1 \hspace{0.1em} A_0 \right]\) e \(\textbf{B} = \left[ B_{n - 1} \hspace{0.1em} B_{n - 2} \hspace{0.1em} ... \hspace{0.1em} B_1 \hspace{0.1em} B_0 \right]\), espressi in notazione posizionale con \(n\) bit, è necessario costruire una rete che accetti in ingresso \(2n\) bit e generi la somma binaria dei due,\(\textbf{S} = \left[ S_{n - 1} \hspace{0.1em} S_{n - 2} \hspace{0.1em} ... \hspace{0.1em} S_1 \hspace{0.1em} S_0 \right]\), secondo il classico procedimento di somma con riporto evidenziato in figura 5.30a. Partendo da destra si inizia a sommare \(A_0\) con \(B_0\); detto \(R_0\) il riporto, questi dovrà essere sommato con la somma di \(A_1\) e \(B_1\), che genera \(R_1\); questo va sommato con la somma di \(A_2\) e \(B_2\) e così via. È evidente che il riporto \(R_{-1}\) della colonna \(A_0 || B_0\) vale \(0\) e che se l’ultimo riporto, Rn ́1
dovesse valere 1, siamo di fronte a una situazione di overflow, che richiede il passaggio alla notazione a virgola
mobile. Per realizzare un tale circuito bisogna modificare il semisommatore, in modo da includere il contributo
Ri ́1 del riporto del passo precedente. In questo modo si ottiene il sommatore completo (o full adder), la cui
tavola di verita` e riportata in figura 5.31a. La somma di ` Ai, Bi e Ri ́1 vale 1 solo quando c’e un numero dispari `
di 1 nella somma, ed e quindi lo XOR dei tre bit; ` Ri vale 1 quando Ai e Bi sono entrambi a 1 (qualunque sia il
valore di Ri ́1), oppure quando Ri ́1 “ 1 e Ai ‘ Bi “ 1. Per ricavare in modo formale l’espressione risolutiva
scriviamo i minterm di entrambe le funzioni che si ricavano dalla tavola di verita di figura 5.31a e procediamo con

\subsubsection{Calcolo della differenza mediante sommatore}
Com'è noto, i numeri negativi, in binario, vengono rappresentati con la notazione mediante complemento a \(2\). Ciò significa che la differenza \(A - B\) si realizza come \(A + (- B)\), ove \(- B\) si ottiene complementando \(B\) e sommando \(1\). Si ha, dunque
\[A - B = A + (- B) = A + \overline{B} + 1\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Si osservi che la rappresentazione in binario dei numeri negativi sfrutta un difetto di ogni rappresentazione con una memoria limitata, ovvero l'\textbf{overflow}. In generale, sarebbe necessario che fosse presente un circuito che appositamente rilevi la presenza di tale overflow e provveda alla modifica della rappresentazione del risultato.\\
Anche con una base consueta quale quella decimale è possibile operare sfruttando l'overflow, infatti
\[
    \rowcolors{1}{white}{white}
    \begin{array}{rlc}
         3 & 7 & -\\
         1 & 5 & =\\
         2 & 2 &
    \end{array}
\]
che si può tradurre anche come
\[
    \rowcolors{1}{white}{white}
    \begin{array}{crlc}
         & 3 & 7 & +\\
         & 8 & 5 & =\\
         1 & 2 & 2 & =\\
         & 2 & 2 &
    \end{array}
\]
Ove \(85\) non è nient'altro che \(100 - 15\) che permette di sfruttare l'overflow per ottenere una corretta rappresentazione del risultato cercato.\\
La stessa cosa si può ripetere anche per il sistema binario, ovvero, se si deve realizzare \(5 - 2\) con \(n = 4\) bit, si rappresenta \(2\) in complemento a \(2\), ovvero \(2^4 - 2 = 14 = (1110)_2\), da cui
\[
    \rowcolors{1}{white}{white}
    \begin{array}{cccccc}
         & 0 & 1 & 0 & 1 & +\\
         & 1 & 1 & 1 & 0 & =\\
         1 & 0 & 0 & 1 & 1 & =
         & & & 0 & 0 & 1 & 1 &
    \end{array}
\]

\newpage
\begin{center}
    9 Novembre 2021
\end{center}

\subsection{Riassunto}
Impiegando un multiplexer è possibile costruire qualunque funzione booleana. Inoltre, tale dispositivo permette una grandissima versatilità, in quanto cambiando i valori di ingresso è possibile costruire tutte le funzioni booleane a \(n\) variabili, ovvero \(2^{2^n}\).\\
Inoltre, i multiplexer vengono realizzati su larga scala e quindi, alla fine, il costo di una rete logica di questo tipo è inferiore rispetto ad una rete logica costituita ad hoc.\\
Naturalmente, poi, si osserva che gli ingressi a \(0\) non è conveniente che siano considerati, in quanto sicuramente porteranno a \(0\) l'uscita. Quindi gli unici piedini di ingresso che devono essere prolungati sono gli \(1\), i quali vengono direttamente costruiti internamente al circuito.\\
Un'altra significativa ottimizzazione prevederebbe l'eliminazione di una porta OR con più ingressi, ma impiegando una sola porta OR con un solo ingresso, dato dall'unione di tutte le uscite delle porte AND. Ma ciò è logicamente corretto, ma fisicamente erroneo, in quando se due uscite delle AND si trovano a potenziale diverso si viene a creare un cortocircuito, che può essere risolto con la presenza di un diodo per ciascuna uscita delle porte AND, che permette di propagare la corrente in un solo senso.\\
Tale approccio consente una programmazione in fabbrica della rete circuitale, la quale presenta una matrice di contatti costituita da una rete di tracce che devono essere bruciate a seconda delle proprie esigenze.\\
Ciò permette di eliminare i \(2^n\) piedini di ingresso, in quanto la rete non viene più programmata dall'esterno, ma solamente dall'interno. Si è di fatto costituita una memoria ROM, la quale può essere interrogata semplicemente fornendo in ingresso l'indirizzo della cella di memoria di cui si vuole sapere il contenuto.

\vspace{1em}
\noindent
L'Unità Logico Aritmetica è il cuore del funzionamento di un calcolatore, il quale consente di effettuare qualsiasi operazione aritmetica, permettendo anche di controllare la presenza di \textbf{overflow}, ovvero il fenomeno che si verifica quando un'operazione produce un valore che eccede la capacità di rappresentazione della struttura aritmetica, il valore risultante è errato.\\
Naturalmente è noto che la somma tra due valori binari si può realizzare con uno XOR, mentre il riporto di può realizzare con un semplice AND. Questo dispositivo costituisce un semisommatore o \textit{half-adder}, che posto in serie con un altro semisommatore permette di realizzare il sommatore completo o \textit{full-adder}.\\
Naturalmente, in questo caso, si rinuncia ad una minimizzazione del circuito, ma ad una ottimizzazione del circuito con i dispositivi già noti.

\vspace{1em}
\noindent
Naturalmente, il sommatore consente di eseguire delle somme, ma per eseguire delle differenze è fondamentale comprendere la modalità di rappresentazione binaria dei numeri negativi in complemento a \(2\), la quale consente di centrare in \(0\) l'intervallo \([0, 2^{n} - 1]\) costituito da tutti i valori rappresentabili con \(n\) bit, in modo tale da rappresentare anche i valori negativi.\\
Tale rappresentazione risulta essere geniale, in quanto consente di sfruttare un difetto della rappresentazione binaria, ovvero l'\textbf{overflow} per rappresentare anche i numeri negativi, ed eseguire, quindi, le differenze.\\
Ciò consente di rappresentare correttamente tutti i valori da \([-2^{n - 1}, 2^{n - 1} - 1]\); se si eccede tale intervallo, naturalmente, si ottiene un errore.\\
Per rappresentare un numero binario in complemento a \(2\) sarà necessario complementare il valore binario e poi sommarci \(1\). Questo, in quanto, l'operazione di complemento propriamente detta sarebbe
\[-x = 2^n - x\]
ma osservando che
\[x + \overline{x} = 2^n - 1 \rightarrow \overline{x} + 1= 2^n - x\]
per cui il numero negativo \(-x\) si ottiene complementando \(x\) e aggiungendovi \(1\).\\

\vspace{1em}
\noindent
Le tre porte di sinistra servono invece per dare un segnale di allarme quando si è in presenza di overflow; infatti dalla tavola si può osservare che tale condizione si realizza quando si verificano le seguenti condizioni:
\begin{itemize}
    \item quando si sommano due numeri negativi (cioè con \(1\) nella prima posizione) e il risultato è, invece, positivo (con \(0\) nella prima posizione);
    \item quando si sommano due numeri positivi (con \(0\) nella prima posizione) e il risultato è, invece, negativo (con \(1\) nella prima posizione).
\end{itemize}
La prima delle due condizioni si ha con \(A_{n - 1} = 1, B_{n - 1} = 1, S_{n - 1} = 0\), e quando si realizza fornisce un uscita \(1\) nella porta AND di sinistra; la seconda condizione si ha con \(A_{n - 1} = 0, B_{n - 1} = 0, S_{n - 1} = 1\), e fornisce un uscita 1 nella porta AND di destra. La porta OR raccoglie dunque l’unione logica dei due eventi.\\
Il segnale di allarme viene usato per commutare nella rappresentazione a virgola mobile. In figura 5.34a viene illustrato il simbolo schematico della ALU descritta dalla rete 5.32. Con una piccola modifica della circuiteria è possibile fare in modo da realizzare, oltre alla somma e alla differenza tra \(A\) e \(B\), anche l’AND e l’OR tra i due ed eventuali altre operazioni logiche; lo schema di figura 5.34b mostra una ALU completa, nella quale i comandi \(C_A\), \(C_B\), \(R_{-1}\) e tutti gli altri per attivare le varie operazioni logiche sono rappresentati con la notazione \(Com_1, Com_2, ..., Com_n\).

\newpage
\section{Circuiti sequenziali}
I circuiti considerati fino a questo punto sono i circuiti combinatori, nei quali in ogni istante la configurazione di una generica variabile di uscita \(y_i\) dipende unicamente dal valore assunto dalle variabili d’ingresso \(x_1, x_2, ..., x_n\), secondo la funzione Booleana \(y_i = f_i(x_1, x_2, ..., x_n)\), con \(1 \leq i \leq m\).\\
Il modello generale di un circuito combinatorio e illustrato di seguito, in cui si suppone che che le variabili in ingresso vengono immediatamente propagate in uscita opportunamente processate. Si noti, infatti, che in esso non compare la variabile temporale, a sottolineare il fatto che i valori presi in considerazione per le \(n\) variabili di ingresso si riferiscono allo stesso istante e il comportamento della rete, se escludiamo i fenomeni transitori, e univocamente dedotto dalla tavola di verità che stabilisce il legame tra ciascuna \(y_i\) e le variabili d’ingresso \(x_1, x_2, ..., x_n\).

% Contenitore per immagini
\begin{figure}[H]
    \centering
        \includegraphics[scale=0.4]{img/circuiti_sequenziali/image1.png}
    \caption{Schema generale di un circuito di commutazione con \(n\) ingressi e \(m\) uscite}
    \label{fig:schema_circuito_commutazione}
\end{figure}

\noindent
Nel caso in cui in un sistema il valore delle uscite dipenda anche dalla storia passata della circuiteria che lo costituisce, ovvero dallo stato della rete, si parla di sistema o circuito sequenziale. Il sistema telefonico è un tipico esempio di sistema sequenziale: se infatti si è in procinto di comporre l’ultima cifra di un numero telefonico, il comportamento del sistema dipenderà anche dalle cifre precedentemente selezionate; questa cifra è l’ingresso attuale del sistema e l’uscita sarà il segnale che effettuerà il collegamento. Ovviamente l’ingresso attuale non è il solo fattore che determina il collegamento, poiché anche le cifre composte precedentemente sono ugualmente importanti. Anche un calcolatore elettronico e un esempio di circuito sequenziale, anzi, è l’esempio per eccellenza; di solito in esso vengono usati in maniera sequenziale diversi sottoinsiemi che possono essere di volta in volta sequenziali o combinatori.\\
Da un punto di vista formale un circuito sequenziale e un \textbf{automa a stati finiti} \(M\), cioè un sistema dinamico \textbf{discreto} (nella scansione del tempo e nella descrizione del suo stato) e \textbf{stazionario} (il sistema si comporta alla stessa maniera indipendentemente dall’istante di tempo in cui agisce). Esso è caratterizzato da:
\begin{itemize}
    \item un insieme finito \(\mathbb{Q} = \{q_1, q_2, ...., q_S\}\) di stati interni;
    \item un insieme finito \(\mathbb{A} = \{a_1, a_2, ..., a_K\}\) di valori che possono essere assunti dalle variabili d’ingresso \(\textbf{x} = \{x_1, x_2, ..., x_n\}\);
    \item un insieme finito \(\mathbb{B} = \{b_1, b_2, ..., b_D\}\) di valori che possono essere assunti dalle variabili di uscita \(\textbf{y} = \{y_1, y_2, ..., y_m\}\);
    \item un insieme di regole, detto \textit{mappa di transizione \(\tau\)}, che specifica lo stato \(q*\) raggiunto dalla macchina a partire dallo stato \(q\) per effetto dell’ingresso \(\textbf{x}\);
    \item un insieme di regole, detto \textit{mappa delle uscite \(\mathbb{U}\)}, che specifica il valore \(\textbf{y*}\) assunto dalle variabili di uscita \(\{y_1, y_2, ..., y_m\}\) per effetto dell'ingresso \textbf{x} applicato allo stato q.
\end{itemize}

\vspace{1em}
\noindent
La macchina sequenziale e pertanto definita dai cinque insiemi citati:
\[M = \left(\mathbb{Q}, \mathbb{A}, \mathbb{B}, \tau, \mathbb{U} \right)\]
Tanto per fare un breve esempio si consideri la seguente tabella

\subsection{Moduli sequenziali asincroni}
Nei sistemi sequenziali introdotti in precedenza, l’informazione sulla storia passata del circuito, ovvero il valore acquisito dalla variabile di stato Q, deve essere memorizzato su un qualche supporto. Si possono
avere diversi tipi di dispositivi di memorizzazione, ma uno dei più usati è il cosiddetto flip-flop, ovvero un circuito \textbf{bi-stabile}.\\
In figura seguente viene illustrato il flip-flop già introdotto nella figura 2.26, nel quale l’uscita di un transistor in interdizione viene connessa con l’ingresso di un transistor in conduzione. Sono transistor ad emettitore comune, in quanto l'emettitore viene posto a massa.\\
Il circuito che si ottiene e bistabile, nel senso che esso può stare indifferentemente e stabilmente in uno o nell'altro dei due stati rappresentati in figura 6.3a e 6.3b. Il funzionamento e basato sul fatto che, quando il transistor di sinistra è interdetto (non passa corrente nel circuito di collettore), allora la sua tensione di collettore e alta (\(v = 2,6 V\)); ciò polarizza la base del transistor di destra, che entra in `
piena conduzione, facendo collassare a un valore basso (v † 0, 4 V) la sua tensione di uscita (figura 6.3a), che
corrisponde a uno 0 logico. I ruoli dei due transistor si scambiano quanto la tensione di collettore del transistor di
destra viene portata (con un impulso) a un valore (v ° 2, 6 V) (figura 6.3b). Dal funzionamento del circuito risulta
evidente che esso costituisce un elemento di memoria di 1 bit; infatti si puo decidere che l’uscita del collettore `
di uno dei due transistor rappresenti la variabile logica il cui valore vogliamo memorizzare; scegliendo p.es. il
transistor di destra, se vogliamo memorizzare 1 dobbiamo mandare lo stesso transistor in interdizione; per lo 0
dobbiamo mandarlo in conduzione (in una logica positiva).

\vspace{1em}
\noindent
\textbf{Osservazione}: Tale circuito, anche se perfettamente funzionante, in realtà non viene impiegato, in quanto non è determinabile a priori quale configurazione il sistema raggiungerà quando viene data tensione al circuito, a causa di microscopiche differenze tra le resistenze di carico e dei transistor stessi.\\
Naturalmente il comportamento di ciascun transistor dipende anche dalle uscite dei due transistor, in quanto in uno dei due stati ciascun transistor si trova in uno stato di \textbf{minimo locale energetico} che, però, può essere condizionato dalla variazione di tensione dei collettori dei due transistor stessi.

\vspace{1em}
\subsection{Il Flip-Flop Set-Reset - FFSR}
Anche se perfettamente funzionante, questa realizzazione non viene usata nella pratica per memorizzare bit, poiché si preferisce sempre ricorrere alle porte logiche, che costituiscono le unità elementari di qualunque circuito logico. Il vantaggio di tale approccio consiste nel fatto che, stando all’interno di una certa famiglia logica, tutti i segnali di comando e i livelli di tensione sono uniformati per l’intero circuito; possiamo così aggiungere singole unita funzionali senza preoccuparci di uniformare i livelli di tensione, poiché sono già standardizzati all’interno della famiglia. Mostreremo allora le due realizzazioni principali del cosiddetto Flip-Flop Set-Reset (FFSR), basate rispettivamente sulle porte NOR e sulle porte NAND.

\vspace{1em}
\noindent
\subsubsection{Latch di NOR}
La figura 6.4 illustra un flip-flop realizzato con due porte NOR; in gergo viene anche chiamato \textbf{Latch di NOR}. La prima cosa che balza all’occhio è il fatto che entrambe le uscite \(X\) e \(Y\) sono riportate all'ingresso; questo lascia presagire che il valore assunto dalle variabili di uscita dipenda anche dalle uscite stesse. Se si impostano le equazioni del sistema otteniamo che conferma la nostra previsione. Nonostante l’equazione (6.1) sia impeccabile, non ci rende conto chiaramente
del comportamento di questa semplice rete. La cosa migliore da fare e allora quella di fissare i valori di \(S, R, X\) e \(Y\) in tutti i modi possibili e vedere quali quaterne sono compatibili con i vincoli imposti dalle equazioni 6.1.\\
Nella figura 6.5a vengono riportate tutte le possibili combinazioni per \(R, S, X\) e \(Y\); quelle in rosso non soddisfano l’equazione 6.1, perche \(X \neq \overline{R} \cdot (S + X)\) oppure \(Y \neq \overline{S + X}\); queste configurazioni non sono stabili.\\
Nella successiva figura 6.5b si riportano invece i soli stati stabili, per semplicità di lettura. Si osservi che, a parte il caso in cui \(R = S = 1\), che escludiamo per i motivi che vedremo nel seguito, in tutte le altre combinazioni lecite si ha sempre \(X = \overline{Y}\) , cioè \(X\) e \(Y\) sono l’uno complementare dell'altro.\\
Partiamo ora dalla condizione R “ S “ 0; dalla tabella 6.5b osserviamo che ci sono due stati stabili possibili, uno
con X “ 0, Y “ 1 e l’altro con X “ 1, Y “ 0; supponiamo di essere nel secondo, cioe` X “ 1, Y “ 0, cos`ı come
evidenziato in figura 6.6a. Supponiamo ora di portare l’ingresso R da 0 a 1 nell’istante t1; quando cio avviene, `
l’uscita della porta 1 commuta a X “ 0 con un certo ritardo ⌧ , legato ai tempi di commutazione dei transistor della
porta. Il nuovo segnale X “ 0 alimenta l’ingresso della porta 2, facendo commutare Y a 1 con un ritardo pari a 2⌧ .
Se ora riportiamo R a 0 (si veda figura 6.6b), X e Y rimangono nella stessa configurazione acquisita, cioe` X “ 0
e Y “ 1, poiche essa  ́ e stabile rispetto a ` R “ S “ 0, a norma della tabella 6.5b. Riportando ora R nuovamente a
1, non cambia comunque nulla, perche con ` X “ 0 e Y “ 1, R e S possono stare stabilmente in ciascuno dei due
stati R “ S “ 0 oppure R “ 1, S “ 0. Quello che e successo ` e che inviando un impulso sull’ingresso ` R, che
viene chiamato impulso di Reset, l’ingresso X va (o permane) a 0.

\newpage
\begin{center}
    10 Novembre 2021
\end{center}

\subsection{Riassunto}
La costruzione di un semisommatore è molto semplice, in quanto prevede di costruire la tabella di verità della somma di due valori binari, che si traduce semplicemente in una porta XOR e del riporto della somma che è, appunto, una porta AND.\\
Il sommatore completo, invece, è dato da due half-adder in serie. Ciò giustifica la presenza di tre input, anziché due, in quanto è necessario tenere conto anche del riporto della somma precedente.\\
Tuttavia, tale approccio, pur essendo significativamente valido, non tiene conto dell'eventualità di un overflow, così come non prevede la presenza del calcolo di differenze.\\
Per risolvere tale problema, è necessario comprendere la rappresentazione a complemento a \(2\) dei numeri binari negativi, ovvero
\[-x = \overline{x} + 1\]
Attraverso tale approccio si è in grado di eseguire la differenza, prevedendo la presenza, nel sommatore, di un pin che permette la complementazione di \(B\) e l'azzeramento di \(A\), anche se si sarebbe potuto procedere anche in modo opposto, ma comunque perfettamente analogo.\\
Il controllo dell'overflow, a cui si faceva riferimento in precedenza, è sufficiente prevedere due casistiche, ovvero
\begin{itemize}
    \item la somma di due numeri negativi (con \(1\) come primo bit) che produce un valore positivo (con \(0\) come primo bit).

    \item la somma di due numeri positivi (con \(0\) come primo bit) che produce un valore negativo (con \(1\) come primo bit).
\end{itemize}
eventualità che si possono rilevare grazie a due porte AND, le cui uscite costituiranno gli ingressi di una porta OR che porta il segnale.\\
Di fatto, in questo modo, si è costruita una unità logico aritmetica, che viene rappresentata specificatamente con il simbolo seguente

% Contenitore per immagini
\begin{figure}[H]
    \centering
        \includegraphics[scale=0.4]{img/circuiti_combinatori/image22.png}
    \caption{ALU}
    \label{fig:alu}
\end{figure}

\noindent
Tuttavia, i circuiti combinatori non sono gli unici dispositivi che vengono considerati. Essi, infatti, producono un risultato in uscita che dipende esclusivamente dalla configurazione degli ingressi, mentre nulla influenza lo stato interno del circuito.\\
I circuiti sequenziali, invece, vengono influenzati dallo stato interno del sistema, che può essere concepito come un automa a stati finiti, per cui l'ossatura strutturale dei circuiti sequenziali è data dai circuiti sequenziali, in quanto sono fondamentali anche gli ingressi, ma prevedendo anche una componente di retroazione che ne influenza lo stato.\\
Il circuito sequenziale fondamentale è il \textit{flip-flop}, che può essere rappresentato dalla configurazione dei transistor seguenti, perfettamente bistabile, ovvero in grado di trovarsi equivalentemente e stabilmente su ciascuna delle \(2\) configurazioni possibili.

% Contenitore per immagini
\begin{figure}[H]
    \centering
    \subfloat[\parbox{\linewidth}{Il transistor di sinistra del \textit{flip-flop} è interdetto; ciò porta conduzione il transistor di destra, che fornisce uscita logica \(0\)} ]{{\includegraphics[width=0.45 \textwidth]{img/circuiti_sequenziali/image3.png} }}%
    \qquad
    \subfloat[\parbox{\linewidth}{ Il transistor di sinistra del \textit{flip-flop} è in conduzione; ciò porta in interdizione il transistor di destra, che fornisce uscita logica \(1\)} 2]{{\includegraphics[width=0.45 \textwidth]{img/circuiti_sequenziali/image4.png} }}%
    \label{fig:flip-flop}
\end{figure}

\noindent
Tale circuito, per quanto costituisca un vero e proprio dispositivo di memoria, non viene utilizzato, in quanto quando viene fornita tensione non è noto su quale stato si andrebbe a posizionare. Inoltre, per cambiare stato, bisognerebbe forza la base di un transistor per comandare il collettore dell'altro transistor, il quale, tuttavia, è collegata al collettore del transistor considerato in principio.\\
Per questo tale dispositivo costituisce unicamente un oscillatore \(RC\).

\vspace{1em}
\noindent
\textbf{Latch di NOR}\\\\
Il Latch di NOR è un classico dispositivo a retroazione, in cui i valori delle uscite non possono essere determinate algebricamente, in quanto dipendono anche dalle uscite.\\
Una volta ottenute le equazioni delle uscite, che sono influenzate da loro stesse, bisogna costruire una tabella con \(2^4\) entrate e verificare per quali combinazioni di ingressi e uscite del Latch di NOR risultano essere compatibili con i vincoli imposti dal circuito stesso.\\
Pertanto, la tabella \(2^4\) si traduce in una tabella a \(5\) entrate, anche se l'ultima non viene prevista nel funzionamento del dispositivo, in quanto è l'unica che non prevede che le uscite siano \(X = X\) e \(Y = \overline{X}\). Inoltre, fornendo il valore \(1\) logico su entrambi gli ingressi, il circuito ottenuto non è noto su quale configurazione si andrà a posizionare, a causa di piccole variazioni di costruzione dei dispositivi.\\
Studiando i diversi stati si ottiene il seguente schema, ottenuto analizzando la variazione di \(R\) da \(0\) a \(1\) e da \(1\) a \(0\).

\begin{table}[H]
    \centering
    \setlength{\tabcolsep}{10pt}
    \renewcommand{\arraystretch}{1.4}
    \begin{tabularx}{\textwidth}{PP}
    {
        % Contenitore per immagini
        \begin{figure}[H]
            \centering
                \includegraphics[scale=0.4]{img/circuiti_sequenziali/image10.png}
            \caption{Funzionamento di \textit{flip-flop}}
            \label{fig:flip-flop}
        \end{figure}
    }
    &
    {

    }
    \end{tabularx}
    \caption{Reset del \textit{flip-flop}}
    \label{tab:reset}
\end{table}

\vspace{1em}
\noindent
\textbf{Osservazione}: Tuttavia, per comprendere il funzionamento del sistema, è necessario comprendere anche il suo comportamento tendendo presente anche lo stato precedente del circuito, come illustrato nella seguente tabella:

\\
Di seguito il funzionamento: Con il vincolo che uno dei due input \(R\) o \(S\) deve essere uguale a \(0\), ovvero \(R \cdot S\), fornendo un impulso di \textit{reset} \(X\) va a \(0\), mentre fornendo un impulso di set \(X\) va a \(1\). Attraverso la mappa di Karnaugh si ottiene la funzione
\[X = S + x \cdot \overline{R}\]
Si è detto che non si tollerano due ingressi contemporaneamente a \(1\), in quanto
\begin{itemize}
    \item ambedue le uscite sarebbero a \(0\), violando la condizione base di funzionamento di un \textit{flip-flop}, secondo la quale le due uscite devono essere sempre complementari.

    \item Se ambedue gli ingressi tornassero a \(0\) al medesimo istante, lo stato in cui il \textit{flip-flop} si porterebbe non sarebbe prevedibile e al limite potrebbe realizzarsi una condizione di oscillazione.
\end{itemize}
Con il vincolo \(R \cdot S = 0\), il \textit{flip-flop RS} diventa un dispositivo di memorizzazione affidabile.

\subsection{Latch di NAND}
Analogamente a quanto visto per il \textbf{Latch di NOR}, si può procedere per costruire un \textbf{Latch di NAND} che sarà il \textbf{corrispettivo duale} di quanto visto in precedenza.\\
Infatti, la configurazione \(R\) e \(S\) uguale a \(0\) non è ammissibile per il sistema, mentre tutti gli altri stati prevedono un comportamento esattamente identico. Pertanto

\\Funzionamento: Con il vincolo che \(R + S = 1\), con un impulso \(0\) su \(S\) porta l'uscita \(X\) a \(0\), mentre un impulso a \(0\) su R riporta l'uscita \(X\) a \(1\).

\vspace{1em}
\noindent
\textbf{Osservazione}: Naturalmente tali dispositivi funzionano in modo perfettamente identico, solamente che i segnali di controllo dovranno essere a \(1\) per il NOR, mentre a \(0\) in NAND. Entrambi, però, funzionano in modo \textbf{asincrono}: è noto che, nei calcolatori, vi è un clock interno che controlla il funzionamento del sistema, per cui costituisce un sistema sincrono, più facilmente controllabile, ove le variazioni del sistema possono avvenire solamente in specifici istanti di clock, cosa che non accade con i \textit{flip-flop}, ove le variazioni degli ingressi possono avvenire in qualsiasi istante. Ciò costituirebbe un problema, in quanto le variazioni degli ingressi potrebbero verificarsi mentre il segnale non è ancora stato propagato all'interno del circuito stesso.

\subsection{\textit{Flip-Flop} SR sincrono}
Si distinguono, in generale, due tipi di segnali
\begin{itemize}
    \item \textit{Impulso}: segnale che normalmente si mantiene ad un livello, usualmente \(0\), e va all'altro livello solamente per intervalli di tempo estremamente brevi;

    \item A \textit{livelli}: segnale che può rimanere sia a \(0\) che a \(1\) per periodi di tempo indefiniti e comunque molto lunghi se paragonati alla durata di un impulso.
\end{itemize}
Si ottiene, di fatto, il seguente \textit{flip-flop SR sincrono}, ovvero un dispositivo che funziona come \textit{flip-flop SR} solamente in corrispondenza degli istanti di clock.

\subsection{\textit{Flip-Flop} JK}
Per arginare l'impossibilità di gestire gli ingressi di \(R\) e \(S\) entrambi a \(1\) è stato ideato il \textit{Flip-Flop} JK, che prevede che
\begin{itemize}
    \item Quando (K = J = 1), se \(x = 0\), allora \(X = 1\).
    \item Quando \(K = J = 1\), se \(x = 1\), allora \(X = 0\)
\end{itemize}
Ovvero l'uscita deve essere complementata a seconda dello stato precedente. Naturalmente, in questo caso, \(S = J\), mentre \(R = K\). Si ottiene, quindi
\[X = \overline{x} \cdot X + x \cdot \overline{K}\]
Si ottiene, pertanto, che
\begin{itemize}
    \item Quando \(x = 1\), si abilita la sola porta AND del \textit{reset K}
    \item Quando \(x = 0\), si abilita la sola porta AND del \textit{set J}
    \item Se entrambi \(J\) e \(K\) sono a \(1\), \(x = 1\) forza un \textit{reset}, mentre \(x = 0\) forza un \textit{set}.
\end{itemize}

\subsection{Flip-Flop di tipo T}
Nel \textit{flip-flop} T, ove \(T\) sta per \textit{Toggle}, mentre il \textit{clock} è il solo segnale d'ingresso. Invece, tale dispositivo, funziona in modo tale che, quando \(T = 1\), allora l'uscita cambia stato ad ogni istante di clock, mentre se \(T = 0\) ciò non accade. Un possibile impiego di tale dispositivo permette di dimezzare la frequenza di clock del sistema stessa.

\subsection{\textit{Flip-Flop} di tipo D}
Nel \textit{flip-flop} D, ove \(D\) sta per delay, l'uscita dopo un impulso di \textit{clock} è uguale al valore presente all'ingresso \(D\) all'istante di clock. Infatti si ottiene che
\[X = \overline{x}D + x \overline{D}x\]

\subsection{Registri e contatori}
I flip-flop costituiscono la circuiteria di base per la memorizzazione di singoli bit in formato elettronico. A partire da essi si possono costruire unita per la memorizzazione di blocchi di \(m\) bit denominati registri; la figura mostra un esempio in tal senso, nel quale si costruisce un registro di \(m\) celle di memoria a partire da \(m\) flip-flop di tipo \(D\).

% Contenitore per immagini
\begin{figure}[H]
    \centering
        \includegraphics[scale=0.4]{img/circuiti_sequenziali/image10.png}
    \caption{Registro di memoria da \(m\)-bit}
    \label{fig:registro_di_memoria_da_m_bit}
\end{figure}

\noindent
Gli stessi \(m\) flip-flop di tipo \(D\) possono essere organizzati per realizzare i registri a scorrimento, che sono di fondamentale importanza per i flussi informativi interni ai calcolatori. Il circuito e rappresentato in figura e il suo funzionamento e intuitivo: a ogni istante di tempo il contenuto del registro j-esimo si sposta nel registro \((j - 1)\)-esimo e si rende disponibile per l’uscita, che rende possibile, sotto opportune condizioni e attraverso una retroazione, la generazione di sequenze pseudocasuali con un equo bilanciamento di zeri e di uni secondo la legge debole dei grandi numeri, ma vi sarà anche una distribuzione quanto più eterogenea degli zeri e degli uni relativamente alla lunghezza della sequenza considerata.\\
Viene illustrato di seguito:

% Contenitore per immagini
\begin{figure}[H]
    \centering
        \includegraphics[scale=0.4]{img/circuiti_sequenziali/image11.png}
    \caption{Registro a scorrimento}
    \label{fig:registro_scorrimento}
\end{figure}

\subsection{Contatore}
Con \(m\) \textit{flip-flop} di tipo T è possibile realizzare anche un contatore, che scandisce, una dopo l’altra, tutte le 2m
configurazioni da 00...0 a 111...1. Per capirne il funzionamento facciamo riferimento al contatore a 2 bit di figura
6.18, partendo dalla configurazione 00. Il flip-flop di sinistra ha sempre J “ K “ 1, e in corrispondenza del primo


\newpage
\begin{center}
    15 Novembre 2021
\end{center}
\subsection{Riassunto}
I circuiti sequenziali si distinguono dai circuiti combinatori in quanto è presente una retroazione tra ingresso e uscita, rappresentabile tramite il concetto di automa a stati finiti.\\
Con un circuito realizzato attraverso due transistors viene definito bistabile, ma non garantisce una affidabilità. Il suo principio, tuttavia, viene trasferito alle porte logiche, realizzando i latch di NOR, per il quale, esprimendo le uscite in funzione degli ingressi, si ottiene un cortocircuito logico. Realizzando le quaterne degli ingressi e delle uscite e ponendole in una tabella si rilevano \(11\) stati non stabili e non conformi ai vincoli circuitali. Solamente \(5\) sono gli stati stabili, anche se la configurazione con gli ingressi a \(1\), non da un punto di vista logico, ma dal punto di vista concettuale.\\
In questo caso, si hanno due ingressi \(R\) e \(S\): dando un impulso di \(R\) si porta la variabile di uscita \(X\) a \(0\), con un impulso \(S\) l'uscita \(X\) va a \(1\).\\
Analizzando anche, nella tabella di verità, lo stato precedente \(x\) si ottiene la funzione specifica,
con il vincolo che \(R \cdot S = 0\).\\
Pertanto, fintantoché viene alimentato, tale circuito mantiene la sua configurazione; è un circuito bistabile in cui il cambio di variabile è più semplificato rispetto al circuito con due transistor.

\vspace{1em}
\noindent
Naturalmente, è possibile anche realizzare un \textit{flip-flop} perfettamente equivalente, realizzato in logica duale, per cui il vincolo, in questo caso è che
\[R + S = 1\]
Taluni dispositivi, però, sono \textbf{asincroni}, ovvero in qualsiasi momento è possibile interagire con il sistema per cambiarne lo stato. Tuttavia, i dispositivi digitali sono sincroni, ovvero cambiano stato esclusivamente in corrispondenza di un preciso istante di clock. Inoltre, è doveroso tenere conto anche dei tempi di ritardo di propagazione del segnale nei circuiti, latenze determinate dalle capacità dei condensatori; anche quando ve ne sono, però, sono sempre da tenere presente le cosiddette \textbf{capacità parassite}, ovvero le capacità che si vengono a creare quando delle tracce di rame a differente potenziale sono poste in prossimità, ma non si toccano. Tali capacità parassite sono ininfluente a basse frequenze, ma quando le frequenze aumentano si avrà un'impedenza prossima allo \(0\), creando un cortocircuito, in quanto
\[Z = \frac{1}{I \cdot \omega \cdot C}\]
ove per \(Z\) è da intendere l'impedenza. Ciò potrebbe determinare anche dei fenomeni oscillatori. Ciò per spiegare che quando si cambiano i valori di ingresso in una porta si otterrà una variazione del valore di uscita dopo un certo \(\delta\); e se vi sono delle porte concatenate si dovranno sommare tutti i \(\delta\) delle porte.\\
Per tale ragione non si possono impiegare dei \textit{flip-flop} asincroni, in quanto si avrebbe un circuito estremamente instabile.

\vspace{1em}
\noindent
Per risolvere tale problema sarà sufficiente introdurre due porte AND agli ingressi \(R\) e \(S\) che prendano in ingresso l'impulso di clock.\\
Un altro significativo \textit{flip-flop} è il \(FFJK\), il quale permette di prendere in considerazione anche gli ingressi a \(0\) e a \(1\), per cui si prevede in ogni caso la commutazione dell'uscita (\(x = 1\) si forza un \textit{reset}, \(x = 0\) si forza un \textit{set}).\\
Collegando fra di loto i due ingressi si ottiene il \textit{flip-flop} T, per cui se \(T = 1\) si ha una continua commutazione dell'uscita, ad ogni istante di clock. Ciò permette di dimezzare la frequenza del clock, e così a cascata.\\
Il \textit{flip-flop} di tipo D, invece, permette di propagare in uscita il valore di \(D\) in ingresso.

\vspace{1em}
\noindent
\textbf{Registri}: I \textit{flip-flop} costituiscono la circuiteria di base per la memorizzazione di un singolo bit in formato elettronico e vengono realizzati attraverso i \textit{flip-flop} di tipo \(D\).\\
Vi sono anche i registri a scorrimento , costruiti concatenando \(n\) \textit{flip-flop} di tipo \(D\), dimodochè dopo \(n\) istanti si avrà in uscita il primo bit inserito.\\
Naturalmente l'uscita del registro può andare ad alimentare uno o più registri in ingresso, costituendo i registri a scorrimento retroazionati, che se opportunamente configurati, si possono ottenere tutte le \(2^n - 1\) configurazioni possibili con \(n\) bit, meno la configurazione nulla, per motivazioni legate al comportamento algebrico del sistema.

\vspace{1em}
\noindent
Utilizzando i \textit{flip-flop} di tipo \(T\) si riesce ad ottenere anche un contatore. Se si hanno \(n\) \textit{flip-flop}, si riesce a contare da \(0\) fino a \(2^n - 1\), con una continua ripetizione del ciclo.
Quando si hanno \(3\) \textit{flip-flop}, si dovrà usare una porta AND che prende in ingresso l'entrata \(X_0\) e l'uscita \(X_1\) e la cui uscita costituirà l'ingresso del terzo \textit{flip-flop}.

\newpage
\section{Codifica}
La codifica dei segnali che servono per alimentare un computer è fondamentale per la comprensione del funzionamento dei calcolatori. Ciò è la prima base per capire la connessione tra alto livello e basso livello di funzionamento di un computer.\\
Il calcolatore, infatti, è costituito da supporti di natura diversa che operano sempre in logica binaria. Questo, per quello che si è visto, deriva da una esigenza da un punto di vista pratico (per ragioni di dissipazione del sistema) e anche funzionale (in quanto la logica binaria è retta dall'algebra booleana).\\
Inoltre, è molto difficile che i dispositivi digitali si guastino, in quanto operano in una condizione ideale di dissipazione: quando si verifica un guasto, infatti, di solito è di natura elettrica riguardante l'alimentazione.\\
La problematica di gestione della rappresentazione di tutte le possibili informazioni in ingresso in logica binaria non è da sottovalutare. Infatti, le possibili informazioni in ingresso che devono essere processate da un elaboratore sono molteplici e svariate (caratteri alfanumerici, suoni, immagini, calcoli), e ciascuna deve essere opportunamente codificata attraverso una stringa di \textit{bit}.

\vspace{1em}
\subsubsection{Codifica dei caratteri}
Per poter codificare un carattere si potrebbe pensare di associare in modo univoco una stringa binaria a ogni lettera, dimodoché se vi sono \(k\) lettere, si dovranno impiegare \(2^{\log_2(k)}\) n-uple. Questo, naturalmente, nell'ipotesi in cui tutte le lettere siano codificate con lo stesso numero di bit; ma naturalmente si può anche prevedere di comprimere i messaggi rappresentando le lettere più frequenti con meno bit (come nel caso dell'alfabeto Morse, oppure come nei sistemi di compressione di file). In generale, vi sono quattro tipo di codifica delle stringhe:
\begin{itemize}
    \item Da blocco a blocco
    \item Da blocco a stringa di lunghezza variabile
    \item Da stringa di lunghezza variabile a blocco
    \item Da stringa di lunghezza variabile a stringa di lunghezza variabile
\end{itemize}
Se si hanno circa \(K = 111\) lettere (come in una tastiera), allora si dovranno usare
\[n \geq \log_2(k)\]
ovvero il più piccolo naturale maggiore di \(\log_2(k)\), rappresentato come segue
\[n = \lceil \log_2(k) \rceil\]
che, nel caso analizzato, si traduce in
\[n = \lceil \log_2(111) \rceil = 7\]
Da questa evidenza è nata la \textbf{tabella ASCII (American Standard Code for Information Interchanges)} che, negli anni \('60\), era sufficiente per rappresentare tutti i simboli che si impiegavano nelle tastiere dei primi computer che venivano introdotte.\\
Naturalmente, però, la diffusione dei calcolatori nel mondo occidentale ha palesato la necessità di introdurre un nuovo standard
\[\text{ISO 8859-}n, 1 \leq n \leq 16\]
ove \(n\) rappresenta il numero di bit impiegati per la codifica dei caratteri alfanumerici. Si pervenne, ben presto, alla codifica dei caratteri attraverso lo standard \(UTF (Unicode Transformation Format)\), ben presto soppiantato dall'Unicode a \(16\) bit e poi anche da quello dell'Unicode a \(32\) bit.\\
In realtà, vi sono anche delle sottocodifiche
\begin{itemize}
    \item UTF-8, a lunghezza variabile \(1-4\) byte
    \item UTF-16, a lunghezza variabile \(2-4\) byte
    \item UTF-32, a lunghezza costante di \(4\) byte
\end{itemize}

\vspace{1em}
\subsubsection{Codifica dei numeri}
Naturalmente i caratteri numerici possono essere impiegati sia in combinazione con i caratteri alfabetici, ma anche per eseguire dei calcoli. Naturalmente, si capisce immediatamente che i valori numerici, essendo infiniti, non potranno essere tutti rappresentati all'interno dei calcolatori, per cui se ne darà una rappresentazione approssimata.\\
È noto che un valore numerico si rappresenta nella notazione posizionale come segue
\[(523)_{10} = 5 \cdot 10^2 + 2 \cdot 10^1 + 3 \cdot 10^0\]
Più uin generale, si ha che
\[a_n \hspace{0.5em} a_{n - 1} \hspace{0.5em} ... \hspace{0.5em} a_1 \hspace{0.5em} a_0 = a_n \cdot b^n + a_{n - 1} \cdot b^{n - 1} + ... + a_1 \cdot b^1 + a_0 \cdot b^0\]

\vspace{1em}
\subsubsection{Conversione da base \(2\) a base \(10\)}
Per la conversione da binario a decimale è sufficiente sommare tutte le potenze di \(2\) corrispondenti agli \(1\) logici per ottenere il valore numerico decimale cercato.

\vspace{1em}
\subsubsection{Conversione da base \(10\) a base \(2\)}
Per la conversione da decimale a binario è sufficiente dividere il valore numerico decimale per \(2\) fino a che non si ottiene un resto \(\leq 1\) e considerare i resti di ciascuna divisione in ordine e per ottenere il valore binario sarà sufficiente leggere tali resti dall'ultimo al primo.

\vspace{1em}
\subsection{Operazioni binarie}
Le operazioni tra valori binari (ma con qualsiasi base, in realtà), palesano un evidente problema, quello dell'\textbf{overflow}. Tale inconveniente permette di rappresentare i numeri binari negativi in complemento a \(2\).\\
Se si operasse ponendo il bit più significativo a \(1\) per rappresentare i numeri negativi e \(0\) per rappresentare i positivi, si incorrerebbe in un errore evidente nelle operazioni di calcolo.

\newpage
\begin{center}
    15 Novembre 2021
\end{center}
\subsection{Riassunto}: La codifica del mondo esterno all'interno del computer prevede una mappatura specifica per ciascuna delle specifiche informazioni  da elaborare.\\
In particolare, le modalità di rappresentazione dei caratteri alfabetici può avvenire in \(4\) modalità, impiegando stringhe di lunghezza variabile o blocchi di lunghezza fissa. Naturalmente, per codificare \(k\) caratteri con \(n\) bit si devono impiegare
\[n = \lceil \log_2(k) \rceil\]
bit. A partire dalla tabella \textbf{ASCII} a \(7\) bit, si è poi passati ad una codifica a \(8\) bit per poi introdurre il sistema \textbf{UNICODE}, ancora oggi impiegata.

\vspace{1em}
\noindent
Per quanto riguarda la rappresentazione dei caratteri numerici, si effettua attraverso la rappresentazione posizionale.\\
La conversione da base \(2\) a base \(10\) si ottiene in maniera immediata; mentre la conversione da base \(10\) a base \(2\) prevede semplicemente di eseguire reiteratamente la divisione per \(2\) del quoziente e tenere conto del resto.\\
La rappresentazione dei numeri binari negativi può avvenire esclusivamente attraverso il complemento a \(2\). Il procedimento adottato nel caso binario è il medesimo per qualsiasi base. Infatti, considerando la somma \(37 - 15\) si può interpretare come \(37 + (100 - 15) - 100\), ovvero \(122 - 100 = 22\) che è proprio il risultato cercato. Infatti, nell'ipotetica condizioni in cui si avessero avuto due sole posizioni per rappresentare i valori numerici, il valore \(100\) sarebbe stato automaticamente sottratto grazie al fenomeno dell'overflow.\\
In generale, per ottenere un numero in complemento a \(10\), avendo il vincolo di \(n\) celle di memoria si deve eseguire
\[comp_{10}(x) = 10^{n} - x\]
In questo modo si riesce a centrare l'intervallo \(\left[ 0 : 10^{n} - 1 \right]\) in zero. La stessa cosa vale esattamente anche nel caso binario, in cui
\[-x = \overline{x} + 1\]
questo in quanto è noto che \(-x = 2^{n} - 1\), ma anche \(\overline{x} + x = 2^{n} - 1\), pertanto si ha che \(-x = \)\\
Un'altra rappresentazione possibile, ma oramai desueta, oltre al complemento a \(2\) si ha anche il complemento a \(1\), che prevede semplicemente di complementare la rappresentazione dei numeri positivi. Tuttavia, in questo caso, si ha una doppia rappresentazione del valore \(0\) e bisogna anche cambiare le operazioni di calcolo.\\

\vspace{1em}
\noindent
Tuttavia, anche se si è stati in grado di rappresentare i numeri negativi, non è possibile rappresentare tutti i numeri reali, in quanto non si hanno infiniti bit. Per arginare il problema si deve ricorrere ad un ulteriore sistema di rappresentazione, ovvero quello a \textbf{virgola mobile}.

\subsection{Rappresentazioni in \textit{floating-point}}
La rappresentazione a virgola mobile prevede di considerare una mantissa \(m\) e un esponente \(e\) che, nel caso della base decimale si ha
\[N = \pm \hspace{0.5em} m \cdot 10^{\pm e}\]
da cui si ottiene che, la rappresentazione in virgola mobile dei numeri reali è
\[[\pm] \hspace{0.5em} [m] \hspace{0.5em} [\pm] \hspace{0.5em} [e]\]
Da cui si conviene che, assegnando \(1\) bit per il segno e i restanti alla mantissa \(m\) e all'esponente \(e\) si riesce ad avere un'ampia gamma e dinamica di rappresentazione dei numeri reali sulla retta reale, pur non riuscendo a saturare interamente la densità dei numeri reali.\\
Infatti, la rappresentazione esposta introduce un'approssimazione, in quanto la precisione di rappresentazione dipende strettamente dal numero di cifre significative, ovvero dal numero di bit sia della mantissa che dell'esponente.\\
Ufficialmente, la rappresentazione in virgola mobile è stata standardizzata dalla \textbf{IEEE 754}, la quale prevede una precisa rappresentazione del valore numerico, distinto in base alla precisione, ovvero
\begin{itemize}
    \item \textit{Single-Precisione}, con \textbf{IEE 754-32} con \(23\) bit per la mantissa e \(8\) bit per l'esponente (rappresentato mediante eccesso a \(127\));
    \item \textit{Double-Precisione}, con \textbf{IEE 754-64} con \(52\) bit per la mantissa e \(11\) bit per l'esponente (rappresentato mediante eccesso a \(1023\)).
\end{itemize}

\vspace{1em}
\subsubsection{Segnali analogici}
Come è possibile codificare un segnale analogico il quale ha infiniti valori e varia con continuità nel tempo. Per poter eseguire tale rappresentazione si ricorre al \textbf{campionamento} del segnale, la cui frequenza, naturalmente, deve essere la più alta possibile. Naturalmente, la lettura del segnale avviene in maniera discreta e finita, in quanto non si dispone di strumenti atti ad una lettura con precisione infinita, ma anche se vi fosse, non si disporrebbe degli strumenti atti a rappresentare tale letture (se in \textit{floating-point}, per quanto appena visto, si avranno blocchetti di \(32\) o \(64\) bit).\\
Per poter ricostruire la forma d'onda di partenza con sufficiente precisione si deve avere una frequenza di campionamento sufficientemente elevata. La frequenza di campionamento, indicata con \(f_c\), è legata strettamente alla banda (ovvero l'estensione in frequenza del segnale che si sta considerando, così per un apparato ad alta fedeltà si ha una banda che va da \(20 Hz\) a \(20 kHz\)) del segnale e, secondo il \textbf{teorema di Nyquist} si ha che se
\[f_c > 2B = f_N\]
si può ricostruire il segnale senza ambiguità, ove \(f_N\) è la \textbf{frequenza di Nyquist}.

\vspace{1em}
\noindent
\textbf{Osservazione}: Naturalmente, bisogna tenere presente anche gli errori di quantizzazione, ovvero l'errore di rappresentazione. Infatti, il valore del campione viene decodificato usando \(n\) bit; ciò comporta un errore che diminuisce all'aumentare del numero di bit impiegati per la rappresentazione del valore campionato.\\
Il diagramma dell'errore è un dente di sega con valore assoluto di \(1\), ma se viene centrato nella metà del diagramma stesso si riesce a diminuire il valore assoluto a \(0.5\).

\vspace{1em}
\noindent
\textbf{Osservazione}: Da un punto di vista pratico, si ha che una \textbf{Conversione A/D} avviene dando in pasto un segnale analogico al \textbf{campionatore} il quale, successivamente, produce in uscita dei campioni che vengono dati in pasto al \textbf{quantizzatore} che produce in uscita i valori opportunamente rappresentati in binario.\\
Tali valori, opportunamente quantizzati, per essere convertiti in analogico, vengono dati in pasto a un \textbf{generatore d'impulsi} che deve essere poi seguito da un \textbf{filtro passa basso} che lascia passare solamente le frequenze più basse. Questo, infatti, perché un impulso è una variazione con una frequenza praticamente infinita del segnale considerato (infatti, è come se si avesse una sinusoide con una elevata frequenza) per cui un filtro basso taglia i contributi alle elevate frequenze e si riesce a creare le connessioni per ricostruire la forma originale del segnale.\\
È noto che i filtri passa alto e passa basso vengono realizzati con delle \textbf{celle R-C} che si comportano in modo opposto alle elevate e basse frequenze.\\
Naturalmente, tale processo palesa degli errori (errori di campionamento, di quantizzazione e del filtro passa basso).\\
Naturalmente i circuiti digitali non possono processare impulsi a frequenza arbitrariamente elevata, per cui gli impulsi campionati vengono interpretati sottoforma di \quotes{blocchetti} i quali mantengono lo stesso livello del segnale per il tempo di campionamento.

\vspace{1em}
\subsubsection{Immagini}
Per la digitalizzazione delle immagini con sostrato e modalità di tipo digitale è stata la conseguente evoluzione della rappresentazione delle immagini con sostrato e modalità di tipo analogico.\\
Un tubo termoionico è una sorta di tubo con dentro un'ampolla di vetro con catodo e anodo. Il filamento del catodo, costituito da ossidi, generalmente, quando viene alimentato con una certa tensione si scalda. Gli ossidi di Bario e Stronzio vengono sollecitati dall'agitazione termica, per cui si viene creare una nuvola elettronica attorno al catodo. Se l'anodo viene alimentato con una corrente positiva, allora gli elettroni vengono attirati dall'anodo e il flusso di elettroni viene ripristinata dalla batteria. Esattamente come per un diodo, si ha il flusso di elettroni solamente in senso.\\
Inoltre, se fra anodo e catodo si pone una griglia alimentato da una certa tensione negativa si viene a creare una barriera di potenziale che, a seconda della tensione di alimentazione può essere più o meno elevata che limita il flusso di elettroni. Si è costruito, quindi, un \textbf{triodo}.\\
Ebbene, le videocamere analogiche operano con un tubo termoionico, nel quale, però, vengono inserite anche delle bobine di deflessione per convogliare il fascio elettronico in un unico punto, costruendo, di fatto, un pennello elettronico.


\newpage
\begin{center}
    17 Novembre 2021
\end{center}

\subsection{Riassunto}
La rappresentazione dei numeri interi in binario si basa sulla tecnica del complemento a \(2\). I numeri reali, invece, non possono essere interamente rappresentati attraverso un calcolatore, per quanta memoria si possa impiegare. Allora si procede ad effettuare un troncamento del numero, il quale viene rappresentato con due componenti, la \textit{mantissa} e l'\textit{esponente}, ciascuno con opportuno segno. La rappresentazione a virgola mobile consente di avere un'ampia dinamica di rappresentazione, sia dei numeri grandi che di quelli piccoli.\\
È implicito, tuttavia, che la rappresentazione in \textit{floating-point} porta con sé un'approssimazione, tale per cui non vale più la proprietà associativa dell'addizione. Dal punto di vista della normalizzazione, si ha che lo standard \(IEEE 754\) a \(32\) bit (singola precisione) e \(64\) bit (doppia precisione).\\
Per quanto concerne la rappresentazione dei segnali analogici, ovvero segnali che variano con continuità nel tempo, si procede ad eseguire il campionamento, ovvero al prelievo ad intervalli regolari di campioni del segnale che, naturalmente, dovranno pur sempre essere rappresentati in modo discreto. Nyquist afferma che se la frequenza di campionamento è almeno doppia della larghezza di banda allora si riesce a ricostruitre il segnale di partenza senza amboguità. Naturalmente in tal senso si dovrà tenere presente anche dell'errore di quantizzazione, il quale viene progressivamente attenutato all'aumentare del numero di bit di rappresentazione.\\
Per la rigenerazione del segnale di partenza si impiega un generatore di impulsi e di un filtro passa basso; questo permetterebbe, dal punto di vista ideale, di ricostruire esattamente il segnale di partenza. Tuttavia, bisogna tenere presente sia dell'errore di campionamento, sia dell'errore di quantizzazione, sia dell'errore del generatore d'impulsi. Inoltre, la gestione degli impulsi a frequenza arbitrariamente elevata è difficoltosa, si procede a mantenere il livello del segnale quantizzato per tutto l'intervallo di tempo del campionamento.\\

\vspace{1em}
\noindent
Per quanto riguarda le immagini riprodotte dal punto di vista analogico si ha un tubo a raggi catodici di emettitori di elettroni che vengono proiettati in un tubo termoionico, in cui il catodo viene alimentato con una tensione che produce una nuvola elettronica che vengono attirati verso l'anodo e vengono convogliati verso un punto attraverso delle tecniche di deflessione magnetica, attraverso, quindi, delle bobine.\\
Sullo strato esterno della telecamera analogica vengono poste delle sostanze fotoconduttive, ovvero modificano la loro luminosità a seconda della loro conducibilità. Ovvero la modulazione del pennello elettronico viene modulata dall'intensità di luminosità dell'immagine che si sta riprendendo.\\
Taluna è una telecamera analogica, la quale rappresenta un dispositivo trasmettitore che, attraverso tecniche di modulazione di una portante (frequenza molto elevata), trasmette ad un dispositivo ricevente analogo, sempre operante a tubo catodico, in cui l'intensità del fascio viene modulata dall'intensità luminosa dell'immagine da riprodurre.\\
La tecnologia dei tubi \textbf{CRT} sono molto costosi, ingombranti e delicati (in quanto è composto di vetro), per cui la tecnologia è molto sofisticata, per cui cui non si riusciva ad abbattere i costi. Inoltre, essendo vuoti all'interno, esiste la possibilità che implodano e, inoltre, data l'elevata intensità del fascio elettronico, c'era la concreta possibilità di generare dei raggi X, molto pericolosi.

\vspace{1em}
\noindent
\textbf{Osservazione}: La combinazione dei tre colori base produce tutto lo spettro elettromagnetico del visibile. Per cui, per produrre il colore nell'immagine si dovranno avere avere tre fasci elettronici prodotti da \(3\) catodi; se ciascuno dei tre fasci va a colpire dei fosfori particolari che reagiscono alla sollecitazione dei tre fasci, per cui si ha l'effetto del colore sulla terna di fosfori che viene percepito dall'occhio umano.\\
Pertanto si hanno tre fasci (uno riservato al rosso, uno al blu e uno al verde) che vanno a colpire una cella (una terna di fosfori) che viene opportunamente sollecitata per produrre il colore desiderata.\\
Ad oggi, invece, si ricorre alla tecnologia dei cristalli liquidi. Infatti, se con il sistema analogico si aveva una continua rappresentazione dell'immagine nel tempo, dal punto di vista digitale si procede alla discretizzazione dell'immagine attraverso la tecnica della maggioranza (si dispone una griglia di pixel e se un pixel è più colorato che bianco, allora viene colorato.\\
Naturalmente è ovvio che tanto più è fitta la griglia di pixel (ovvero tanto più è elevata la risoluzione dell'immagine, tanto maggiore sarà la qualità finale dell'immagine discretizzata). Per la rappresentazione della scala di grigi si associa a ciascuna colorazione una opportuna codifica, mentre per la riproduzione dell'immagine si procede a riprodurre una differente gradazione luminosa.\\
Tanto maggiore sarà la profondità di colore (ovvero i livelli di grigio) maggiore sarà la colorazione e la qualità risultante dell'immagine riprodotta. La stessa cosa vale anche per i colori.\\
Per la creazione dei colori non si usa più un pennello elettronico che colpisce un fosforo, ma vengono realizzati da dei dispositivi a semiconduttori, come i LED: in prima approssimazione, infatti, ciascuno dei tre colori primari viene rappresentato da un diodo LED emettitore di luce. Infatti, ciascun colore viene costruito dalla combinazione lineare dei tre colori primari, con una qualità di rappresentazione che dipende dal numero di bit associati a ciascun colore primario.\\
Le diverse tecnologie di rappresentazione che si sono susseguite hanno previsto, in principio \(8\) bit per pixel, associandone \(3\) al rosso e verde, mentre \(2\) al blu in quanto l'occhio umano è meno sensibili a questo colore e più sensibile rispetto al verde.\\
Il canale \(\alpha\) permette anche di modificare la rappresentazione attraverso la trasparenza delle immagini.

\vspace{1em}
\noindent
\textbf{Osservazione}: Si capisce facilmente, però, le immagini pesano molto a seconda del numero di bit scelti. Infatti, data una risoluzione di \(1280 \times 1024\) con \(32 bit/pixel\) si ha un peso di
\[1280 \cdot 1024 \cdot 32 = 5 MB\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Il numero di immagini che si possono creare con una griglia \(m \cdot n\) con solo bianco e nero si ottiene
\[2^{m \cdot n}\]

\vspace{1em}
\noindent
\textbf{Osservazione}: Il \textbf{bifenile} è un \textbf{cristallo nematico} con una struttura elicoidale che se viene sollecitato da una luce polarizzata (ovvero una luce in cui è stato isolato una delle due sue componenti, elettrica e magnetica) produce un colore.\\
Infatti, illuminando dal basso con una luce polarizzata un filtro polarizzatore e ponendo sopra un ulteriore filtro polarizzatore posto ortogonalmente al filtro sottostante e la luce può uscire accompagnata: questo accade in condizione di riposo. Se al filtro viene sollecitato da un campo elettrico, allora la luce non viene più accompagnata in uscita, ma viene sbarrata dal filtro polarizzatore e ciò permette di creare l'immagine. Tuttavia, si necessita di una illuminazione esterna per riuscire a vedere l'immagine: sono i cosiddetti critalli liquidi passivi.\\
La tecnologia TFT, ovverosia Thin Film Transistor, si ha una illuminazione interna, sottostante, prodotta da un dispositivo a semiconduttore. Il controllo di ogni singolo pixel avviene su ogni riga e su ogni colonna e un segnale a \(20 V\) viene fatto passare per ciascuna riga. Taluno è il segnale di attivazione che permette di attivare ciascun subpixel a seconda dello stato del gate di giascuno. Ogni singolo subpixel, infatti, contiene delle capacità che permettono di mantenere la corrente fino a quando non si costruisce una immagine completa. Tale tempistica è necessaria per fare in modo che al turno successivo la tensione da \(20 V\) vada ad alimentare nuovamente i condensatori e così via.\\
Tale tecnologia, tuttavia, continua ed essere molto costosa, in quanto gli schermi per i quali non risulta funzionante anche un solo pixel vengono scartati.

\subsection{Rappresentazione fisica dei bit}
I simboli binari hanno una loro rappresentazione fisica. Infatti, i due stati \(1/0\) devono essere equiprobabili ed interpretati come presenza/assenza di una certa grandezza fisica (come una tensione e una corrente).\\
Da un punto di vista meccanico, un bit è rappresentato attraverso un interruttore (acceso/spento). In maniera più sofisticata, un bit può essere rappresentato anche attraverso un relè, che può essere comandato a distanza. Infatti, un relè è una bobina avvolta ad un nucleo ferromagnetico che quando viene sollecitata, va ad azionare o a chiudere un interruttore fisico.\\
Ad oggi i relè vengono utilizzati quando si necessita di azionare un grosso carico senza impiegare un interruttore standard. Infatti, quando si deve azionare un grosso carico con una molla dalla resistività più piccola possibile per abbassare quanto più la dissipazione di corrente. Pertanto l'interruttore normale viene impiegato solamente per lasciar passare la corrente e azionare il relè.\\
Dal punto di vista magnetico, il bit può essere rappresentato attraverso l'anello di ferrite, molto fragile ma capace di memorizzare un bit attraverso un mutamento dell'orientamento del campo magnetico. Si tratta, comunque, di una tecnologia poco efficiente perché si hanno pochi bit per \(cm^2\).
Gli Hard-Disk vengono realizzati in policarbonato su cui viene posto del materiale ferromagnetico che viene polarizzato attraverso una testina; pertanto la memorizzazione dei bit viene associata non alla tipologia di polarizzazione (nord/sud), ma al mutamento della polarizzazione dallo stato precedente a quello successivo.\\
Il bit elettrico viene rappresentato da un condensatore che, molto intuitivamente, rappresento
\begin{itemize}
    \item Il bit logico \(1\) se il condensatore è carico.
    \item Il bit logico \(0\) se il condensatore è scarico.
\end{itemize}
Infatti, i condensatori presentano una resistenza di dissipazione, causa del fatto che il condensatore si scarica dopo un certo tempo (la resistenza dovrebbe essere infinita per avere un tempo di scaricamento infinito). Naturalmente, quindi, per mantenere la memorizzazione del bit sul condensatore si ha che questo deve essere sempre alimentato per mantenere il suo stato.\\
Ancora un altro modo per rappresentare un bit elettronicamente è il transistor; infatti, quando il transistor è in interdizione rappresenta lo stato logico \(1\), lo stato logico \(0\) se in saturazione. Questo dispositivo, come il condensatore e il \textit{flip-flop}, devono essere sempre realizzati.\\
È stato anche possibile realizzare dei CD di memorizzazione sui quali viene posto una lamina di alluminio che, all'atto di masterizzazione, vengono bruciate con un laser alcune tracce dimodochè queste diventino poco riflettente. Quando il CD viene letto il bit \(1\) solamente sui fronti in cui la riflessione aumenta e diminuisce, lettura eseguita attraverso una tecnologia molto complessa.\\
Tale tecnologia si è poi evoluta passando da \(CD\) a \(DVD\) a \(HD \textbf{ } DVD\) e \(Blue \textbf{ } Ray\).

\subsubsection{Bit nelle memoria RAM}
Il bit nelle RAM statiche (SRAM) vengono realizzati con una tecnologia è molto complessa, in cui sono contenuti \(6\) transistor che vanno a creare un \textit{flip-flop} e che garantisce tempi di risposti ridotti. Mentre la memoria RAM dinamica memorizza i propri bit attraverso un condensatore e i tempi di risposta sono molto ridotti

\subsubsection{Seriale e Parallelo}
La trasmissione dei bit può avvenire un modo seriale, impiegando una sola linea, ma in maniera molto lenta, mentre in modo parallelo si usano più linee di trasmissione, ma con tempi di trasmissione molto ridotti.

\newpage
\begin{center}
    22 Novembre 2021
\end{center}
\subsection{Riassunto}
La codifica delle immagini, ad oggi, è totalmente digitale, mentre in passato si eseguivano delle scansioni esclusivamente analogiche. Per la realizzazione dei colori ci si basa sulla terna dei colori primari \textbf{RGB}, per cui, nei tubi catodici il colore viene riprodotto andando a sollecitare attraverso dei fasci elettronici ciascuna delle celle contenente un colore primario che, viste da lontano, riproducevano correttamente l'immagine colorata.\\
Dal punto di vista digitale, l'immagine viene scansionata attraverso una rete \(m \times n\) di pixel, ciascuno dei quali può essere colorato (prima attraverso una scala di grigio, poi attraverso una opportuna codifica dei diversi colori dell'iride). Naturalmente, tanto più sono i bit per la descrizione di un pixel, tanto più raffinata sarà la riproduzione dell'immagine. Si capisce immediatamente, naturalmente, che le immagini sono molto pesanti in termini di memoria, tanto più pesanti a seconda del tipo di standard impiegati.\\
Gli schermi, ad oggi, sono realizzate attraverso la tecnologia a cristalli liquidi sfruttando delle particolari proprietà di alcuni composti organici, quali il \textbf{bifenile}, ottenendo una matrice a cristalli liquidi passiva, oppure attiva.\\
La rappresentazione meccanica di un bit può essere ricondotta ad un interruttore, mentre dal punto di vista elettromeccanico si possono impiegare i relè. I bit, negli anni \('60\), venivano memorizzato in degli anelli di ferrite, le quali potevano essere polarizzate in modo diretto o inverso, ma con un rapporto di memorizzazione e dimensione assolutamente ridicola.\\
Gli Hard-Disk, invece, sono ancora oggi utilizzati e funzionando attraverso una variazione di intensità ferromagnetica. Le capacità, inoltre, possono rappresentare un bit, associando lo stato carico come stato alto, mentre se il condensatore è scarico, si ha lo \(0\) (questa tipologia di memoria è naturalmente volatile, in quanto il circuito deve essere sempre alimentata).\\
Il transistor, in modo perfettamente analogo, consente di memorizzare i bit associando un valore alla condizione di saturazione e interdizione. Anche i \textit{flip-flop} possono memorizzare dei bit, dando un colpo di set si porta l'uscita a \(1\), mentre si ottiene lo stato logico \(0\) dando un colpo di reset.\\
I dispositivi CD sono stati introdotti relativamente di recente, e attraverso una testina laser è possibile leggere il disco, riuscendo a distinguere i bit \(1\) e \(0\) attraverso la differenza tra zone bruciate e zone luminose del disco di policarbonato su cui sono stati eseguite delle tracce attraverso un fascio laser.\\
Le memorie RAM possono essere statiche (costose e molto efficienti) o dinamiche (poco costose, ma molto lente, specialmente nei temi di risposta). I bit, su una linea, possono essere trasmessi in serie, impiegando una sola linea, ma uno alla volta, oppure in parallelo, impiegando più linee di trasmissione, ma i bit arrivano a destinazione tutti insieme.\\
Per la trasmissione dei segnali su una linea, i segnali analogici possono essere trasmessi codificando un valore con l'ampiezza del segnale, trasmesso ad intervalli regolari, oppure attraverso un segnale continuo, mentre attraverso un segnale digitale si codificano attraverso i comuni bit.

\newpage
\section{Rivoluzione microelettronica}
La tecnologia odierna, così rivoluzionaria, è stata ottenuta attraverso un'evoluzione lunga e progressiva di tecnologie precedenti.\\
La prima fase della rivoluzione microelettronica riguarda l'introduzione di un primo componente attivo (che viene usata per amplificare il segnale, a differenza dei componenti passivi, come le resistenze), ovvero il \textbf{diodo di Fleming} (\(1904\)): un tubo termoionico è costituito da un anodo e un catodo, il quale, quando viene alimentato, produce una nuvola elettronica che viene attirata dall'anodo quando questo viene alimentato e assume potenziale positivo. Naturalmente, tale circuito, chiuso da una batteria, è un dispositivo unidirezionale, in quanto gli elettroni transitano dal catodo all'anodo, il quale può essere impiegato per \textbf{raddrizzare la corrente} alternata, facendola divenire corrente continua.\\
Il \textbf{diodo di Fleming}, tuttavia, non è ancora un dispositivo attivo, ma lo sarebbe diventato due anni dopo, nel \((1906\)), con l'introduzione del \textbf{triodo di de Forest}, il quale era un dispositivo che aggiungeva al diodo di Fleming una griglia (una spirale, concretamente) che si trova tra il catodo e l'anodo: in questo modo, gli elettroni che transitano dl catodo all'anodo devono prima passare attraverso la griglia, la quale può essere polarizzata opportunamente per amplificare o attenuare un segnale. Il triodo può anche operare in una condizione di saturazione o interdizione.\\
In principio, un triodo, ovvero un tubo termoionico, veniva associato ad un singolo bit, ma il dispositivo aveva una dimensione di circa \(7-8\) centimetri.\\
Successivamente, negli anni \('80\), i dispositivi venivano realizzato non più in vetro, ma attraverso la bachelite (il primo isolante realizzato in maniera sintetica). Inoltre, bisogna ricordare che i tubi non avevano vita eterna, per cui nel tempo perdevano le loro proprietà e i filamenti interni si consumavano, per cui dovevano essere sostituiti.\\
Nel tempo, però, si è cercato di miniaturizzare tali dispositivi, ma anche tale processo venne limitato a causa delle \textbf{scariche disruttive}, ovvero delle scariche che si vengono a determinare quando due elettrodi vengono posti troppo vicini fra di loro. Di fatto, se non fossero stati introdotti i transistor non si avrebbe avuto la possibilità di evolvere tecnologico.

\subsection{Seconda fase: Transistor}
L'introduzione dei \textbf{transistor} avvenne nel (\(1948\)), costituito dapprima attraverso un cristallo di \textbf{germanio}, che si trova sullo stesso gruppo del silicio nella tavola periodica degli elementi di Mendelehev. Naturalmente le dimensioni erano molto ridotte, ma ancora considerevoli a causa della struttura circostante il cristallo di germanio necessaria per la trasmissione del segnale. In ogni caso, però, la dissipazione e la tensione sono molto ridotte e la durata è eterna, dell'ordine di \(100.000\) ore.\\
A partire dagli anni \('70\) i transistor vengono realizzati con dei contenitori (\textit{case}) di metallo e con un cristallo di silicio.

\subsection{Circuiti integrati}
Con un cristallo di silicio è possibile realizzare un transistor, mentre introducendo dei cristalli di dimensioni più elevate è possibile creare più transistor in un solo chip e interconnessi fra di loro danno vita ad un circuito integrato, le cui dimensioni, dalla fine degli anni \('70\) e l'inizio degli anni \('80\) sono stati realizzati con dimensioni sempre più piccole.

\vspace{1em}
\noindent
\textbf{Osservazione}: La crescita dell'integrazione, ovvero della concentrazione di transistor in un singolo chip, è di tipo esponenziale, con un raddoppio di circa \(18\) e \(24\) mesi, nota come \textbf{legge di Moore}. Ad oggi, invece, la curva incomincia ad appiattirsi, in quanto si è arrivati ad un punto in cui le tracce del chip sono dell'ordine degli atomi. E l'appiattimento della curva è un'eventualità assolutamente inevitabile, che caratterizza tutti i processi in natura.\\
La legge di Moore ha influenzato significativamente il mercato tecnologico, permettendo di abbattere i costi e di migliorare in maniera importante la qualità del prodotto, ottimizzando persino il consumo di potenza.\\
Ciò ha delle ripercussione anche dal punto di vista software. Infatti, \textit{il software è come un gas}, in quanto segue le \(3\) leggi della termodinamica
\begin{itemize}
    \item Il software diventa sempre più complesso all'aumentare delle prestazioni del supporto tecnologico
    \item Il software limita la propria complessità secondo la legge di Moore, a causa della limitazione della tecnologica hardware a disposizione
    \item Quando la tecnologia hardware non è più in grado di stare al passo con l'esigenza software dell'utente, vengono introdotti dei nuovi dispositivi hardware, sempre più prestazionali.
\end{itemize}

\subsection{Concetto di informazione}
È noto che i \textbf{bit} costituiscono la \textbf{minima quantità di informazione associata a due stati equiprobabili}.\\
L'\textbf{informatica} riguarda la \textbf{gestione e l'elaborazione automatica dell'informazione}. Ma è importante chiedersi che cosa sia l'\textbf{informazione}: l'informazione nasce a seguito di una variazione (una differenza) di una certa grandezza fisica, la quale si può sviluppare tanto in modo analogico, quanto in modo digitale. Tale differenza si propaga attraverso dei canali di comunicazione attraverso i quali è possibile prelevare un'informazione dalla relativa sorgente.\\
La variazione può essere trasmessa sia oltrepassando la \textbf{barriera spaziale}, oppure attraverso una \textbf{barriera temporale}. Banalmente, un supporto di trasmissione dell'informazione è la \textbf{memoria}.\\
È fondamentale, inoltre, comprendere anche il concetto di \textbf{stratificazione gerarchica delle differenze}, in quanto le differenze possono essere rilevate anche su delle differenze (si pensi a dei dati che sono frutto di rilevazioni di differenze e poi agli attributi dei dati, che sono nuovamente delle differenze, ma rilevate su delle nuove differenze).\\
Inoltre, quando una sorgente di informazione genera un flusso informazionale, vi sono diversi canali di informazione che vengono sollecitati, i quali portano con sé informazioni di natura diversa, che possono essere rilevati dagli utenti, i quali sono in grado di recepire tali informazioni, ma hanno anche la possibilità di scartare certe informazioni.\\
L'informazione, pertanto, si può rilevare su diversi piani, ovvero
\begin{itemize}
    \item Un'informazione che si può considerare
    \item Un'informazione che si vuole considerare
    \item Un'informazione latente, ovvero disponibile, ma non immediatamente fruibile
\end{itemize}
L'informazione, poi, è alla base del cosiddetto \textbf{processo di comunicazione}, il quale si dirama in più passi
\begin{enumerate}
    \item \textbf{Rilevamento - Livello sintattico}, ovvero una certa grandezza fisica viene rilevata attraverso uno strumento.

    \item \textbf{Comprensione - Livello semantico}, la quale richiede che vi sia uno strumento cognitivo superiore, quale il cervello umano, che sia in grado di processare l'informazione attraverso i propri processi cognitivi, mediante l'esperienza e la capacità acquisite.

    \item \textbf{Impiego - Livello pragmatico}, ovvero reagire all'informazione o fruire dell'informazione per compiere un'azione conseguente o sviluppare un pensiero successivo connesso all'informazione rilevata e compresa.
\end{enumerate}

\newpage
\begin{center}
    23 Novembre 2021
\end{center}
\subsection{Riassunto}
La rivoluzione microelettronica si articola in \(3\) fasi. La prima riguarda la costruzione dei tubi termoionici, ovvero dei dispositivi pesanti, ingombranti, fragili, poco duraturi e con una potenza dissipata assai inferiore.\\
La seconda fase riguarda i transistor, dispositivi assai più efficienti, in tutti i sensi, rispetto ai tubi termoionici, per poi giungere alla terza fase, riguardante i circuiti integrati, che rappresentano la concentrazione massima possibile dei transistor in un circuito integrato, che segue una legge nota come legge di Moore, di carattere esponenziale.\\
Tale legge è stata valida fino ad oggi, quando si è arrivati ad una miniaturizzazione tale da scontrarsi con dei limiti quantistici. Infatti, è molto interessante capire come il software si comporti come un vero e proprio gas, cercando sempre di richiedere maggiori prestazioni alle macchine che lo supportano.\\

\vspace{1em}
\noindent
Il bit dell'informazione è l'unità minima di informazione in grado di contenere i dettagli di due stati egualmente probabili.\\
Un sistema basato sulle interazioni informazionali è di natura molto più complessa rispetto ad un qualsiasi sistema fisico o biologico. L'informazione, inoltre, nasce quando si assiste ad una differenza di una certa grandezza fisica: senza differenze non si ha informazione, la quale può essere trasmessa attraverso lo spazio o il tempo.\\
Tuttavia, è anche fondamentale rilevare che oltre alle differenze di primo livello, meramente superficiali, possono essere rilevate anche differenze di più livelli, ovvero delle differenze sulle differenze.\\
Inoltre le informazioni possono essere destinate a più utenti che avranno la possibilità di valutarle oppure no. Inoltre il processo di comunicazione si diparte in tre rami
\begin{enumerate}
    \item Rilevamento, a livello sintattico
    \item Comprensione, a livello semantico, la quale può avvenire solamente con l'esperienza
    \item Impiego, a livello pragmatico, che si pone a livello dell'utente e riguarda l'utilizzo dell'informazione per i propri fini
\end{enumerate}
Nella tecnologia di elaborazione dell'informazione, anche mediante i calcolatori, ci si è sempre fermati al livello sintattico, al fine di garantire una comunicazione intelligibile.\\
Solamente di recente si è cercato di sfondare la barriera semantica, anche se è molto complesso, cercando di rielaborare in tal senso le informazioni, in quanto per fare ciò si necessita di un cervello, di una infrastruttura logica che è capace di simulare la volontà e la direzione del pensiero umano.\\
Grazie all'enorme patrimonio esperienziale e informazionale contenuto nel Web, ovvero alla stratificazione sintattica di frasi e stringhe strutturate logicamente e aventi senso compiuto, è possibile iniziare ad avere una prima risibile forma di interazione con un sistema esperto, nel senso prettamente pratico del tempo.

\vspace{1em}
\subsection{Ridondanza}
La \textbf{ridondanza} è un eccesso d'informazione rispetto a quella strettamente necessaria per ricostruire il tutto, e risulta fondamentale per fare previsioni sui dati mancanti con una probabilità di successo superiore alla distribuzione uniforme.\\
L'informazione trasmessa, infatti, è costituito da un'informazione essenziale, non compressibile ed essenziale, e da tutto ciò che non è essenziale, appunto, la \textbf{ridondanza}.\\
Anche la ridondanza, come l'informazione, può essere di tipo \textbf{sintattico} e \textbf{semantico}, la prima riguardante i dati, mentre il secondo riguardante il significato.\\
Per impiegare la ridondanza semantica al fine di completare un'informazione essenziale è fondamentale valutare la frequenza relativa delle lettere dell'alfabeto della lingua impiegata per la scrittura dell'informazione.\\
Pertanto, per ricostruire l'integrità dell'informazione essenziale, oltre alle frequenze relative delle singole lettere, sarà necessario anche impiegare la frequenza relativa delle coppie di lettere, in modo tale da valutare di volta in volta le lettere che seguono quelle precedenti.\\
Riuscendo a procedere in questo modo si riesce a costruire sintatticamente l'informazione essenziale e, anche se l'informazione non ha senso compiuto, ovvero è scorretta semanticamente, ma assomiglia ad un'informazione della lingua di trasmissione, in quanto costruita proprio sulla base delle frequenze relative delle lettere delle parole della lingua di riferimento.\\
Quindi l'informazione non coincide con il supporto (infatti è possibile cambiare infinite volte il supporto di trasmissione di trasmissione, ma l'informazione rimane inalterata, al più cambierà la persistenza dell'informazione stessa).\\
Inoltre, l'informazione non segue le leggi di conservazione della fisica, in quanto distribuendola essa non diminuisce. Pertanto non è una grandezza fisica e dipende dal contesto, in quanto la stessa informazione sintattica può assumere dei significati differenti, dal punto di vista semantico, a seconda del contesto, ovvero a seconda dell'esperienza dell'osservatore che interpreta l'informazione sintattica fornita.\\
È fondamentale anche capire che l'assenza di informazione è essa stessa un'informazione.

\newpage
\section{Storia dell'informatica}
L'informatica deriva dal francese \textit{Information Automatiqué}. L'informatica non è riducibile al calcolatore, in quanto è nata quando il computer ancora non c'era, nel \(1936\).\\
Di fatto, l'informatica non dipende dalla tecnologia di supporto e non è vincolata all'esistenza stessa di un calcolatore.\\
Nel \(1936\), infatti, sono sfociate due desideri millenari dell'essere umano
\begin{itemize}
    \item Il sogno millenario di una macchina per eseguire i calcoli in modo automatico
    \item Il progetto Hilbertiano (dal tedesco David Hilbert, un celeberrimo matematico dei primi anni del \('900\)) di \textit{meccanizzazione della matematica} che consentisse di ottenere tutti i teoremi a partire degli assiomi e dalle regole di inferenza note (ovvero le regole con le quali si passa da affermazioni vere ad altre affermazioni vere, come la dimostrazione per assurdo).
\end{itemize}
In questo anno si assiste alla costruzione del primo calcolatore da parte di \textit{Conrad Zuse}, un calcolatore meccanico rudimentale, ma straordinario dal punto di vista concettuale e la pubblicazione dei \(3\) articoli relativi al primo modello di computazione da parte di \textit{Alan Turing}.\\
\textit{Kurt Godel} ha dimostrato che la matematica ha dei limiti intrinseci, ovvero che tutto ciò che è vero non è dimostrabile, realizzando anche un secondo modello oltre a quello di \textit{Alan Turing}, avviando una rivoluzione matematica paragonabile a quella di Einstein per la fisica.\\
\textit{Alan Turing} pubblicò, nel \(1936\) tre articoli che erano una dissertazione meramente matematica e logica, e nulla aveva a che fare con il concetto di informatica, che al tempo nemmeno esisteva.\\
\textit{Charles Babbage} fu il primo a concepire il concetto di computer moderno, anche se nel primo \('800\) non riuscì a realizzare un calcolatore vero e proprio, in quanto la tecnologia del tempo non era sufficientemente sofisticata per gli scopi di Babbage.\\
Nel \(1643\) venne costruite la Pascalina che risuciva, attraverso processi meccanici, riusciva ad eseguire le somme e le sottrazioni.\\
Nel \(1674\) venne concepita una nuova macchina, le \textit{ruote di Leibniz}, che permetteva di eseguire moltiplicazioni e divisioni, con un hardware completamente diverso rispetto alla Pascalina.\\
Successivamente venne realizzata la \textit{macchina analitica}, che permetteva di riprogrammare la medesima macchina per eseguire più operazioni diverse, a differenza delle macchine cablate precedenti.\\
\textit{Ada Byron}, figlia di Lord Byron, fu la prima programmatrice della storia, in quanto fu la prima a comprendere le potenzialità dell'invenzione di \textit{Babbage}.\\
Verso la metà dell'\('800\) \textit{George Boole} concepì l'algebra booleana, senza impiegarla concretamente. Cento anni dopo \textit{Shannon} riuscì ad impiegare proficuamente l'algebra booleana per progettare e controllare le reti di interruttori nei circuiti elettronici.\\
Verso l'inizio del \('900\) erano già largamente diffuse delle macchine meccaniche capaci di eseguire dei calcoli, in uso nei grandi magazzini.\\
Nel \(1936\) venne realizzato il primo computer meccanico, la \textit{Z1}, realizzato da \textit{Zuse}, che poi venne distrutta nei bombardamenti, poi realizzando la \textit{Z2} e infine la \textit{Z3}.\\
Pertanto, si possono individuare tre livelli di astrazione del concetto di calcolatore
\begin{itemize}
    \item Più macchine per assolvere a diversi scopi
    \item Una stessa macchina, ma con più software
    \item Una stessa macchina e un solo software per riuscire a risolvere problemi diversi, secondo il calcolatore universale e gli \textit{interprete} di Alan Turing.
\end{itemize}
\textit{John von Neumann} concepì la moderna architettura dei calcolatori moderni, con una memoria e un'unità di calcolo che permette di processare programmi memorizzati in memoria.\\
Tutti i modelli che si sono susseguiti nella storia sono tutti in grado di processare le medesime funzioni di calcolo, per cui tutti sono fra di loro equivalenti, ma espressione di diversi meccanismi per sfruttare la potenza di calcolo degli elaboratori.\\
Inoltre, è fondamentale osservare che fino agli anni \('60\) i modelli di computazione proposti non si basavano sulla tecnologia dei calcolatori, ma erano modelli astratti: questo non sorprende, in quanto quando vennero concepiti i computer non esistevano ancora.\\
Alla base del processo computazionale vi è, però, il concetto di \textbf{algoritmo}, ovvero in elenco di istruzioni che devono essere attuate in modo diretto, non possono essere subruotine complesse.\\
Il numero di istruzioni che descrivono la procedura deve essere finito.\\
Il numero di passi per ottenere i risultati deve essere finito.

\newpage
\begin{center}
    24 Novembre 2021
\end{center}
\subsection{Riassunto}
Le varie generazioni di computer si sono susseguite su due binari, quello degli ingegneri, che volevano creare una macchina per elaborare i calcoli in maniera automatica, e dei matematici, i quali volevano meccanizzare la matematica, e con essa ottenere tutti i teoremi a partire dagli assiomi e le regole di inferenza.\\
Nel primo caso vennero realizzate delle prime macchine rudimentali, come la pascalina, per poi sfociare nella straordinaria invenzione della Z1.\\
Nel 1936 contemporaneamente si realizza il primo computer e vengono pubblicati i primi contributi teorici relativi alla struttura di un modello di computazione, ma solamente dal punto di vista astratto, come da parte di Turing.\\
Tuttavia, il problema che si ravvisò negli anni fu che i diversi modelli di computazione erano completamente distaccati e slegati dalle caratteristiche tecniche, architetturali e strutturali dei calcolatori veri e propri, proprio perché al tempo non esistevano.\\
Ciò che però si capì, è che tutti i modelli, per quanto indipendenti fra loro e logicamente distinti, puntano allo stesso insieme di funzioni computabili, ovvero l'insieme di problemi di risolubili.\\
Ciò, però, è relativamente limitante, in quanto le funzioni computabili sono molto poche, in quanto hanno un ordine naturale, per cui il rapporto tra le funzioni computabili e quelle che teoricamente si potrebbero concepire è pari al rapporto tra i numeri naturali e quelli reali.\\
Nel \(1936\) venne concepito il modello \textbf{RAM} (anche chiamato \textbf{Unlimited} ...) che permette di creare una connessione logica tra il linguaggio macchina e quello di alto livello: alla base del linguaggio RAM si pone la procedura effettiva, chiamata algoritmo, il quale deve presentare delle caratteristiche imprescindibile
\begin{enumerate}
    \item Ogni istruzione elementare si deve attuare in modo \quotes{diretto}
    \item Il \textbf{numero di istruzioni} che descrivono la procedura deve essere \textbf{finito}
    \item Il \textbf{numero di passi} per ottenere i risultati deve essere \textbf{finito}: l'algoritmo, infatti, deve produrre una risposta in un tempo finito, anche se è possibile che i programmi concreti possano incorrere in delle computazioni infinite: in questo si ha la distinzione tra \textbf{programma} e \textbf{algoritmo}.
\end{enumerate}

\vspace{1em}
\subsection{Nozione di algoritmo}
Un algoritmo presenta le seguenti caratteristiche
\begin{enumerate}
    \item Esso è composto da istruzioni \(I_1, ..., I_s\) di lunghezza finita
    \item Deve essere presente un \textbf{agente di calcolo} (ovvero una circuiteria a cui viene demandato il compito di eseguire i calcoli)
    \item Deve essere presente, e a disposizione della memoria.
    \item La circuiteria \(\mathcal{A}\) interagisce con \(\mathcal{P}\) in \textbf{modalità discreta} e non certamente in modalità analogica.
    \item La circuiteria \(\mathcal{A}\) interagisce con \(\mathcal{P}\) in \textbf{modalità deterministica}, ovvero la macchina si comporterà sempre allo stesso modo partendo dallo stesso stato iniziale e producendo il medesimo stato d'uscita.
\end{enumerate}
Inoltre è opportuno osservare che il calcolatore non presenta una limitazione sulla dimensione dei dati d'ingresso, così come non è necessario fissare la dimensione dell'insieme \(\mathcal{I} = \{I_1, I_2, ... I_k\}\) di istruzioni. Naturalmente non ha senso imporre una limitazione sulla dimensione della memoria (infatti nel modello RAM si richiede che la memoria sia infinita, ma questo è impossibile).\\
Ciò che è necessario limitare è la capacità di computazione di \(\mathcal{A}\), in quanto le istruzioni richiedono di eseguire delle operazioni elementari.\\
Non ha senso imporre un limite sulla lunghezza della computazione, ma ha senso affermare che la lunghezza della computazione sia finita. Tuttavia, nel modello computazionale, sono ammesse computazioni con un numero infinito di passi (computazioni non terminanti): sono i cosiddetti loop innescati dai bachi, ovvero i \textit{bug}, i quali non sono mai eliminabili completamente (in quanto le possibilità di incorrere in un \textit{bug} sono infinite, e vi sono dei teoremi che permettono di dimostrare che non è possibile costruire un programma di test che possa individuare tutti i \textit{bug}).\\
Si potrebbe dimostrare che se si imponesse un limite al numero di passi non si sarebbe in grado di costruire dei programmi in grado di esprimere nella sua interezza le capacità computazionali dei computer.\\
Pertanto, accettando la possibilità di avere delle \textbf{computazioni non terminanti} si riesce ad ottenere un programma reale. Dal punto di vista teorico si ha un algoritmo; aggiungendo a tale concetto la possibilità che ci possano essere delle computazioni non terminanti, ossia dei \textit{bug}, si ottengono dagli algoritmi i programmi.

\vspace{1em}
\subsection{Modello RAM}
Il modello RAM presenta un nastro di memoria, costituita da delle celle nelle quali è possibile inserire un qualsiasi numero reale, illimitato superiormente, ovverosia avente la potenzialità dell'infinito. Inoltre è presente, naturalmente, anche il programma \(\mathcal{P}\) che è costituita da una serie di istruzioni, le quali si possono riassumere in \(4\) tipologie, le prime \(3\) di natura aritmetica, l'ultima di natura logica (responsabile della capacità di computazione del calcolatore)
\begin{enumerate}
    \item \textbf{Azzeramento} \(Z(n)\), ovvero \(r_n := 0\);
    \item \textbf{Incremento} \(S(n)\), ovvero \(r_n := r_n + 1\);
    \item \textbf{Assegnazione} \(T(m, n)\), ovvero \(r_m = r_n\);
    \item \textbf{Salto condizionato} \(C(m, n, q)\), per cui se \(r_n = r_m\) si va all'istruzione \(I_q\).
\end{enumerate}

\vspace{1em}
\subsection{Computazione}
Per eseguire la computazione RAM bisogna fornire un \textit{nastro}, caricato con una \textit{configurazione iniziale} costituita da una sequenza \(a_1, a_2,a_3, ..., a_n\) di numeri reali; se \(\mathcal{P} = I_1, I_2, ..., I_s\) è il programma associato alla macchina, la computazione inizia eseguendo l'istruzione \(I_1\). Dopo averla eseguita, la macchina RAM dovrà eseguire la \textit{prossima istruzione} \(I_{\textit{NEXT}}\) finché si raggiunge uno STOP (se mai si raggiunge).

\vspace{1em}
\subsubsection{Prossima istruzione}
Naturalmente l'istruzione successiva \(I_{\textit{NEXT}}\) sarà quella numericamente successiva \(I_{\textit{NEXT}} = I_{k + 1}\) se l'istruzione precedente \(I_k\) è di tipo aritmetico, altrimenti sarà l'istruzione specificata dall'istruzione logica eseguita, ovvero \(I_q\), naturalmente se la condizione indicata viene soddisfatta.

\vspace{1em}
\subsubsection{STOP della computazione}
La computazione si ferma per due possibili motivi
\begin{itemize}
    \item È stata eseguita \(I_k = I_s\) aritmetica, oppure \(I_k = I_s = C(m, n, q)\), con \(r_m \neq r_n\), ovvero è stata eseguita l'ultima istruzione del programma.
    \item È stata eseguita \(I_k = C(m, n, q)\), con \(r_m = r_n\) e \(q > s\), ovvero è stata ottenuta la soluzione richiesta e si esegue una uscita anticipata dal programma e, quindi, si esegue un'istruzione successiva a quella finale, non presente nel programma.
\end{itemize}

\vspace{1em}
\subsubsection{Configurazione iniziale}
È la configurazione dalla quale si parte per effettuare la computazione. Se \(a_1, a_2, ..., a_n\) sono i dati di ingresso, per convenzione essi vengono posti all'inizio del nastro (nelle prime \(n\) celle), lasciando a \(0\) tutte le altre (infinite) celle di memoria.

\vspace{1em}
\subsubsection{Configurazione finale}
È la configurazione che si ottiene alla fine della computazione. Per convenzione il valore \(b\) calcolato dalla computazione è il contenuto della prima cella. Ciò accade ovviamente nel solo caso in cui la computazione termini.

\vspace{1em}
\subsubsection{Convergenza}
Indicando con la notazione \(\mathcal{P} (a_1, a_2, ..., a_n)\) la computazione del programma \(\mathcal{P}\) a partire dalla configurazione iniziale \(a_1, a_2, ..., a_n\), se tale computazione termina si afferma che c'è stata \textbf{convergenza}, e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \downarrow\). Se \(b\) è il contenuto della prima cella alla fine della computazione si dice che la computazione è andata a convergenza su \(b\) e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \downarrow b\). Se la computazione non termina si dice che si è avuta una \textbf{divergenza} e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \uparrow\).

\vspace{1em}
\subsubsection{Calcolo di una funzione tramite un programma}
Si afferma che il programma \(\mathcal{P}\) RAM-calcola (in quanto il modello adottato è il modello RAM, altrimenti si sarebbe detto Turing-calcola, Charles-calcola) la funzione \(f\) se, \(\forall a_1, a_2, ..., a_n, b\)
\[\mathcal{P}(a_1, a_2, ..., a_n) \downarrow b \hspace{1em} \leftrightarrow \hspace{1em}
    \left\{
        \rowcolors{1}{white}{white}
        \begin{array}{l}
             a_1, a_2, ..., a_n \in \text{Dom}(f)\\
             b = f(a_1, a_2, ..., a_n)
        \end{array}
    \right.
\]

\vspace{1em}
\subsubsection{Funzione calcolabile}
Una funzione \(f\) si dice \textbf{calcolabile} se esiste un programma \(\mathcal{P}\) che la RAM-calcola.

\vspace{1em}
\noindent
\textbf{Osservazione}: Pertanto, il numero delle funzioni calcolabili si traduce effettivamente nel numero di problemi risolubili, in quanto risolvere un problema si traduce nel trovare una funzione che se calcolata permette di ottenere la soluzione richiesta del problema.

\vspace{1em}
\subsubsection{Linguaggio delle funzioni}
Per esprimere il funzionamento e l'attività di un calcolatore si ricorre al linguaggio delle funzioni.

\vspace{1em}
\noindent
\textbf{Esempio}: Si scriva un programma che calcola la funzione \(f(x) = 0, \forall x\), impiegando le \(3\) funzioni aritmetiche note e l'unica funzione logica disponibile.\\
Si consideri, allora, un nastro un cui nella prima cella è presente il valore \(x\).

\newpage
\begin{center}
    26 Novembre 2021
\end{center}
\subsection{Riassunto}
Il percorso storico dei primi modelli di computazione si è diramato in due direzioni: da un lato per la meccanizzazione della matematica, dall'altro per la meccanizzazione dei calcoli in modo automatico.\\
Ciò portò alla realizzazione del primo calcolatore da parte di \textit{Conrad Zuse} nel \(1936\) e, sempre nello stesso anno, si diffusero ben \(4\) differenti modelli di computazione, formulati da parti di logici e matematici: essi si fondano su concetti e processi logici completamente diversi, ma è interessante osservare come tutti puntino al medesimo insieme di funzioni calcolabili, e quindi di problemi risolubili.\\
L'ultimo modello di computazione \(\textbf{modello RAM}\) venne introdotto in modo tale da ritagliare le modalità computazionali oggetto di interesse sulla struttura fisica e strutturale di un calcolatore. Ciò permette di capire la limitatezza del calcolo computazionale, il quale non può risolvere tutti i problemi pensabili: infatti, l'insieme delle funzioni computabili ha la cardinalità dei numeri naturali, quindi è \textbf{numerabile}, mentre l'insieme dei problemi da risolvere ha l'ordine dei numeri reali, quindi non è numerabile, e lo scarto è infinito.\\
Alla base del calcolo computazionale vi è la cosiddetta \textbf{procedura effettiva} o \textbf{algoritmo}, il quale deve presentare delle caratteristiche imprescindibili
\begin{itemize}
    \item Ogni istruzione deve essere direttamente attuabile
    \item Il numero delle istruzioni deve essere finito
    \item Il numero dei passi deve essere finito
\end{itemize}

\vspace{1em}
\noindent
Il modello RAM è un modello molto semplice, il quale prevede di disporre di una \textbf{memoria infinita} (per questo è un modello astratto, senza una controparte concreta); vi sono delle celle di memoria che contengono dei numeri naturali (di qualunque grandezza, per cui ogni cella può contenere un insieme di informazioni non limitabili superiormente) che vengono impiegate nella computazione, basata su quattro possibili istruzioni:
\begin{enumerate}
    \item \textit{Z(n)}: azzeramento della cella n-esima
    \item \textit{S(n)}: incremento della cella n-esima
    \item \textit{T(m, n)}: trasferimento del contenuto della cella n-esima nella cella m-esima
    \item \textit{C(m, n, q)}: salto condizionato, per cui se il contenuto della cella n-esima è uguale al contenuto della cella m-esima, si esegue l'istruzione q-esima.
\end{enumerate}
Per eseguire la computazione RAM bisogna fornire un \textit{nastro}, caricato con una \textit{configurazione iniziale} costituita da una sequenza \(a_1, a_2,a_3, ..., a_n\) di numeri reali; se \(\mathcal{P} = I_1, I_2, ..., I_s\) è il programma associato alla macchina, la computazione inizia eseguendo l'istruzione \(I_1\). Dopo averla eseguita, la macchina RAM dovrà eseguire la \textit{prossima istruzione} \(I_{\textit{NEXT}}\) finché si raggiunge uno STOP (se mai si raggiunge).\\
Naturalmente l'istruzione successiva \(I_{\textit{NEXT}}\) sarà quella numericamente successiva \(I_{\textit{NEXT}} = I_{k + 1}\) se l'istruzione precedente \(I_k\) è di tipo aritmetico, altrimenti sarà l'istruzione specificata dall'istruzione logica eseguita, ovvero \(I_q\), naturalmente se la condizione indicata viene soddisfatta.\\
La computazione si ferma per due possibili motivi
\begin{itemize}
    \item È stata eseguita \(I_k = I_s\) aritmetica, oppure \(I_k = I_s = C(m, n, q)\), con \(r_m \neq r_n\), ovvero è stata eseguita l'ultima istruzione del programma.
    \item È stata eseguita \(I_k = C(m, n, q)\), con \(r_m = r_n\) e \(q > s\), ovvero è stata ottenuta la soluzione richiesta e si esegue una uscita anticipata dal programma e, quindi, si esegue un'istruzione successiva a quella finale, non presente nel programma.
\end{itemize}
La configurazione iniziale è la configurazione dalla quale si parte per effettuare la computazione. Se \(a_1, a_2, ..., a_n\) sono i dati di ingresso, per convenzione essi vengono posti all'inizio del nastro (nelle prime \(n\) celle), lasciando a \(0\) tutte le altre (infinite) celle di memoria.\\
La configurazione finale è la configurazione che si ottiene alla fine della computazione. Per convenzione il valore \(b\) calcolato dalla computazione è il contenuto della prima cella. Ciò accade ovviamente nel solo caso in cui la computazione termini.\\
Indicando con la notazione \(\mathcal{P} (a_1, a_2, ..., a_n)\) la computazione del programma \(\mathcal{P}\) a partire dalla configurazione iniziale \(a_1, a_2, ..., a_n\), se tale computazione termina si afferma che c'è stata \textbf{convergenza}, e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \downarrow\). Se \(b\) è il contenuto della prima cella alla fine della computazione si dice che la computazione è andata a convergenza su \(b\) e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \downarrow b\). Se la computazione non termina si dice che si è avuta una \textbf{divergenza} e si scrive \(\mathcal{P}(a_1, a_2, ..., a_n) \uparrow\).\\
Si afferma che il programma \(\mathcal{P}\) RAM-calcola (in quanto il modello adottato è il modello RAM, altrimenti si sarebbe detto Turing-calcola, Charles-calcola) la funzione \(f\) se, \(\forall a_1, a_2, ..., a_n, b\)
\[\mathcal{P}(a_1, a_2, ..., a_n) \downarrow b \hspace{1em} \leftrightarrow \hspace{1em}
    \left\{
        \rowcolors{1}{white}{white}
        \begin{array}{l}
             a_1, a_2, ..., a_n \in \text{Dom}(f)\\
             b = f(a_1, a_2, ..., a_n)
        \end{array}
    \right.
\]
Una funzione \(f\) si dice \textbf{calcolabile} se esiste un programma \(\mathcal{P}\) che la RAM-calcola.\\
Una computazione potrebbe anche essere non terminante, come nel caso di una funzione con ciclo infinito: allora si dirà in quel caso che la n-upla \(a_1, a_2, ..., a_n\) non appartiene al dominio della funzione, ovvero la funzione non è definita per l'n-upla \(a_1, a_2, ..., a_n\).

\vspace{1em}
\noindent
\textbf{Osservazione}: Se all'interno di un programma vengono inserite delle istruzioni superflue che non alterano il funzionamento di un programma, si ottiene un programma strutturalmente e logicamente diverso, ma che produce il medesimo risultato, calcolando la stessa funzione.

\vspace{1em}
\noindent
\textbf{Esempio}: Per sommare fra di loro due numeri \(x\) e \(y\) senza saperne il valore, si dovrà controllare in prima analisi se il contenuto della seconda cella è uguale a quello della terza, ovvero \(y = 0\).\\
Se così non è si procede ad incrementare la prima e la terza cella e si esegue un salto incondizionato alla prima istruzione di controllo: se la seconda e la terza cella sono uguali allora si termina il programma, altrimenti si continua il ciclo:
\begin{enumerate}
    \item \(C(2, 3, 99)\)
    \item \(S(1)\)
    \item \(S(3)\)
    \item \(C(1, 1, 1)\)
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esercizio}: Per eseguire la sottrazione tra due numeri si proceda a capire come si esegue la cosiddetta \textbf{somma naturale}, ovvero
\[f(x) = x \overdotline 1 = \left\{
    \rowcolors{1}{white}{white}
    \begin{array}{ccc}
         x - 1 & \text{se} & x > 0\\
         0 & \text{se} & x = 0
    \end{array}
\right.\]
Per cui si procede come segue
\begin{enumerate}
    \item \(C(1, 4, 99)\)
    \item \(S(3)\)
    \item \(C(1, 3, 7)\)
    \item \(S(2)\)
    \item \(S(3)\)
    \item \(C(1, 1, 3)\)
    \item \(T(2. 1)\)
\end{enumerate}

\vspace{1em}
\noindent
\textbf{Esercizio}: Se si vuole eseguire la differenza tra due valori numerici sarà sufficiente eseguire il programma seguente
\begin{enumerate}
    \item \(C(1, 2,5)\)
    \item \(S(2)\)
    \item \(S(3)\)
    \item \(C(1, 1, 1)\)
    \item \(T(3, 1)\)
\end{enumerate}
Nel caso in cui \(x < y\) la differenza non può essere effettuata, allora si deve fare in modo che il programma cicli in maniera indefinita.

\vspace{1em}
\subsection{Programmazione imperativa}
Ogni istruzione corrisponde a un \quotes{comando} che viene impartito alla macchina, e che prevede l'esecuzione di un certo lavoro.\\
Si si fa riferimento al paradigma più usato di \textbf{programmazione imperativa}, denominato \textit{programmazione strutturata}, è possibile affermare che un programma è solitamente costruito nel seguente modo:
\begin{itemize}
    \item \textbf{una parte dichiarativa}, in cui si dichiarano tutte le variabili del programma e il loro tipo (come, ad esempio, variabile intera, variabile carattere, etc.)
    \item \textbf{una parte che descrive l'algoritmo} risolutiva utilizzato, basato sulle istruzioni del linguaggio che, a loro volto, si suddividono in
    \begin{itemize}
        \item istruzioni di lettura e scrittura (scrittura a video, scrittura su disco, lettura da tastiera, ...)
        \item istruzioni di assegnamento (del valore a una variabile)
        \item istruzioni logiche di controllo del programma
    \end{itemize}
\end{itemize}

\vspace{1em}
\noindent
\subsubsection{Istruzioni logiche di controllo}
Esistono essenzialmente tre tipi di strutture logiche di controllo del programma
\begin{enumerate}
    \item Sequenza
    \item Selezione
    \item Iterazione
\end{enumerate}

\vspace{1em}
\subsubsection{Selezione}
Per eseguire un \textbf{if} \(C\) \textbf{then} \(I_{\text{SI}}\) \textbf{else} \(I_{\text{NO}}\) è sufficiente eseguire due salti condizionati, come mostrato di seguito
\begin{enumerate}
    \item \(I_\text{\textit{prec}}\)
    \item \(C(m, n, 5)\)
    \item \(I_{\textit{NO}}\)
    \item \(C(1, 1, 6)\)
    \item \(I_{\textit{SI}}\)
    \item \(I_{\textit{succ}}\)
\end{enumerate}

\vspace{1em}
\subsubsection{Iterazione while - do}
Per eseguire un \textbf{while} \(C\) \textbf{do} \(I\) si procede come segue
\begin{enumerate}
    \item \(I_{\textit{prec}}\)
    \item \(C(m, n, 4)\)
    \item \(C(1, 1, 6)\)
    \item \(I\)
    \item \(C(1, 1, 2)\)
    \item \(I_{\textit{succ}}\)
\end{enumerate}

\vspace{1em}
\subsubsection{Iterazione repeat - unti}
Per eseguire un \textbf{repeat} \(I\) \textbf{until} \(C\) si procede come segue
\begin{enumerate}
    \item \(I_{\textit{prec}}\)
    \item \(I\)
    \item \(C(m, n, 5)\)
    \item \(C(1, 1, 2)\)
    \item \(I_{\textit{succ}}\)
\end{enumerate}

\subsection{Tesi di Church-Turing}
Tutto ciò che può essere fatto col calcolatore tradizionale può essere realizzato anche col \quotes{calcolatore} astratto del modello RAM (o qualunque altro modello di calcolo equivalente) e viceversa.\\
O meglio, si può fare di più con il modello RAM che con un modello concreto, in quanto si ha una quantità di memoria infinita nel primo, mentre è finita nel secondo.\\
Per questa ragione, si ha che il modello del calcolatore è \textbf{Turing-completo}, in quanto rispetta il modello computazionale di Turing.

\newpage
\section{Architettura dei calcolatori}
È nota la struttura fisica di un sommatore, in grado di eseguire somme e sottrazioni e capace anche di individuare l'overflow.\\
Dopodiché sono stati progettati i differenti \textit{flip-flop} che si pongono alla base dei registri normali, sequenziali e dei contatori.

\vspace{1em}
\subsection{Componenti essenziali di un calcolatore}
Le componenti essenziali di un calcolatore sono \(3\), così come stabilito da Von-Neuman:
\begin{enumerate}
    \item una \textit{memoria indirizzabile}, che possa contenere il programma e i dati
    \item un'\textit{unità logico-aritmetica}, che possa lavorare sui dati della memoria, ovvero l'agente di calcolo
    \item un \textit{program counter}, cioè un registro che indica l'indirizzo di memoria dell'istruzione che deve essere eseguita
\end{enumerate}

\vspace{1em}
\noindent
\subsection{Ciclo \textit{fetch-decode-execute}}
Le istruzione di un calcolatore vengono eseguite secondo un ciclo che prevede di eseguire tre istruzioni, secondo un ciclo nella forma \textbf{repeat} \(I\) \textbf{until} \(C\), ovvero
\begin{enumerate}
    \item \(PC \leftarrow 0\);
    \item \textbf{repeat}
    \begin{enumerate}
        \item istruzione \leftarrow memoria \([PC]\)
        \item decode(istruzione)
        \item fetch(operandi)
        \item execute
        \item \(PC \leftarrow PC + 1\)
    \end{enumerate}
    \item \textbf{until} istruzione  = STOP
\end{enumerate}

\newpage
\begin{center}
    30 Novembre 2021
\end{center}
\subsection{Riassunto}
L'architettura dei calcolatori è basata sull'infrastruttura logica fornita da Jhon Von Neumann. In particolare, all'interno del calcolatore dovrà essere inserito un programma che dovrà essere compilato dal calcolatore e tradotto in linguaggio macchia per poi essere eseguito.\\
Il funzionamento del computer si può riassumere con il ciclo \textit{fetch-decode-execute} di seguito presentato
\begin{enumerate}
    \item \(PC \leftarrow 0\);
    \item \textbf{repeat}
    \begin{enumerate}
        \item istruzione \leftarrow memoria \([PC]\)
        \item decode(istruzione)
        \item fetch(operandi)
        \item execute
        \item \(PC \leftarrow PC + 1\)
    \end{enumerate}
    \item \textbf{until} istruzione  = STOP
\end{enumerate}
Tale ciclo si arresta quando si raggiunge lo STOP della computazione. L'architettura dei calcolatori che consente di svolgere tali operazioni è così formata
\begin{enumerate}
    \item L'ALU, ovvero l'unità logico aritmetica in cui è presente il sommatore già studiato.
    \item I registri, che sono le unità di memoria più vicine all'ALU
    \item La memoria RAM, ovvero la memoria volatile sulla quale viene caricato il programma da eseguire.
    \item Il Program Counter, il quale è un registro di memoria che indica l'indirizzo della cella di memoria che contiene l'istruzione che deve essere eseguite.
    \item Il RI, ovvero il registro che contiene l'istruzione da eseguire.
    \item L'ACC, ovvero l'accumulatore dei risultati delle operazioni.
\end{enumerate}

\vspace{1em}
\subsection{Struttura di base del calcolatore}
Alla base dell'infrastruttura del calcolatore si pongono i seguenti quattro elementi
\begin{itemize}
    \item Processore
    \item Memoria primaria o principale (RAM)
    \item Memoria secondaria o di massa (HDD)
    \item Periferiche di I/O
\end{itemize}

\vspace{1em}
\subsubsection{Processore}
All'interno della CPU sono presenti due componenti fondamentali UC (Unità di Controllo) e ALU (Arithmetic Logic Unit), alla quale viene associato un Processore Matematico, impiegato per svolgere le operazioni a virgola mobile. Inoltre sono presenti i seguenti registri
\begin{itemize}
    \item PC - Program Counter
    \item RS - Registro di Stato (per gestire, per esempio, gli overflow)
    \item RI - Registro delle Istruzioni
    \item Registri Generali
    \item Registri di gestione RAM, per la gestione della lettura/scrittura
    \begin{itemize}
        \item RIM - Registro Indirizzi di Memoria
        \item RDM - Registro Dati di Memoria
        \item RC - Registro di Controllo
    \end{itemize}
\end{itemize}

\vspace{1em}
\noindent
\textbf{Osservazione}: Se il registro RIM è a \(32\) bit, significa che possono essere indirizzati fino a \(2^32 = 4GB\) celle di memoria. Il RC, ovvero il registro di controllo della memoria RAM indica se deve essere eseguita un'operazione di lettura, oppure di scrittura. all'interno del registro dati di memoria (RDM) viene inserito il dato che deve essere letto o scritto da/nell'indirizzo di memoria specificato nel RIM.\\
Si capisce, però, che il punto in cui devono essere eseguite le operazioni (ALU) è fisicamente distante dal punto in cui si acquisiscono, o inseriscono le informazioni (ovvero la RAM): ciò comporta un rallentamento e una limitazione della capacità di calcolo, per non parlare del bassissimo efficientamento energetico che contraddistingue tale sistema.

\vspace{1em}
\subsection{Istruzioni in linguaggio ASSEMBLY}
Le istruzioni di basso livello in linguaggio ASSEMBLY sono di quattro tipi
\begin{itemize}
    \item Istruzioni di I/O
    \begin{itemize}
        \item \textbf{READ INP 1322}: Legge da tastiera e mette il dato nella cella 1322 della memoria RAM
        \item \textbf{WRITE OUT 1902}: Scrive a video il contenuto della cella 1902 della memoria RAM
    \end{itemize}
    \item Istruzioni logico/aritmetiche
    \begin{itemize}
        \item \textbf{ADD R1 R2}
        \item \textbf{MUL R1 R2}
    \end{itemize}
    \item Istruzioni di accesso alla memoria
    \begin{itemize}
        \item \textbf{LOAD 1672 R2}
        \item \textbf{STORE R1 1559}
    \end{itemize}
    \item Istruzioni di salto
    \begin{itemize}
        \item \textbf{BRLT}
        \item \textbf{JUMP}
    \end{itemize}
\end{itemize}

\vspace{1em}
\noindent
\textbf{Osservazione}: Le operazioni che devono essere eseguite per effettuare un'operazione:
\begin{enumerate}
    \item L'indirizzo di memoria specificato nel PC deve essere copiato nel registro RIM
    \item Nel registro RC viene specificata l'operazione da eseguire: lettura
    \item Una volta letto il contenuto della cella di memoria specificata, l'istruzione viene inserita all'interno del RDM
    \item Il contenuto del registro RDM viene trasferito nel registro RI in modo tale che possa essere eseguito dal processore
    \item Nel caso di una lettura, bisogna ripetere le operazioni di lettura dalla memoria RAM e inserire il contenuto letto nel primo registro disponibile
    \item Una volta eseguita l'operazione viene incrementato il PC
    \item Si ripetono le operazioni precedenti con iterazioni
\end{enumerate}
Tali istruzioni possono essere riassunte in 5 macroistruzioni
\begin{enumerate}
    \item IF - Instruction Fetch
    \item ID - Instruction Decode
    \item EX - Execture
    \item MEM - Memorization
    \item WB - Write BACK
\end{enumerate}
Ad oggi queste operazioni non vengono più eseguire in serie, ma in parallelo (\textit{pipeline}), con il significativo vantaggio che ad ogni ciclo di clock viene eseguita una operazioni.\\
Le istruzioni che vengono specificate in linguaggio ASSEMBLY sono, per quanto di basso livello, comunque orientate all'utente e, per poter essere eseguite dalla macchina devono essere tradotte in linguaggio macchina. Il processo di traduzione avviene in due passaggi
\begin{enumerate}
    \item Dopo aver scritto il programma in linguaggio ad alto livello, questo viene \textbf{compilato} in linguaggio ASSEMBLY
    \item Il programma scritto in \textbf{ASSEMBLY} viene assemblato dall'\textbf{assemblatore}, il quale converte tale programma in linguaggio macchina (ISA), ovvero come sequenza di \(0\) e \(1\).
\end{enumerate}
In realtà, però, sono presenti più di due livelli di traduzione dei programmi, come riportato di seguito
\begin{itemize}
    \item Livello -1 - Elettronico, a livello circuitale: transistor, mosfet
    \item Livello 0 - Logico, di prte logiche
    \item Livello 1 - Microarchitettura, come ALU e registri
    \item Livello 2 - ISA (\textit{Instruction Set Architecture})
    \item Livello 3 - Sistema Operativo
    \item Livello 4 - Assemblatore
    \item Livello 5 - Linguaggi applicativi
\end{itemize}
In questo modo la progettazione del livello i-esimo deve valutare solamente cosa c'è al livello \(i - 1\) e \(i + 1\).

\vspace{1em}
\subsection{Gerarchia di memoria}
A mano a mano che ci si allontana dalla unità logico aritmetica si incontrano memorie più capienti, meno costose, e più lente, come HD e SSD, mentre risalendo la gerarchia si incontrano la RAM, la memoria CACHE e e i registri.

\vspace{1em}
\subsubsection{Registri CPU}
I registri della CPU sono contraddistinti da
\begin{itemize}
    \item Altissima velocità di accesso
    \item Bassissima capacità
    \item Altissima velocità di trasferimento dati
    \item Integrati nell'infrastruttura
\end{itemize}

\vspace{1em}
\subsubsection{RAM}
Le memorie RAM (Random Access Memory), pur sempre volatili, sono di due tipi
\begin{itemize}
    \item DRAM, poco costosa, poco efficiente e lenta
    \item SRAM, costosa, efficiente e molto veloce
\end{itemize}
Le RAM hanno un accesso a tempo costante, sono relativamente veloci e poco capienti, se comparate alle memorie secondarie.

\vspace{1em}
\subsubsection{Memoria Cache}
La memoria Cache è in stretto contatto con il processore (è realizzata nel chip) e permette di evitare l'accesso alla RAM. Il tempo di accesso è molto ridotto, è basata sulla tecnologia SRAM e ha una dimensione assai inferiore alla RAM.\\
Anche all'interno dei moderni processori le memorie cache vengono gerarchizzate, in modo tale da ridurre il più possibile il ritardo di lettura/scrittura e gestire le interazioni fra i diversi core.

\vspace{1em}
\subsubsection{Memoria secondaria}
Le memorie secondarie sono due tipologie
\begin{itemize}
    \item Hard Disk
    \begin{itemize}
        \item con alta capacità di memorizzazione
        \item a basso costo
        \item ad alto tempo di accesso
        \item con memoria permanente (non volatile)
        \item basata sulla tecnologia elettromeccanica (sul disco di policarbonato viene letto e scritto grazie ad una testina meccanica): per questo la tecnologia è molto arretrata, a causa dell'inerzia tra i dispositivi meccanici e a causa della presenza dei motori ad alto consumo.
        \item è possibile anche creare dei banchi di HD in modo tale da aumentare la capacità
    \end{itemize}

    \item Solid State Disk (SSD), ovvero la prima memoria elettronica \textbf{non volatile}, che permette di memorizzare le informazioni imprigionando gli elettroni in una zona di potenziale dalla quale è difficile scappare. Gli SSD
    \begin{itemize}
        \item hanno alta capacità di memorizzazione
        \item hanno alto costo, seppur in diminuzione, ma di sicuro maggiore agli HD
        \item hanno elevata velocità di lettura e basso tempo di risposta e di accesso
    \end{itemize}
\end{itemize}
Naturalmente, a queste memorie di massa interne, si possono sommare delle memorie di massa esterne che, pur essendo molto capienti, hanno tempi di accesso, lettura e scrittura molto elevati.

\end{document}
